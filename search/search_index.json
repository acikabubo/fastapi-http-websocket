{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"FastAPI HTTP/WebSocket Template","text":"<p>A production-ready FastAPI template with comprehensive HTTP and WebSocket support, including authentication, RBAC, rate limiting, audit logging, and monitoring.</p> <ul> <li> <p> Quick Start</p> <p>Get up and running in 5 minutes</p> <p> Getting Started</p> </li> <li> <p> Production Ready</p> <p>Deploy to production with confidence</p> <p> Deployment Guide</p> </li> <li> <p> Secure by Default</p> <p>Built-in authentication, RBAC, and rate limiting</p> <p> Security Guide</p> </li> <li> <p> Observable</p> <p>Prometheus metrics, Grafana dashboards, and structured logging</p> <p> Monitoring Guide</p> </li> </ul>"},{"location":"#features","title":"Features","text":""},{"location":"#dual-protocol-support","title":"Dual Protocol Support","text":"<ul> <li>\u2705 HTTP REST API - FastAPI-powered REST endpoints with OpenAPI documentation</li> <li>\u2705 WebSocket Handlers - Package-based WebSocket routing with JSON message format</li> <li>\u2705 Unified Business Logic - Share code between protocols using Repository + Command pattern</li> </ul>"},{"location":"#authentication-authorization","title":"Authentication &amp; Authorization","text":"<ul> <li>\u2705 Keycloak Integration - Enterprise-grade authentication with JWT tokens</li> <li>\u2705 RBAC System - Decorator-based role access control co-located with handlers</li> <li>\u2705 Token Validation - Automatic token verification and user extraction</li> <li>\u2705 Session Management - Redis-backed session tracking</li> </ul>"},{"location":"#rate-limiting-security","title":"Rate Limiting &amp; Security","text":"<ul> <li>\u2705 HTTP Rate Limiting - Sliding window algorithm per user/IP</li> <li>\u2705 WebSocket Rate Limiting - Connection and message rate limits</li> <li>\u2705 Redis-Backed - Distributed rate limiting across instances</li> <li>\u2705 Configurable Limits - Per-endpoint and per-user limits</li> </ul>"},{"location":"#database-persistence","title":"Database &amp; Persistence","text":"<ul> <li>\u2705 PostgreSQL - Async SQLModel/SQLAlchemy integration</li> <li>\u2705 Database Migrations - Alembic for schema versioning</li> <li>\u2705 Connection Pooling - Optimized connection management</li> <li>\u2705 Repository Pattern - Testable data access layer</li> </ul>"},{"location":"#monitoring-observability","title":"Monitoring &amp; Observability","text":"<ul> <li>\u2705 Prometheus Metrics - HTTP/WebSocket request metrics, database queries, rate limits</li> <li>\u2705 Grafana Dashboards - Pre-built dashboards for FastAPI, Keycloak, and logs</li> <li>\u2705 Structured Logging - JSON logs with correlation IDs</li> <li>\u2705 Loki Integration - Centralized log aggregation</li> </ul>"},{"location":"#audit-compliance","title":"Audit &amp; Compliance","text":"<ul> <li>\u2705 User Action Logging - Track all user actions with context</li> <li>\u2705 Async Queue Processing - Non-blocking audit log writes</li> <li>\u2705 Searchable Logs - Query audit trail with filters</li> <li>\u2705 Retention Policies - Configurable log retention</li> </ul>"},{"location":"#developer-experience","title":"Developer Experience","text":"<ul> <li>\u2705 Type Safety - Full mypy --strict compliance</li> <li>\u2705 Code Quality - Pre-commit hooks with ruff, mypy, interrogate</li> <li>\u2705 Testing - Pytest with async support, 66% coverage</li> <li>\u2705 Docker Support - Full development environment via docker-compose</li> <li>\u2705 Hot Reload - Uvicorn auto-reload during development</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>graph TB\n    Client[Client] --&gt;|HTTP/WS| Traefik[Traefik Reverse Proxy]\n    Traefik --&gt;|:8000| App[FastAPI Application]\n\n    App --&gt;|Auth| KC[Keycloak]\n    App --&gt;|Data| PG[(PostgreSQL)]\n    App --&gt;|Cache/Rate Limit| Redis[(Redis)]\n\n    App --&gt;|Metrics| Prom[Prometheus]\n    Prom --&gt;|Dashboard| Grafana[Grafana]\n    App --&gt;|Logs| Loki[Loki]\n    Loki --&gt;|Query| Grafana\n\n    style App fill:#4051b5,stroke:#333,stroke-width:2px,color:#fff\n    style Traefik fill:#37abc8,stroke:#333,stroke-width:2px,color:#fff</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":""},{"location":"#http-endpoint","title":"HTTP Endpoint","text":"<pre><code>from fastapi import APIRouter, Depends\nfrom app.dependencies import AuthorRepoDep\nfrom app.commands.author_commands import CreateAuthorCommand\nfrom app.schemas.author import CreateAuthorInput\n\nrouter = APIRouter()\n\n@router.post(\"/authors\")\nasync def create_author(\n    data: CreateAuthorInput,\n    repo: AuthorRepoDep\n) -&gt; Author:\n    \"\"\"Create a new author.\"\"\"\n    command = CreateAuthorCommand(repo)\n    return await command.execute(data)\n</code></pre>"},{"location":"#websocket-handler","title":"WebSocket Handler","text":"<pre><code>from app.routing import pkg_router\nfrom app.api.ws.constants import PkgID\nfrom app.schemas.models import RequestModel, ResponseModel\n\n@pkg_router.register(PkgID.GET_AUTHORS)\nasync def get_authors(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Get list of authors via WebSocket.\"\"\"\n    async with async_session() as session:\n        repo = AuthorRepository(session)\n        authors = await repo.get_all()\n\n        return ResponseModel.success(\n            request.pkg_id,\n            request.req_id,\n            data=[a.model_dump() for a in authors]\n        )\n</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":"<p>This template is ideal for applications requiring:</p> <ul> <li>Real-time Communication - Chat apps, live dashboards, collaborative tools</li> <li>IoT/Device Management - Device telemetry, command &amp; control</li> <li>Trading/Financial - Order management, market data streaming</li> <li>Gaming - Multiplayer game servers, lobby systems</li> <li>Monitoring - Real-time alerts, log streaming</li> </ul>"},{"location":"#technology-stack","title":"Technology Stack","text":"Component Technology Purpose Web Framework FastAPI 0.121+ High-performance async API framework ASGI Server Uvicorn Production ASGI server Database PostgreSQL 13+ Primary data store ORM SQLModel Type-safe database models Cache/Queue Redis 7+ Rate limiting, sessions, caching Authentication Keycloak Enterprise SSO and identity management Reverse Proxy Traefik v3 Load balancing, SSL termination Metrics Prometheus Time-series metrics collection Dashboards Grafana Visualization and alerting Logging Loki + Grafana Alloy Log aggregation and querying Container Docker + Compose Development and deployment"},{"location":"#project-status","title":"Project Status","text":"<ul> <li>\u2705 Production Ready - Battle-tested patterns and best practices</li> <li>\u2705 Type Safe - Full mypy compliance with strict mode</li> <li>\u2705 Well Tested - 66% coverage (target: 80%+)</li> <li>\u2705 Documented - Comprehensive guides and API reference</li> <li>\u2705 Observable - Full monitoring and logging stack</li> <li>\u2705 Secure - Authentication, RBAC, rate limiting, audit logs</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li> <p>New to the project?</p> <p>Start with the Installation Guide to set up your development environment.</p> </li> <li> <p>Ready to build?</p> <p>Follow the Quick Start to create your first endpoints.</p> </li> <li> <p>Deploying to production?</p> <p>Check out the Production Deployment Guide.</p> </li> <li> <p>Want to contribute?</p> <p>Read the Contributing Guide to get started.</p> </li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#support","title":"Support","text":"<ul> <li>\ud83d\udcd6 Documentation</li> <li>\ud83d\udc1b Issue Tracker</li> <li>\ud83d\udcac Discussions</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete reference documentation for HTTP and WebSocket APIs.</p>"},{"location":"api-reference/#api-documentation","title":"API Documentation","text":"<ul> <li>HTTP API - REST endpoint reference</li> <li>WebSocket API - WebSocket handler reference</li> <li>Response Models - Response format specifications</li> <li>Exceptions - Error handling and status codes</li> </ul>"},{"location":"api-reference/#interactive-documentation","title":"Interactive Documentation","text":"<p>When running locally, visit:</p> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> <li>OpenAPI JSON: http://localhost:8000/openapi.json</li> </ul>"},{"location":"api-reference/exceptions/","title":"Exception Handling","text":""},{"location":"api-reference/exceptions/#overview","title":"Overview","text":"<p>This document describes the exception handling patterns used in the application.</p>"},{"location":"api-reference/exceptions/#http-exceptions","title":"HTTP Exceptions","text":""},{"location":"api-reference/exceptions/#fastapi-httpexception","title":"FastAPI HTTPException","text":"<p>Used for HTTP endpoints:</p> <pre><code>from fastapi import HTTPException\n\nraise HTTPException(status_code=404, detail=\"Author not found\")\n</code></pre>"},{"location":"api-reference/exceptions/#common-http-exceptions","title":"Common HTTP Exceptions","text":"<p>401 Unauthorized: <pre><code>raise HTTPException(status_code=401, detail=\"Not authenticated\")\n</code></pre></p> <p>403 Forbidden: <pre><code>raise HTTPException(status_code=403, detail=\"Forbidden\")\n</code></pre></p> <p>404 Not Found: <pre><code>raise HTTPException(status_code=404, detail=\"Resource not found\")\n</code></pre></p> <p>422 Validation Error:</p> <p>Automatically raised by Pydantic for invalid data.</p> <p>500 Internal Server Error:</p> <p>Unhandled exceptions are caught and returned as 500 errors.</p>"},{"location":"api-reference/exceptions/#websocket-exceptions","title":"WebSocket Exceptions","text":""},{"location":"api-reference/exceptions/#error-response-pattern","title":"Error Response Pattern","text":"<p>WebSocket handlers return error responses instead of raising exceptions:</p> <pre><code>try:\n    # Handler logic\n    return ResponseModel.success(...)\nexcept ValueError as e:\n    return ResponseModel.err_msg(\n        pkg_id=request.pkg_id,\n        req_id=request.req_id,\n        msg=str(e),\n        status_code=RSPCode.INVALID_DATA\n    )\nexcept Exception as e:\n    logger.error(f\"Handler error: {e}\", exc_info=True)\n    return ResponseModel.err_msg(\n        pkg_id=request.pkg_id,\n        req_id=request.req_id,\n        msg=\"Internal error\",\n        status_code=RSPCode.ERROR\n    )\n</code></pre>"},{"location":"api-reference/exceptions/#connection-exceptions","title":"Connection Exceptions","text":"<p>WebSocketDisconnect:</p> <p>Raised when client disconnects:</p> <pre><code>from starlette.websockets import WebSocketDisconnect\n\ntry:\n    data = await websocket.receive_text()\nexcept WebSocketDisconnect:\n    # Clean up connection\n    await on_disconnect(websocket, 1000)\n</code></pre>"},{"location":"api-reference/exceptions/#custom-exceptions","title":"Custom Exceptions","text":""},{"location":"api-reference/exceptions/#database-exceptions","title":"Database Exceptions","text":"<pre><code>from sqlalchemy.exc import IntegrityError\n\ntry:\n    await session.commit()\nexcept IntegrityError as e:\n    await session.rollback()\n    logger.error(f\"Database constraint violation: {e}\")\n    raise HTTPException(status_code=400, detail=\"Duplicate entry\")\n</code></pre>"},{"location":"api-reference/exceptions/#validation-exceptions","title":"Validation Exceptions","text":"<pre><code>from pydantic import ValidationError\n\ntry:\n    data = InputModel(**request.data)\nexcept ValidationError as e:\n    return ResponseModel.err_msg(\n        pkg_id=request.pkg_id,\n        req_id=request.req_id,\n        msg=str(e),\n        status_code=RSPCode.INVALID_DATA\n    )\n</code></pre>"},{"location":"api-reference/exceptions/#error-logging","title":"Error Logging","text":"<p>All exceptions are logged with full context:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\ntry:\n    # Operation\n    pass\nexcept Exception as e:\n    logger.error(\n        f\"Operation failed: {e}\",\n        exc_info=True,\n        extra={\"user_id\": user.sub, \"pkg_id\": request.pkg_id}\n    )\n</code></pre>"},{"location":"api-reference/exceptions/#best-practices","title":"Best Practices","text":"<ol> <li>Use specific exceptions - Catch specific exception types</li> <li>Log with context - Include user_id, request_id, etc.</li> <li>Return user-friendly messages - Don't expose internal details</li> <li>Clean up resources - Use try-finally or context managers</li> <li>Handle async exceptions - Use proper async exception handling</li> </ol>"},{"location":"api-reference/exceptions/#related","title":"Related","text":"<ul> <li>HTTP API Error Handling</li> <li>WebSocket API Error Handling</li> </ul>"},{"location":"api-reference/http-api/","title":"HTTP API Documentation","text":""},{"location":"api-reference/http-api/#overview","title":"Overview","text":"<p>This FastAPI application provides RESTful HTTP endpoints with OpenAPI/Swagger documentation. All endpoints support JSON request/response format and include automatic validation via Pydantic models.</p>"},{"location":"api-reference/http-api/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000\nhttps://localhost:8000 (production with TLS)\n</code></pre>"},{"location":"api-reference/http-api/#authentication","title":"Authentication","text":"<p>Most endpoints require authentication via Keycloak access token passed in the Authorization header:</p> <pre><code>Authorization: Bearer &lt;access_token&gt;\n</code></pre>"},{"location":"api-reference/http-api/#obtaining-access-token","title":"Obtaining Access Token","text":"<p>Endpoint: <code>POST /login</code></p> <p>Request: <pre><code>curl -X POST http://localhost:8000/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"username\": \"your_username\",\n    \"password\": \"your_password\"\n  }'\n</code></pre></p> <p>Response: <pre><code>{\n  \"access_token\": \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"expires_in\": 300,\n  \"refresh_expires_in\": 1800,\n  \"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"token_type\": \"Bearer\",\n  \"scope\": \"profile email\"\n}\n</code></pre></p> <p>Token Expiration: - Access tokens: 300 seconds (5 minutes) - Refresh tokens: 1800 seconds (30 minutes)</p>"},{"location":"api-reference/http-api/#rate-limiting","title":"Rate Limiting","text":"<p>HTTP endpoints are rate-limited to prevent abuse:</p> <p>Default Limits: - 60 requests per minute per user/IP - Burst allowance: 10 additional requests</p> <p>Rate Limit Headers:</p> <p>All responses include rate limit information:</p> <pre><code>X-RateLimit-Limit: 60\nX-RateLimit-Remaining: 45\nX-RateLimit-Reset: 1705320000\n</code></pre> <p>Rate Limit Exceeded Response:</p> <p>Status Code: <code>429 Too Many Requests</code></p> <pre><code>{\n  \"detail\": \"Rate limit exceeded. Try again in 30 seconds.\"\n}\n</code></pre>"},{"location":"api-reference/http-api/#endpoints","title":"Endpoints","text":""},{"location":"api-reference/http-api/#health-check","title":"Health Check","text":""},{"location":"api-reference/http-api/#get-health","title":"GET /health","text":"<p>Check the health status of the application and its dependencies.</p> <p>Authentication: Not required</p> <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"status\": \"healthy\",\n  \"database\": \"healthy\",\n  \"redis\": \"healthy\"\n}\n</code></pre> <p>Unhealthy Response: <code>503 Service Unavailable</code></p> <pre><code>{\n  \"status\": \"unhealthy\",\n  \"database\": \"unhealthy\",\n  \"redis\": \"healthy\"\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/health\n</code></pre>"},{"location":"api-reference/http-api/#authors-endpoints","title":"Authors Endpoints","text":""},{"location":"api-reference/http-api/#post-authors","title":"POST /authors","text":"<p>Create a new author.</p> <p>Authentication: Required (Role: <code>user</code>)</p> <p>Request Body:</p> <pre><code>{\n  \"name\": \"John Doe\"\n}\n</code></pre> <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"id\": 1,\n  \"name\": \"John Doe\"\n}\n</code></pre> <p>Error Responses:</p> Status Code Reason Response 401 Unauthorized <code>{\"detail\": \"Not authenticated\"}</code> 403 Permission denied <code>{\"detail\": \"Forbidden\"}</code> 422 Validation error <code>{\"detail\": [...validation errors...]}</code> 500 Database error <code>{\"detail\": \"Internal server error\"}</code> <p>Example:</p> <pre><code>curl -X POST http://localhost:8000/authors \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"John Doe\"}'\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\nresponse = requests.post(\n    'http://localhost:8000/authors',\n    headers={'Authorization': f'Bearer {token}'},\n    json={'name': 'John Doe'}\n)\n\nif response.status_code == 200:\n    author = response.json()\n    print(f\"Created author with ID: {author['id']}\")\n</code></pre>"},{"location":"api-reference/http-api/#get-authors","title":"GET /authors","text":"<p>Retrieve a list of authors with optional filtering.</p> <p>Authentication: Required (Role: <code>user</code>)</p> <p>Query Parameters:</p> Parameter Type Required Description <code>id</code> integer No Filter by author ID <code>name</code> string No Filter by author name (case-insensitive, partial match) <p>Response: <code>200 OK</code></p> <pre><code>[\n  {\n    \"id\": 1,\n    \"name\": \"John Doe\"\n  },\n  {\n    \"id\": 2,\n    \"name\": \"Jane Smith\"\n  }\n]\n</code></pre> <p>Empty Result:</p> <pre><code>[]\n</code></pre> <p>Example:</p> <pre><code># Get all authors\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  http://localhost:8000/authors\n\n# Filter by name\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/authors?name=John\"\n\n# Filter by ID\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/authors?id=1\"\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\nresponse = requests.get(\n    'http://localhost:8000/authors',\n    headers={'Authorization': f'Bearer {token}'},\n    params={'name': 'John'}\n)\n\nauthors = response.json()\nfor author in authors:\n    print(f\"{author['id']}: {author['name']}\")\n</code></pre>"},{"location":"api-reference/http-api/#get-authors_paginated","title":"GET /authors_paginated","text":"<p>Retrieve a paginated list of authors with optional filtering.</p> <p>Authentication: Required (Role: <code>user</code>)</p> <p>Query Parameters:</p> Parameter Type Required Default Description <code>page</code> integer No 1 Page number (&gt;=1) <code>per_page</code> integer No 20 Items per page (&gt;=1) <code>id</code> integer No - Filter by author ID <code>name</code> string No - Filter by author name <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": 1,\n      \"name\": \"John Doe\"\n    },\n    {\n      \"id\": 2,\n      \"name\": \"Jane Smith\"\n    }\n  ],\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 42,\n    \"pages\": 3\n  }\n}\n</code></pre> <p>Metadata Fields:</p> Field Description <code>page</code> Current page number <code>per_page</code> Number of items per page <code>total</code> Total number of items matching filters <code>pages</code> Total number of pages <p>Example:</p> <pre><code># Get first page (default 20 items)\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  http://localhost:8000/authors_paginated\n\n# Get specific page with custom page size\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/authors_paginated?page=2&amp;per_page=10\"\n\n# Paginate with filters\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/authors_paginated?page=1&amp;per_page=10&amp;name=Smith\"\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\ndef get_all_authors(token):\n    \"\"\"Fetch all authors using pagination.\"\"\"\n    all_authors = []\n    page = 1\n\n    while True:\n        response = requests.get(\n            'http://localhost:8000/authors_paginated',\n            headers={'Authorization': f'Bearer {token}'},\n            params={'page': page, 'per_page': 100}\n        )\n\n        data = response.json()\n        all_authors.extend(data['items'])\n\n        if page &gt;= data['meta']['pages']:\n            break\n\n        page += 1\n\n    return all_authors\n</code></pre>"},{"location":"api-reference/http-api/#metrics-endpoint","title":"Metrics Endpoint","text":""},{"location":"api-reference/http-api/#get-metrics","title":"GET /metrics","text":"<p>Retrieve Prometheus metrics for monitoring.</p> <p>Authentication: Not required</p> <p>Content-Type: <code>text/plain; version=0.0.4</code></p> <p>Response: <code>200 OK</code></p> <pre><code># HELP http_requests_total Total number of HTTP requests\n# TYPE http_requests_total counter\nhttp_requests_total{method=\"GET\",endpoint=\"/authors\",status_code=\"200\"} 1234.0\n\n# HELP http_request_duration_seconds HTTP request duration in seconds\n# TYPE http_request_duration_seconds histogram\nhttp_request_duration_seconds_bucket{method=\"GET\",endpoint=\"/authors\",le=\"0.005\"} 100.0\n\n# HELP ws_connections_active Active WebSocket connections\n# TYPE ws_connections_active gauge\nws_connections_active 5.0\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/metrics\n</code></pre>"},{"location":"api-reference/http-api/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/http-api/#standard-error-response-format","title":"Standard Error Response Format","text":"<p>All error responses follow this structure:</p> <pre><code>{\n  \"detail\": \"Error message describing what went wrong\"\n}\n</code></pre>"},{"location":"api-reference/http-api/#http-status-codes","title":"HTTP Status Codes","text":"Code Name Description 200 OK Request successful 401 Unauthorized Missing or invalid authentication token 403 Forbidden User lacks required permissions 404 Not Found Resource not found 422 Unprocessable Entity Validation error in request data 429 Too Many Requests Rate limit exceeded 500 Internal Server Error Server-side error occurred 503 Service Unavailable Service or dependency unhealthy"},{"location":"api-reference/http-api/#validation-errors-422","title":"Validation Errors (422)","text":"<p>Pydantic validation errors include detailed field-level information:</p> <pre><code>{\n  \"detail\": [\n    {\n      \"type\": \"string_type\",\n      \"loc\": [\"body\", \"name\"],\n      \"msg\": \"Input should be a valid string\",\n      \"input\": 123\n    }\n  ]\n}\n</code></pre> <p>Fields: - <code>type</code>: Type of validation error - <code>loc</code>: Location of error (path to field) - <code>msg</code>: Human-readable error message - <code>input</code>: The invalid input value</p>"},{"location":"api-reference/http-api/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<p>Endpoints are protected by role-based access control defined in handler decorators using the <code>require_roles()</code> dependency.</p> <p>Implementation: <pre><code>from app.dependencies.permissions import require_roles\n\n@router.get(\"/authors\", dependencies=[Depends(require_roles(\"get-authors\"))])\nasync def get_authors():\n    ...\n</code></pre></p> <p>Common Roles:</p> Role Description Example Usage <code>get-authors</code> View author list GET /api/authors <code>create-author</code> Create new authors POST /api/authors <code>admin</code> Administrative privileges DELETE operations, admin endpoints <p>Permission Denied Response: <code>403 Forbidden</code></p> <pre><code>{\n  \"detail\": \"Forbidden\"\n}\n</code></pre>"},{"location":"api-reference/http-api/#openapiswagger-documentation","title":"OpenAPI/Swagger Documentation","text":"<p>Interactive API documentation is available at:</p> <p>Swagger UI: http://localhost:8000/docs</p> <p>ReDoc: http://localhost:8000/redoc</p> <p>OpenAPI JSON: http://localhost:8000/openapi.json</p> <p>These provide: - Interactive request testing - Request/response schema documentation - Example values - Authentication configuration</p>"},{"location":"api-reference/http-api/#best-practices","title":"Best Practices","text":""},{"location":"api-reference/http-api/#1-token-management","title":"1. Token Management","text":"<pre><code>import requests\nfrom datetime import datetime, timedelta\n\nclass APIClient:\n    def __init__(self, base_url):\n        self.base_url = base_url\n        self.token = None\n        self.token_expiry = None\n\n    def login(self, username, password):\n        response = requests.post(\n            f'{self.base_url}/login',\n            json={'username': username, 'password': password}\n        )\n        data = response.json()\n\n        self.token = data['access_token']\n        self.token_expiry = datetime.now() + timedelta(seconds=data['expires_in'])\n\n    def _ensure_authenticated(self):\n        if not self.token or datetime.now() &gt;= self.token_expiry:\n            raise Exception('Token expired or missing')\n\n    def get_authors(self, **filters):\n        self._ensure_authenticated()\n        response = requests.get(\n            f'{self.base_url}/authors',\n            headers={'Authorization': f'Bearer {self.token}'},\n            params=filters\n        )\n        response.raise_for_status()\n        return response.json()\n</code></pre>"},{"location":"api-reference/http-api/#2-error-handling","title":"2. Error Handling","text":"<pre><code>import requests\nfrom requests.exceptions import RequestException\n\ndef safe_api_call(func):\n    def wrapper(*args, **kwargs):\n        try:\n            response = func(*args, **kwargs)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.HTTPError as e:\n            if e.response.status_code == 401:\n                print(\"Authentication failed\")\n            elif e.response.status_code == 403:\n                print(\"Permission denied\")\n            elif e.response.status_code == 429:\n                print(\"Rate limit exceeded\")\n            else:\n                print(f\"HTTP error: {e}\")\n        except RequestException as e:\n            print(f\"Request failed: {e}\")\n        return None\n\n    return wrapper\n\n@safe_api_call\ndef get_authors(token):\n    return requests.get(\n        'http://localhost:8000/authors',\n        headers={'Authorization': f'Bearer {token}'}\n    )\n</code></pre>"},{"location":"api-reference/http-api/#3-pagination-handling","title":"3. Pagination Handling","text":"<pre><code>def fetch_all_pages(token, endpoint, per_page=100):\n    \"\"\"\n    Fetch all pages from a paginated endpoint.\n\n    Args:\n        token: Authentication token\n        endpoint: API endpoint URL\n        per_page: Items per page\n\n    Yields:\n        Individual items from all pages\n    \"\"\"\n    page = 1\n\n    while True:\n        response = requests.get(\n            endpoint,\n            headers={'Authorization': f'Bearer {token}'},\n            params={'page': page, 'per_page': per_page}\n        )\n        response.raise_for_status()\n\n        data = response.json()\n\n        for item in data['items']:\n            yield item\n\n        if page &gt;= data['meta']['pages']:\n            break\n\n        page += 1\n\n# Usage\nfor author in fetch_all_pages(token, 'http://localhost:8000/authors_paginated'):\n    print(f\"{author['id']}: {author['name']}\")\n</code></pre>"},{"location":"api-reference/http-api/#4-rate-limiting","title":"4. Rate Limiting","text":"<pre><code>import time\nfrom functools import wraps\n\ndef rate_limit_handler(func):\n    \"\"\"Decorator to handle rate limiting with automatic retry.\"\"\"\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        max_retries = 3\n        retry_count = 0\n\n        while retry_count &lt; max_retries:\n            try:\n                response = func(*args, **kwargs)\n\n                # Check rate limit headers\n                remaining = int(response.headers.get('X-RateLimit-Remaining', 0))\n\n                if remaining &lt; 5:\n                    # Approaching limit, slow down\n                    time.sleep(1)\n\n                return response\n\n            except requests.exceptions.HTTPError as e:\n                if e.response.status_code == 429:\n                    retry_after = int(e.response.headers.get('Retry-After', 60))\n                    print(f\"Rate limited. Waiting {retry_after}s...\")\n                    time.sleep(retry_after)\n                    retry_count += 1\n                else:\n                    raise\n\n        raise Exception(\"Max retries exceeded for rate limiting\")\n\n    return wrapper\n\n@rate_limit_handler\ndef get_authors_safe(token):\n    return requests.get(\n        'http://localhost:8000/authors',\n        headers={'Authorization': f'Bearer {token}'}\n    )\n</code></pre>"},{"location":"api-reference/http-api/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api-reference/http-api/#1-use-pagination","title":"1. Use Pagination","text":"<p>For large datasets, always use paginated endpoints:</p> <pre><code># Good: Paginated request\nresponse = requests.get(\n    'http://localhost:8000/authors_paginated',\n    params={'page': 1, 'per_page': 50}\n)\n\n# Avoid: Non-paginated request for large datasets\nresponse = requests.get('http://localhost:8000/authors')  # May return thousands\n</code></pre>"},{"location":"api-reference/http-api/#2-filter-early","title":"2. Filter Early","text":"<p>Apply filters to reduce data transfer:</p> <pre><code># Good: Filter on server\nresponse = requests.get(\n    'http://localhost:8000/authors',\n    params={'name': 'Smith'}\n)\n\n# Avoid: Fetch all and filter on client\nresponse = requests.get('http://localhost:8000/authors')\nauthors = [a for a in response.json() if 'Smith' in a['name']]\n</code></pre>"},{"location":"api-reference/http-api/#3-reuse-connections","title":"3. Reuse Connections","text":"<p>Use session objects for multiple requests:</p> <pre><code>session = requests.Session()\nsession.headers.update({'Authorization': f'Bearer {token}'})\n\n# Reuses underlying TCP connection\nfor i in range(10):\n    response = session.get('http://localhost:8000/authors')\n</code></pre>"},{"location":"api-reference/http-api/#monitoring","title":"Monitoring","text":""},{"location":"api-reference/http-api/#health-checks","title":"Health Checks","text":"<p>Implement periodic health checks for service monitoring:</p> <pre><code>import requests\nimport time\n\ndef monitor_service(url, interval=30):\n    \"\"\"Monitor service health.\"\"\"\n    while True:\n        try:\n            response = requests.get(f'{url}/health', timeout=5)\n            health = response.json()\n\n            if health['status'] != 'healthy':\n                alert(f\"Service unhealthy: {health}\")\n\n        except Exception as e:\n            alert(f\"Health check failed: {e}\")\n\n        time.sleep(interval)\n</code></pre>"},{"location":"api-reference/http-api/#metrics-integration","title":"Metrics Integration","text":"<p>Scrape Prometheus metrics for monitoring:</p> <pre><code># prometheus.yml\nscrape_configs:\n  - job_name: 'fastapi-app'\n    static_configs:\n      - targets: ['localhost:8000']\n    metrics_path: '/metrics'\n    scrape_interval: 15s\n</code></pre>"},{"location":"api-reference/http-api/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api-reference/http-api/#authentication-issues","title":"Authentication Issues","text":"<p>Problem: 401 Unauthorized</p> <p>Solutions: 1. Verify token hasn't expired (check <code>exp</code> claim) 2. Ensure token is in Authorization header: <code>Bearer &lt;token&gt;</code> 3. Check Keycloak server is accessible 4. Verify username/password are correct</p>"},{"location":"api-reference/http-api/#rate-limiting_1","title":"Rate Limiting","text":"<p>Problem: 429 Too Many Requests</p> <p>Solutions: 1. Implement exponential backoff 2. Check <code>X-RateLimit-Reset</code> header for retry time 3. Reduce request frequency 4. Cache responses when possible</p>"},{"location":"api-reference/http-api/#validation-errors","title":"Validation Errors","text":"<p>Problem: 422 Unprocessable Entity</p> <p>Solutions: 1. Review validation error details in response 2. Check field types match schema 3. Ensure required fields are present 4. Validate data before sending</p>"},{"location":"api-reference/http-api/#database-errors","title":"Database Errors","text":"<p>Problem: 500 Internal Server Error</p> <p>Solutions: 1. Check <code>/health</code> endpoint for database status 2. Review server logs for detailed errors 3. Verify database connection configuration 4. Contact system administrator if persistent</p>"},{"location":"api-reference/http-api/#support","title":"Support","text":"<p>For additional help: - Interactive documentation: http://localhost:8000/docs - Health status: http://localhost:8000/health - Enable debug logging: <code>LOG_LEVEL=DEBUG</code> - Check application logs for detailed error traces</p>"},{"location":"api-reference/response-models/","title":"Response Models","text":""},{"location":"api-reference/response-models/#overview","title":"Overview","text":"<p>This document describes the standard response models used across both HTTP and WebSocket APIs.</p>"},{"location":"api-reference/response-models/#http-response-models","title":"HTTP Response Models","text":""},{"location":"api-reference/response-models/#standard-response","title":"Standard Response","text":"<p>HTTP endpoints return data directly with appropriate status codes:</p> <pre><code>{\n  \"id\": 1,\n  \"name\": \"John Doe\"\n}\n</code></pre>"},{"location":"api-reference/response-models/#paginated-response","title":"Paginated Response","text":"<p>Paginated endpoints return data with metadata:</p> <pre><code>{\n  \"items\": [...],\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 42,\n    \"pages\": 3\n  }\n}\n</code></pre>"},{"location":"api-reference/response-models/#error-response","title":"Error Response","text":"<pre><code>{\n  \"detail\": \"Error message\"\n}\n</code></pre>"},{"location":"api-reference/response-models/#websocket-response-models","title":"WebSocket Response Models","text":""},{"location":"api-reference/response-models/#responsemodel","title":"ResponseModel","text":"<p>All WebSocket responses use the <code>ResponseModel</code> structure:</p> <pre><code>class ResponseModel(BaseModel):\n    pkg_id: int\n    req_id: str\n    status_code: int\n    data: dict | list | None = None\n    meta: MetadataModel | None = None\n</code></pre> <p>Example Success Response:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 0,\n  \"data\": [{\"id\": 1, \"name\": \"John Doe\"}],\n  \"meta\": null\n}\n</code></pre> <p>Example Error Response:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 2,\n  \"data\": {\"msg\": \"Invalid data\"},\n  \"meta\": null\n}\n</code></pre>"},{"location":"api-reference/response-models/#metadatamodel","title":"MetadataModel","text":"<p>Pagination metadata for WebSocket responses:</p> <pre><code>class MetadataModel(BaseModel):\n    page: int\n    per_page: int\n    total: int\n    pages: int\n</code></pre> <p>Example:</p> <pre><code>{\n  \"page\": 1,\n  \"per_page\": 20,\n  \"total\": 42,\n  \"pages\": 3\n}\n</code></pre>"},{"location":"api-reference/response-models/#helper-methods","title":"Helper Methods","text":""},{"location":"api-reference/response-models/#responsemodelsuccess","title":"ResponseModel.success()","text":"<p>Create a success response:</p> <pre><code>return ResponseModel.success(\n    pkg_id=request.pkg_id,\n    req_id=request.req_id,\n    data=[author.model_dump() for author in authors]\n)\n</code></pre>"},{"location":"api-reference/response-models/#responsemodelerr_msg","title":"ResponseModel.err_msg()","text":"<p>Create an error response:</p> <pre><code>return ResponseModel.err_msg(\n    pkg_id=request.pkg_id,\n    req_id=request.req_id,\n    msg=\"Author not found\",\n    status_code=RSPCode.ERROR\n)\n</code></pre>"},{"location":"api-reference/response-models/#response-status-codes","title":"Response Status Codes","text":"<p>See WebSocket API for complete list of response codes.</p>"},{"location":"api-reference/response-models/#related","title":"Related","text":"<ul> <li>HTTP API - HTTP endpoints and responses</li> <li>WebSocket API - WebSocket message format</li> </ul>"},{"location":"api-reference/websocket-api/","title":"WebSocket API Documentation","text":""},{"location":"api-reference/websocket-api/#overview","title":"Overview","text":"<p>This FastAPI application provides a WebSocket API for real-time bidirectional communication. The WebSocket endpoint uses a package-based routing system where requests are dispatched to handlers based on Package IDs (PkgID).</p>"},{"location":"api-reference/websocket-api/#connection","title":"Connection","text":""},{"location":"api-reference/websocket-api/#endpoint","title":"Endpoint","text":"<pre><code>ws://localhost:8000/web\nwss://localhost:8000/web (for production with TLS)\n</code></pre>"},{"location":"api-reference/websocket-api/#authentication","title":"Authentication","text":"<p>Authentication is required via Keycloak access token passed as a query parameter:</p> <pre><code>ws://localhost:8000/web?token=&lt;your_access_token&gt;\n</code></pre> <p>Connection Limits: - Maximum concurrent connections per user: 5 (configurable via <code>WS_MAX_CONNECTIONS_PER_USER</code>) - Exceeding this limit results in connection rejection with code <code>1008</code> (Policy Violation)</p>"},{"location":"api-reference/websocket-api/#rate-limiting","title":"Rate Limiting","text":"<p>Message Rate Limits: - Default: 100 messages per minute per user (configurable via <code>WS_MESSAGE_RATE_LIMIT</code>) - Exceeding rate limit returns error response with <code>RSPCode.ERROR</code></p>"},{"location":"api-reference/websocket-api/#message-format","title":"Message Format","text":""},{"location":"api-reference/websocket-api/#request-message","title":"Request Message","text":"<p>All client requests must follow this JSON structure:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"method\": \"\",\n  \"data\": {}\n}\n</code></pre> <p>Fields:</p> Field Type Required Description <code>pkg_id</code> integer Yes Package identifier routing request to specific handler (see PkgID Reference) <code>req_id</code> string (UUID) Yes Unique request identifier for tracking responses <code>method</code> string No Optional method name (handler-specific, defaults to empty string) <code>data</code> object No Request payload containing handler-specific parameters (defaults to <code>{}</code>)"},{"location":"api-reference/websocket-api/#response-message","title":"Response Message","text":"<p>All server responses follow this JSON structure:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 0,\n  \"meta\": null,\n  \"data\": []\n}\n</code></pre> <p>Fields:</p> Field Type Description <code>pkg_id</code> integer Same as request pkg_id, identifies the handler that processed the request <code>req_id</code> string (UUID) Same as request req_id, for request/response correlation <code>status_code</code> integer Response code indicating operation result (see RSPCode Reference) <code>meta</code> object/null Optional metadata (e.g., pagination info) <code>data</code> object/array/null Response payload containing results or error details"},{"location":"api-reference/websocket-api/#package-id-reference-pkgid","title":"Package ID Reference (PkgID)","text":"PkgID Name Description Required Role 1 <code>GET_AUTHORS</code> Retrieve list of authors with optional filters <code>user</code> 2 <code>GET_PAGINATED_AUTHORS</code> Retrieve paginated list of authors <code>user</code> 3 <code>THIRD</code> Reserved for future use TBD"},{"location":"api-reference/websocket-api/#handler-details","title":"Handler Details","text":""},{"location":"api-reference/websocket-api/#1-get_authors-pkgid-1","title":"1. GET_AUTHORS (PkgID: 1)","text":"<p>Retrieves a list of authors with optional filtering.</p> <p>Request Data Schema:</p> <pre><code>{\n  \"filters\": {\n    \"id\": 123,        // optional: filter by author ID\n    \"name\": \"John\"    // optional: filter by author name (case-insensitive, partial match)\n  }\n}\n</code></pre> <p>Success Response:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 0,\n  \"meta\": null,\n  \"data\": [\n    {\n      \"id\": 1,\n      \"name\": \"John Doe\"\n    },\n    {\n      \"id\": 2,\n      \"name\": \"Jane Smith\"\n    }\n  ]\n}\n</code></pre> <p>Example Request:</p> <pre><code>const ws = new WebSocket('ws://localhost:8000/web?token=YOUR_TOKEN');\n\nws.onopen = () =&gt; {\n  ws.send(JSON.stringify({\n    pkg_id: 1,\n    req_id: crypto.randomUUID(),\n    method: \"\",\n    data: {\n      filters: {\n        name: \"John\"\n      }\n    }\n  }));\n};\n\nws.onmessage = (event) =&gt; {\n  const response = JSON.parse(event.data);\n  console.log('Authors:', response.data);\n};\n</code></pre> <p>Error Responses:</p> status_code Reason data.msg 1 Database error \"Database error occurred\" 2 Invalid filter parameters \"Invalid filter parameters\" 3 Permission denied \"Permission denied\""},{"location":"api-reference/websocket-api/#2-get_paginated_authors-pkgid-2","title":"2. GET_PAGINATED_AUTHORS (PkgID: 2)","text":"<p>Retrieves a paginated list of authors with optional filtering.</p> <p>Request Data Schema:</p> <pre><code>{\n  \"page\": 1,           // required: page number (&gt;=1)\n  \"per_page\": 20,      // required: items per page (&gt;=1)\n  \"filters\": {\n    \"id\": 123,         // optional: filter by author ID\n    \"name\": \"John\"     // optional: filter by author name\n  }\n}\n</code></pre> <p>Success Response:</p> <pre><code>{\n  \"pkg_id\": 2,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 0,\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 42,\n    \"pages\": 3\n  },\n  \"data\": [\n    {\n      \"id\": 1,\n      \"name\": \"John Doe\"\n    },\n    {\n      \"id\": 2,\n      \"name\": \"Jane Smith\"\n    }\n  ]\n}\n</code></pre> <p>Example Request:</p> <pre><code>ws.send(JSON.stringify({\n  pkg_id: 2,\n  req_id: crypto.randomUUID(),\n  method: \"\",\n  data: {\n    page: 1,\n    per_page: 20,\n    filters: {\n      name: \"Smith\"\n    }\n  }\n}));\n</code></pre> <p>Error Responses:</p> status_code Reason data.msg 1 Database error \"Database error occurred\" 2 Invalid pagination parameters \"Invalid pagination parameters\" 3 Permission denied \"Permission denied\""},{"location":"api-reference/websocket-api/#response-code-reference-rspcode","title":"Response Code Reference (RSPCode)","text":"Code Name Description 0 <code>OK</code> Operation completed successfully 1 <code>ERROR</code> General error occurred 2 <code>INVALID_DATA</code> Provided data is invalid or malformed 3 <code>PERMISSION_DENIED</code> User lacks required permissions for the operation"},{"location":"api-reference/websocket-api/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/websocket-api/#client-side-error-handling","title":"Client-Side Error Handling","text":"<pre><code>ws.onmessage = (event) =&gt; {\n  const response = JSON.parse(event.data);\n\n  if (response.status_code !== 0) {\n    // Handle error\n    switch (response.status_code) {\n      case 1:\n        console.error('Server error:', response.data.msg);\n        break;\n      case 2:\n        console.error('Invalid data:', response.data.msg);\n        // Validate and retry with corrected data\n        break;\n      case 3:\n        console.error('Permission denied:', response.data.msg);\n        // User needs different role or authentication\n        break;\n      default:\n        console.error('Unknown error:', response);\n    }\n    return;\n  }\n\n  // Success - process data\n  console.log('Success:', response.data);\n};\n\nws.onerror = (error) =&gt; {\n  console.error('WebSocket error:', error);\n};\n\nws.onclose = (event) =&gt; {\n  if (event.code === 1008) {\n    console.error('Connection rejected: Maximum concurrent connections exceeded');\n  } else if (event.code === 1003) {\n    console.error('Connection closed: Invalid message format');\n  } else {\n    console.log('Connection closed:', event.code, event.reason);\n  }\n};\n</code></pre>"},{"location":"api-reference/websocket-api/#common-connection-close-codes","title":"Common Connection Close Codes","text":"Code Reason Description 1000 Normal Closure Connection closed normally 1003 Unsupported Data Invalid message format 1008 Policy Violation Connection limit exceeded or rate limit violation 4001 Unauthorized Invalid or expired authentication token"},{"location":"api-reference/websocket-api/#broadcast-messages","title":"Broadcast Messages","text":"<p>The server may send unsolicited broadcast messages to all connected clients:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"00000000-0000-0000-0000-000000000000\",\n  \"data\": {\n    \"event\": \"update\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n  }\n}\n</code></pre> <p>Identifying Broadcasts: - <code>req_id</code> will be <code>00000000-0000-0000-0000-000000000000</code> (UUID with int=0) - Not correlated to any client request</p>"},{"location":"api-reference/websocket-api/#authentication_1","title":"Authentication","text":""},{"location":"api-reference/websocket-api/#obtaining-access-token","title":"Obtaining Access Token","text":"<p>Use the HTTP <code>/login</code> endpoint or Keycloak direct grant flow:</p> <pre><code>curl -X POST http://localhost:8000/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"username\": \"your_username\",\n    \"password\": \"your_password\"\n  }'\n</code></pre> <p>Response:</p> <pre><code>{\n  \"access_token\": \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"expires_in\": 300,\n  \"refresh_expires_in\": 1800,\n  \"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"token_type\": \"Bearer\"\n}\n</code></pre>"},{"location":"api-reference/websocket-api/#token-expiration","title":"Token Expiration","text":"<ul> <li>Access tokens expire after 5 minutes (300 seconds) by default</li> <li>Client must handle reconnection with refreshed token</li> <li>Monitor <code>exp</code> claim in JWT payload</li> </ul>"},{"location":"api-reference/websocket-api/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<p>Each handler requires specific roles defined in its <code>@pkg_router.register()</code> decorator. Users must have the required role in their Keycloak token to access handlers.</p> <p>Implementation: <pre><code>@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    roles=[\"get-authors\"]  # Required roles\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n</code></pre></p> <p>Common Roles: - <code>get-authors</code>: View author list - <code>create-author</code>: Create new authors - <code>admin</code>: Administrative privileges</p> <p>Finding Role Requirements: Check the handler code in <code>app/api/ws/handlers/</code> to see which roles are required for each <code>PkgID</code>.</p>"},{"location":"api-reference/websocket-api/#best-practices","title":"Best Practices","text":""},{"location":"api-reference/websocket-api/#1-request-id-management","title":"1. Request ID Management","text":"<p>Always generate unique UUIDs for each request to correlate responses:</p> <pre><code>function generateRequestId() {\n  return crypto.randomUUID();\n}\n\nconst requestMap = new Map();\n\nfunction sendRequest(pkgId, data) {\n  const reqId = generateRequestId();\n  requestMap.set(reqId, { pkgId, timestamp: Date.now() });\n\n  ws.send(JSON.stringify({\n    pkg_id: pkgId,\n    req_id: reqId,\n    data: data\n  }));\n\n  return reqId;\n}\n\nws.onmessage = (event) =&gt; {\n  const response = JSON.parse(event.data);\n  const request = requestMap.get(response.req_id);\n\n  if (request) {\n    requestMap.delete(response.req_id);\n    // Process response with context\n  }\n};\n</code></pre>"},{"location":"api-reference/websocket-api/#2-connection-management","title":"2. Connection Management","text":"<p>Implement reconnection logic with exponential backoff:</p> <pre><code>let reconnectAttempts = 0;\nconst maxReconnectAttempts = 5;\n\nfunction connect() {\n  const ws = new WebSocket(`ws://localhost:8000/web?token=${token}`);\n\n  ws.onclose = (event) =&gt; {\n    if (reconnectAttempts &lt; maxReconnectAttempts) {\n      const delay = Math.min(1000 * Math.pow(2, reconnectAttempts), 30000);\n      setTimeout(() =&gt; {\n        reconnectAttempts++;\n        connect();\n      }, delay);\n    }\n  };\n\n  ws.onopen = () =&gt; {\n    reconnectAttempts = 0;\n  };\n}\n</code></pre>"},{"location":"api-reference/websocket-api/#3-token-refresh","title":"3. Token Refresh","text":"<p>Proactively refresh tokens before expiration:</p> <pre><code>function scheduleTokenRefresh(expiresIn) {\n  // Refresh 30 seconds before expiration\n  const refreshDelay = (expiresIn - 30) * 1000;\n\n  setTimeout(async () =&gt; {\n    const newToken = await refreshAccessToken();\n    // Reconnect with new token\n    ws.close(1000, 'Token refresh');\n    connect(newToken);\n  }, refreshDelay);\n}\n</code></pre>"},{"location":"api-reference/websocket-api/#4-message-validation","title":"4. Message Validation","text":"<p>Always validate responses before processing:</p> <pre><code>function isValidResponse(response) {\n  return (\n    response &amp;&amp;\n    typeof response.pkg_id === 'number' &amp;&amp;\n    typeof response.req_id === 'string' &amp;&amp;\n    typeof response.status_code === 'number'\n  );\n}\n\nws.onmessage = (event) =&gt; {\n  try {\n    const response = JSON.parse(event.data);\n    if (!isValidResponse(response)) {\n      console.error('Invalid response format:', response);\n      return;\n    }\n    // Process valid response\n  } catch (error) {\n    console.error('Failed to parse response:', error);\n  }\n};\n</code></pre>"},{"location":"api-reference/websocket-api/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api-reference/websocket-api/#rate-limiting_1","title":"Rate Limiting","text":"<p>To avoid hitting rate limits: - Batch requests when possible - Implement client-side throttling - Cache frequently requested data - Use pagination for large datasets</p>"},{"location":"api-reference/websocket-api/#connection-pooling","title":"Connection Pooling","text":"<p>For multi-user applications: - Reuse connections across requests - Implement connection pooling - Monitor connection count per user - Close idle connections</p>"},{"location":"api-reference/websocket-api/#pagination","title":"Pagination","text":"<p>For large result sets: - Always use paginated endpoints (<code>GET_PAGINATED_AUTHORS</code>) - Request reasonable page sizes (20-100 items) - Implement infinite scroll or pagination UI - Cache previous pages on client</p>"},{"location":"api-reference/websocket-api/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api-reference/websocket-api/#connection-refused","title":"Connection Refused","text":"<p>Problem: WebSocket connection fails with 403 Forbidden</p> <p>Solutions: - Verify token is valid and not expired - Check token is passed in query parameter: <code>?token=...</code> - Ensure user has required roles in Keycloak</p>"},{"location":"api-reference/websocket-api/#rate-limit-exceeded","title":"Rate Limit Exceeded","text":"<p>Problem: Receiving <code>RSPCode.ERROR</code> frequently</p> <p>Solutions: - Implement client-side rate limiting - Reduce message frequency - Check <code>WS_MESSAGE_RATE_LIMIT</code> server configuration</p>"},{"location":"api-reference/websocket-api/#invalid-data-errors","title":"Invalid Data Errors","text":"<p>Problem: Receiving <code>RSPCode.INVALID_DATA</code></p> <p>Solutions: - Validate data schema before sending - Check required fields are present - Ensure data types match schema - Review handler-specific documentation</p>"},{"location":"api-reference/websocket-api/#connection-drops","title":"Connection Drops","text":"<p>Problem: WebSocket disconnects frequently</p> <p>Solutions: - Implement reconnection logic - Check network stability - Monitor server logs for errors - Verify token hasn't expired</p>"},{"location":"api-reference/websocket-api/#support","title":"Support","text":"<p>For issues or questions: - Check application logs for detailed error messages - Review Keycloak configuration for authentication issues - Check handler decorator for RBAC requirements (e.g., <code>@pkg_router.register(roles=[...])</code>) - Enable debug logging: Set <code>LOG_LEVEL=DEBUG</code> in environment</p>"},{"location":"architecture/","title":"Architecture","text":"<p>Learn about the system architecture, design patterns, and technical decisions.</p>"},{"location":"architecture/#contents","title":"Contents","text":"<ul> <li>Overview - System architecture and component interactions</li> <li>Design Patterns - Repository, Command, and Dependency Injection patterns</li> <li>Request Flow - HTTP and WebSocket request processing</li> <li>RBAC System - Role-based access control implementation</li> </ul>"},{"location":"architecture/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>graph TB\n    Client[Client] --&gt;|HTTP/WS| Traefik[Traefik]\n    Traefik --&gt; App[FastAPI App]\n    App --&gt; PG[(PostgreSQL)]\n    App --&gt; Redis[(Redis)]\n    App --&gt; KC[Keycloak]</code></pre> <p>See Overview for detailed architecture documentation.</p>"},{"location":"architecture/design-patterns/","title":"Design Patterns Guide","text":"<p>Status: \u2705 Implemented Date: 2025-12-05 Issue: #29</p>"},{"location":"architecture/design-patterns/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Why These Patterns?</li> <li>Pattern 1: Dependency Injection</li> <li>Pattern 2: Repository Pattern</li> <li>Pattern 3: Command Pattern</li> <li>Complete Example: Author Feature</li> <li>Testing Strategies</li> <li>Migration Guide</li> <li>Best Practices</li> </ul>"},{"location":"architecture/design-patterns/#overview","title":"Overview","text":"<p>This guide explains the modern design patterns implemented in this FastAPI application. These patterns improve code quality through:</p> <ul> <li>Testability - Easy to mock and test in isolation</li> <li>Reusability - Share logic across HTTP and WebSocket handlers</li> <li>Maintainability - Clear separation of concerns</li> <li>Type Safety - Full type hints and IDE support</li> <li>Flexibility - Easy to swap implementations</li> </ul>"},{"location":"architecture/design-patterns/#pattern-summary","title":"Pattern Summary","text":"Pattern Purpose Location Dependency Injection Manage dependencies without singletons <code>app/dependencies.py</code> Repository Abstract data access <code>app/repositories/</code> Command Encapsulate business logic <code>app/commands/</code>"},{"location":"architecture/design-patterns/#why-these-patterns","title":"Why These Patterns?","text":""},{"location":"architecture/design-patterns/#problems-with-old-approach","title":"Problems with Old Approach","text":""},{"location":"architecture/design-patterns/#singleton-pattern-metaclass","title":"\u274c Singleton Pattern (Metaclass)","text":"<pre><code># OLD: app/managers/rbac_manager.py\nfrom app.utils.singleton import SingletonMeta\n\nclass RBACManager(metaclass=SingletonMeta):\n    def __init__(self):\n        self.config = load_config()\n\n# Usage - hidden dependency!\nrbac = RBACManager()  # Always returns same instance\n</code></pre> <p>Problems: - Hard to test (global mutable state) - Can't override/mock easily - Hidden dependencies - Not compatible with FastAPI's DI</p>"},{"location":"architecture/design-patterns/#active-record-pattern","title":"\u274c Active Record Pattern","text":"<pre><code># OLD: app/models/author.py\nclass Author(SQLModel, table=True):\n    id: int | None = None\n    name: str\n\n    @classmethod\n    async def create(cls, session: AsyncSession, author: \"Author\"):\n        # Data access mixed with model definition\n        session.add(author)\n        await session.flush()\n        return author\n</code></pre> <p>Problems: - Violates Single Responsibility Principle - Can't test business logic without database - Hard to swap data sources - Business logic tied to data structure</p>"},{"location":"architecture/design-patterns/#logic-in-handlers","title":"\u274c Logic in Handlers","text":"<pre><code># OLD: Direct model access from handlers\n@router.post(\"/authors\")\nasync def create_author(author: Author):\n    async with async_session() as session:\n        return await Author.create(session, author)  # No business logic!\n</code></pre> <p>Problems: - Duplicate code between HTTP and WebSocket - Can't reuse business logic - Testing requires full setup</p>"},{"location":"architecture/design-patterns/#solutions-with-new-patterns","title":"\u2705 Solutions with New Patterns","text":"<pre><code># NEW: Clean separation of concerns\nRepository (data access) \u2192 Command (business logic) \u2192 Handler (protocol)\n</code></pre>"},{"location":"architecture/design-patterns/#pattern-1-dependency-injection","title":"Pattern 1: Dependency Injection","text":""},{"location":"architecture/design-patterns/#overview_1","title":"Overview","text":"<p>Replace singleton pattern with FastAPI's dependency injection system.</p>"},{"location":"architecture/design-patterns/#implementation","title":"Implementation","text":"<p>File: <code>app/dependencies.py</code></p> <pre><code>from functools import lru_cache\nfrom typing import Annotated\nfrom fastapi import Depends\nfrom app.managers.rbac_manager import RBACManager\n\n# Use @lru_cache for singleton behavior\n@lru_cache\ndef get_rbac_manager() -&gt; RBACManager:\n    \"\"\"Get cached RBAC manager instance.\"\"\"\n    return RBACManager()\n\n# Type-safe dependency annotation\nRBACDep = Annotated[RBACManager, Depends(get_rbac_manager)]\n</code></pre>"},{"location":"architecture/design-patterns/#usage","title":"Usage","text":"<p>HTTP Handler: <pre><code>from app.dependencies import RBACDep, AuthorRepoDep\n\n@router.get(\"/authors\")\nasync def get_authors(\n    rbac: RBACDep,  # Injected automatically!\n    repo: AuthorRepoDep,\n) -&gt; list[Author]:\n    # Dependencies are explicitly declared\n    return await repo.get_all()\n</code></pre></p> <p>WebSocket Handler: <pre><code># WebSocket can't use Depends(), so instantiate manually\nasync def ws_handler(request: RequestModel):\n    async with async_session() as session:\n        repo = AuthorRepository(session)\n        # Use repository...\n</code></pre></p>"},{"location":"architecture/design-patterns/#testing","title":"Testing","text":"<pre><code>def test_endpoint():\n    # Override dependency for testing\n    app.dependency_overrides[get_rbac_manager] = lambda: MockRBAC()\n\n    # Test with mocked dependency\n    response = client.get(\"/authors\")\n</code></pre>"},{"location":"architecture/design-patterns/#benefits","title":"Benefits","text":"<p>\u2705 Testable - Can override with mocks \u2705 Explicit - Dependencies clearly declared \u2705 Type-safe - IDE autocomplete and type checking \u2705 Flexible - Easy to swap implementations</p>"},{"location":"architecture/design-patterns/#pattern-2-repository-pattern","title":"Pattern 2: Repository Pattern","text":""},{"location":"architecture/design-patterns/#overview_2","title":"Overview","text":"<p>Separate data access logic from business logic by encapsulating all database operations in repository classes.</p>"},{"location":"architecture/design-patterns/#implementation_1","title":"Implementation","text":"<p>Base Repository: <code>app/repositories/base.py</code></p> <pre><code>from typing import Generic, Type, TypeVar\nfrom sqlmodel import select\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\nT = TypeVar(\"T\")\n\nclass BaseRepository(Generic[T]):\n    \"\"\"Generic repository with common CRUD operations.\"\"\"\n\n    def __init__(self, session: AsyncSession, model: Type[T]):\n        self.session = session\n        self.model = model\n\n    async def get_by_id(self, id: int) -&gt; T | None:\n        return await self.session.get(self.model, id)\n\n    async def get_all(self, **filters) -&gt; list[T]:\n        stmt = select(self.model)\n        for key, value in filters.items():\n            if value is not None:\n                stmt = stmt.where(getattr(self.model, key) == value)\n        result = await self.session.exec(stmt)\n        return list(result.all())\n\n    async def create(self, entity: T) -&gt; T:\n        self.session.add(entity)\n        await self.session.flush()\n        await self.session.refresh(entity)\n        return entity\n\n    async def update(self, entity: T) -&gt; T:\n        self.session.add(entity)\n        await self.session.flush()\n        await self.session.refresh(entity)\n        return entity\n\n    async def delete(self, entity: T) -&gt; None:\n        await self.session.delete(entity)\n        await self.session.flush()\n\n    async def exists(self, **filters) -&gt; bool:\n        stmt = select(self.model)\n        for key, value in filters.items():\n            if value is not None:\n                stmt = stmt.where(getattr(self.model, key) == value)\n        result = await self.session.exec(stmt)\n        return result.first() is not None\n</code></pre> <p>Specific Repository: <code>app/repositories/author_repository.py</code></p> <pre><code>from app.models.author import Author\nfrom app.repositories.base import BaseRepository\n\nclass AuthorRepository(BaseRepository[Author]):\n    \"\"\"Repository for Author entity with specialized queries.\"\"\"\n\n    def __init__(self, session: AsyncSession):\n        super().__init__(session, Author)\n\n    async def get_by_name(self, name: str) -&gt; Author | None:\n        \"\"\"Get author by exact name match.\"\"\"\n        stmt = select(Author).where(Author.name == name)\n        result = await self.session.exec(stmt)\n        return result.first()\n\n    async def search_by_name(self, name_pattern: str) -&gt; list[Author]:\n        \"\"\"Search authors by name pattern (case-insensitive).\"\"\"\n        stmt = select(Author).where(Author.name.ilike(f\"%{name_pattern}%\"))\n        result = await self.session.exec(stmt)\n        return list(result.all())\n</code></pre>"},{"location":"architecture/design-patterns/#usage_1","title":"Usage","text":"<pre><code># In handler\nasync with async_session() as session:\n    repo = AuthorRepository(session)\n\n    # Use repository methods\n    author = await repo.get_by_id(1)\n    all_authors = await repo.get_all()\n    johns = await repo.search_by_name(\"John\")\n    exists = await repo.exists(name=\"John Doe\")\n</code></pre>"},{"location":"architecture/design-patterns/#testing_1","title":"Testing","text":"<pre><code>@pytest.mark.asyncio\nasync def test_repository():\n    # Mock session\n    mock_session = AsyncMock()\n    mock_session.get.return_value = Author(id=1, name=\"Test\")\n\n    repo = AuthorRepository(mock_session)\n    author = await repo.get_by_id(1)\n\n    assert author.name == \"Test\"\n    mock_session.get.assert_called_once_with(Author, 1)\n</code></pre>"},{"location":"architecture/design-patterns/#benefits_1","title":"Benefits","text":"<p>\u2705 Abstraction - Hide database details \u2705 Reusable - Use same repository in multiple handlers \u2705 Testable - Mock session, not database \u2705 Maintainable - Change queries in one place</p>"},{"location":"architecture/design-patterns/#pattern-3-command-pattern","title":"Pattern 3: Command Pattern","text":""},{"location":"architecture/design-patterns/#overview_3","title":"Overview","text":"<p>Encapsulate business operations as command objects that can be reused across different handler types (HTTP, WebSocket).</p>"},{"location":"architecture/design-patterns/#implementation_2","title":"Implementation","text":"<p>Base Command: <code>app/commands/base.py</code></p> <pre><code>from abc import ABC, abstractmethod\nfrom typing import Generic, TypeVar\n\nTInput = TypeVar(\"TInput\")\nTOutput = TypeVar(\"TOutput\")\n\nclass BaseCommand(ABC, Generic[TInput, TOutput]):\n    \"\"\"Base command for business operations.\"\"\"\n\n    @abstractmethod\n    async def execute(self, input_data: TInput) -&gt; TOutput:\n        \"\"\"Execute the command with input data.\"\"\"\n        pass\n</code></pre> <p>Specific Command: <code>app/commands/author_commands.py</code></p> <pre><code>from pydantic import BaseModel\nfrom app.commands.base import BaseCommand\nfrom app.repositories.author_repository import AuthorRepository\n\n# Input/Output models\nclass GetAuthorsInput(BaseModel):\n    id: int | None = None\n    name: str | None = None\n    search_term: str | None = None\n\n# Command implementation\nclass GetAuthorsCommand(BaseCommand[GetAuthorsInput, list[Author]]):\n    \"\"\"Command to get authors with optional filtering.\"\"\"\n\n    def __init__(self, repository: AuthorRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: GetAuthorsInput) -&gt; list[Author]:\n        # Business logic here\n        if input_data.search_term:\n            return await self.repository.search_by_name(input_data.search_term)\n\n        filters = {}\n        if input_data.id is not None:\n            filters[\"id\"] = input_data.id\n        if input_data.name is not None:\n            filters[\"name\"] = input_data.name\n\n        return await self.repository.get_all(**filters)\n\n\nclass CreateAuthorCommand(BaseCommand[CreateAuthorInput, Author]):\n    \"\"\"Command to create a new author.\"\"\"\n\n    def __init__(self, repository: AuthorRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: CreateAuthorInput) -&gt; Author:\n        # Business logic: Check for duplicates\n        existing = await self.repository.get_by_name(input_data.name)\n        if existing:\n            raise ValueError(f\"Author '{input_data.name}' already exists\")\n\n        author = Author(name=input_data.name)\n        return await self.repository.create(author)\n</code></pre>"},{"location":"architecture/design-patterns/#usage_2","title":"Usage","text":"<p>HTTP Handler: <pre><code>@router.get(\"/authors\")\nasync def get_authors(\n    repo: AuthorRepoDep,\n    search: str | None = None,\n) -&gt; list[Author]:\n    command = GetAuthorsCommand(repo)\n    input_data = GetAuthorsInput(search_term=search)\n    return await command.execute(input_data)\n</code></pre></p> <p>WebSocket Handler: <pre><code>@pkg_router.register(PkgID.GET_AUTHORS)\nasync def get_authors_ws(request: RequestModel) -&gt; ResponseModel:\n    async with async_session() as session:\n        repo = AuthorRepository(session)\n        command = GetAuthorsCommand(repo)  # Same command!\n        input_data = GetAuthorsInput(**request.data)\n        authors = await command.execute(input_data)\n\n        return ResponseModel(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            data=[a.model_dump() for a in authors]\n        )\n</code></pre></p> <p>Key Point: Same business logic (<code>GetAuthorsCommand</code>) used in both protocols! \ud83c\udfaf</p>"},{"location":"architecture/design-patterns/#testing_2","title":"Testing","text":"<pre><code>@pytest.mark.asyncio\nasync def test_command():\n    # Mock repository\n    mock_repo = AsyncMock()\n    mock_repo.get_by_name.return_value = None\n    mock_repo.create.return_value = Author(id=1, name=\"New\")\n\n    # Test command with mock\n    command = CreateAuthorCommand(mock_repo)\n    input_data = CreateAuthorInput(name=\"New\")\n    result = await command.execute(input_data)\n\n    assert result.name == \"New\"\n    mock_repo.get_by_name.assert_called_once_with(\"New\")\n    mock_repo.create.assert_called_once()\n</code></pre>"},{"location":"architecture/design-patterns/#benefits_2","title":"Benefits","text":"<p>\u2705 Reusable - Same logic in HTTP and WebSocket \u2705 Testable - Mock repository, not database \u2705 Maintainable - Change logic in one place \u2705 Composable - Commands can call other commands</p>"},{"location":"architecture/design-patterns/#complete-example-author-feature","title":"Complete Example: Author Feature","text":""},{"location":"architecture/design-patterns/#architecture-flow","title":"Architecture Flow","text":"<pre><code>HTTP Request \u2192 Router \u2192 Command \u2192 Repository \u2192 Database\n                  \u2193         \u2193           \u2193\n            Dependencies  Business    Data\n            Injected      Logic       Access\n</code></pre>"},{"location":"architecture/design-patterns/#step-by-step-implementation","title":"Step-by-Step Implementation","text":""},{"location":"architecture/design-patterns/#1-define-models","title":"1. Define Models","text":"<pre><code># app/models/author.py\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    # No business logic methods!\n</code></pre>"},{"location":"architecture/design-patterns/#2-create-repository","title":"2. Create Repository","text":"<pre><code># app/repositories/author_repository.py\nclass AuthorRepository(BaseRepository[Author]):\n    def __init__(self, session: AsyncSession):\n        super().__init__(session, Author)\n\n    async def get_by_name(self, name: str) -&gt; Author | None:\n        # Custom query\n        ...\n</code></pre>"},{"location":"architecture/design-patterns/#3-create-commands","title":"3. Create Commands","text":"<pre><code># app/commands/author_commands.py\nclass CreateAuthorInput(BaseModel):\n    name: str\n\nclass CreateAuthorCommand(BaseCommand[CreateAuthorInput, Author]):\n    def __init__(self, repository: AuthorRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: CreateAuthorInput) -&gt; Author:\n        # Business logic with validation\n        ...\n</code></pre>"},{"location":"architecture/design-patterns/#4-setup-dependencies","title":"4. Setup Dependencies","text":"<pre><code># app/dependencies.py\ndef get_author_repository(session: SessionDep) -&gt; AuthorRepository:\n    return AuthorRepository(session)\n\nAuthorRepoDep = Annotated[AuthorRepository, Depends(get_author_repository)]\n</code></pre>"},{"location":"architecture/design-patterns/#5-create-http-endpoint","title":"5. Create HTTP Endpoint","text":"<pre><code># app/api/http/author.py\n@router.post(\"/authors\", status_code=201)\nasync def create_author(\n    data: CreateAuthorInput,\n    repo: AuthorRepoDep,\n) -&gt; Author:\n    command = CreateAuthorCommand(repo)\n    return await command.execute(data)\n</code></pre>"},{"location":"architecture/design-patterns/#6-create-websocket-handler","title":"6. Create WebSocket Handler","text":"<pre><code># app/api/ws/handlers/author_handlers.py\n@pkg_router.register(PkgID.CREATE_AUTHOR)\nasync def create_author_ws(request: RequestModel) -&gt; ResponseModel:\n    async with async_session() as session:\n        repo = AuthorRepository(session)\n        command = CreateAuthorCommand(repo)  # Same command!\n        input_data = CreateAuthorInput(**request.data)\n        author = await command.execute(input_data)\n\n        return ResponseModel(..., data=author.model_dump())\n</code></pre>"},{"location":"architecture/design-patterns/#testing-strategies","title":"Testing Strategies","text":""},{"location":"architecture/design-patterns/#1-repository-tests","title":"1. Repository Tests","text":"<pre><code>@pytest.fixture\ndef mock_session():\n    session = AsyncMock(spec=AsyncSession)\n    session.add = MagicMock()\n    session.flush = AsyncMock()\n    session.exec = AsyncMock()\n    return session\n\n@pytest.mark.asyncio\nasync def test_create(mock_session):\n    repo = AuthorRepository(mock_session)\n    author = Author(name=\"Test\")\n\n    created = await repo.create(author)\n\n    mock_session.add.assert_called_once_with(author)\n    mock_session.flush.assert_called_once()\n</code></pre>"},{"location":"architecture/design-patterns/#2-command-tests","title":"2. Command Tests","text":"<pre><code>@pytest.mark.asyncio\nasync def test_create_command():\n    mock_repo = AsyncMock()\n    mock_repo.get_by_name.return_value = None\n    mock_repo.create.return_value = Author(id=1, name=\"New\")\n\n    command = CreateAuthorCommand(mock_repo)\n    result = await command.execute(CreateAuthorInput(name=\"New\"))\n\n    assert result.id == 1\n    mock_repo.create.assert_called_once()\n</code></pre>"},{"location":"architecture/design-patterns/#3-handler-tests","title":"3. Handler Tests","text":"<pre><code>def test_http_endpoint(client):\n    # Override dependency\n    app.dependency_overrides[get_author_repository] = lambda: MockRepo()\n\n    response = client.post(\"/authors\", json={\"name\": \"Test\"})\n    assert response.status_code == 201\n</code></pre>"},{"location":"architecture/design-patterns/#migration-guide","title":"Migration Guide","text":""},{"location":"architecture/design-patterns/#for-new-features","title":"For New Features","text":"<p>Use the new patterns from the start:</p> <ol> <li>Create Repository extending <code>BaseRepository</code></li> <li>Create Commands for business logic</li> <li>Setup Dependencies in <code>app/dependencies.py</code></li> <li>Create HTTP/WebSocket handlers using commands</li> </ol>"},{"location":"architecture/design-patterns/#for-existing-features","title":"For Existing Features","text":"<p>Gradual migration approach:</p> <ol> <li>Create repository for data access</li> <li>Create commands for business logic</li> <li>Create new endpoints using new patterns</li> <li>Keep old endpoints for backward compatibility</li> <li>Migrate clients to use new endpoints</li> <li>Remove old endpoints once migration complete</li> </ol>"},{"location":"architecture/design-patterns/#example-migration","title":"Example Migration","text":"<pre><code># BEFORE (old pattern)\n@router.get(\"/books-old\")\nasync def get_books_old():\n    async with async_session() as session:\n        return await Book.get_list(session)\n\n# AFTER (new pattern - runs alongside)\n@router.get(\"/books\")\nasync def get_books(repo: BookRepoDep):\n    command = GetBooksCommand(repo)\n    return await command.execute(GetBooksInput())\n</code></pre>"},{"location":"architecture/design-patterns/#best-practices","title":"Best Practices","text":""},{"location":"architecture/design-patterns/#1-keep-models-simple","title":"1. Keep Models Simple","text":"<p>\u274c Don't add business logic to models: <pre><code>class Author(SQLModel, table=True):\n    async def validate_unique_name(self):  # \u274c No!\n        ...\n</code></pre></p> <p>\u2705 Do keep models as data containers: <pre><code>class Author(SQLModel, table=True):\n    id: int | None = None\n    name: str\n    # Just data, no logic\n</code></pre></p>"},{"location":"architecture/design-patterns/#2-use-commands-for-business-logic","title":"2. Use Commands for Business Logic","text":"<p>\u274c Don't put logic in handlers: <pre><code>@router.post(\"/authors\")\nasync def create_author(data: dict):\n    # Validation logic here  # \u274c No!\n    if len(data[\"name\"]) &lt; 2:\n        raise ValueError(\"Too short\")\n    ...\n</code></pre></p> <p>\u2705 Do encapsulate in commands: <pre><code>class CreateAuthorCommand:\n    async def execute(self, input_data):\n        # Validation and business logic here  # \u2705 Yes!\n        ...\n</code></pre></p>"},{"location":"architecture/design-patterns/#3-type-everything","title":"3. Type Everything","text":"<pre><code># \u2705 Full type hints\nclass GetAuthorsCommand(BaseCommand[GetAuthorsInput, list[Author]]):\n    def __init__(self, repository: AuthorRepository) -&gt; None:\n        self.repository = repository\n\n    async def execute(self, input_data: GetAuthorsInput) -&gt; list[Author]:\n        ...\n</code></pre>"},{"location":"architecture/design-patterns/#4-test-in-isolation","title":"4. Test in Isolation","text":"<pre><code># \u2705 Test command without database\nasync def test_command():\n    mock_repo = AsyncMock()  # No real database!\n    command = CreateAuthorCommand(mock_repo)\n    result = await command.execute(CreateAuthorInput(name=\"Test\"))\n    assert result.name == \"Test\"\n</code></pre>"},{"location":"architecture/design-patterns/#references","title":"References","text":"<ul> <li>Repository Pattern - Martin Fowler</li> <li>Command Pattern - Refactoring Guru</li> <li>Dependency Injection in FastAPI</li> <li>Issue #29</li> </ul> <p>Last Updated: 2025-12-05 Author: Claude Code Status: \u2705 Active</p>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>Last Updated: 2025-11-25</p>"},{"location":"architecture/overview/#system-architecture","title":"System Architecture","text":"<p>This FastAPI application implements a dual-protocol API server supporting both HTTP REST and WebSocket connections with centralized authentication and authorization.</p>"},{"location":"architecture/overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          Client Layer                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  HTTP Clients              \u2502           WebSocket Clients        \u2502\n\u2502  (REST API calls)          \u2502           (Real-time bidirectional)\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                                  \u2502\n             v                                  v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  HTTP Endpoints            \u2502    \u2502  WebSocket Endpoint (/web)     \u2502\n\u2502  - /authors                \u2502    \u2502  - Connection auth             \u2502\n\u2502  - /health                 \u2502    \u2502  - Message routing             \u2502\n\u2502  - FastAPI routers         \u2502    \u2502  - PackageRouter dispatch      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                                 \u2502\n             v                                 v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Middleware Layer                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  1. AuthenticationMiddleware (Keycloak JWT validation)         \u2502\n\u2502  2. require_roles() dependency (RBAC permission checking)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n             v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Business Logic Layer                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  HTTP Handlers             \u2502           WebSocket Handlers       \u2502\n\u2502  - app/api/http/           \u2502           - app/api/ws/handlers/   \u2502\n\u2502                            \u2502           - Registered with        \u2502\n\u2502                            \u2502             @pkg_router.register() \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                                  \u2502\n             v                                  v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Managers &amp; Services                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  - RBACManager (permission checking)                            \u2502\n\u2502  - KeycloakManager (authentication)                             \u2502\n\u2502  - ConnectionManager (WebSocket connections)                    \u2502\n\u2502  - PackageRouter (WebSocket request routing)                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n             v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Data Layer                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  PostgreSQL Database       \u2502           Redis Cache              \u2502\n\u2502  - SQLModel/SQLAlchemy     \u2502           - Session management     \u2502\n\u2502  - Async operations        \u2502           - Pub/Sub                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/overview/#core-components","title":"Core Components","text":""},{"location":"architecture/overview/#1-request-flow","title":"1. Request Flow","text":""},{"location":"architecture/overview/#http-request-flow","title":"HTTP Request Flow","text":"<pre><code>Client Request\n    \u2193\nAuthenticationMiddleware (validates JWT)\n    \u2193\nrequire_roles() FastAPI dependency (checks RBAC permissions)\n    \u2193\nHTTP Handler (app/api/http/)\n    \u2193\nDatabase/Redis operations\n    \u2193\nResponse to Client\n</code></pre>"},{"location":"architecture/overview/#websocket-request-flow","title":"WebSocket Request Flow","text":"<pre><code>Client Connection\n    \u2193\nPackageAuthWebSocketEndpoint (validates JWT from query params)\n    \u2193\nConnection established\n    \u2193\nClient sends JSON message: {\"pkg_id\": 1, \"req_id\": \"uuid\", \"data\": {...}}\n    \u2193\nPackageRouter.handle_request()\n    \u2193\n1. Validate request format\n2. Check RBAC permissions (RBACManager)\n3. Validate data against JSON schema\n4. Dispatch to registered handler\n    \u2193\nHandler processes request\n    \u2193\nResponse: {\"pkg_id\": 1, \"req_id\": \"uuid\", \"status_code\": 0, \"data\": {...}}\n    \u2193\nSend to client via WebSocket\n</code></pre>"},{"location":"architecture/overview/#2-authentication-system","title":"2. Authentication System","text":"<p>Provider: Keycloak (OpenID Connect / OAuth 2.0)</p> <p>Components: - <code>app/auth.py</code> - Authentication backend for Starlette - <code>app/managers/keycloak_manager.py</code> - Keycloak client wrapper - <code>app/schemas/user.py</code> - User model with roles</p> <p>Token Flow: 1. User authenticates with Keycloak (username/password or SSO) 2. Keycloak returns JWT access token 3. Client includes token in requests:    - HTTP: <code>Authorization: Bearer &lt;token&gt;</code> header    - WebSocket: <code>?Authorization=Bearer &lt;token&gt;</code> query parameter 4. <code>AuthBackend.authenticate()</code> validates and decodes JWT 5. User object with roles attached to request context</p> <p>Configuration (see <code>app/settings.py</code>): - <code>KEYCLOAK_REALM</code> - Keycloak realm name - <code>KEYCLOAK_CLIENT_ID</code> - OAuth client ID - <code>KEYCLOAK_BASE_URL</code> - Keycloak server URL - <code>EXCLUDED_PATHS</code> - Paths that bypass authentication (e.g., /health)</p>"},{"location":"architecture/overview/#3-authorization-rbac","title":"3. Authorization (RBAC)","text":"<p>Current Implementation: Decorator-based roles defined in code</p> <p>Components: - <code>app/managers/rbac_manager.py</code> - Permission checking logic - <code>app/dependencies/permissions.py</code> - FastAPI dependency for HTTP endpoints - <code>app/routing.py</code> - PackageRouter with permissions registry</p> <p>Permission Definition:</p> <p>WebSocket Handlers: <pre><code>@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    roles=[\"get-authors\"]  # Permissions defined here\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n</code></pre></p> <p>HTTP Endpoints: <pre><code>from app.dependencies.permissions import require_roles\n\n@router.get(\n    \"/authors\",\n    dependencies=[Depends(require_roles(\"get-authors\"))]\n)\nasync def get_authors():\n    ...\n</code></pre></p> <p>Permission Checking: - WebSocket: <code>RBACManager.check_ws_permission(pkg_id, user)</code> - reads from <code>pkg_router.permissions_registry</code> - HTTP: <code>require_roles(*roles)</code> FastAPI dependency - Default policy: If no roles specified = public access</p>"},{"location":"architecture/overview/#4-websocket-package-router","title":"4. WebSocket Package Router","text":"<p>Purpose: Route WebSocket messages to appropriate handlers based on package ID (PkgID).</p> <p>Key Files: - <code>app/routing.py</code> - PackageRouter class - <code>app/api/ws/constants.py</code> - PkgID enum definitions - <code>app/api/ws/handlers/</code> - Handler implementations</p> <p>Handler Registration: <pre><code>@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    validator_callback=validator,\n    roles=[\"get-authors\"]  # Permission specification\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    # Handler implementation\n    pass\n</code></pre></p> <p>Request/Response Format: - Request: <code>{\"pkg_id\": 1, \"req_id\": \"uuid\", \"data\": {...}}</code> - Response: <code>{\"pkg_id\": 1, \"req_id\": \"uuid\", \"status_code\": 0, \"data\": {...}, \"meta\": null}</code></p> <p>Features: - Automatic JSON schema validation - RBAC permission checking - Request/response correlation via req_id - Error handling with status codes</p>"},{"location":"architecture/overview/#5-database-layer","title":"5. Database Layer","text":"<p>Technology: PostgreSQL with async SQLModel/SQLAlchemy</p> <p>Configuration (see <code>app/storage/db.py</code>): - Connection pooling (configurable pool size) - Async operations (asyncpg driver) - Automatic retry on connection failure</p> <p>Models: <code>app/models/</code> - Inherit from SQLModel with <code>table=True</code> - Support async operations - Class methods for common operations</p> <p>Pagination Helper: <pre><code>results, meta = await get_paginated_results(\n    Author,\n    page=1,\n    per_page=20,\n    filters={\"status\": \"active\"}\n)\n</code></pre></p>"},{"location":"architecture/overview/#6-connection-management","title":"6. Connection Management","text":"<p>WebSocket Connections: <code>app/managers/websocket_connection_manager.py</code> - Track active connections - Broadcast to all connected clients - Automatic cleanup on disconnect</p> <p>Redis Sessions: <code>app/storage/redis.py</code> - Session storage - Pub/sub for cross-instance communication - Connection pooling</p>"},{"location":"architecture/overview/#7-background-tasks","title":"7. Background Tasks","text":"<p>Location: <code>app/tasks/</code></p> <p>Current Tasks: - <code>kc_user_session_task</code> - Monitor Keycloak session expiration via Redis pub/sub</p> <p>Management: - Started in app startup handler - Graceful shutdown on app termination - Tracked in global tasks list</p>"},{"location":"architecture/overview/#design-patterns","title":"Design Patterns","text":""},{"location":"architecture/overview/#singleton-pattern","title":"Singleton Pattern","text":"<p>Used for managers that should have single instance: - <code>RBACManager</code> - <code>KeycloakManager</code> - Implemented via <code>SingletonMeta</code> metaclass</p>"},{"location":"architecture/overview/#decorator-pattern","title":"Decorator Pattern","text":"<p>Used for handler registration and enhancement: - <code>@pkg_router.register()</code> - WebSocket handler registration - <code>@router.get/post()</code> - HTTP endpoint registration - Proposed: <code>@require_roles()</code> for inline permission declarations</p>"},{"location":"architecture/overview/#repository-pattern","title":"Repository Pattern","text":"<p>Models encapsulate data access: - Class methods for CRUD operations - Async session management - Filter support</p>"},{"location":"architecture/overview/#configuration-management","title":"Configuration Management","text":"<p>File: <code>app/settings.py</code></p> <p>Technology: Pydantic Settings (loads from environment variables)</p> <p>Key Settings: - Database connection parameters - Keycloak configuration - Redis connection - Pool sizes and timeouts - Debug flags (development only)</p>"},{"location":"architecture/overview/#security-considerations","title":"Security Considerations","text":""},{"location":"architecture/overview/#current-security-measures","title":"Current Security Measures","text":"<ul> <li>\u2705 JWT-based authentication via Keycloak</li> <li>\u2705 RBAC for endpoint authorization</li> <li>\u2705 Middleware authentication ordering</li> <li>\u2705 Excluded paths for public endpoints</li> <li>\u2705 WebSocket authentication on connection</li> </ul>"},{"location":"architecture/overview/#known-issues-see-codebase-improvements","title":"Known Issues (see Codebase Improvements)","text":"<ul> <li>\u26a0\ufe0f Middleware order issue (#5)</li> <li>\u26a0\ufe0f Hardcoded credentials in settings (#6)</li> <li>\u26a0\ufe0f No rate limiting</li> <li>\u26a0\ufe0f No request correlation IDs</li> </ul>"},{"location":"architecture/overview/#performance-considerations","title":"Performance Considerations","text":""},{"location":"architecture/overview/#current-optimizations","title":"Current Optimizations","text":"<ul> <li>Async I/O throughout</li> <li>Database connection pooling</li> <li>Redis for caching and sessions</li> <li>Singleton managers</li> </ul>"},{"location":"architecture/overview/#potential-improvements","title":"Potential Improvements","text":"<ul> <li>Database query optimization (pagination)</li> <li>WebSocket broadcast concurrency</li> <li>Redis connection pool tuning</li> <li>Response caching</li> </ul>"},{"location":"architecture/overview/#scalability","title":"Scalability","text":""},{"location":"architecture/overview/#current-limitations","title":"Current Limitations","text":"<ul> <li>Single-instance architecture (WebSocket state)</li> <li>No load balancing strategy</li> <li>File-based RBAC configuration</li> </ul>"},{"location":"architecture/overview/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Multi-instance with Redis pub/sub</li> <li>Database-backed RBAC for runtime updates</li> <li>Distributed session management</li> <li>Horizontal scaling with load balancer</li> </ul>"},{"location":"architecture/overview/#testing-strategy","title":"Testing Strategy","text":"<p>Test Files: <code>tests/</code></p> <p>Current Coverage: ~57% (4 of 7 API files)</p> <p>Test Types: - Unit tests (handlers, managers) - Integration tests (marked with <code>@pytest.mark.integration</code>) - Mock-based authentication tests - Real Keycloak authentication tests</p> <p>See: Testing Guide</p>"},{"location":"architecture/overview/#deployment","title":"Deployment","text":""},{"location":"architecture/overview/#dependencies","title":"Dependencies","text":"<ul> <li>Python 3.13+</li> <li>PostgreSQL 12+</li> <li>Redis 6+</li> <li>Keycloak 20+</li> </ul>"},{"location":"architecture/overview/#environment","title":"Environment","text":"<ul> <li>Docker Compose for local development</li> <li>Environment variables for configuration</li> <li>Health check endpoint for monitoring</li> </ul>"},{"location":"architecture/overview/#startup-process","title":"Startup Process","text":"<ol> <li>Load settings from environment</li> <li>Initialize database connection</li> <li>Wait for database availability</li> <li>Register WebSocket handlers</li> <li>Register HTTP routers</li> <li>Start background tasks</li> <li>Start server</li> </ol>"},{"location":"architecture/overview/#related-documentation","title":"Related Documentation","text":"<ul> <li>RBAC System - Role-based access control implementation</li> <li>Design Patterns - Repository + Command + DI patterns</li> <li>Request Flow - Detailed sequence diagrams</li> <li>Testing Guide - How to test the application</li> <li>Authentication Guide - Working with Keycloak</li> </ul>"},{"location":"architecture/overview/#diagrams","title":"Diagrams","text":""},{"location":"architecture/overview/#component-interaction","title":"Component Interaction","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Client     \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   FastAPI    \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  Keycloak    \u2502\n\u2502              \u2502      \u2502  Application \u2502      \u2502    (Auth)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502        \u2502        \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u25bc\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502PostgreSQL\u2502 \u2502Redis \u2502 \u2502Mgrs   \u2502\n              \u2502   (DB)   \u2502 \u2502(Cache\u2502 \u2502(RBAC, \u2502\n              \u2502          \u2502 \u2502)     \u2502 \u2502Keycloak\u2502\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/overview/#maintenance","title":"Maintenance","text":"<p>Code Organization: - Follow existing package structure - Keep handlers thin (business logic in services/managers) - Use type hints throughout - Maintain 80%+ docstring coverage</p> <p>Adding New Features: 1. Define models in <code>app/models/</code> 2. Create schemas in <code>app/schemas/</code> 3. Implement handlers in <code>app/api/http/</code> or <code>app/api/ws/handlers/</code> 4. Specify required roles in handler decorators (WebSocket: <code>roles=[]</code>, HTTP: <code>require_roles()</code>) 5. Write tests in <code>tests/</code> 6. Update documentation</p>"},{"location":"architecture/rbac/","title":"RBAC System","text":"<p>Role-Based Access Control (RBAC) in this application uses a decorator-based approach where permissions are defined directly in handler code.</p>"},{"location":"architecture/rbac/#overview","title":"Overview","text":"<p>The RBAC system provides:</p> <ul> <li>Decorator-based permissions - Roles defined directly with handlers</li> <li>Type-safe - All permissions in Python code, not external files</li> <li>Co-located - Permissions live next to the code they protect</li> <li>Two protocols - Works for both HTTP and WebSocket</li> </ul>"},{"location":"architecture/rbac/#components","title":"Components","text":""},{"location":"architecture/rbac/#rbacmanager","title":"RBACManager","text":"<p>Singleton manager for permission checking:</p> <ul> <li><code>check_ws_permission(pkg_id, user)</code> - Validates WebSocket permissions</li> <li><code>require_roles(*roles)</code> - FastAPI dependency for HTTP endpoints</li> <li>Reads from <code>pkg_router.permissions_registry</code> for WebSocket</li> <li>No external configuration files needed</li> </ul> <p>Location: <code>app/managers/rbac_manager.py</code></p>"},{"location":"architecture/rbac/#permissions-registry","title":"Permissions Registry","text":"<p>The <code>PackageRouter</code> maintains a registry of required roles for each WebSocket handler:</p> <pre><code># Internal registry structure\npermissions_registry: dict[PkgID, list[str]] = {\n    PkgID.GET_AUTHORS: [\"get-authors\"],\n    PkgID.CREATE_AUTHOR: [\"create-author\", \"admin\"],\n    PkgID.DELETE_AUTHOR: [\"delete-author\", \"admin\"]\n}\n</code></pre>"},{"location":"architecture/rbac/#websocket-rbac","title":"WebSocket RBAC","text":""},{"location":"architecture/rbac/#defining-permissions","title":"Defining Permissions","text":"<p>Use the <code>roles</code> parameter in the <code>@pkg_router.register()</code> decorator:</p> <pre><code>from app.routing import pkg_router\nfrom app.api.ws.constants import PkgID\nfrom app.schemas.request import RequestModel\nfrom app.schemas.response import ResponseModel\n\n@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    roles=[\"get-authors\"]  # Required roles\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Get all authors - requires 'get-authors' role.\"\"\"\n    # Handler implementation\n    ...\n</code></pre>"},{"location":"architecture/rbac/#multiple-roles","title":"Multiple Roles","text":"<p>User must have ALL specified roles:</p> <pre><code>@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"delete-author\", \"admin\"]  # Requires BOTH roles\n)\nasync def delete_author_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Delete author - requires both 'delete-author' AND 'admin' roles.\"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#public-endpoints","title":"Public Endpoints","text":"<p>Omit the <code>roles</code> parameter for public access (no authentication required):</p> <pre><code>@pkg_router.register(\n    PkgID.PUBLIC_DATA,\n    json_schema=PublicDataSchema\n    # No roles parameter = public access\n)\nasync def public_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Public endpoint - no authentication required.\"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#http-rbac","title":"HTTP RBAC","text":""},{"location":"architecture/rbac/#defining-permissions_1","title":"Defining Permissions","text":"<p>Use the <code>require_roles()</code> FastAPI dependency:</p> <pre><code>from fastapi import APIRouter, Depends\nfrom app.dependencies.permissions import require_roles\nfrom app.schemas.author import Author\n\nrouter = APIRouter(prefix=\"/api\", tags=[\"authors\"])\n\n@router.get(\n    \"/authors\",\n    dependencies=[Depends(require_roles(\"get-authors\"))]\n)\nasync def get_authors() -&gt; list[Author]:\n    \"\"\"Get all authors - requires 'get-authors' role.\"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#multiple-roles_1","title":"Multiple Roles","text":"<p>User must have ALL specified roles:</p> <pre><code>@router.delete(\n    \"/authors/{author_id}\",\n    dependencies=[Depends(require_roles(\"delete-author\", \"admin\"))]\n)\nasync def delete_author(author_id: int):\n    \"\"\"Delete author - requires BOTH 'delete-author' AND 'admin' roles.\"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#public-endpoints_1","title":"Public Endpoints","text":"<p>Omit the <code>dependencies</code> parameter for public access:</p> <pre><code>@router.get(\"/health\")\nasync def health_check():\n    \"\"\"Public endpoint - no authentication required.\"\"\"\n    return {\"status\": \"healthy\"}\n</code></pre>"},{"location":"architecture/rbac/#permission-flow","title":"Permission Flow","text":""},{"location":"architecture/rbac/#http-request-flow","title":"HTTP Request Flow","text":"<pre><code>1. Client sends request with JWT token\n   \u2193\n2. AuthenticationMiddleware validates token\n   \u2193\n3. require_roles() dependency checks user roles\n   \u2193\n   \u251c\u2500 User has required roles \u2192 Continue to handler\n   \u2514\u2500 User missing roles \u2192 Return 403 Forbidden\n</code></pre>"},{"location":"architecture/rbac/#websocket-request-flow","title":"WebSocket Request Flow","text":"<pre><code>1. Client connects with JWT token in query params\n   \u2193\n2. PackageAuthWebSocketEndpoint validates token\n   \u2193\n3. Client sends message with pkg_id\n   \u2193\n4. PackageRouter.handle_request() checks permissions\n   \u2193\n5. RBACManager.check_ws_permission(pkg_id, user)\n   \u2193\n   \u251c\u2500 User has required roles \u2192 Dispatch to handler\n   \u2514\u2500 User missing roles \u2192 Return error response\n</code></pre>"},{"location":"architecture/rbac/#role-management","title":"Role Management","text":""},{"location":"architecture/rbac/#defining-roles-in-keycloak","title":"Defining Roles in Keycloak","text":"<p>Roles are managed in Keycloak:</p> <ol> <li>Log into Keycloak Admin Console</li> <li>Select your realm</li> <li>Navigate to Roles \u2192 Realm roles</li> <li>Click Create role</li> <li>Define role name (e.g., <code>get-authors</code>, <code>create-author</code>)</li> </ol>"},{"location":"architecture/rbac/#assigning-roles-to-users","title":"Assigning Roles to Users","text":"<ol> <li>Navigate to Users in Keycloak Admin</li> <li>Select the user</li> <li>Go to Role mapping tab</li> <li>Click Assign role</li> <li>Select the roles to assign</li> </ol>"},{"location":"architecture/rbac/#role-naming-convention","title":"Role Naming Convention","text":"<p>Follow these conventions for consistency:</p> <ul> <li>Use kebab-case: <code>get-authors</code>, <code>create-author</code></li> <li>Use descriptive names: <code>delete-author</code> not <code>del-auth</code></li> <li>Resource-action format: <code>{action}-{resource}</code></li> <li>Examples:</li> <li><code>get-authors</code> - View authors</li> <li><code>create-author</code> - Create new authors</li> <li><code>update-author</code> - Modify authors</li> <li><code>delete-author</code> - Remove authors</li> <li><code>admin</code> - Administrative privileges</li> </ul>"},{"location":"architecture/rbac/#common-patterns","title":"Common Patterns","text":""},{"location":"architecture/rbac/#read-only-access","title":"Read-Only Access","text":"<pre><code># WebSocket\n@pkg_router.register(PkgID.GET_AUTHORS, roles=[\"viewer\"])\n\n# HTTP\n@router.get(\"/authors\", dependencies=[Depends(require_roles(\"viewer\"))])\n</code></pre>"},{"location":"architecture/rbac/#write-access","title":"Write Access","text":"<pre><code># WebSocket\n@pkg_router.register(PkgID.CREATE_AUTHOR, roles=[\"editor\"])\n\n# HTTP\n@router.post(\"/authors\", dependencies=[Depends(require_roles(\"editor\"))])\n</code></pre>"},{"location":"architecture/rbac/#admin-only-access","title":"Admin-Only Access","text":"<pre><code># WebSocket\n@pkg_router.register(PkgID.DELETE_AUTHOR, roles=[\"admin\"])\n\n# HTTP\n@router.delete(\"/authors/{id}\", dependencies=[Depends(require_roles(\"admin\"))])\n</code></pre>"},{"location":"architecture/rbac/#combined-permissions","title":"Combined Permissions","text":"<p>Require both a specific permission AND admin role:</p> <pre><code># WebSocket\n@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"delete-author\", \"admin\"]\n)\n\n# HTTP\n@router.delete(\n    \"/authors/{id}\",\n    dependencies=[Depends(require_roles(\"delete-author\", \"admin\"))]\n)\n</code></pre>"},{"location":"architecture/rbac/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/rbac/#permission-denied-403","title":"Permission Denied (403)","text":"<p>Symptom: Users get 403 Forbidden errors</p> <p>Diagnosis: <pre><code># Check user roles in Keycloak\n# Admin Console \u2192 Users \u2192 &lt;user&gt; \u2192 Role Mappings\n\n# Check handler code for required roles\n# WebSocket: @pkg_router.register(PkgID.*, roles=[\"role-name\"])\n# HTTP: dependencies=[Depends(require_roles(\"role-name\"))]\n\n# Check application logs\ndocker logs hw-server | grep -i \"permission\\|rbac\"\n</code></pre></p> <p>Solution:</p> <ol> <li>Verify user has the required role(s) in Keycloak</li> <li>Check handler decorator to see what roles are required</li> <li>Ensure JWT token includes the roles (check token claims)</li> </ol>"},{"location":"architecture/rbac/#finding-required-roles","title":"Finding Required Roles","text":"<p>To find what roles are required for an endpoint:</p> <p>WebSocket: <pre><code># Search handler code\ngrep -r \"@pkg_router.register\" app/api/ws/handlers/ | grep \"PkgID.YOUR_HANDLER\"\n</code></pre></p> <p>HTTP: <pre><code># Search endpoint code\ngrep -r \"require_roles\" app/api/http/\n</code></pre></p>"},{"location":"architecture/rbac/#testing-rbac","title":"Testing RBAC","text":"<pre><code># tests/test_rbac.py\nimport pytest\nfrom app.managers.rbac_manager import RBACManager\nfrom app.schemas.user import UserModel\n\ndef test_user_with_correct_role():\n    \"\"\"Test user with correct role can access endpoint.\"\"\"\n    user = UserModel(\n        sub=\"user123\",\n        username=\"testuser\",\n        roles=[\"get-authors\"]\n    )\n    rbac = RBACManager()\n\n    # Should allow access\n    assert rbac.check_ws_permission(PkgID.GET_AUTHORS, user) is True\n\ndef test_user_without_role():\n    \"\"\"Test user without role is denied access.\"\"\"\n    user = UserModel(\n        sub=\"user123\",\n        username=\"testuser\",\n        roles=[\"viewer\"]  # Missing 'get-authors'\n    )\n    rbac = RBACManager()\n\n    # Should deny access\n    assert rbac.check_ws_permission(PkgID.GET_AUTHORS, user) is False\n</code></pre>"},{"location":"architecture/rbac/#best-practices","title":"Best Practices","text":""},{"location":"architecture/rbac/#1-principle-of-least-privilege","title":"1. Principle of Least Privilege","text":"<p>Only grant the minimum roles needed:</p> <pre><code># Good - specific permission\n@pkg_router.register(PkgID.GET_AUTHORS, roles=[\"get-authors\"])\n\n# Avoid - overly broad\n@pkg_router.register(PkgID.GET_AUTHORS, roles=[\"admin\"])\n</code></pre>"},{"location":"architecture/rbac/#2-descriptive-role-names","title":"2. Descriptive Role Names","text":"<p>Use clear, descriptive role names:</p> <pre><code># Good\nroles=[\"create-author\", \"update-author\"]\n\n# Avoid\nroles=[\"writer\", \"modifier\"]\n</code></pre>"},{"location":"architecture/rbac/#3-co-locate-permissions","title":"3. Co-locate Permissions","text":"<p>Define permissions next to the code they protect:</p> <pre><code># Good - roles defined with handler\n@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"delete-author\", \"admin\"]\n)\nasync def delete_author_handler(request: RequestModel):\n    ...\n\n# This makes it obvious what roles are required\n</code></pre>"},{"location":"architecture/rbac/#4-document-role-requirements","title":"4. Document Role Requirements","text":"<p>Add docstrings explaining what roles are required:</p> <pre><code>@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"delete-author\", \"admin\"]\n)\nasync def delete_author_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"\n    Delete an author.\n\n    Requires BOTH 'delete-author' AND 'admin' roles.\n    User must have all specified roles to access this endpoint.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#5-test-rbac-logic","title":"5. Test RBAC Logic","text":"<p>Always write tests for permission checks:</p> <pre><code># Test both allowed and denied scenarios\ndef test_authorized_access():\n    \"\"\"Test user with correct roles can access.\"\"\"\n    ...\n\ndef test_unauthorized_access():\n    \"\"\"Test user without roles is denied.\"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#security-considerations","title":"Security Considerations","text":""},{"location":"architecture/rbac/#token-validation","title":"Token Validation","text":"<ul> <li>JWT tokens are validated on every request</li> <li>Expired tokens are automatically rejected</li> <li>Token signature is verified against Keycloak public key</li> </ul>"},{"location":"architecture/rbac/#role-extraction","title":"Role Extraction","text":"<ul> <li>Roles are extracted from <code>realm_access.roles</code> in JWT</li> <li>Only roles from the configured Keycloak realm are used</li> <li>Invalid or missing role claims result in empty role list</li> </ul>"},{"location":"architecture/rbac/#permission-checking","title":"Permission Checking","text":"<ul> <li>User must have ALL required roles (AND logic)</li> <li>No roles specified = public access (use cautiously)</li> <li>Permission denied returns 403 Forbidden (not 401)</li> </ul>"},{"location":"architecture/rbac/#related-documentation","title":"Related Documentation","text":"<ul> <li>Authentication Guide - Setting up Keycloak and users</li> <li>HTTP API Reference - HTTP endpoint documentation</li> <li>WebSocket API Reference - WebSocket handler documentation</li> <li>Testing Guide - Testing RBAC logic</li> </ul>"},{"location":"architecture/request-flow/","title":"Sequence Diagrams","text":"<p>This document provides detailed sequence diagrams for key flows in the application.</p>"},{"location":"architecture/request-flow/#authentication-flow","title":"Authentication Flow","text":""},{"location":"architecture/request-flow/#http-login-flow","title":"HTTP Login Flow","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant FastAPI\n    participant KeycloakManager\n    participant Keycloak\n    participant Redis\n\n    Client-&gt;&gt;FastAPI: POST /login {username, password}\n    FastAPI-&gt;&gt;KeycloakManager: login(username, password)\n    KeycloakManager-&gt;&gt;Keycloak: Token request (OAuth2 password grant)\n    Keycloak--&gt;&gt;KeycloakManager: {access_token, refresh_token, expires_in}\n    KeycloakManager--&gt;&gt;FastAPI: Token data\n    FastAPI-&gt;&gt;Redis: Store user session\n    Redis--&gt;&gt;FastAPI: OK\n    FastAPI--&gt;&gt;Client: {access_token, refresh_token, expires_in}</code></pre>"},{"location":"architecture/request-flow/#websocket-authentication-flow","title":"WebSocket Authentication Flow","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant WebSocket\n    participant AuthBackend\n    participant Keycloak\n    participant ConnectionLimiter\n    participant ConnectionManager\n\n    Client-&gt;&gt;WebSocket: Connect ws://host/web?token=&lt;jwt&gt;\n    WebSocket-&gt;&gt;AuthBackend: authenticate(connection)\n    AuthBackend-&gt;&gt;AuthBackend: Extract token from query params\n    AuthBackend-&gt;&gt;Keycloak: Validate JWT signature\n    Keycloak--&gt;&gt;AuthBackend: Token valid, user claims\n    AuthBackend--&gt;&gt;WebSocket: UserModel(sub, roles, ...)\n    WebSocket-&gt;&gt;ConnectionLimiter: check_limit(user_id)\n\n    alt Connection limit exceeded\n        ConnectionLimiter--&gt;&gt;WebSocket: Limit exceeded\n        WebSocket--&gt;&gt;Client: Close 1008 (Policy Violation)\n    else Limit OK\n        ConnectionLimiter--&gt;&gt;WebSocket: OK\n        WebSocket-&gt;&gt;ConnectionManager: connect(websocket)\n        ConnectionManager--&gt;&gt;WebSocket: Connection added\n        WebSocket--&gt;&gt;Client: Connection established\n    end</code></pre>"},{"location":"architecture/request-flow/#http-request-flow","title":"HTTP Request Flow","text":""},{"location":"architecture/request-flow/#get-authors-with-filtering","title":"GET /authors with Filtering","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant PrometheusMiddleware\n    participant RateLimitMiddleware\n    participant AuthMiddleware\n    participant Handler\n    participant RBACDependency as require_roles()\n    participant Database\n\n    Client-&gt;&gt;PrometheusMiddleware: GET /authors?name=John\n    PrometheusMiddleware-&gt;&gt;PrometheusMiddleware: Start metrics timer\n    PrometheusMiddleware-&gt;&gt;RateLimitMiddleware: Forward request\n\n    RateLimitMiddleware-&gt;&gt;RateLimitMiddleware: Get rate limit key\n    RateLimitMiddleware-&gt;&gt;RateLimitMiddleware: Check Redis counter\n\n    alt Rate limit exceeded\n        RateLimitMiddleware--&gt;&gt;Client: 429 Too Many Requests\n    else Rate limit OK\n        RateLimitMiddleware-&gt;&gt;AuthMiddleware: Forward request\n\n        AuthMiddleware-&gt;&gt;AuthMiddleware: Extract Authorization header\n        AuthMiddleware-&gt;&gt;AuthMiddleware: Validate JWT token\n        AuthMiddleware-&gt;&gt;AuthMiddleware: Populate request.state.user\n\n        alt Invalid token\n            AuthMiddleware--&gt;&gt;Client: 401 Unauthorized\n        else Valid token\n            AuthMiddleware-&gt;&gt;RBACDependency: Check permissions (FastAPI dependency)\n\n            RBACDependency-&gt;&gt;RBACDependency: Verify user has required roles\n\n            alt Permission denied\n                RBACDependency--&gt;&gt;Client: 403 Forbidden\n            else Permission granted\n                RBACDependency-&gt;&gt;Handler: Forward to endpoint\n\n                Handler-&gt;&gt;Handler: Validate query params\n                Handler-&gt;&gt;Database: SELECT * FROM author WHERE name ILIKE '%John%'\n                Database--&gt;&gt;Handler: [Author rows]\n                Handler--&gt;&gt;RBACDependency: [Author list]\n                RBACDependency--&gt;&gt;AuthMiddleware: Response\n                AuthMiddleware--&gt;&gt;RateLimitMiddleware: Response\n                RateLimitMiddleware-&gt;&gt;RateLimitMiddleware: Add X-RateLimit headers\n                RateLimitMiddleware--&gt;&gt;PrometheusMiddleware: Response\n                PrometheusMiddleware-&gt;&gt;PrometheusMiddleware: Record metrics\n                PrometheusMiddleware--&gt;&gt;Client: 200 OK + [Authors]\n            end\n        end\n    end</code></pre>"},{"location":"architecture/request-flow/#post-authors-create","title":"POST /authors (Create)","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Middleware\n    participant Handler\n    participant Session\n    participant Database\n\n    Client-&gt;&gt;Middleware: POST /authors {name: \"New Author\"}\n    Note over Middleware: Authentication &amp; Authorization\n    Middleware-&gt;&gt;Handler: Validated request\n\n    Handler-&gt;&gt;Handler: Validate request body (Pydantic)\n\n    alt Validation error\n        Handler--&gt;&gt;Client: 422 Validation Error\n    else Valid data\n        Handler-&gt;&gt;Session: async with async_session()\n        Session--&gt;&gt;Handler: Session context\n\n        Handler-&gt;&gt;Handler: Author.create(session, author)\n        Handler-&gt;&gt;Database: INSERT INTO author VALUES (...)\n        Database--&gt;&gt;Handler: Author with ID\n\n        Handler-&gt;&gt;Database: COMMIT transaction\n        Database--&gt;&gt;Handler: OK\n\n        Handler--&gt;&gt;Client: 200 OK + {id: 1, name: \"New Author\"}\n    end</code></pre>"},{"location":"architecture/request-flow/#websocket-request-flow","title":"WebSocket Request Flow","text":""},{"location":"architecture/request-flow/#get_authors-request-pkgid-1","title":"GET_AUTHORS Request (PkgID: 1)","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant WebEndpoint\n    participant RateLimiter\n    participant PackageRouter\n    participant RBACManager\n    participant Handler\n    participant Database\n\n    Client-&gt;&gt;WebEndpoint: Send JSON: {pkg_id: 1, req_id: \"uuid\", data: {filters: {name: \"John\"}}}\n\n    WebEndpoint-&gt;&gt;WebEndpoint: Parse JSON message\n    WebEndpoint-&gt;&gt;WebEndpoint: Create RequestModel\n\n    WebEndpoint-&gt;&gt;RateLimiter: check_rate_limit(user_id)\n\n    alt Rate limit exceeded\n        RateLimiter--&gt;&gt;WebEndpoint: Limit exceeded\n        WebEndpoint--&gt;&gt;Client: {status_code: 1, msg: \"Rate limit exceeded\"}\n    else Rate OK\n        RateLimiter--&gt;&gt;WebEndpoint: OK\n\n        WebEndpoint-&gt;&gt;PackageRouter: handle_request(request)\n\n        PackageRouter-&gt;&gt;RBACManager: check_ws_permission(pkg_id, user)\n\n        alt Permission denied\n            RBACManager--&gt;&gt;PackageRouter: Permission denied\n            PackageRouter--&gt;&gt;WebEndpoint: {status_code: 3, msg: \"Permission denied\"}\n            WebEndpoint--&gt;&gt;Client: Error response\n        else Permission granted\n            RBACManager--&gt;&gt;PackageRouter: OK\n\n            PackageRouter-&gt;&gt;PackageRouter: Validate data against JSON schema\n\n            alt Schema validation error\n                PackageRouter--&gt;&gt;WebEndpoint: {status_code: 2, msg: \"Invalid data\"}\n                WebEndpoint--&gt;&gt;Client: Error response\n            else Valid schema\n                PackageRouter-&gt;&gt;Handler: Execute handler(request)\n\n                Handler-&gt;&gt;Database: SELECT * FROM author WHERE name ILIKE '%John%'\n                Database--&gt;&gt;Handler: [Author rows]\n\n                Handler-&gt;&gt;Handler: Build ResponseModel\n                Handler--&gt;&gt;PackageRouter: {status_code: 0, data: [...]}\n\n                PackageRouter--&gt;&gt;WebEndpoint: ResponseModel\n                WebEndpoint--&gt;&gt;Client: {pkg_id: 1, req_id: \"uuid\", status_code: 0, data: [...]}\n            end\n        end\n    end</code></pre>"},{"location":"architecture/request-flow/#get_paginated_authors-request-pkgid-2","title":"GET_PAGINATED_AUTHORS Request (PkgID: 2)","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant WebEndpoint\n    participant PackageRouter\n    participant Handler\n    participant PaginationUtil\n    participant Database\n\n    Client-&gt;&gt;WebEndpoint: {pkg_id: 2, req_id: \"uuid\", data: {page: 1, per_page: 20}}\n\n    Note over WebEndpoint: Rate limiting &amp; auth checks passed\n\n    WebEndpoint-&gt;&gt;PackageRouter: handle_request(request)\n    PackageRouter-&gt;&gt;Handler: get_paginated_authors_handler(request)\n\n    Handler-&gt;&gt;PaginationUtil: get_paginated_results(Author, page=1, per_page=20)\n\n    PaginationUtil-&gt;&gt;Database: SELECT COUNT(id) FROM author\n    Database--&gt;&gt;PaginationUtil: total=42\n\n    PaginationUtil-&gt;&gt;PaginationUtil: Calculate pages (42/20 = 3)\n\n    PaginationUtil-&gt;&gt;Database: SELECT * FROM author OFFSET 0 LIMIT 20\n    Database--&gt;&gt;PaginationUtil: [20 Author rows]\n\n    PaginationUtil--&gt;&gt;Handler: (results, MetadataModel{page: 1, per_page: 20, total: 42, pages: 3})\n\n    Handler-&gt;&gt;Handler: Build ResponseModel with meta\n    Handler--&gt;&gt;WebEndpoint: {status_code: 0, data: [...], meta: {...}}\n\n    WebEndpoint--&gt;&gt;Client: Complete response with pagination metadata</code></pre>"},{"location":"architecture/request-flow/#broadcast-flow","title":"Broadcast Flow","text":""},{"location":"architecture/request-flow/#server-initiated-broadcast","title":"Server-Initiated Broadcast","text":"<pre><code>sequenceDiagram\n    participant BackgroundTask\n    participant ConnectionManager\n    participant WebSocket1\n    participant WebSocket2\n    participant WebSocket3\n    participant Client1\n    participant Client2\n    participant Client3\n\n    BackgroundTask-&gt;&gt;BackgroundTask: Event occurs (e.g., data update)\n    BackgroundTask-&gt;&gt;BackgroundTask: Build BroadcastDataModel\n    BackgroundTask-&gt;&gt;ConnectionManager: broadcast(message)\n\n    ConnectionManager-&gt;&gt;ConnectionManager: Create connections snapshot\n    ConnectionManager-&gt;&gt;ConnectionManager: asyncio.gather(...)\n\n    par Broadcast to all clients\n        ConnectionManager-&gt;&gt;WebSocket1: send_json(message)\n        WebSocket1--&gt;&gt;Client1: {pkg_id: 1, req_id: \"00000000-...\", data: {...}}\n    and\n        ConnectionManager-&gt;&gt;WebSocket2: send_json(message)\n        WebSocket2--&gt;&gt;Client2: {pkg_id: 1, req_id: \"00000000-...\", data: {...}}\n    and\n        ConnectionManager-&gt;&gt;WebSocket3: send_json(message)\n\n        Note over WebSocket3: Connection failed\n        WebSocket3--xClient3: Exception\n        ConnectionManager-&gt;&gt;ConnectionManager: Safe error handling\n        ConnectionManager-&gt;&gt;ConnectionManager: disconnect(WebSocket3)\n    end\n\n    ConnectionManager--&gt;&gt;BackgroundTask: Broadcast complete</code></pre>"},{"location":"architecture/request-flow/#rate-limiting-flow","title":"Rate Limiting Flow","text":""},{"location":"architecture/request-flow/#sliding-window-rate-limiting","title":"Sliding Window Rate Limiting","text":"<pre><code>sequenceDiagram\n    participant Request\n    participant RateLimiter\n    participant Redis\n\n    Request-&gt;&gt;RateLimiter: check_rate_limit(key=\"user:john\", limit=60, window=60s)\n\n    RateLimiter-&gt;&gt;RateLimiter: current_time = now()\n    RateLimiter-&gt;&gt;RateLimiter: window_start = current_time - 60\n\n    RateLimiter-&gt;&gt;Redis: ZREMRANGEBYSCORE(key, -inf, window_start)\n    Note over Redis: Remove old requests outside window\n    Redis--&gt;&gt;RateLimiter: Removed count\n\n    RateLimiter-&gt;&gt;Redis: ZCARD(key)\n    Note over Redis: Count requests in current window\n    Redis--&gt;&gt;RateLimiter: current_count=45\n\n    alt current_count &gt;= limit\n        RateLimiter--&gt;&gt;Request: (False, 0) - Rate limit exceeded\n        Note over Request: Return 429 error\n    else current_count &lt; limit\n        RateLimiter-&gt;&gt;Redis: ZADD(key, current_time, request_id)\n        Note over Redis: Add current request to set\n        Redis--&gt;&gt;RateLimiter: OK\n\n        RateLimiter-&gt;&gt;Redis: EXPIRE(key, window * 2)\n        Note over Redis: Set TTL for automatic cleanup\n        Redis--&gt;&gt;RateLimiter: OK\n\n        RateLimiter-&gt;&gt;RateLimiter: remaining = limit - current_count - 1\n        RateLimiter--&gt;&gt;Request: (True, remaining) - Request allowed\n        Note over Request: Continue processing\n    end</code></pre>"},{"location":"architecture/request-flow/#websocket-connection-limiting","title":"WebSocket Connection Limiting","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant WebSocket\n    participant ConnectionLimiter\n    participant Redis\n\n    Client-&gt;&gt;WebSocket: Connect (user_id=\"user123\")\n    WebSocket-&gt;&gt;ConnectionLimiter: add_connection(user_id, connection_id)\n\n    ConnectionLimiter-&gt;&gt;Redis: SADD(\"ws:connections:user123\", connection_id)\n    Redis--&gt;&gt;ConnectionLimiter: OK\n\n    ConnectionLimiter-&gt;&gt;Redis: SCARD(\"ws:connections:user123\")\n    Note over Redis: Count connections for user\n    Redis--&gt;&gt;ConnectionLimiter: count=5\n\n    alt count &gt; max_connections (e.g., 5)\n        ConnectionLimiter-&gt;&gt;Redis: SREM(\"ws:connections:user123\", connection_id)\n        Redis--&gt;&gt;ConnectionLimiter: OK\n        ConnectionLimiter--&gt;&gt;WebSocket: False - Limit exceeded\n        WebSocket--&gt;&gt;Client: Close 1008 (Policy Violation)\n    else count &lt;= max_connections\n        ConnectionLimiter--&gt;&gt;WebSocket: True - Connection allowed\n        WebSocket--&gt;&gt;Client: Connection established\n    end</code></pre>"},{"location":"architecture/request-flow/#error-handling-flow","title":"Error Handling Flow","text":""},{"location":"architecture/request-flow/#handler-error-recovery","title":"Handler Error Recovery","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Handler\n    participant Database\n    participant Logger\n\n    Client-&gt;&gt;Handler: Request with valid data\n\n    Handler-&gt;&gt;Database: Execute query\n\n    alt Database error (SQLAlchemyError)\n        Database--xHandler: SQLAlchemyError\n        Handler-&gt;&gt;Logger: log.error(\"Database error: ...\")\n        Handler-&gt;&gt;Handler: Build error ResponseModel\n        Handler--&gt;&gt;Client: {status_code: 1, msg: \"Database error occurred\"}\n    else Validation error\n        Database--&gt;&gt;Handler: Success\n        Handler-&gt;&gt;Handler: Process results\n        Handler-&gt;&gt;Handler: Validation fails\n        Handler-&gt;&gt;Logger: log.error(\"Validation error: ...\")\n        Handler--&gt;&gt;Client: {status_code: 2, msg: \"Invalid data\"}\n    else Unexpected error\n        Database--&gt;&gt;Handler: Success\n        Handler-&gt;&gt;Handler: Processing...\n        Handler--xHandler: Unexpected exception\n        Note over Handler: Exception propagates up\n        Handler-&gt;&gt;Logger: log.exception(\"Unexpected error\")\n        Handler--&gt;&gt;Client: {status_code: 1, msg: \"Internal error\"}\n    else Success\n        Database--&gt;&gt;Handler: Results\n        Handler-&gt;&gt;Handler: Process and format\n        Handler--&gt;&gt;Client: {status_code: 0, data: [...]}\n    end</code></pre>"},{"location":"architecture/request-flow/#health-check-flow","title":"Health Check Flow","text":""},{"location":"architecture/request-flow/#health-check-with-dependency-verification","title":"Health Check with Dependency Verification","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant HealthEndpoint\n    participant Database\n    participant Redis\n\n    Client-&gt;&gt;HealthEndpoint: GET /health\n\n    par Check all dependencies\n        HealthEndpoint-&gt;&gt;Database: SELECT 1\n\n        alt Database OK\n            Database--&gt;&gt;HealthEndpoint: Success\n            HealthEndpoint-&gt;&gt;HealthEndpoint: db_status = \"healthy\"\n        else Database failed\n            Database--xHealthEndpoint: Exception\n            HealthEndpoint-&gt;&gt;HealthEndpoint: db_status = \"unhealthy\"\n        end\n    and\n        HealthEndpoint-&gt;&gt;Redis: PING\n\n        alt Redis OK\n            Redis--&gt;&gt;HealthEndpoint: PONG\n            HealthEndpoint-&gt;&gt;HealthEndpoint: redis_status = \"healthy\"\n        else Redis failed\n            Redis--xHealthEndpoint: Exception\n            HealthEndpoint-&gt;&gt;HealthEndpoint: redis_status = \"unhealthy\"\n        end\n    end\n\n    HealthEndpoint-&gt;&gt;HealthEndpoint: Aggregate statuses\n\n    alt All healthy\n        HealthEndpoint--&gt;&gt;Client: 200 OK {status: \"healthy\", database: \"healthy\", redis: \"healthy\"}\n    else Any unhealthy\n        HealthEndpoint--&gt;&gt;Client: 503 Service Unavailable {status: \"unhealthy\", ...}\n    end</code></pre>"},{"location":"architecture/request-flow/#metrics-collection-flow","title":"Metrics Collection Flow","text":""},{"location":"architecture/request-flow/#prometheus-metrics-scraping","title":"Prometheus Metrics Scraping","text":"<pre><code>sequenceDiagram\n    participant Prometheus\n    participant MetricsEndpoint\n    participant MetricsRegistry\n\n    loop Every scrape_interval (15s)\n        Prometheus-&gt;&gt;MetricsEndpoint: GET /metrics\n\n        MetricsEndpoint-&gt;&gt;MetricsRegistry: Collect all metrics\n\n        MetricsRegistry-&gt;&gt;MetricsRegistry: Gather HTTP request counters\n        MetricsRegistry-&gt;&gt;MetricsRegistry: Gather WebSocket metrics\n        MetricsRegistry-&gt;&gt;MetricsRegistry: Gather application metrics\n\n        MetricsRegistry--&gt;&gt;MetricsEndpoint: Metrics in text format\n\n        MetricsEndpoint--&gt;&gt;Prometheus: text/plain metrics\n        Note over MetricsEndpoint,Prometheus: # HELP http_requests_total...&lt;br/&gt;# TYPE http_requests_total counter&lt;br/&gt;http_requests_total{...} 1234.0\n\n        Prometheus-&gt;&gt;Prometheus: Store time series data\n        Prometheus-&gt;&gt;Prometheus: Evaluate alerting rules\n    end</code></pre>"},{"location":"architecture/request-flow/#notes","title":"Notes","text":"<p>These diagrams use Mermaid syntax and can be rendered using: - GitHub (automatic rendering) - Mermaid Live Editor: https://mermaid.live/ - VS Code with Mermaid extension - Documentation tools that support Mermaid</p> <p>For complex flows, refer to the source code in: - <code>app/middlewares/</code> - Middleware implementations - <code>app/routing.py</code> - WebSocket routing logic - <code>app/api/ws/handlers/</code> - WebSocket handlers - <code>app/api/http/</code> - HTTP handlers</p>"},{"location":"cookiecutter/","title":"Cookiecutter Template","text":"<p>This project can be used as a Cookiecutter template to generate new projects.</p>"},{"location":"cookiecutter/#contents","title":"Contents","text":"<ul> <li>Overview - Template features and structure</li> <li>Customization - Customizing the generated project</li> <li>Examples - Example projects built with this template</li> </ul>"},{"location":"cookiecutter/#quick-start","title":"Quick Start","text":"<p>```bash</p>"},{"location":"cookiecutter/#install-cookiecutter","title":"Install cookiecutter","text":"<p>pip install cookiecutter</p>"},{"location":"cookiecutter/#generate-new-project","title":"Generate new project","text":"<p>cookiecutter gh:acikabubo/fastapi-http-websocket</p>"},{"location":"cookiecutter/#follow-the-prompts-to-customize-your-project","title":"Follow the prompts to customize your project","text":"<p>```</p> <p>See Overview for more information.</p>"},{"location":"deployment/","title":"Deployment","text":"<p>Production deployment guides and operational documentation.</p>"},{"location":"deployment/#deployment-guides","title":"Deployment Guides","text":"<ul> <li>Docker Deployment - Container-based deployment</li> <li>Production Setup - Production configuration and best practices</li> <li>Security Guide - Security hardening and best practices</li> <li>Monitoring &amp; Observability - Setting up monitoring stack</li> <li>Troubleshooting - Common issues and solutions</li> <li>Backup &amp; Recovery - Data protection strategies</li> </ul>"},{"location":"deployment/#quick-deploy","title":"Quick Deploy","text":"<p>```bash</p>"},{"location":"deployment/#using-docker-compose","title":"Using Docker Compose","text":"<p>docker-compose -f docker-compose.prod.yml up -d</p>"},{"location":"deployment/#or-using-the-makefile","title":"Or using the Makefile","text":"<p>make deploy-prod ```</p> <p>See Production Setup for detailed deployment procedures.</p>"},{"location":"deployment/backup-recovery/","title":"Backup and Recovery Guide","text":"<p>This guide covers comprehensive backup strategies, disaster recovery procedures, and data protection for the FastAPI HTTP/WebSocket application.</p>"},{"location":"deployment/backup-recovery/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Backup Strategy Overview</li> <li>Database Backups</li> <li>Redis Backups</li> <li>Configuration Backups</li> <li>Volume Backups</li> <li>Automated Backup Scripts</li> <li>Backup Verification</li> <li>Disaster Recovery</li> <li>Point-in-Time Recovery</li> <li>Testing Recovery Procedures</li> </ul>"},{"location":"deployment/backup-recovery/#backup-strategy-overview","title":"Backup Strategy Overview","text":""},{"location":"deployment/backup-recovery/#backup-types","title":"Backup Types","text":"Component Backup Type Frequency Retention Priority PostgreSQL Database Full + WAL Full: DailyWAL: Continuous 30 days full7 days WAL Critical Redis Data Snapshot + AOF Snapshot: HourlyAOF: Continuous 7 days High Configuration Files Full copy On change + Daily 30 days High Docker Volumes Tarball Weekly 4 weeks Medium Keycloak Database Full dump Daily 30 days Critical Application Logs Archive Daily 90 days Medium"},{"location":"deployment/backup-recovery/#backup-locations","title":"Backup Locations","text":"<p>Primary Backup Storage: - Local: <code>/backups</code> directory (bind-mounted volume) - Network: NFS/CIFS share for immediate access</p> <p>Secondary Backup Storage: - Cloud: S3-compatible storage (AWS S3, MinIO, etc.) - Offsite: Remote backup server via rsync/restic</p>"},{"location":"deployment/backup-recovery/#rto-and-rpo-targets","title":"RTO and RPO Targets","text":"<ul> <li>RTO (Recovery Time Objective): 1 hour</li> <li>RPO (Recovery Point Objective): 15 minutes</li> <li>Database corruption detection: Within 6 hours</li> <li>Backup restoration testing: Monthly</li> </ul>"},{"location":"deployment/backup-recovery/#database-backups","title":"Database Backups","text":""},{"location":"deployment/backup-recovery/#postgresql-backup-methods","title":"PostgreSQL Backup Methods","text":""},{"location":"deployment/backup-recovery/#1-logical-backups-with-pg_dump","title":"1. Logical Backups with pg_dump","text":"<p>Full Database Backup:</p> <pre><code>#!/bin/bash\n# scripts/backup_db.sh\n\nBACKUP_DIR=\"/backups/postgres\"\nDATE=$(date +%Y%m%d_%H%M%S)\nDB_NAME=\"fastapi_prod\"\nDB_USER=\"prod_user\"\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Create backup\ndocker exec hw-db pg_dump -U \"$DB_USER\" -Fc \"$DB_NAME\" &gt; \\\n  \"$BACKUP_DIR/${DB_NAME}_${DATE}.dump\"\n\n# Compress backup\ngzip \"$BACKUP_DIR/${DB_NAME}_${DATE}.dump\"\n\n# Create metadata\ncat &gt; \"$BACKUP_DIR/${DB_NAME}_${DATE}.meta\" &lt;&lt;EOF\n{\n  \"timestamp\": \"$(date -Iseconds)\",\n  \"database\": \"$DB_NAME\",\n  \"size\": \"$(du -h \"$BACKUP_DIR/${DB_NAME}_${DATE}.dump.gz\" | cut -f1)\",\n  \"pg_version\": \"$(docker exec hw-db psql -U postgres -t -c 'SELECT version();' | head -1)\"\n}\nEOF\n\necho \"Backup completed: ${DB_NAME}_${DATE}.dump.gz\"\n\n# Remove backups older than 30 days\nfind \"$BACKUP_DIR\" -name \"*.dump.gz\" -mtime +30 -delete\nfind \"$BACKUP_DIR\" -name \"*.meta\" -mtime +30 -delete\n</code></pre> <p>Per-Table Backup:</p> <pre><code># Backup specific table (useful for large tables)\ndocker exec hw-db pg_dump -U prod_user -Fc -t author fastapi_prod &gt; \\\n  /backups/postgres/author_$(date +%Y%m%d).dump\n</code></pre> <p>Schema-Only Backup:</p> <pre><code># Backup schema without data (useful for migrations)\ndocker exec hw-db pg_dump -U prod_user -Fc --schema-only fastapi_prod &gt; \\\n  /backups/postgres/schema_$(date +%Y%m%d).dump\n</code></pre>"},{"location":"deployment/backup-recovery/#2-physical-backups-with-pg_basebackup","title":"2. Physical Backups with pg_basebackup","text":"<p>Base Backup:</p> <pre><code>#!/bin/bash\n# scripts/backup_db_physical.sh\n\nBACKUP_DIR=\"/backups/postgres/base\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Create base backup\ndocker exec hw-db pg_basebackup -U postgres -D - -Ft -z -X fetch | \\\n  tar -xzf - -C \"$BACKUP_DIR/${DATE}\"\n\necho \"Base backup completed: $BACKUP_DIR/${DATE}\"\n</code></pre> <p>Enable WAL Archiving:</p> <pre><code># docker/postgres/postgresql.conf\nwal_level = replica\narchive_mode = on\narchive_command = 'test ! -f /backups/postgres/wal/%f &amp;&amp; cp %p /backups/postgres/wal/%f'\nmax_wal_senders = 3\n</code></pre>"},{"location":"deployment/backup-recovery/#3-continuous-wal-archiving","title":"3. Continuous WAL Archiving","text":"<p>Setup:</p> <pre><code># docker-compose.yml\nservices:\n  hw-db:\n    volumes:\n      - ./backups/postgres/wal:/backups/postgres/wal\n      - ./docker/postgres/postgresql.conf:/etc/postgresql/postgresql.conf\n    command: postgres -c config_file=/etc/postgresql/postgresql.conf\n</code></pre> <p>Archive WAL Files:</p> <pre><code>#!/bin/bash\n# scripts/archive_wal.sh\n\nWAL_DIR=\"/backups/postgres/wal\"\nARCHIVE_DIR=\"/backups/postgres/wal_archive\"\nDATE=$(date +%Y%m%d)\n\n# Move old WAL files to archive\nfind \"$WAL_DIR\" -name \"*.wal\" -mtime +1 -exec mv {} \"$ARCHIVE_DIR/${DATE}/\" \\;\n\n# Compress archived WAL files\nfind \"$ARCHIVE_DIR\" -name \"*.wal\" ! -name \"*.gz\" -exec gzip {} \\;\n\n# Remove archives older than 7 days\nfind \"$ARCHIVE_DIR\" -type d -mtime +7 -exec rm -rf {} \\;\n</code></pre>"},{"location":"deployment/backup-recovery/#restore-postgresql-database","title":"Restore PostgreSQL Database","text":""},{"location":"deployment/backup-recovery/#from-pg_dump-backup","title":"From pg_dump Backup","text":"<p>Complete Restore:</p> <pre><code>#!/bin/bash\n# scripts/restore_db.sh\n\nBACKUP_FILE=\"$1\"\nDB_NAME=\"fastapi_prod\"\nDB_USER=\"prod_user\"\n\nif [ -z \"$BACKUP_FILE\" ]; then\n  echo \"Usage: $0 &lt;backup_file.dump.gz&gt;\"\n  exit 1\nfi\n\necho \"WARNING: This will DROP and recreate the database!\"\nread -p \"Continue? (yes/no): \" confirm\n\nif [ \"$confirm\" != \"yes\" ]; then\n  echo \"Restore cancelled\"\n  exit 0\nfi\n\n# Stop application\ndocker-compose stop hw-server\n\n# Uncompress if needed\nif [[ $BACKUP_FILE == *.gz ]]; then\n  gunzip -c \"$BACKUP_FILE\" &gt; \"${BACKUP_FILE%.gz}\"\n  BACKUP_FILE=\"${BACKUP_FILE%.gz}\"\nfi\n\n# Drop existing connections\ndocker exec hw-db psql -U postgres -c \\\n  \"SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname='$DB_NAME';\"\n\n# Drop and recreate database\ndocker exec hw-db psql -U postgres -c \"DROP DATABASE IF EXISTS $DB_NAME;\"\ndocker exec hw-db psql -U postgres -c \"CREATE DATABASE $DB_NAME OWNER $DB_USER;\"\n\n# Restore backup\ndocker exec -i hw-db pg_restore -U \"$DB_USER\" -d \"$DB_NAME\" -Fc &lt; \"$BACKUP_FILE\"\n\necho \"Database restored successfully\"\n\n# Restart application\ndocker-compose start hw-server\n</code></pre>"},{"location":"deployment/backup-recovery/#point-in-time-recovery-pitr-with-wal","title":"Point-in-Time Recovery (PITR) with WAL","text":"<pre><code>#!/bin/bash\n# scripts/pitr_restore.sh\n\nBASE_BACKUP=\"/backups/postgres/base/20250118_120000\"\nWAL_ARCHIVE=\"/backups/postgres/wal_archive\"\nTARGET_TIME=\"2025-01-18 14:30:00\"\n\n# Stop database\ndocker-compose stop hw-db\n\n# Remove current data\ndocker volume rm postgres-hw-data\ndocker volume create postgres-hw-data\n\n# Restore base backup\ndocker run --rm \\\n  -v postgres-hw-data:/var/lib/postgresql/data \\\n  -v \"$BASE_BACKUP:/backup\" \\\n  postgres:13 \\\n  bash -c \"cp -r /backup/* /var/lib/postgresql/data/\"\n\n# Create recovery.conf\ncat &gt; recovery.conf &lt;&lt;EOF\nrestore_command = 'cp $WAL_ARCHIVE/%f %p'\nrecovery_target_time = '$TARGET_TIME'\nrecovery_target_action = 'promote'\nEOF\n\n# Copy recovery.conf to data directory\ndocker run --rm \\\n  -v postgres-hw-data:/var/lib/postgresql/data \\\n  -v \"$(pwd)/recovery.conf:/recovery.conf\" \\\n  postgres:13 \\\n  bash -c \"cp /recovery.conf /var/lib/postgresql/data/\"\n\n# Start database\ndocker-compose start hw-db\n\necho \"Point-in-time recovery to $TARGET_TIME initiated\"\n</code></pre>"},{"location":"deployment/backup-recovery/#keycloak-database-backup","title":"Keycloak Database Backup","text":"<pre><code>#!/bin/bash\n# scripts/backup_keycloak.sh\n\nBACKUP_DIR=\"/backups/keycloak\"\nDATE=$(date +%Y%m%d_%H%M%S)\nDB_NAME=\"keycloak_prod\"\nDB_USER=\"prod_user\"\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Backup Keycloak database\ndocker exec hw-db pg_dump -U \"$DB_USER\" -Fc \"$DB_NAME\" &gt; \\\n  \"$BACKUP_DIR/${DB_NAME}_${DATE}.dump\"\n\ngzip \"$BACKUP_DIR/${DB_NAME}_${DATE}.dump\"\n\necho \"Keycloak database backed up: ${DB_NAME}_${DATE}.dump.gz\"\n\n# Export realm configuration\ndocker exec hw-keycloak /opt/keycloak/bin/kc.sh export \\\n  --dir /tmp/export \\\n  --realm production\n\ndocker cp hw-keycloak:/tmp/export \"$BACKUP_DIR/realm_export_${DATE}\"\n\necho \"Keycloak realm exported: realm_export_${DATE}\"\n</code></pre>"},{"location":"deployment/backup-recovery/#redis-backups","title":"Redis Backups","text":""},{"location":"deployment/backup-recovery/#redis-backup-methods","title":"Redis Backup Methods","text":""},{"location":"deployment/backup-recovery/#1-rdb-snapshots","title":"1. RDB Snapshots","text":"<p>Manual Snapshot:</p> <pre><code># Trigger immediate snapshot\ndocker exec hw-redis redis-cli BGSAVE\n\n# Wait for completion\ndocker exec hw-redis redis-cli LASTSAVE\n\n# Copy snapshot\ndocker cp hw-redis:/data/dump.rdb /backups/redis/dump_$(date +%Y%m%d_%H%M%S).rdb\n</code></pre> <p>Automated Snapshots:</p> <pre><code>#!/bin/bash\n# scripts/backup_redis.sh\n\nBACKUP_DIR=\"/backups/redis\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Trigger snapshot\ndocker exec hw-redis redis-cli BGSAVE\n\n# Wait for completion (check every second)\nwhile [ \"$(docker exec hw-redis redis-cli LASTSAVE)\" == \"$LAST_SAVE\" ]; do\n  sleep 1\ndone\n\n# Copy snapshot\ndocker cp hw-redis:/data/dump.rdb \"$BACKUP_DIR/dump_${DATE}.rdb\"\n\necho \"Redis snapshot created: dump_${DATE}.rdb\"\n\n# Remove snapshots older than 7 days\nfind \"$BACKUP_DIR\" -name \"dump_*.rdb\" -mtime +7 -delete\n</code></pre>"},{"location":"deployment/backup-recovery/#2-aof-append-only-file-backups","title":"2. AOF (Append-Only File) Backups","text":"<p>Enable AOF:</p> <pre><code># docker/redis/redis.conf\nappendonly yes\nappendfilename \"appendonly.aof\"\nappendfsync everysec\n</code></pre> <p>Backup AOF:</p> <pre><code># Copy AOF file\ndocker cp hw-redis:/data/appendonly.aof /backups/redis/appendonly_$(date +%Y%m%d_%H%M%S).aof\n</code></pre>"},{"location":"deployment/backup-recovery/#restore-redis-data","title":"Restore Redis Data","text":"<p>From RDB Snapshot:</p> <pre><code>#!/bin/bash\n# scripts/restore_redis.sh\n\nBACKUP_FILE=\"$1\"\n\nif [ -z \"$BACKUP_FILE\" ]; then\n  echo \"Usage: $0 &lt;backup_file.rdb&gt;\"\n  exit 1\nfi\n\n# Stop Redis\ndocker-compose stop hw-redis\n\n# Copy backup to data directory\ndocker cp \"$BACKUP_FILE\" hw-redis:/data/dump.rdb\n\n# Start Redis\ndocker-compose start hw-redis\n\necho \"Redis restored from $BACKUP_FILE\"\n</code></pre> <p>From AOF:</p> <pre><code># Stop Redis\ndocker-compose stop hw-redis\n\n# Copy AOF file\ndocker cp appendonly_backup.aof hw-redis:/data/appendonly.aof\n\n# Start Redis (will replay AOF)\ndocker-compose start hw-redis\n</code></pre>"},{"location":"deployment/backup-recovery/#configuration-backups","title":"Configuration Backups","text":""},{"location":"deployment/backup-recovery/#backup-configuration-files","title":"Backup Configuration Files","text":"<pre><code>#!/bin/bash\n# scripts/backup_config.sh\n\nBACKUP_DIR=\"/backups/config\"\nDATE=$(date +%Y%m%d_%H%M%S)\nPROJECT_DIR=\"/app\"\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Create tarball of configuration files\ntar -czf \"$BACKUP_DIR/config_${DATE}.tar.gz\" \\\n  --exclude='*.pyc' \\\n  --exclude='__pycache__' \\\n  --exclude='.git' \\\n  \"$PROJECT_DIR/.env.production\" \\\n  \"$PROJECT_DIR/docker/.srv_env\" \\\n  \"$PROJECT_DIR/docker/.pg_env.production\" \\\n  \"$PROJECT_DIR/docker/.kc_env.production\" \\\n  \"$PROJECT_DIR/docker/docker-compose.yml\" \\\n  \"$PROJECT_DIR/docker/traefik/\" \\\n  \"$PROJECT_DIR/docker/prometheus/\" \\\n  \"$PROJECT_DIR/docker/grafana/\" \\\n  \"$PROJECT_DIR/docker/loki/\" \\\n  \"$PROJECT_DIR/uvicorn_logging.json\"\n\necho \"Configuration backed up: config_${DATE}.tar.gz\"\n\n# Remove backups older than 30 days\nfind \"$BACKUP_DIR\" -name \"config_*.tar.gz\" -mtime +30 -delete\n</code></pre>"},{"location":"deployment/backup-recovery/#restore-configuration","title":"Restore Configuration","text":"<pre><code>#!/bin/bash\n# scripts/restore_config.sh\n\nBACKUP_FILE=\"$1\"\n\nif [ -z \"$BACKUP_FILE\" ]; then\n  echo \"Usage: $0 &lt;config_backup.tar.gz&gt;\"\n  exit 1\nfi\n\n# Extract configuration\ntar -xzf \"$BACKUP_FILE\" -C /\n\necho \"Configuration restored from $BACKUP_FILE\"\necho \"Review configuration files before restarting services!\"\n</code></pre>"},{"location":"deployment/backup-recovery/#volume-backups","title":"Volume Backups","text":""},{"location":"deployment/backup-recovery/#backup-docker-volumes","title":"Backup Docker Volumes","text":"<pre><code>#!/bin/bash\n# scripts/backup_volumes.sh\n\nBACKUP_DIR=\"/backups/volumes\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Backup each volume\nfor VOLUME in postgres-hw-data redis-hw-data grafana-data prometheus-data loki-data; do\n  echo \"Backing up volume: $VOLUME\"\n\n  docker run --rm \\\n    -v \"$VOLUME:/data\" \\\n    -v \"$BACKUP_DIR:/backup\" \\\n    alpine \\\n    tar czf \"/backup/${VOLUME}_${DATE}.tar.gz\" -C /data .\n\n  echo \"Volume backed up: ${VOLUME}_${DATE}.tar.gz\"\ndone\n\n# Remove backups older than 4 weeks\nfind \"$BACKUP_DIR\" -name \"*.tar.gz\" -mtime +28 -delete\n</code></pre>"},{"location":"deployment/backup-recovery/#restore-docker-volumes","title":"Restore Docker Volumes","text":"<pre><code>#!/bin/bash\n# scripts/restore_volume.sh\n\nVOLUME_NAME=\"$1\"\nBACKUP_FILE=\"$2\"\n\nif [ -z \"$VOLUME_NAME\" ] || [ -z \"$BACKUP_FILE\" ]; then\n  echo \"Usage: $0 &lt;volume_name&gt; &lt;backup_file.tar.gz&gt;\"\n  exit 1\nfi\n\necho \"WARNING: This will replace all data in volume $VOLUME_NAME!\"\nread -p \"Continue? (yes/no): \" confirm\n\nif [ \"$confirm\" != \"yes\" ]; then\n  echo \"Restore cancelled\"\n  exit 0\nfi\n\n# Stop services using the volume\ndocker-compose stop\n\n# Remove existing volume\ndocker volume rm \"$VOLUME_NAME\"\n\n# Create new volume\ndocker volume create \"$VOLUME_NAME\"\n\n# Restore data\ndocker run --rm \\\n  -v \"$VOLUME_NAME:/data\" \\\n  -v \"$(dirname \"$BACKUP_FILE\"):/backup\" \\\n  alpine \\\n  tar xzf \"/backup/$(basename \"$BACKUP_FILE\")\" -C /data\n\necho \"Volume restored: $VOLUME_NAME\"\n\n# Restart services\ndocker-compose up -d\n</code></pre>"},{"location":"deployment/backup-recovery/#automated-backup-scripts","title":"Automated Backup Scripts","text":""},{"location":"deployment/backup-recovery/#comprehensive-backup-script","title":"Comprehensive Backup Script","text":"<pre><code>#!/bin/bash\n# scripts/backup_all.sh\n\nset -e\n\nBACKUP_ROOT=\"/backups\"\nDATE=$(date +%Y%m%d_%H%M%S)\nLOG_FILE=\"$BACKUP_ROOT/backup_${DATE}.log\"\n\n# Function to log messages\nlog() {\n  echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$LOG_FILE\"\n}\n\n# Function to handle errors\nerror_exit() {\n  log \"ERROR: $1\"\n  exit 1\n}\n\nlog \"Starting comprehensive backup\"\n\n# 1. Backup PostgreSQL\nlog \"Backing up PostgreSQL database...\"\nbash /scripts/backup_db.sh || error_exit \"PostgreSQL backup failed\"\n\n# 2. Backup Keycloak\nlog \"Backing up Keycloak...\"\nbash /scripts/backup_keycloak.sh || error_exit \"Keycloak backup failed\"\n\n# 3. Backup Redis\nlog \"Backing up Redis...\"\nbash /scripts/backup_redis.sh || error_exit \"Redis backup failed\"\n\n# 4. Backup configuration\nlog \"Backing up configuration files...\"\nbash /scripts/backup_config.sh || error_exit \"Configuration backup failed\"\n\n# 5. Backup volumes (weekly only)\nif [ \"$(date +%u)\" -eq 7 ]; then\n  log \"Backing up Docker volumes (weekly)...\"\n  bash /scripts/backup_volumes.sh || error_exit \"Volume backup failed\"\nfi\n\n# 6. Upload to remote storage\nlog \"Uploading backups to remote storage...\"\nbash /scripts/upload_backups.sh \"$DATE\" || log \"WARNING: Remote upload failed\"\n\n# 7. Verify backups\nlog \"Verifying backups...\"\nbash /scripts/verify_backups.sh \"$DATE\" || log \"WARNING: Backup verification failed\"\n\n# 8. Send notification\nlog \"Sending backup notification...\"\ncurl -X POST \"https://api.slack.com/webhooks/your-webhook\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"text\\\": \\\"Backup completed successfully: $DATE\\\"}\" || log \"WARNING: Notification failed\"\n\nlog \"Comprehensive backup completed successfully\"\n</code></pre>"},{"location":"deployment/backup-recovery/#cron-schedule","title":"Cron Schedule","text":"<pre><code># /etc/cron.d/backups\n\n# Full backup daily at 2 AM\n0 2 * * * root /scripts/backup_all.sh &gt;&gt; /backups/cron.log 2&gt;&amp;1\n\n# Redis snapshots every hour\n0 * * * * root /scripts/backup_redis.sh &gt;&gt; /backups/redis_cron.log 2&gt;&amp;1\n\n# Configuration backup on changes (use inotify-tools)\n# @reboot root /scripts/watch_config_changes.sh &gt;&gt; /backups/config_watch.log 2&gt;&amp;1\n</code></pre>"},{"location":"deployment/backup-recovery/#upload-backups-to-s3","title":"Upload Backups to S3","text":"<pre><code>#!/bin/bash\n# scripts/upload_backups.sh\n\nDATE=\"$1\"\nBACKUP_DIR=\"/backups\"\nS3_BUCKET=\"s3://my-backups/fastapi-prod\"\n\n# Requires AWS CLI configured\n# apt-get install awscli\n# aws configure\n\n# Upload database backups\naws s3 sync \"$BACKUP_DIR/postgres/\" \"$S3_BUCKET/postgres/\" \\\n  --exclude \"*\" \\\n  --include \"*${DATE}*\"\n\n# Upload Redis backups\naws s3 sync \"$BACKUP_DIR/redis/\" \"$S3_BUCKET/redis/\" \\\n  --exclude \"*\" \\\n  --include \"*${DATE}*\"\n\n# Upload configuration\naws s3 sync \"$BACKUP_DIR/config/\" \"$S3_BUCKET/config/\" \\\n  --exclude \"*\" \\\n  --include \"*${DATE}*\"\n\n# Set lifecycle policy (delete after 90 days)\naws s3api put-bucket-lifecycle-configuration \\\n  --bucket my-backups \\\n  --lifecycle-configuration file://s3-lifecycle.json\n\necho \"Backups uploaded to S3\"\n</code></pre> <p>S3 Lifecycle Policy:</p> <pre><code>{\n  \"Rules\": [\n    {\n      \"Id\": \"Delete old backups\",\n      \"Status\": \"Enabled\",\n      \"Prefix\": \"fastapi-prod/\",\n      \"Expiration\": {\n        \"Days\": 90\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"deployment/backup-recovery/#backup-verification","title":"Backup Verification","text":""},{"location":"deployment/backup-recovery/#verify-database-backups","title":"Verify Database Backups","text":"<pre><code>#!/bin/bash\n# scripts/verify_backups.sh\n\nBACKUP_FILE=\"$1\"\nTEST_DB=\"fastapi_test_restore\"\n\nif [ -z \"$BACKUP_FILE\" ]; then\n  echo \"Usage: $0 &lt;backup_file.dump.gz&gt;\"\n  exit 1\nfi\n\necho \"Verifying database backup: $BACKUP_FILE\"\n\n# Uncompress if needed\nif [[ $BACKUP_FILE == *.gz ]]; then\n  gunzip -c \"$BACKUP_FILE\" &gt; \"${BACKUP_FILE%.gz}\"\n  BACKUP_FILE=\"${BACKUP_FILE%.gz}\"\nfi\n\n# Create test database\ndocker exec hw-db psql -U postgres -c \"DROP DATABASE IF EXISTS $TEST_DB;\"\ndocker exec hw-db psql -U postgres -c \"CREATE DATABASE $TEST_DB;\"\n\n# Restore to test database\ndocker exec -i hw-db pg_restore -U postgres -d \"$TEST_DB\" -Fc &lt; \"$BACKUP_FILE\"\n\nif [ $? -eq 0 ]; then\n  echo \"\u2705 Backup verification PASSED\"\n\n  # Verify data integrity\n  ROW_COUNT=$(docker exec hw-db psql -U postgres -d \"$TEST_DB\" -t -c \"SELECT COUNT(*) FROM author;\")\n  echo \"   Author table has $ROW_COUNT rows\"\n\n  # Drop test database\n  docker exec hw-db psql -U postgres -c \"DROP DATABASE $TEST_DB;\"\nelse\n  echo \"\u274c Backup verification FAILED\"\n  exit 1\nfi\n</code></pre>"},{"location":"deployment/backup-recovery/#automated-backup-testing","title":"Automated Backup Testing","text":"<pre><code>#!/bin/bash\n# scripts/test_restore_monthly.sh\n# Run this monthly to verify restore procedures\n\nBACKUP_DIR=\"/backups\"\nTEST_DATE=$(date +%Y%m%d)\n\necho \"Monthly backup restore test - $TEST_DATE\"\n\n# Find most recent backup\nLATEST_BACKUP=$(ls -t \"$BACKUP_DIR/postgres/\"*.dump.gz | head -1)\n\necho \"Testing restore from: $LATEST_BACKUP\"\n\n# Verify backup\nbash /scripts/verify_backups.sh \"$LATEST_BACKUP\"\n\nif [ $? -eq 0 ]; then\n  echo \"\u2705 Monthly restore test PASSED\"\n\n  # Send success notification\n  curl -X POST \"https://api.slack.com/webhooks/your-webhook\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\\\"text\\\": \\\"Monthly backup restore test PASSED: $TEST_DATE\\\"}\"\nelse\n  echo \"\u274c Monthly restore test FAILED\"\n\n  # Send failure alert\n  curl -X POST \"https://api.slack.com/webhooks/your-webhook\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\\\"text\\\": \\\"\ud83d\udea8 Monthly backup restore test FAILED: $TEST_DATE\\\"}\"\n\n  exit 1\nfi\n</code></pre>"},{"location":"deployment/backup-recovery/#disaster-recovery","title":"Disaster Recovery","text":""},{"location":"deployment/backup-recovery/#complete-system-recovery","title":"Complete System Recovery","text":"<p>Recovery Steps:</p> <pre><code>#!/bin/bash\n# scripts/disaster_recovery.sh\n\nset -e\n\necho \"=== DISASTER RECOVERY PROCEDURE ===\"\necho \"This will restore the entire system from backups\"\nread -p \"Enter backup date (YYYYMMDD_HHMMSS): \" BACKUP_DATE\n\nBACKUP_DIR=\"/backups\"\n\n# 1. Stop all services\necho \"1. Stopping all services...\"\ndocker-compose -f docker/docker-compose.yml down\n\n# 2. Remove all volumes\necho \"2. Removing existing volumes...\"\ndocker volume rm postgres-hw-data redis-hw-data grafana-data prometheus-data loki-data\n\n# 3. Recreate volumes\necho \"3. Recreating volumes...\"\ndocker volume create postgres-hw-data\ndocker volume create redis-hw-data\ndocker volume create grafana-data\ndocker volume create prometheus-data\ndocker volume create loki-data\n\n# 4. Restore configuration\necho \"4. Restoring configuration files...\"\ntar -xzf \"$BACKUP_DIR/config/config_${BACKUP_DATE}.tar.gz\" -C /\n\n# 5. Start database services\necho \"5. Starting database services...\"\ndocker-compose -f docker/docker-compose.yml up -d hw-db hw-redis\nsleep 30\n\n# 6. Restore PostgreSQL database\necho \"6. Restoring PostgreSQL database...\"\nLATEST_DB_BACKUP=$(ls -t \"$BACKUP_DIR/postgres/\"*${BACKUP_DATE}*.dump.gz | head -1)\nbash /scripts/restore_db.sh \"$LATEST_DB_BACKUP\"\n\n# 7. Restore Keycloak database\necho \"7. Restoring Keycloak database...\"\nLATEST_KC_BACKUP=$(ls -t \"$BACKUP_DIR/keycloak/\"*${BACKUP_DATE}*.dump.gz | head -1)\ngunzip -c \"$LATEST_KC_BACKUP\" | docker exec -i hw-db pg_restore -U prod_user -d keycloak_prod -Fc\n\n# 8. Restore Redis data\necho \"8. Restoring Redis data...\"\nLATEST_REDIS_BACKUP=$(ls -t \"$BACKUP_DIR/redis/\"*${BACKUP_DATE}*.rdb | head -1)\nbash /scripts/restore_redis.sh \"$LATEST_REDIS_BACKUP\"\n\n# 9. Start remaining services\necho \"9. Starting application services...\"\ndocker-compose -f docker/docker-compose.yml up -d\n\n# 10. Wait for services to be healthy\necho \"10. Waiting for services to be healthy...\"\nfor i in {1..30}; do\n  if curl -s http://localhost:8000/health &gt; /dev/null; then\n    echo \"\u2705 Application is healthy\"\n    break\n  fi\n  echo \"Waiting for application to be ready... ($i/30)\"\n  sleep 10\ndone\n\n# 11. Verify recovery\necho \"11. Verifying recovery...\"\ncurl -s http://localhost:8000/health | jq\n\necho \"=== DISASTER RECOVERY COMPLETED ===\"\necho \"Please verify:\"\necho \"  - Application: http://localhost:8000/health\"\necho \"  - Grafana: http://localhost:3000\"\necho \"  - Keycloak: http://localhost:8080\"\n</code></pre>"},{"location":"deployment/backup-recovery/#recovery-runbook","title":"Recovery Runbook","text":"<p>Step-by-Step Manual Recovery:</p> <ol> <li> <p>Assess Damage: <pre><code># Check what's running\ndocker ps -a\n\n# Check volumes\ndocker volume ls\n\n# Review recent logs\njournalctl -u docker --since \"1 hour ago\"\n</code></pre></p> </li> <li> <p>Identify Latest Backups: <pre><code># List available backups\nls -lh /backups/postgres/ | tail -5\nls -lh /backups/redis/ | tail -5\nls -lh /backups/config/ | tail -5\n</code></pre></p> </li> <li> <p>Stop Services: <pre><code>docker-compose -f docker/docker-compose.yml down\n</code></pre></p> </li> <li> <p>Restore Database: <pre><code># Follow database restore steps\nbash /scripts/restore_db.sh &lt;backup_file&gt;\n</code></pre></p> </li> <li> <p>Restore Configuration: <pre><code>tar -xzf /backups/config/config_latest.tar.gz -C /\n</code></pre></p> </li> <li> <p>Restart Services: <pre><code>docker-compose -f docker/docker-compose.yml up -d\n</code></pre></p> </li> <li> <p>Verify Recovery: <pre><code># Check health endpoints\ncurl http://localhost:8000/health\ncurl http://localhost:8080/health\n\n# Check logs\ndocker logs hw-server --tail 50\ndocker logs hw-keycloak --tail 50\n</code></pre></p> </li> <li> <p>Notify Stakeholders: <pre><code># Send recovery notification\necho \"System recovered from backup at $(date)\" | \\\n  mail -s \"System Recovery Complete\" ops@example.com\n</code></pre></p> </li> </ol>"},{"location":"deployment/backup-recovery/#point-in-time-recovery","title":"Point-in-Time Recovery","text":""},{"location":"deployment/backup-recovery/#postgresql-pitr","title":"PostgreSQL PITR","text":"<p>Requirements: - Base backup (pg_basebackup) - Continuous WAL archiving - Target recovery time</p> <p>Recovery Procedure:</p> <pre><code>#!/bin/bash\n# scripts/pitr.sh\n\nTARGET_TIME=\"$1\"\nBASE_BACKUP=\"/backups/postgres/base/latest\"\nWAL_ARCHIVE=\"/backups/postgres/wal_archive\"\n\nif [ -z \"$TARGET_TIME\" ]; then\n  echo \"Usage: $0 'YYYY-MM-DD HH:MM:SS'\"\n  exit 1\nfi\n\necho \"Point-in-Time Recovery to: $TARGET_TIME\"\n\n# Stop database\ndocker-compose stop hw-db\n\n# Backup current data (safety measure)\ndocker run --rm \\\n  -v postgres-hw-data:/data \\\n  -v /backups/postgres:/backup \\\n  alpine tar czf \"/backup/pre_pitr_$(date +%Y%m%d_%H%M%S).tar.gz\" -C /data .\n\n# Remove current data\ndocker volume rm postgres-hw-data\ndocker volume create postgres-hw-data\n\n# Restore base backup\ndocker run --rm \\\n  -v postgres-hw-data:/var/lib/postgresql/data \\\n  -v \"$BASE_BACKUP:/backup\" \\\n  postgres:13 bash -c \"cp -r /backup/* /var/lib/postgresql/data/\"\n\n# Create recovery configuration\ncat &gt; /tmp/recovery.signal &lt;&lt;EOF\n# Trigger recovery mode\nEOF\n\ncat &gt; /tmp/postgresql.auto.conf &lt;&lt;EOF\nrestore_command = 'cp $WAL_ARCHIVE/%f %p'\nrecovery_target_time = '$TARGET_TIME'\nrecovery_target_action = 'promote'\nEOF\n\n# Copy recovery files\ndocker run --rm \\\n  -v postgres-hw-data:/var/lib/postgresql/data \\\n  -v /tmp:/tmp \\\n  postgres:13 bash -c \"cp /tmp/recovery.signal /tmp/postgresql.auto.conf /var/lib/postgresql/data/\"\n\n# Start database (recovery will begin automatically)\ndocker-compose start hw-db\n\necho \"Point-in-Time Recovery initiated. Monitor logs:\"\necho \"  docker logs hw-db -f\"\n</code></pre>"},{"location":"deployment/backup-recovery/#testing-recovery-procedures","title":"Testing Recovery Procedures","text":""},{"location":"deployment/backup-recovery/#monthly-recovery-test-checklist","title":"Monthly Recovery Test Checklist","text":"<p>Test Schedule: First Sunday of each month</p> <p>Test Procedure:</p> <ol> <li> <p>Prepare Test Environment: <pre><code># Use separate test docker-compose file\ncp docker/docker-compose.yml docker/docker-compose.test.yml\n# Modify ports to avoid conflicts (8001, 5433, etc.)\n</code></pre></p> </li> <li> <p>Test Database Restore: <pre><code># Restore latest backup to test environment\ndocker-compose -f docker/docker-compose.test.yml up -d hw-db-test\nbash /scripts/restore_db.sh &lt;latest_backup&gt;\n</code></pre></p> </li> <li> <p>Verify Data Integrity: <pre><code># Check row counts\ndocker exec hw-db-test psql -U prod_user -d fastapi_prod \\\n  -c \"SELECT 'authors', COUNT(*) FROM author UNION ALL SELECT 'books', COUNT(*) FROM book;\"\n\n# Check recent data\ndocker exec hw-db-test psql -U prod_user -d fastapi_prod \\\n  -c \"SELECT * FROM author ORDER BY id DESC LIMIT 5;\"\n</code></pre></p> </li> <li> <p>Test Application Startup: <pre><code># Start application with test database\ndocker-compose -f docker/docker-compose.test.yml up -d hw-server-test\n\n# Test health endpoint\ncurl http://localhost:8001/health\n</code></pre></p> </li> <li> <p>Document Results: <pre><code># Create test report\ncat &gt; /backups/test_reports/recovery_test_$(date +%Y%m%d).txt &lt;&lt;EOF\nRecovery Test Report\nDate: $(date)\nBackup Used: $BACKUP_FILE\nDatabase Rows: $ROW_COUNT\nApplication Health: $(curl -s http://localhost:8001/health)\nTest Result: PASS/FAIL\nNotes: ...\nEOF\n</code></pre></p> </li> <li> <p>Cleanup: <pre><code>docker-compose -f docker/docker-compose.test.yml down\ndocker volume rm postgres-test-data\n</code></pre></p> </li> </ol>"},{"location":"deployment/backup-recovery/#automated-recovery-testing","title":"Automated Recovery Testing","text":"<pre><code>#!/bin/bash\n# scripts/automated_recovery_test.sh\n\nREPORT_DIR=\"/backups/test_reports\"\nDATE=$(date +%Y%m%d_%H%M%S)\nREPORT_FILE=\"$REPORT_DIR/recovery_test_${DATE}.txt\"\n\nmkdir -p \"$REPORT_DIR\"\n\necho \"=== AUTOMATED RECOVERY TEST ===\" | tee \"$REPORT_FILE\"\necho \"Date: $(date)\" | tee -a \"$REPORT_FILE\"\n\n# Test database restore\necho \"Testing database restore...\" | tee -a \"$REPORT_FILE\"\nLATEST_BACKUP=$(ls -t /backups/postgres/*.dump.gz | head -1)\nbash /scripts/verify_backups.sh \"$LATEST_BACKUP\" &gt;&gt; \"$REPORT_FILE\" 2&gt;&amp;1\n\nif [ $? -eq 0 ]; then\n  echo \"\u2705 Database restore test: PASSED\" | tee -a \"$REPORT_FILE\"\nelse\n  echo \"\u274c Database restore test: FAILED\" | tee -a \"$REPORT_FILE\"\n  exit 1\nfi\n\n# Test Redis restore\necho \"Testing Redis restore...\" | tee -a \"$REPORT_FILE\"\nLATEST_REDIS=$(ls -t /backups/redis/*.rdb | head -1)\n# Add Redis restore test logic here\n\necho \"=== TEST COMPLETED ===\" | tee -a \"$REPORT_FILE\"\n\n# Send report\nmail -s \"Recovery Test Report - $DATE\" ops@example.com &lt; \"$REPORT_FILE\"\n</code></pre>"},{"location":"deployment/backup-recovery/#backup-monitoring","title":"Backup Monitoring","text":""},{"location":"deployment/backup-recovery/#backup-health-checks","title":"Backup Health Checks","text":"<pre><code>#!/bin/bash\n# scripts/check_backup_health.sh\n\nBACKUP_DIR=\"/backups\"\nALERT_EMAIL=\"ops@example.com\"\n\n# Check if daily backup exists\nTODAY=$(date +%Y%m%d)\nif ! ls \"$BACKUP_DIR/postgres/\"*${TODAY}*.dump.gz &gt; /dev/null 2&gt;&amp;1; then\n  echo \"\u26a0\ufe0f WARNING: No database backup found for today\" | \\\n    mail -s \"Backup Alert: Missing Daily Backup\" \"$ALERT_EMAIL\"\nfi\n\n# Check backup age\nLATEST_BACKUP=$(ls -t \"$BACKUP_DIR/postgres/\"*.dump.gz | head -1)\nBACKUP_AGE=$(($(date +%s) - $(stat -c %Y \"$LATEST_BACKUP\")))\n\nif [ $BACKUP_AGE -gt 86400 ]; then\n  echo \"\u26a0\ufe0f WARNING: Latest backup is older than 24 hours\" | \\\n    mail -s \"Backup Alert: Backup Too Old\" \"$ALERT_EMAIL\"\nfi\n\n# Check backup size\nBACKUP_SIZE=$(du -b \"$LATEST_BACKUP\" | cut -f1)\nMIN_SIZE=$((1024 * 1024 * 10))  # 10 MB minimum\n\nif [ $BACKUP_SIZE -lt $MIN_SIZE ]; then\n  echo \"\u26a0\ufe0f WARNING: Backup size is suspiciously small\" | \\\n    mail -s \"Backup Alert: Small Backup Size\" \"$ALERT_EMAIL\"\nfi\n\necho \"Backup health check completed\"\n</code></pre>"},{"location":"deployment/backup-recovery/#additional-resources","title":"Additional Resources","text":"<ul> <li>PostgreSQL Backup Documentation</li> <li>Redis Persistence</li> <li>Docker Volume Backups</li> <li>AWS S3 Backup Best Practices</li> </ul>"},{"location":"deployment/backup-recovery/#emergency-contacts","title":"Emergency Contacts","text":"<ul> <li>On-Call Engineer: PagerDuty rotation</li> <li>Database Administrator: dba@example.com</li> <li>DevOps Team: devops@example.com</li> <li>Security Team: security@example.com</li> </ul>"},{"location":"deployment/docker/","title":"Docker Deployment Guide","text":"<p>This guide covers Docker-specific deployment configurations, best practices, and optimization techniques for the FastAPI HTTP/WebSocket application.</p>"},{"location":"deployment/docker/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Dockerfile Best Practices</li> <li>Multi-Stage Builds</li> <li>Docker Compose Production</li> <li>Image Optimization</li> <li>Security Hardening</li> <li>Health Checks</li> <li>Resource Limits</li> <li>Networking</li> </ul>"},{"location":"deployment/docker/#dockerfile-best-practices","title":"Dockerfile Best Practices","text":""},{"location":"deployment/docker/#production-dockerfile","title":"Production Dockerfile","text":"<p>Create <code>docker/Dockerfile.production</code>:</p> <pre><code># ============================================\n# Stage 1: Builder - Install dependencies\n# ============================================\nFROM python:3.11-slim as builder\n\n# Set environment variables\nENV PYTHONUNBUFFERED=1 \\\n    PYTHONDONTWRITEBYTECODE=1 \\\n    PIP_NO_CACHE_DIR=1 \\\n    PIP_DISABLE_PIP_VERSION_CHECK=1\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    build-essential \\\n    libpq-dev \\\n    curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Create wheel directory\nWORKDIR /wheels\n\n# Copy requirements and build wheels\nCOPY requirements.txt .\nRUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements.txt\n\n# ============================================\n# Stage 2: Runtime - Minimal production image\n# ============================================\nFROM python:3.11-slim\n\n# Set environment variables\nENV PYTHONUNBUFFERED=1 \\\n    PYTHONDONTWRITEBYTECODE=1 \\\n    PATH=\"/home/appuser/.local/bin:$PATH\"\n\n# Install runtime dependencies only\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    libpq5 \\\n    curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Create non-root user\nRUN useradd -m -u 1000 -s /bin/bash appuser\n\n# Set working directory\nWORKDIR /app\n\n# Copy wheels from builder\nCOPY --from=builder /wheels /wheels\n\n# Install Python packages from wheels\nRUN pip install --no-cache --no-index --find-links=/wheels /wheels/* \\\n    &amp;&amp; rm -rf /wheels\n\n# Copy application code\nCOPY --chown=appuser:appuser . .\n\n# Switch to non-root user\nUSER appuser\n\n# Expose port\nEXPOSE 8000\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \\\n  CMD curl -f http://localhost:8000/health || exit 1\n\n# Run application\nCMD [\"uvicorn\", \"app:application\", \\\n     \"--host\", \"0.0.0.0\", \\\n     \"--port\", \"8000\", \\\n     \"--workers\", \"4\", \\\n     \"--log-config\", \"/app/uvicorn_logging.json\"]\n</code></pre>"},{"location":"deployment/docker/#key-features","title":"Key Features","text":"<ol> <li>Multi-stage build: Separates build and runtime dependencies (smaller image)</li> <li>Non-root user: Runs as <code>appuser</code> (UID 1000) for security</li> <li>Minimal base: Uses <code>slim</code> variant to reduce attack surface</li> <li>Health check: Built-in Docker health monitoring</li> <li>Optimized layers: Leverages Docker layer caching</li> </ol>"},{"location":"deployment/docker/#multi-stage-builds","title":"Multi-Stage Builds","text":""},{"location":"deployment/docker/#why-multi-stage","title":"Why Multi-Stage?","text":"<ul> <li>Smaller images: Build dependencies (gcc, build-essential) not in final image</li> <li>Faster deployment: Less data to push/pull</li> <li>Better security: Fewer packages = smaller attack surface</li> </ul>"},{"location":"deployment/docker/#build-process","title":"Build Process","text":"<pre><code># Build production image\ndocker build -f docker/Dockerfile.production -t fastapi-app:1.0.0 .\n\n# Check image size\ndocker images fastapi-app:1.0.0\n\n# Expected: ~300-400MB (vs ~800MB+ without multi-stage)\n</code></pre>"},{"location":"deployment/docker/#layer-optimization","title":"Layer Optimization","text":"<pre><code># \u274c BAD: Changes to code trigger full rebuild\nCOPY . .\nRUN pip install -r requirements.txt\n\n# \u2705 GOOD: Dependencies cached separately\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\n</code></pre>"},{"location":"deployment/docker/#docker-compose-production","title":"Docker Compose Production","text":""},{"location":"deployment/docker/#production-compose-file","title":"Production Compose File","text":"<p>Create <code>docker/docker-compose.prod.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  hw-server:\n    image: fastapi-app:${VERSION:-latest}\n    container_name: hw-server-prod\n    hostname: hw-server\n\n    networks:\n      - hw-network\n\n    # No exposed ports - only accessible via Traefik\n    expose:\n      - \"8000\"\n\n    # Production volume (code built into image)\n    volumes:\n      - /var/log/fastapi:/app/logs\n\n    # Run as non-root user\n    user: \"1000:1000\"\n\n    env_file:\n      - ../.env.production\n      - .srv_env.production\n\n    # Resource limits\n    deploy:\n      replicas: 3\n      resources:\n        limits:\n          cpus: '2'\n          memory: 2G\n        reservations:\n          cpus: '1'\n          memory: 1G\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 120s\n\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n\n    depends_on:\n      hw-db:\n        condition: service_healthy\n      hw-redis:\n        condition: service_healthy\n      hw-keycloak:\n        condition: service_healthy\n      traefik:\n        condition: service_healthy\n\n    restart: unless-stopped\n\n    # Security options\n    security_opt:\n      - no-new-privileges:true\n\n    # Read-only root filesystem (logs volume is writable)\n    read_only: true\n    tmpfs:\n      - /tmp\n\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n\n  hw-db:\n    image: postgres:13\n    container_name: hw-db-prod\n\n    networks:\n      - hw-network\n\n    # Only expose to internal network\n    expose:\n      - \"5432\"\n\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n      - ./backups:/backups\n\n    env_file:\n      - .pg_env.production\n\n    deploy:\n      resources:\n        limits:\n          cpus: '2'\n          memory: 4G\n        reservations:\n          cpus: '1'\n          memory: 2G\n\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n      start_period: 10s\n\n    restart: unless-stopped\n\n    # PostgreSQL tuning\n    command: &gt;\n      postgres\n      -c shared_buffers=2GB\n      -c effective_cache_size=6GB\n      -c maintenance_work_mem=512MB\n      -c checkpoint_completion_target=0.9\n      -c wal_buffers=16MB\n      -c default_statistics_target=100\n      -c random_page_cost=1.1\n      -c effective_io_concurrency=200\n      -c work_mem=16MB\n      -c min_wal_size=1GB\n      -c max_wal_size=4GB\n      -c max_connections=100\n\n  hw-redis:\n    image: redis:7-alpine\n    container_name: hw-redis-prod\n\n    networks:\n      - hw-network\n\n    expose:\n      - \"6379\"\n\n    volumes:\n      - redis-data:/data\n      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro\n\n    deploy:\n      resources:\n        limits:\n          cpus: '1'\n          memory: 2G\n        reservations:\n          cpus: '0.5'\n          memory: 1G\n\n    command: redis-server /usr/local/etc/redis/redis.conf\n\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n      start_period: 5s\n\n    restart: unless-stopped\n\nnetworks:\n  hw-network:\n    name: hw-network-prod\n    driver: bridge\n    ipam:\n      config:\n        - subnet: 172.25.0.0/16\n\nvolumes:\n  postgres-data:\n    name: postgres-prod-data\n  redis-data:\n    name: redis-prod-data\n  prometheus-data:\n    name: prometheus-prod-data\n  grafana-data:\n    name: grafana-prod-data\n  loki-data:\n    name: loki-prod-data\n  traefik-certificates:\n    name: traefik-prod-certs\n</code></pre>"},{"location":"deployment/docker/#image-optimization","title":"Image Optimization","text":""},{"location":"deployment/docker/#size-reduction-techniques","title":"Size Reduction Techniques","text":"<ol> <li> <p>Use Alpine base images (where possible):    <pre><code>FROM python:3.11-alpine\n# But beware: Some packages need build dependencies\n</code></pre></p> </li> <li> <p>Multi-stage builds (as shown above)</p> </li> <li> <p>Remove build artifacts:    <pre><code>RUN pip install -r requirements.txt \\\n    &amp;&amp; pip cache purge \\\n    &amp;&amp; rm -rf /root/.cache\n</code></pre></p> </li> <li> <p>Minimize layers:    <pre><code># \u274c BAD: 3 layers\nRUN apt-get update\nRUN apt-get install -y curl\nRUN rm -rf /var/lib/apt/lists/*\n\n# \u2705 GOOD: 1 layer\nRUN apt-get update &amp;&amp; apt-get install -y curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n</code></pre></p> </li> <li> <p>Use .dockerignore:    <pre><code># .dockerignore\n__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv/\nvenv/\n.git\n.gitignore\n.env\n.env.*\ndocker-compose*.yml\nDockerfile*\nREADME.md\ntests/\ndocs/\n.pytest_cache\n.coverage\nhtmlcov/\n</code></pre></p> </li> </ol>"},{"location":"deployment/docker/#build-cache-optimization","title":"Build Cache Optimization","text":"<pre><code># Use BuildKit for better caching\nDOCKER_BUILDKIT=1 docker build -t fastapi-app:latest .\n\n# Use cache from registry\ndocker build --cache-from fastapi-app:latest -t fastapi-app:1.0.1 .\n</code></pre>"},{"location":"deployment/docker/#security-hardening","title":"Security Hardening","text":""},{"location":"deployment/docker/#1-non-root-user","title":"1. Non-Root User","text":"<pre><code># Create user with specific UID\nRUN useradd -m -u 1000 -s /bin/bash appuser\n\n# Set ownership\nCOPY --chown=appuser:appuser . .\n\n# Switch to user\nUSER appuser\n</code></pre>"},{"location":"deployment/docker/#2-read-only-root-filesystem","title":"2. Read-Only Root Filesystem","text":"<pre><code># docker-compose.yml\nservices:\n  app:\n    read_only: true\n    tmpfs:\n      - /tmp\n      - /var/run\n</code></pre>"},{"location":"deployment/docker/#3-drop-capabilities","title":"3. Drop Capabilities","text":"<pre><code>services:\n  app:\n    cap_drop:\n      - ALL\n    cap_add:\n      - NET_BIND_SERVICE  # Only if binding to port &lt; 1024\n</code></pre>"},{"location":"deployment/docker/#4-security-options","title":"4. Security Options","text":"<pre><code>services:\n  app:\n    security_opt:\n      - no-new-privileges:true\n      - apparmor:docker-default\n      - seccomp:unconfined  # Only if needed\n</code></pre>"},{"location":"deployment/docker/#5-secrets-management","title":"5. Secrets Management","text":"<pre><code># Use Docker secrets (Swarm mode)\nservices:\n  app:\n    secrets:\n      - db_password\n      - api_key\n\nsecrets:\n  db_password:\n    external: true\n  api_key:\n    external: true\n</code></pre> <pre><code># Read secrets in app\nwith open('/run/secrets/db_password', 'r') as f:\n    db_password = f.read().strip()\n</code></pre>"},{"location":"deployment/docker/#health-checks","title":"Health Checks","text":""},{"location":"deployment/docker/#application-health-check","title":"Application Health Check","text":"<pre><code>HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \\\n  CMD curl -f http://localhost:8000/health || exit 1\n</code></pre>"},{"location":"deployment/docker/#fastapi-health-endpoint","title":"FastAPI Health Endpoint","text":"<pre><code># app/api/http/health.py\nfrom fastapi import APIRouter, Response, status\nfrom app.storage.db import async_session\nfrom app.storage.redis import RRedis\n\nrouter = APIRouter()\n\n@router.get(\"/health\")\nasync def health_check():\n    \"\"\"\n    Health check endpoint.\n\n    Checks:\n    - Application is running\n    - Database connection\n    - Redis connection\n    \"\"\"\n    checks = {\n        \"status\": \"healthy\",\n        \"checks\": {}\n    }\n\n    # Database check\n    try:\n        async with async_session() as session:\n            await session.execute(\"SELECT 1\")\n        checks[\"checks\"][\"database\"] = \"healthy\"\n    except Exception as e:\n        checks[\"status\"] = \"unhealthy\"\n        checks[\"checks\"][\"database\"] = f\"unhealthy: {str(e)}\"\n\n    # Redis check\n    try:\n        redis = RRedis()\n        await redis.ping()\n        checks[\"checks\"][\"redis\"] = \"healthy\"\n    except Exception as e:\n        checks[\"status\"] = \"unhealthy\"\n        checks[\"checks\"][\"redis\"] = f\"unhealthy: {str(e)}\"\n\n    status_code = status.HTTP_200_OK if checks[\"status\"] == \"healthy\" else status.HTTP_503_SERVICE_UNAVAILABLE\n\n    return Response(\n        content=json.dumps(checks),\n        status_code=status_code,\n        media_type=\"application/json\"\n    )\n</code></pre>"},{"location":"deployment/docker/#monitoring-health-status","title":"Monitoring Health Status","text":"<pre><code># Check container health\ndocker ps --filter health=healthy\ndocker ps --filter health=unhealthy\n\n# Inspect health status\ndocker inspect --format='{{json .State.Health}}' hw-server | jq\n</code></pre>"},{"location":"deployment/docker/#resource-limits","title":"Resource Limits","text":""},{"location":"deployment/docker/#memory-limits","title":"Memory Limits","text":"<pre><code>services:\n  app:\n    deploy:\n      resources:\n        limits:\n          memory: 2G  # Hard limit\n        reservations:\n          memory: 1G  # Minimum guaranteed\n</code></pre>"},{"location":"deployment/docker/#cpu-limits","title":"CPU Limits","text":"<pre><code>services:\n  app:\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'  # Max 2 CPUs\n        reservations:\n          cpus: '1.0'  # Min 1 CPU\n</code></pre>"},{"location":"deployment/docker/#monitoring-resource-usage","title":"Monitoring Resource Usage","text":"<pre><code># Real-time stats\ndocker stats\n\n# Specific container\ndocker stats hw-server\n\n# Export stats\ndocker stats --no-stream --format \"table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\" &gt; stats.txt\n</code></pre>"},{"location":"deployment/docker/#networking","title":"Networking","text":""},{"location":"deployment/docker/#bridge-network-default","title":"Bridge Network (Default)","text":"<pre><code>networks:\n  hw-network:\n    driver: bridge\n    ipam:\n      config:\n        - subnet: 172.25.0.0/16\n</code></pre>"},{"location":"deployment/docker/#custom-network-settings","title":"Custom Network Settings","text":"<pre><code>services:\n  app:\n    networks:\n      hw-network:\n        ipv4_address: 172.25.0.10\n        aliases:\n          - api\n          - fastapi-app\n</code></pre>"},{"location":"deployment/docker/#network-isolation","title":"Network Isolation","text":"<pre><code># Public network (Traefik)\nnetworks:\n  public:\n    external: true\n\n# Private network (backend services)\nnetworks:\n  private:\n    internal: true  # No external access\n\nservices:\n  traefik:\n    networks:\n      - public\n\n  app:\n    networks:\n      - public\n      - private\n\n  db:\n    networks:\n      - private  # Only accessible from app\n</code></pre>"},{"location":"deployment/docker/#logging","title":"Logging","text":""},{"location":"deployment/docker/#json-logging-driver","title":"JSON Logging Driver","text":"<pre><code>services:\n  app:\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n        labels: \"production,fastapi\"\n</code></pre>"},{"location":"deployment/docker/#centralized-logging","title":"Centralized Logging","text":"<pre><code># Use Loki driver (requires plugin)\nservices:\n  app:\n    logging:\n      driver: loki\n      options:\n        loki-url: \"http://loki:3100/loki/api/v1/push\"\n        loki-external-labels: \"job=fastapi,environment=production\"\n</code></pre>"},{"location":"deployment/docker/#build-and-deploy-workflow","title":"Build and Deploy Workflow","text":""},{"location":"deployment/docker/#cicd-pipeline-example","title":"CI/CD Pipeline Example","text":"<pre><code># .github/workflows/deploy.yml\nname: Build and Deploy\n\non:\n  push:\n    branches: [main]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Build Docker image\n        run: |\n          docker build -f docker/Dockerfile.production \\\n            -t ghcr.io/user/fastapi-app:${{ github.sha }} \\\n            -t ghcr.io/user/fastapi-app:latest .\n\n      - name: Push to registry\n        run: |\n          echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin\n          docker push ghcr.io/user/fastapi-app:${{ github.sha }}\n          docker push ghcr.io/user/fastapi-app:latest\n\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    steps:\n      - name: Deploy to production\n        run: |\n          ssh user@prod-server \"cd /app &amp;&amp; \\\n            export VERSION=${{ github.sha }} &amp;&amp; \\\n            docker-compose -f docker-compose.prod.yml pull &amp;&amp; \\\n            docker-compose -f docker-compose.prod.yml up -d\"\n</code></pre>"},{"location":"deployment/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/docker/#common-issues","title":"Common Issues","text":"<p>Issue: Container exits immediately <pre><code># Check logs\ndocker logs hw-server\n\n# Check exit code\ndocker inspect hw-server --format='{{.State.ExitCode}}'\n</code></pre></p> <p>Issue: Permission denied <pre><code># Check user\ndocker exec hw-server whoami\n\n# Check file ownership\ndocker exec hw-server ls -la /app\n</code></pre></p> <p>Issue: Out of memory <pre><code># Check memory usage\ndocker stats hw-server\n\n# Increase limit in docker-compose.yml\n</code></pre></p> <p>Issue: Cannot connect to service <pre><code># Check network\ndocker network inspect hw-network\n\n# Check if service is running\ndocker-compose ps\n</code></pre></p>"},{"location":"deployment/docker/#best-practices-summary","title":"Best Practices Summary","text":"<p>\u2705 DO: - Use multi-stage builds - Run as non-root user - Set resource limits - Implement health checks - Use .dockerignore - Pin base image versions - Use BuildKit - Scan images for vulnerabilities</p> <p>\u274c DON'T: - Run as root - Store secrets in images - Use <code>latest</code> tag in production - Ignore security updates - Over-allocate resources - Skip health checks</p>"},{"location":"deployment/docker/#additional-resources","title":"Additional Resources","text":"<ul> <li>Docker Security Best Practices</li> <li>Dockerfile Best Practices</li> <li>Docker Compose Production</li> </ul>"},{"location":"deployment/monitoring/","title":"Monitoring and Observability Guide","text":"<p>Comprehensive guide to monitoring, metrics, logging, and alerting for the FastAPI HTTP/WebSocket application.</p>"},{"location":"deployment/monitoring/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Metrics Collection</li> <li>Grafana Dashboards</li> <li>Prometheus Alerts</li> <li>Log Aggregation</li> <li>Distributed Tracing</li> <li>Performance Monitoring</li> </ul>"},{"location":"deployment/monitoring/#overview","title":"Overview","text":""},{"location":"deployment/monitoring/#monitoring-stack","title":"Monitoring Stack","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Application Components              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 FastAPI \u2502  \u2502 Keycloak \u2502  \u2502 Traefik  \u2502  \u2502\n\u2502  \u2502  :8000  \u2502  \u2502  :9000   \u2502  \u2502  :8080   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502       \u2502            \u2502             \u2502         \u2502\n\u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502              Metrics (/metrics)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502   Prometheus   \u2502  (Metrics DB)\n            \u2502     :9090      \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502    Grafana     \u2502  (Visualization)\n            \u2502     :3000      \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Application Logs                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 FastAPI \u2502  \u2502  Docker  \u2502  \u2502 Traefik  \u2502  \u2502\n\u2502  \u2502  logs   \u2502  \u2502   logs   \u2502  \u2502   logs   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502       \u2502            \u2502             \u2502         \u2502\n\u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502            JSON logs (stdout)              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502  Grafana Alloy \u2502  (Log collector)\n            \u2502    :12345      \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502      Loki      \u2502  (Log aggregation)\n            \u2502     :3100      \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502    Grafana     \u2502  (Log queries)\n            \u2502     :3000      \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"deployment/monitoring/#metrics-collection","title":"Metrics Collection","text":""},{"location":"deployment/monitoring/#application-metrics","title":"Application Metrics","text":"<p>The application exposes Prometheus metrics at <code>/metrics</code> endpoint.</p> <p>Key Metric Types:</p> <ol> <li>Counters: Cumulative values (requests, errors)</li> <li>Gauges: Point-in-time values (connections, queue size)</li> <li>Histograms: Distributions (latency, request size)</li> <li>Summaries: Quantiles (percentiles)</li> </ol>"},{"location":"deployment/monitoring/#available-metrics","title":"Available Metrics","text":""},{"location":"deployment/monitoring/#http-metrics","title":"HTTP Metrics","text":"<pre><code># Total HTTP requests by method, endpoint, status\nhttp_requests_total{method=\"GET\",endpoint=\"/authors\",status_code=\"200\"}\n\n# Request duration histogram (seconds)\nhttp_request_duration_seconds{method=\"POST\",endpoint=\"/authors\"}\n\n# Percentiles\nhttp_request_duration_seconds{method=\"GET\",endpoint=\"/authors\",quantile=\"0.99\"}\n\n# In-progress requests\nhttp_requests_in_progress{method=\"GET\",endpoint=\"/authors\"}\n</code></pre>"},{"location":"deployment/monitoring/#websocket-metrics","title":"WebSocket Metrics","text":"<pre><code># Active WebSocket connections\nws_connections_active\n\n# Total connections by status\nws_connections_total{status=\"accepted\"}\nws_connections_total{status=\"rejected_auth\"}\nws_connections_total{status=\"rejected_limit\"}\n\n# Messages received/sent\nws_messages_received_total\nws_messages_sent_total\n\n# Message processing duration by handler\nws_message_processing_duration_seconds{pkg_id=\"1\"}\n</code></pre>"},{"location":"deployment/monitoring/#database-metrics","title":"Database Metrics","text":"<pre><code># Query duration by operation\ndb_query_duration_seconds{operation=\"select\"}\n\n# Active database connections\ndb_connections_active\n\n# Database errors\ndb_errors_total{operation=\"insert\",error_type=\"integrity_error\"}\n</code></pre>"},{"location":"deployment/monitoring/#rate-limiting-metrics","title":"Rate Limiting Metrics","text":"<pre><code># Rate limit hits by type\nrate_limit_hits_total{limit_type=\"http\"}\nrate_limit_hits_total{limit_type=\"websocket_connection\"}\nrate_limit_hits_total{limit_type=\"websocket_message\"}\n</code></pre>"},{"location":"deployment/monitoring/#authentication-metrics","title":"Authentication Metrics","text":"<pre><code># Auth attempts by status\nauth_attempts_total{status=\"success\"}\nauth_attempts_total{status=\"failed\"}\nauth_attempts_total{status=\"token_expired\"}\n\n# Token validation\ntoken_validation_total{status=\"valid\"}\ntoken_validation_total{status=\"invalid\"}\n</code></pre>"},{"location":"deployment/monitoring/#application-info","title":"Application Info","text":"<pre><code># Application version and environment\napp_info{version=\"1.0.0\",python_version=\"3.11.0\",environment=\"production\"}\n</code></pre>"},{"location":"deployment/monitoring/#traefik-metrics","title":"Traefik Metrics","text":"<pre><code># Requests per service\ntraefik_service_requests_total{service=\"fastapi@docker\"}\n\n# Request duration\ntraefik_service_request_duration_seconds{service=\"fastapi@docker\"}\n\n# Backend server status\ntraefik_service_server_up{service=\"fastapi@docker\"}\n\n# Open connections\ntraefik_service_open_connections{service=\"fastapi@docker\"}\n</code></pre>"},{"location":"deployment/monitoring/#keycloak-metrics","title":"Keycloak Metrics","text":"<pre><code># JVM heap memory\njvm_memory_used_bytes{area=\"heap\"}\njvm_memory_max_bytes{area=\"heap\"}\n\n# Garbage collection\njvm_gc_pause_seconds_sum\njvm_gc_pause_seconds_count\n\n# Thread count\njvm_threads_current\njvm_threads_peak\n</code></pre>"},{"location":"deployment/monitoring/#postgresql-metrics","title":"PostgreSQL Metrics","text":"<p>If using PostgreSQL exporter:</p> <pre><code># Database size\npg_database_size_bytes{datname=\"fastapi_prod\"}\n\n# Active connections\npg_stat_database_numbackends{datname=\"fastapi_prod\"}\n\n# Transactions per second\nrate(pg_stat_database_xact_commit{datname=\"fastapi_prod\"}[5m])\n\n# Cache hit ratio\npg_stat_database_blks_hit / (pg_stat_database_blks_hit + pg_stat_database_blks_read)\n</code></pre>"},{"location":"deployment/monitoring/#redis-metrics","title":"Redis Metrics","text":"<p>If using Redis exporter:</p> <pre><code># Connected clients\nredis_connected_clients\n\n# Memory usage\nredis_memory_used_bytes\nredis_memory_max_bytes\n\n# Commands per second\nrate(redis_commands_processed_total[5m])\n\n# Keyspace hits/misses\nredis_keyspace_hits_total\nredis_keyspace_misses_total\n\n# Hit ratio\nredis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total)\n</code></pre>"},{"location":"deployment/monitoring/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"deployment/monitoring/#existing-dashboards","title":"Existing Dashboards","text":"<p>The application includes pre-configured Grafana dashboards:</p> <ol> <li>FastAPI Metrics (<code>fastapi-metrics.json</code>)</li> <li>Request rates and latency</li> <li>WebSocket connections</li> <li>Error rates</li> <li> <p>Rate limiting</p> </li> <li> <p>Traefik Metrics (<code>traefik-metrics.json</code>)</p> </li> <li>Request distribution</li> <li>Backend health</li> <li>Response times</li> <li> <p>Status codes</p> </li> <li> <p>Keycloak Metrics (<code>keycloak-metrics.json</code>)</p> </li> <li>JVM metrics</li> <li>Memory usage</li> <li>GC activity</li> <li> <p>Thread count</p> </li> <li> <p>Application Logs (<code>application-logs.json</code>)</p> </li> <li>Log volume</li> <li>Error logs</li> <li>HTTP requests</li> <li>Rate limits</li> </ol>"},{"location":"deployment/monitoring/#accessing-dashboards","title":"Accessing Dashboards","text":"<pre><code># Access Grafana\nhttps://grafana.example.com\n\n# Login via Keycloak (auto-redirect)\n\n# Dashboards location\nHome \u2192 Dashboards \u2192 Browse\n\n# Or direct URLs\nhttps://grafana.example.com/d/fastapi-metrics\nhttps://grafana.example.com/d/traefik-metrics\nhttps://grafana.example.com/d/keycloak-metrics\nhttps://grafana.example.com/d/application-logs\n</code></pre>"},{"location":"deployment/monitoring/#creating-custom-dashboards","title":"Creating Custom Dashboards","text":"<p>Via UI: 1. Grafana \u2192 Dashboards \u2192 New Dashboard 2. Add Panel 3. Select Prometheus data source 4. Enter PromQL query 5. Configure visualization 6. Save dashboard</p> <p>Via JSON (recommended for version control):</p> <pre><code>{\n  \"dashboard\": {\n    \"title\": \"Custom Dashboard\",\n    \"panels\": [\n      {\n        \"title\": \"Request Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(http_requests_total[5m])\",\n            \"legendFormat\": \"{{method}} {{endpoint}}\"\n          }\n        ],\n        \"type\": \"graph\"\n      }\n    ]\n  }\n}\n</code></pre> <p>Save to <code>docker/grafana/provisioning/dashboards/custom.json</code> and set permissions to 644.</p>"},{"location":"deployment/monitoring/#prometheus-alerts","title":"Prometheus Alerts","text":""},{"location":"deployment/monitoring/#alert-rules-configuration","title":"Alert Rules Configuration","text":"<p>Create <code>docker/prometheus/alerts/application.yml</code>:</p> <pre><code>groups:\n  - name: application\n    interval: 30s\n    rules:\n      # High Error Rate\n      - alert: HighErrorRate\n        expr: |\n          rate(http_requests_total{status_code=~\"5..\"}[5m])\n          / rate(http_requests_total[5m]) &gt; 0.05\n        for: 5m\n        labels:\n          severity: critical\n          component: fastapi\n        annotations:\n          summary: \"High error rate detected\"\n          description: \"Error rate is {{ $value | humanizePercentage }} (threshold: 5%)\"\n\n      # Slow Response Time\n      - alert: SlowResponseTime\n        expr: |\n          histogram_quantile(0.99,\n            rate(http_request_duration_seconds_bucket[5m])\n          ) &gt; 1.0\n        for: 5m\n        labels:\n          severity: warning\n          component: fastapi\n        annotations:\n          summary: \"Slow response time (p99 &gt; 1s)\"\n          description: \"99th percentile latency is {{ $value }}s\"\n\n      # WebSocket Connection Limit\n      - alert: HighWebSocketConnections\n        expr: ws_connections_active &gt; 1000\n        for: 5m\n        labels:\n          severity: warning\n          component: fastapi\n        annotations:\n          summary: \"High number of WebSocket connections\"\n          description: \"{{ $value }} active connections (threshold: 1000)\"\n\n      # Rate Limit Abuse\n      - alert: RateLimitAbuse\n        expr: rate(rate_limit_hits_total[5m]) &gt; 100\n        for: 5m\n        labels:\n          severity: warning\n          component: fastapi\n        annotations:\n          summary: \"High rate of rate limit hits\"\n          description: \"{{ $value }} rate limit hits per second\"\n\n      # Database Connection Pool Exhaustion\n      - alert: DatabaseConnectionPoolExhausted\n        expr: db_connections_active / db_connections_max &gt; 0.9\n        for: 5m\n        labels:\n          severity: critical\n          component: database\n        annotations:\n          summary: \"Database connection pool nearly exhausted\"\n          description: \"{{ $value | humanizePercentage }} of connections in use\"\n\n  - name: infrastructure\n    interval: 30s\n    rules:\n      # Service Down\n      - alert: ServiceDown\n        expr: up{job=~\"fastapi|keycloak|traefik\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Service {{ $labels.job }} is down\"\n          description: \"Service has been down for 1 minute\"\n\n      # Database Down\n      - alert: DatabaseDown\n        expr: up{job=\"postgres\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n          component: database\n        annotations:\n          summary: \"PostgreSQL is down\"\n          description: \"Database has been unreachable for 1 minute\"\n\n      # Redis Down\n      - alert: RedisDown\n        expr: up{job=\"redis\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n          component: redis\n        annotations:\n          summary: \"Redis is down\"\n          description: \"Redis has been unreachable for 1 minute\"\n\n      # High Memory Usage\n      - alert: HighMemoryUsage\n        expr: |\n          container_memory_usage_bytes{name=\"hw-server\"}\n          / container_spec_memory_limit_bytes{name=\"hw-server\"} &gt; 0.9\n        for: 5m\n        labels:\n          severity: warning\n          component: fastapi\n        annotations:\n          summary: \"High memory usage\"\n          description: \"Memory usage is {{ $value | humanizePercentage }}\"\n\n      # High CPU Usage\n      - alert: HighCPUUsage\n        expr: |\n          rate(container_cpu_usage_seconds_total{name=\"hw-server\"}[5m]) &gt; 0.8\n        for: 5m\n        labels:\n          severity: warning\n          component: fastapi\n        annotations:\n          summary: \"High CPU usage\"\n          description: \"CPU usage is {{ $value | humanizePercentage }}\"\n\n  - name: security\n    interval: 30s\n    rules:\n      # High Failed Login Rate\n      - alert: HighFailedLoginRate\n        expr: rate(auth_attempts_total{status=\"failed\"}[5m]) &gt; 10\n        for: 5m\n        labels:\n          severity: warning\n          component: security\n        annotations:\n          summary: \"High rate of failed login attempts\"\n          description: \"{{ $value }} failed logins per second\"\n\n      # Unauthorized Access Attempts\n      - alert: UnauthorizedAccessAttempts\n        expr: rate(http_requests_total{status_code=\"403\"}[5m]) &gt; 5\n        for: 5m\n        labels:\n          severity: warning\n          component: security\n        annotations:\n          summary: \"High rate of unauthorized access attempts\"\n          description: \"{{ $value }} 403 responses per second\"\n</code></pre>"},{"location":"deployment/monitoring/#alert-manager-configuration","title":"Alert Manager Configuration","text":"<p>Create <code>docker/prometheus/alertmanager.yml</code>:</p> <pre><code>global:\n  resolve_timeout: 5m\n\nroute:\n  group_by: ['alertname', 'severity']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 12h\n  receiver: 'default'\n  routes:\n    - match:\n        severity: critical\n      receiver: 'pagerduty'\n      continue: true\n\n    - match:\n        severity: warning\n      receiver: 'slack'\n\nreceivers:\n  - name: 'default'\n    email_configs:\n      - to: 'ops@example.com'\n        from: 'alertmanager@example.com'\n        smarthost: 'smtp.example.com:587'\n        auth_username: 'alertmanager@example.com'\n        auth_password: 'password'\n\n  - name: 'slack'\n    slack_configs:\n      - api_url: 'https://hooks.slack.com/services/XXX/YYY/ZZZ'\n        channel: '#alerts'\n        title: '{{ range .Alerts }}{{ .Annotations.summary }}\\n{{ end }}'\n        text: '{{ range .Alerts }}{{ .Annotations.description }}\\n{{ end }}'\n\n  - name: 'pagerduty'\n    pagerduty_configs:\n      - service_key: 'YOUR_PAGERDUTY_KEY'\n        description: '{{ .GroupLabels.alertname }}'\n</code></pre>"},{"location":"deployment/monitoring/#testing-alerts","title":"Testing Alerts","text":"<pre><code># Trigger high error rate alert\nfor i in {1..1000}; do\n  curl -X POST https://api.example.com/nonexistent\ndone\n\n# Trigger slow response alert\n# (Requires endpoint that sleeps)\n\n# Check alert status\nhttps://prometheus.example.com/alerts\n\n# Check AlertManager\nhttps://alertmanager.example.com\n</code></pre>"},{"location":"deployment/monitoring/#log-aggregation","title":"Log Aggregation","text":""},{"location":"deployment/monitoring/#structured-logging","title":"Structured Logging","text":"<p>The application uses structured JSON logging (see <code>app/logging.py</code>).</p> <p>Log Format: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"level\": \"INFO\",\n  \"logger\": \"app.api.http.author\",\n  \"message\": \"Author created successfully\",\n  \"request_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"user_id\": \"user123\",\n  \"endpoint\": \"/authors\",\n  \"method\": \"POST\",\n  \"status_code\": 201,\n  \"duration_ms\": 45.2,\n  \"environment\": \"production\"\n}\n</code></pre></p>"},{"location":"deployment/monitoring/#logql-queries","title":"LogQL Queries","text":"<p>Common Queries:</p> <pre><code># Recent error logs\n{service=\"shell\"} | json | level=\"ERROR\"\n\n# Logs for specific user\n{service=\"shell\"} | json | user_id=\"user123\"\n\n# HTTP requests to specific endpoint\n{service=\"shell\"} | json | endpoint=~\"/api/authors.*\"\n\n# Failed authentication attempts\n{service=\"shell\"} | json | logger=~\"app.auth.*\" |~ \"(?i)(error|failed|invalid)\"\n\n# Rate limit violations\n{service=\"shell\"} | json |~ \"(?i)(rate limit|too many requests)\"\n\n# WebSocket logs\n{service=\"shell\"} | json | logger=~\"app.api.ws.*\"\n\n# Slow operations (&gt; 100ms)\n{service=\"shell\"} | json | duration_ms &gt; 100\n\n# Correlate by request ID\n{service=\"shell\"} | json | request_id=\"550e8400-e29b-41d4-a716-446655440000\"\n\n# Error rate over time\nrate({service=\"shell\"} | json | level=\"ERROR\"[5m])\n\n# Top 10 error messages\ntopk(10, sum by (message) (count_over_time({service=\"shell\"} | json | level=\"ERROR\"[1h])))\n</code></pre>"},{"location":"deployment/monitoring/#log-retention","title":"Log Retention","text":"<p>Configure in <code>docker/loki/loki-config.yml</code>:</p> <pre><code>limits_config:\n  retention_period: 744h  # 31 days\n\ntable_manager:\n  retention_deletes_enabled: true\n  retention_period: 744h\n</code></pre>"},{"location":"deployment/monitoring/#distributed-tracing","title":"Distributed Tracing","text":""},{"location":"deployment/monitoring/#opentelemetry-integration-optional","title":"OpenTelemetry Integration (Optional)","text":"<p>For distributed tracing across services:</p> <pre><code># app/tracing.py\nfrom opentelemetry import trace\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\ndef setup_tracing():\n    \"\"\"Configure OpenTelemetry tracing.\"\"\"\n    trace.set_tracer_provider(TracerProvider())\n    tracer = trace.get_tracer(__name__)\n\n    jaeger_exporter = JaegerExporter(\n        agent_host_name=\"jaeger\",\n        agent_port=6831,\n    )\n\n    span_processor = BatchSpanProcessor(jaeger_exporter)\n    trace.get_tracer_provider().add_span_processor(span_processor)\n\n    return tracer\n\n# Usage in request handler\nfrom app.tracing import tracer\n\n@router.post(\"/authors\")\nasync def create_author(data: CreateAuthorInput):\n    with tracer.start_as_current_span(\"create_author\"):\n        # Your code here\n        pass\n</code></pre>"},{"location":"deployment/monitoring/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"deployment/monitoring/#key-performance-indicators-kpis","title":"Key Performance Indicators (KPIs)","text":"Metric Target Critical Response Time (p99) &lt; 500ms &gt; 1s Error Rate &lt; 1% &gt; 5% Availability &gt; 99.9% &lt; 99% WebSocket Connections &lt; 5000 &gt; 10000 Database Connections &lt; 80% &gt; 95% CPU Usage &lt; 70% &gt; 90% Memory Usage &lt; 80% &gt; 95%"},{"location":"deployment/monitoring/#performance-queries","title":"Performance Queries","text":"<pre><code># Average response time by endpoint\navg(rate(http_request_duration_seconds_sum[5m]))\nby (endpoint)\n/\navg(rate(http_request_duration_seconds_count[5m]))\nby (endpoint)\n\n# Request throughput (req/s)\nrate(http_requests_total[5m])\n\n# Error rate percentage\nrate(http_requests_total{status_code=~\"5..\"}[5m])\n/\nrate(http_requests_total[5m]) * 100\n\n# Apdex score (Application Performance Index)\n# Target: 100ms, Tolerating: 400ms\n(\n  sum(rate(http_request_duration_seconds_bucket{le=\"0.1\"}[5m]))\n  + sum(rate(http_request_duration_seconds_bucket{le=\"0.4\"}[5m])) / 2\n)\n/\nsum(rate(http_request_duration_seconds_count[5m]))\n</code></pre>"},{"location":"deployment/monitoring/#load-testing","title":"Load Testing","text":"<p>Use tools like Locust or k6:</p> <pre><code># locustfile.py\nfrom locust import HttpUser, task, between\n\nclass WebsiteUser(HttpUser):\n    wait_time = between(1, 3)\n\n    @task(3)\n    def get_authors(self):\n        self.client.get(\"/authors\")\n\n    @task(1)\n    def create_author(self):\n        self.client.post(\"/authors\", json={\n            \"name\": \"Test Author\",\n            \"bio\": \"Test bio\"\n        })\n\n# Run load test\nlocust -f locustfile.py --host=https://api.example.com\n</code></pre>"},{"location":"deployment/monitoring/#best-practices","title":"Best Practices","text":""},{"location":"deployment/monitoring/#monitoring-checklist","title":"Monitoring Checklist","text":"<ul> <li> All services expose /metrics endpoint</li> <li> Prometheus scraping all targets</li> <li> Grafana dashboards configured</li> <li> Alert rules defined</li> <li> AlertManager configured with receivers</li> <li> Log aggregation working (Loki)</li> <li> Structured JSON logging enabled</li> <li> Retention policies configured</li> <li> Performance baselines established</li> <li> On-call rotation defined</li> </ul>"},{"location":"deployment/monitoring/#alert-best-practices","title":"Alert Best Practices","text":"<ol> <li>Actionable: Every alert should require action</li> <li>Clear: Descriptions should explain what's wrong</li> <li>Prioritized: Use severity levels (critical, warning, info)</li> <li>Tested: Test alerts before deploying</li> <li>Documented: Runbooks for each alert</li> </ol>"},{"location":"deployment/monitoring/#dashboard-best-practices","title":"Dashboard Best Practices","text":"<ol> <li>Overview first: Start with high-level metrics</li> <li>Drill-down: Link to detailed views</li> <li>Time range: Include time range selector</li> <li>Variables: Use template variables for filtering</li> <li>Auto-refresh: Enable for real-time monitoring</li> </ol>"},{"location":"deployment/monitoring/#additional-resources","title":"Additional Resources","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Documentation</li> <li>Loki Documentation</li> <li>PromQL Tutorial</li> <li>LogQL Tutorial</li> </ul>"},{"location":"deployment/production/","title":"Production Deployment Guide","text":"<p>This guide covers deploying the FastAPI HTTP/WebSocket application to production with Traefik reverse proxy, Keycloak authentication, and full observability stack.</p>"},{"location":"deployment/production/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Prerequisites</li> <li>Architecture Overview</li> <li>Environment Configuration</li> <li>Deployment Steps</li> <li>Post-Deployment Verification</li> <li>Scaling</li> <li>Backup and Recovery</li> </ul>"},{"location":"deployment/production/#prerequisites","title":"Prerequisites","text":""},{"location":"deployment/production/#required-services","title":"Required Services","text":"<ul> <li>Docker 24.0+ with Docker Compose v2</li> <li>PostgreSQL 13+ (for application and Keycloak)</li> <li>Redis 7+ (for rate limiting and sessions)</li> <li>Domain Names:</li> <li>API endpoint (e.g., <code>api.example.com</code>)</li> <li>Authentication (e.g., <code>auth.example.com</code>)</li> <li>Monitoring dashboards (e.g., <code>grafana.example.com</code>, <code>prometheus.example.com</code>)</li> <li>Traefik dashboard (e.g., <code>traefik.example.com</code>)</li> </ul>"},{"location":"deployment/production/#ssltls-certificates","title":"SSL/TLS Certificates","text":"<ul> <li>Valid SSL certificates for all domains</li> <li>Let's Encrypt integration configured in Traefik</li> <li>Or provide your own certificates</li> </ul>"},{"location":"deployment/production/#resource-requirements","title":"Resource Requirements","text":"<p>Minimum (Single Instance): - CPU: 2 cores - RAM: 4GB - Disk: 20GB SSD</p> <p>Recommended (Production): - CPU: 4+ cores - RAM: 8GB+ - Disk: 50GB+ SSD - Load balancer for multiple instances</p>"},{"location":"deployment/production/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Internet                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502  Traefik v3.0   \u2502  (Reverse Proxy + SSL)\n            \u2502  Port 80/443    \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n      \u2502              \u2502              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  FastAPI  \u2502  \u2502 Keycloak \u2502  \u2502  Grafana    \u2502\n\u2502  App      \u2502  \u2502  Auth    \u2502  \u2502  Dashboard  \u2502\n\u2502  :8000    \u2502  \u2502  :8080   \u2502  \u2502  :3000      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u2502             \u2502              \u2502\n  \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502          \u2502              \u2502               \u2502\n\u250c\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Postgres\u2502 \u2502  Redis  \u2502  \u2502Prometheus \u2502  \u2502  Loki   \u2502\n\u2502  :5432 \u2502 \u2502  :6379  \u2502  \u2502   :9090   \u2502  \u2502  :3100  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"deployment/production/#environment-configuration","title":"Environment Configuration","text":""},{"location":"deployment/production/#1-create-production-environment-files","title":"1. Create Production Environment Files","text":"<p><code>.env.production</code> (Application environment):</p> <pre><code># ========================================\n# Application Settings\n# ========================================\nENVIRONMENT=production\nDEBUG=false\nLOG_LEVEL=INFO\n\n# ========================================\n# Database Configuration\n# ========================================\nDATABASE_URL=postgresql+asyncpg://prod_user:CHANGE_ME@postgres:5432/fastapi_prod\nDB_POOL_SIZE=20\nDB_MAX_OVERFLOW=10\n\n# ========================================\n# Redis Configuration\n# ========================================\nREDIS_IP=redis\nREDIS_PORT=6379\nREDIS_PASSWORD=CHANGE_ME  # Enable Redis auth\nMAIN_REDIS_DB=0\nAUTH_REDIS_DB=1\nREDIS_MAX_CONNECTIONS=50\n\n# ========================================\n# Keycloak Configuration\n# ========================================\nKEYCLOAK_BASE_URL=https://auth.example.com\nKEYCLOAK_REALM=production\nKEYCLOAK_CLIENT_ID=fastapi-app\nKEYCLOAK_CLIENT_SECRET=CHANGE_ME  # Get from Keycloak admin\n\nKEYCLOAK_ADMIN_USERNAME=admin\nKEYCLOAK_ADMIN_PASSWORD=CHANGE_ME\n\n# ========================================\n# Security\n# ========================================\nSECRET_KEY=CHANGE_ME  # Generate with: openssl rand -hex 32\nALLOWED_HOSTS=[\"api.example.com\"]\nCORS_ORIGINS=[\"https://app.example.com\",\"https://grafana.example.com\"]\n\n# ========================================\n# Rate Limiting\n# ========================================\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_PER_MINUTE=60\nRATE_LIMIT_BURST=10\nWS_MAX_CONNECTIONS_PER_USER=5\nWS_MESSAGE_RATE_LIMIT=100\n\n# ========================================\n# Monitoring\n# ========================================\nPROMETHEUS_ENABLED=true\nLOKI_URL=http://loki:3100\n\n# ========================================\n# Logging\n# ========================================\nLOG_CONSOLE_FORMAT=json  # CRITICAL for production\nAUDIT_QUEUE_MAX_SIZE=10000\n</code></pre> <p><code>docker/.pg_env.production</code> (PostgreSQL):</p> <pre><code>POSTGRES_USER=prod_user\nPOSTGRES_PASSWORD=CHANGE_ME\nPOSTGRES_DB=fastapi_prod\n</code></pre> <p><code>docker/.kc_env.production</code> (Keycloak):</p> <pre><code>KEYCLOAK_ADMIN=admin\nKEYCLOAK_ADMIN_PASSWORD=CHANGE_ME\n\nKC_DB=postgres\nKC_DB_URL_HOST=hw-db\nKC_DB_URL_DATABASE=keycloak_prod\nKC_DB_URL_PORT=5432\nKC_DB_USERNAME=prod_user\nKC_DB_PASSWORD=CHANGE_ME\n\n# Enable production mode\nKC_HOSTNAME=auth.example.com\nKC_HOSTNAME_STRICT=true\nKC_HTTP_ENABLED=false  # Force HTTPS\nKC_PROXY=edge  # Behind Traefik\n\n# Metrics and health\nKC_METRICS_ENABLED=true\nKC_HEALTH_ENABLED=true\n</code></pre>"},{"location":"deployment/production/#2-configure-traefik-for-production","title":"2. Configure Traefik for Production","text":"<p><code>docker/traefik/traefik.yml</code>:</p> <p>Update for production domains:</p> <pre><code>entryPoints:\n  web:\n    address: \":80\"\n    http:\n      redirections:\n        entryPoint:\n          to: websecure\n          scheme: https\n          permanent: true\n\n  websecure:\n    address: \":443\"\n    http:\n      tls:\n        certResolver: letsencrypt\n\ncertificatesResolvers:\n  letsencrypt:\n    acme:\n      email: ops@example.com  # CHANGE THIS\n      storage: /letsencrypt/acme.json\n      httpChallenge:\n        entryPoint: web\n</code></pre> <p><code>docker/docker-compose.prod.yml</code>:</p> <p>Update service labels with production domains:</p> <pre><code>services:\n  hw-server:\n    labels:\n      - \"traefik.http.routers.fastapi.rule=Host(`api.example.com`)\"\n      - \"traefik.http.routers.fastapi.entrypoints=websecure\"\n      - \"traefik.http.routers.fastapi.tls.certresolver=letsencrypt\"\n\n  hw-keycloak:\n    labels:\n      - \"traefik.http.routers.keycloak.rule=Host(`auth.example.com`)\"\n      - \"traefik.http.routers.keycloak.entrypoints=websecure\"\n      - \"traefik.http.routers.keycloak.tls.certresolver=letsencrypt\"\n\n  grafana:\n    labels:\n      - \"traefik.http.routers.grafana.rule=Host(`grafana.example.com`)\"\n      - \"traefik.http.routers.grafana.entrypoints=websecure\"\n      - \"traefik.http.routers.grafana.tls.certresolver=letsencrypt\"\n</code></pre>"},{"location":"deployment/production/#deployment-steps","title":"Deployment Steps","text":""},{"location":"deployment/production/#1-initial-setup","title":"1. Initial Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/acikabubo/fastapi-http-websocket.git\ncd fastapi-http-websocket\n\n# Checkout production branch\ngit checkout main\n\n# Create production environment files\ncp .env.example .env.production\ncp docker/.pg_env docker/.pg_env.production\ncp docker/.kc_env docker/.kc_env.production\n\n# IMPORTANT: Update all passwords and secrets in these files\n</code></pre>"},{"location":"deployment/production/#2-generate-secrets","title":"2. Generate Secrets","text":"<pre><code># Generate SECRET_KEY\nopenssl rand -hex 32\n\n# Generate database passwords\nopenssl rand -base64 32\n\n# Generate Keycloak admin password\nopenssl rand -base64 24\n</code></pre>"},{"location":"deployment/production/#3-configure-dns","title":"3. Configure DNS","text":"<p>Point your domains to the server:</p> <pre><code>api.example.com        \u2192 A     \u2192 SERVER_IP\nauth.example.com       \u2192 A     \u2192 SERVER_IP\ngrafana.example.com    \u2192 A     \u2192 SERVER_IP\nprometheus.example.com \u2192 A     \u2192 SERVER_IP\ntraefik.example.com    \u2192 A     \u2192 SERVER_IP\n</code></pre>"},{"location":"deployment/production/#4-deploy-services","title":"4. Deploy Services","text":"<pre><code># Set UID/GID for file permissions\nexport UID=$(id -u)\nexport GID=$(id -g)\n\n# Create volumes\ndocker volume create postgres-hw-data\ndocker volume create prometheus-data\ndocker volume create grafana-data\ndocker volume create loki-data\ndocker volume create traefik-certificates\n\n# Start services\ndocker-compose -f docker/docker-compose.yml \\\n  --env-file .env.production \\\n  up -d\n\n# Wait for services to be healthy\ndocker-compose -f docker/docker-compose.yml ps\n</code></pre>"},{"location":"deployment/production/#5-database-initialization","title":"5. Database Initialization","text":"<pre><code># Run migrations\ndocker exec hw-server alembic upgrade head\n\n# Verify migrations\ndocker exec hw-server alembic current\ndocker exec hw-server alembic history\n</code></pre>"},{"location":"deployment/production/#6-configure-keycloak","title":"6. Configure Keycloak","text":"<pre><code># Access Keycloak admin console\nhttps://auth.example.com\n\n# Login with admin credentials from .kc_env.production\n\n# Create production realm:\n1. Realm \u2192 Create Realm \u2192 Name: \"production\"\n2. Import realm-export.json (update redirect URIs for production domains)\n\n# Create client for FastAPI:\n1. Clients \u2192 Create Client\n2. Client ID: fastapi-app\n3. Client Authentication: ON\n4. Valid redirect URIs:\n   - https://api.example.com/*\n5. Web Origins: https://api.example.com\n6. Copy client secret to .env.production\n\n# Create users and assign roles\n</code></pre>"},{"location":"deployment/production/#7-configure-grafana","title":"7. Configure Grafana","text":"<pre><code># Access Grafana\nhttps://grafana.example.com\n\n# Login via Keycloak (auto-redirects)\n\n# Import dashboards (already provisioned):\n- FastAPI Metrics\n- Traefik Metrics\n- Keycloak Metrics\n- Application Logs\n\n# Configure alerts:\nAlerting \u2192 Contact points \u2192 Add Slack/Email/PagerDuty\n</code></pre>"},{"location":"deployment/production/#8-verify-ssl-certificates","title":"8. Verify SSL Certificates","text":"<pre><code># Check Traefik dashboard\nhttps://traefik.example.com\n\n# Verify ACME certificates\ndocker exec hw-traefik ls -la /letsencrypt/\n\n# Test HTTPS\ncurl -v https://api.example.com/health\n</code></pre>"},{"location":"deployment/production/#post-deployment-verification","title":"Post-Deployment Verification","text":""},{"location":"deployment/production/#health-checks","title":"Health Checks","text":"<pre><code># Application health\ncurl https://api.example.com/health\n# Expected: {\"status\":\"ok\"}\n\n# Keycloak health\ncurl https://auth.example.com/health\n# Expected: {\"status\":\"UP\"}\n\n# Prometheus\ncurl https://prometheus.example.com/-/healthy\n# Expected: Healthy\n\n# Traefik\ncurl https://traefik.example.com/ping\n# Expected: OK\n</code></pre>"},{"location":"deployment/production/#metrics-verification","title":"Metrics Verification","text":"<pre><code># Check Prometheus targets\nhttps://prometheus.example.com/targets\n\n# All targets should be UP:\n- fastapi (hw-server:8000/metrics)\n- keycloak (hw-keycloak:9000/metrics)\n- traefik (traefik:8080/metrics)\n</code></pre>"},{"location":"deployment/production/#log-verification","title":"Log Verification","text":"<pre><code># Check application logs\ndocker logs hw-server | tail -20\n\n# Expected: Structured JSON logs with no errors\n# Verify LOG_CONSOLE_FORMAT=json is working\n\n# Check Loki ingestion\n# Grafana \u2192 Explore \u2192 Loki \u2192 Query: {service=\"shell\"}\n</code></pre>"},{"location":"deployment/production/#websocket-testing","title":"WebSocket Testing","text":"<pre><code># Test WebSocket connection\nwscat -c wss://api.example.com/web?access_token=YOUR_TOKEN\n\n# Send test message\n{\"pkg_id\": 1, \"req_id\": \"test-123\", \"data\": {}}\n\n# Expected: Response with same req_id\n</code></pre>"},{"location":"deployment/production/#rate-limiting-testing","title":"Rate Limiting Testing","text":"<pre><code># Test HTTP rate limit\nfor i in {1..100}; do curl -s -o /dev/null -w \"%{http_code}\\n\" https://api.example.com/health; done\n\n# Expected: 200 responses, then 429 (Too Many Requests) after limit\n\n# Check rate limit headers\ncurl -I https://api.example.com/health\n# X-RateLimit-Limit: 60\n# X-RateLimit-Remaining: 59\n# X-RateLimit-Reset: 1234567890\n</code></pre>"},{"location":"deployment/production/#scaling","title":"Scaling","text":""},{"location":"deployment/production/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>Update docker-compose.yml:</p> <pre><code>services:\n  hw-server:\n    deploy:\n      replicas: 3  # Run 3 instances\n      resources:\n        limits:\n          cpus: '2'\n          memory: 2G\n        reservations:\n          cpus: '1'\n          memory: 1G\n</code></pre> <p>Adjust Database Connection Pool:</p> <pre><code># If running 3 instances\n# Total connections = 3 \u00d7 DB_POOL_SIZE\n# Keep total &lt; Postgres max_connections\n\nDB_POOL_SIZE=10  # 3 \u00d7 10 = 30 total connections\nDB_MAX_OVERFLOW=5\n</code></pre> <p>Load Balancer Configuration:</p> <p>Traefik automatically load balances across replicas. Monitor distribution:</p> <pre><code># Prometheus query\nrate(http_requests_total[5m]) by (instance)\n</code></pre>"},{"location":"deployment/production/#vertical-scaling","title":"Vertical Scaling","text":"<p>Database:</p> <pre><code># PostgreSQL tuning\nshared_buffers = 2GB  # 25% of RAM\neffective_cache_size = 6GB  # 75% of RAM\nwork_mem = 16MB\nmaintenance_work_mem = 512MB\nmax_connections = 100\n</code></pre> <p>Redis:</p> <pre><code># redis.conf\nmaxmemory 2gb\nmaxmemory-policy allkeys-lru\n</code></pre>"},{"location":"deployment/production/#auto-scaling-kubernetes","title":"Auto-Scaling (Kubernetes)","text":"<p>For Kubernetes deployments, use HPA (Horizontal Pod Autoscaler):</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: fastapi-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: fastapi-app\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n</code></pre>"},{"location":"deployment/production/#backup-and-recovery","title":"Backup and Recovery","text":"<p>See BACKUP_RECOVERY.md for detailed procedures.</p> <p>Quick Backup:</p> <pre><code># Database backup\ndocker exec hw-db pg_dump -U prod_user fastapi_prod &gt; backup-$(date +%Y%m%d).sql\n\n# Volume backup\ndocker run --rm -v postgres-hw-data:/data -v $(pwd):/backup \\\n  alpine tar czf /backup/postgres-data-$(date +%Y%m%d).tar.gz /data\n</code></pre>"},{"location":"deployment/production/#monitoring-and-alerts","title":"Monitoring and Alerts","text":""},{"location":"deployment/production/#key-metrics-to-monitor","title":"Key Metrics to Monitor","text":"Metric Alert Threshold Action <code>http_requests_total{status_code=~\"5..\"}</code> &gt; 5% error rate for 5min Investigate errors <code>http_request_duration_seconds{quantile=\"0.99\"}</code> &gt; 1s for 5min Check slow endpoints <code>ws_connections_active</code> &gt; 1000 Scale horizontally <code>rate_limit_hits_total</code> Sudden spike Check for abuse <code>up{job=\"postgres\"}</code> == 0 Database down! <code>redis_connected_clients</code> &gt; 90% of maxclients Scale Redis"},{"location":"deployment/production/#alert-configuration","title":"Alert Configuration","text":"<p>See MONITORING.md for Prometheus alert rules.</p>"},{"location":"deployment/production/#troubleshooting","title":"Troubleshooting","text":"<p>See TROUBLESHOOTING.md for common issues and solutions.</p> <p>Quick Checks:</p> <pre><code># Check service health\ndocker-compose -f docker/docker-compose.yml ps\n\n# Check logs\ndocker logs hw-server --tail 100\ndocker logs hw-traefik --tail 100\n\n# Check resource usage\ndocker stats\n\n# Check Traefik routing\ncurl https://traefik.example.com/api/http/routers\n</code></pre>"},{"location":"deployment/production/#security-checklist","title":"Security Checklist","text":"<p>Before going live, verify:</p> <ul> <li> All default passwords changed</li> <li> SSL/TLS certificates valid</li> <li> Firewall configured (only 80/443 open)</li> <li> Database accessible only from app containers</li> <li> Redis password enabled</li> <li> Keycloak production mode enabled</li> <li> CORS origins restricted</li> <li> Rate limiting enabled</li> <li> Audit logging enabled</li> <li> Monitoring and alerts configured</li> <li> Backup procedures tested</li> <li> Secrets not committed to git</li> </ul>"},{"location":"deployment/production/#rollback-procedure","title":"Rollback Procedure","text":"<p>If deployment fails:</p> <pre><code># 1. Stop new version\ndocker-compose -f docker/docker-compose.yml down\n\n# 2. Restore database backup\ndocker exec -i hw-db psql -U prod_user fastapi_prod &lt; backup-YYYYMMDD.sql\n\n# 3. Revert to previous git tag\ngit checkout v1.0.0  # Previous stable version\n\n# 4. Redeploy\ndocker-compose -f docker/docker-compose.yml up -d\n\n# 5. Verify\ncurl https://api.example.com/health\n</code></pre>"},{"location":"deployment/production/#additional-resources","title":"Additional Resources","text":"<ul> <li>Docker Deployment Guide</li> <li>Security Guide</li> <li>Monitoring Guide</li> <li>Troubleshooting Guide</li> <li>Backup and Recovery</li> </ul>"},{"location":"deployment/production/#support","title":"Support","text":"<ul> <li>GitHub Issues: https://github.com/acikabubo/fastapi-http-websocket/issues</li> <li>Internal Docs: Confluence/Wiki</li> <li>On-call: PagerDuty rotation</li> </ul>"},{"location":"deployment/security/","title":"Security Guide","text":"<p>Comprehensive security best practices and hardening guidelines for production deployment of the FastAPI HTTP/WebSocket application.</p>"},{"location":"deployment/security/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Security Principles</li> <li>Authentication &amp; Authorization</li> <li>Network Security</li> <li>Data Security</li> <li>Application Security</li> <li>Infrastructure Security</li> <li>Monitoring &amp; Auditing</li> <li>Incident Response</li> <li>Compliance</li> </ul>"},{"location":"deployment/security/#security-principles","title":"Security Principles","text":""},{"location":"deployment/security/#defense-in-depth","title":"Defense in Depth","text":"<p>Implement multiple layers of security:</p> <ol> <li>Network Layer: Firewall, VPC, network segmentation</li> <li>Transport Layer: TLS/SSL encryption</li> <li>Application Layer: Authentication, authorization, input validation</li> <li>Data Layer: Encryption at rest, secure backups</li> <li>Monitoring Layer: Intrusion detection, audit logging</li> </ol>"},{"location":"deployment/security/#least-privilege","title":"Least Privilege","text":"<ul> <li>Users/services should have minimum permissions needed</li> <li>Database users with specific grants only</li> <li>Container capabilities dropped to minimum</li> <li>File system mounted read-only where possible</li> </ul>"},{"location":"deployment/security/#security-by-default","title":"Security by Default","text":"<ul> <li>Authentication required by default</li> <li>Rate limiting enabled</li> <li>Secure headers enforced</li> <li>Debug mode disabled in production</li> </ul>"},{"location":"deployment/security/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"deployment/security/#key-cloak-configuration","title":"Key cloak Configuration","text":""},{"location":"deployment/security/#production-realm-setup","title":"Production Realm Setup","text":"<pre><code># 1. Create production realm\nRealm Name: production\nDisplay Name: Production Environment\nEnabled: ON\n\n# 2. Security Settings\nRealm Settings \u2192 Security Defenses:\n- Brute Force Detection: ON\n- Permanent Lockout: ON\n- Max Login Failures: 5\n- Wait Increment: 60 seconds\n- Quick Login Check: 1000ms\n- Minimum Quick Login Wait: 60 seconds\n\n# 3. Token Settings\nRealm Settings \u2192 Tokens:\n- Access Token Lifespan: 5 minutes\n- Access Token Lifespan For Implicit Flow: 15 minutes\n- Client Login Timeout: 5 minutes\n- Login Action Timeout: 5 minutes\n- Refresh Token Max Reuse: 0\n- SSO Session Idle: 30 minutes\n- SSO Session Max: 10 hours\n</code></pre>"},{"location":"deployment/security/#client-configuration","title":"Client Configuration","text":"<pre><code># FastAPI Client\nClient ID: fastapi-app\nClient Protocol: openid-connect\nAccess Type: confidential\nStandard Flow Enabled: ON\nDirect Access Grants Enabled: OFF  # Disable for production\nService Accounts Enabled: OFF\nAuthorization Enabled: ON\n\n# Valid Redirect URIs (strict)\nhttps://api.example.com/*\n# DO NOT use wildcards like https://* in production\n\n# Web Origins\nhttps://api.example.com\n\n# Advanced Settings\nProof Key for Code Exchange Code Challenge Method: S256  # Enable PKCE\n</code></pre>"},{"location":"deployment/security/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<p>Decorator-Based RBAC Configuration:</p> <p>Roles are defined directly in handler code using decorators:</p> <p>WebSocket Handlers: <pre><code>@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    roles=[\"viewer\"]  # Read-only access\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n\n@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"admin\"]  # Admin only\n)\nasync def delete_author_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n</code></pre></p> <p>HTTP Endpoints: <pre><code>from app.dependencies.permissions import require_roles\n\n@router.get(\"/authors\", dependencies=[Depends(require_roles(\"viewer\"))])\nasync def get_authors():\n    ...\n\n@router.delete(\"/authors/{id}\", dependencies=[Depends(require_roles(\"admin\"))])\nasync def delete_author(id: int):\n    ...\n\n@router.get(\"/health\")  # No require_roles = public endpoint\nasync def health_check():\n    ...\n</code></pre></p> <p>Best Practices:</p> <ol> <li>Principle of Least Privilege: Assign minimum role needed</li> <li>Regular Audits: Review role assignments quarterly</li> <li>Service Accounts: Create dedicated roles for service-to-service auth</li> <li>Temporary Elevation: Use time-limited admin access</li> </ol>"},{"location":"deployment/security/#token-security","title":"Token Security","text":""},{"location":"deployment/security/#jwt-validation","title":"JWT Validation","text":"<pre><code># app/auth.py - Already implemented\nclass AuthBackend(AuthenticationBackend):\n    async def authenticate(self, conn):\n        # 1. Extract token from header/query\n        # 2. Decode and verify signature\n        # 3. Check expiration\n        # 4. Verify audience\n        # 5. Validate issuer\n        # 6. Check not-before (nbf) claim\n        # 7. Verify token wasn't revoked\n</code></pre>"},{"location":"deployment/security/#token-storage","title":"Token Storage","text":"<p>\u274c DON'T: - Store tokens in localStorage (vulnerable to XSS) - Log tokens - Send tokens in URL parameters (except WebSocket initial connection) - Store tokens in cookies without HttpOnly flag</p> <p>\u2705 DO: - Use HttpOnly, Secure cookies for web apps - Store tokens in memory for SPAs - Implement token refresh flow - Use short-lived access tokens (5-15 min) - Use long-lived refresh tokens with rotation</p>"},{"location":"deployment/security/#token-revocation","title":"Token Revocation","text":"<pre><code># Implement token blacklist in Redis\nfrom app.storage.redis import RRedis\n\nasync def revoke_token(token_jti: str, exp: int):\n    \"\"\"Revoke a token by adding to blacklist.\"\"\"\n    redis = RRedis()\n    ttl = exp - int(time.time())\n    await redis.setex(f\"revoked_token:{token_jti}\", ttl, \"1\")\n\nasync def is_token_revoked(token_jti: str) -&gt; bool:\n    \"\"\"Check if token is revoked.\"\"\"\n    redis = RRedis()\n    return await redis.exists(f\"revoked_token:{token_jti}\")\n</code></pre>"},{"location":"deployment/security/#network-security","title":"Network Security","text":""},{"location":"deployment/security/#firewall-rules","title":"Firewall Rules","text":"<pre><code># Allow only necessary ports\nufw default deny incoming\nufw default allow outgoing\n\n# HTTP/HTTPS (Traefik)\nufw allow 80/tcp\nufw allow 443/tcp\n\n# SSH (restrict to specific IPs)\nufw allow from 1.2.3.4 to any port 22\n\n# Enable firewall\nufw enable\n</code></pre>"},{"location":"deployment/security/#tlsssl-configuration","title":"TLS/SSL Configuration","text":""},{"location":"deployment/security/#traefik-tls-settings","title":"Traefik TLS Settings","text":"<pre><code># docker/traefik/traefik.yml\nentryPoints:\n  websecure:\n    address: \":443\"\n    http:\n      tls:\n        options: default\n        certResolver: letsencrypt\n        domains:\n          - main: example.com\n            sans:\n              - \"*.example.com\"\n\n# TLS Options\ntls:\n  options:\n    default:\n      minVersion: VersionTLS12\n      maxVersion: VersionTLS13\n      cipherSuites:\n        - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\n        - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305\n        - TLS_AES_256_GCM_SHA384\n        - TLS_CHACHA20_POLY1305_SHA256\n      sniStrict: true\n</code></pre>"},{"location":"deployment/security/#certificate-management","title":"Certificate Management","text":"<pre><code># Let's Encrypt auto-renewal\n# Traefik handles this automatically\n\n# Check certificate expiration\necho | openssl s_client -servername api.example.com -connect api.example.com:443 2&gt;/dev/null | openssl x509 -noout -dates\n\n# Monitor expiration in Prometheus\nssl_certificate_expiry{domain=\"api.example.com\"} &lt; 604800  # 7 days\n</code></pre>"},{"location":"deployment/security/#network-segmentation","title":"Network Segmentation","text":"<pre><code># docker-compose.yml\nnetworks:\n  # Public network - accessible from internet\n  public:\n    driver: bridge\n\n  # Private network - internal services only\n  private:\n    driver: bridge\n    internal: true  # No external access\n\nservices:\n  traefik:\n    networks:\n      - public  # Internet-facing\n\n  hw-server:\n    networks:\n      - public   # Accessible via Traefik\n      - private  # Can access backend services\n\n  hw-db:\n    networks:\n      - private  # Not accessible from internet\n\n  hw-redis:\n    networks:\n      - private  # Not accessible from internet\n</code></pre>"},{"location":"deployment/security/#data-security","title":"Data Security","text":""},{"location":"deployment/security/#database-security","title":"Database Security","text":""},{"location":"deployment/security/#postgresql-hardening","title":"PostgreSQL Hardening","text":"<p><code>docker/.pg_env.production</code>: <pre><code># Strong password (32+ characters)\nPOSTGRES_PASSWORD=CHANGE_ME_LONG_RANDOM_STRING\n\n# SSL Mode\nPGSSLMODE=require\nPGSSLCERT=/path/to/client-cert.pem\nPGSSLKEY=/path/to/client-key.pem\nPGSSLROOTCERT=/path/to/ca-cert.pem\n</code></pre></p> <p>Connection String: <pre><code>DATABASE_URL=postgresql+asyncpg://user:pass@host:5432/db?ssl=require\n</code></pre></p> <p>PostgreSQL Configuration (<code>postgresql.conf</code>): <pre><code># Authentication\nssl = on\nssl_cert_file = '/var/lib/postgresql/server.crt'\nssl_key_file = '/var/lib/postgresql/server.key'\nssl_ca_file = '/var/lib/postgresql/root.crt'\n\n# Network\nlisten_addresses = '127.0.0.1,172.25.0.0/16'  # Only internal network\n\n# Logging\nlog_connections = on\nlog_disconnections = on\nlog_statement = 'ddl'  # Log DDL statements\nlog_line_prefix = '%t [%p]: user=%u,db=%d,app=%a,client=%h '\n\n# Security\npassword_encryption = scram-sha-256\n</code></pre></p> <p>Database User Permissions: <pre><code>-- Create application user with minimal permissions\nCREATE USER app_user WITH PASSWORD 'STRONG_PASSWORD';\n\n-- Grant only necessary permissions\nGRANT CONNECT ON DATABASE production TO app_user;\nGRANT USAGE ON SCHEMA public TO app_user;\nGRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO app_user;\nGRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO app_user;\n\n-- Revoke dangerous permissions\nREVOKE CREATE ON SCHEMA public FROM PUBLIC;\nREVOKE ALL ON DATABASE postgres FROM PUBLIC;\n</code></pre></p>"},{"location":"deployment/security/#sql-injection-prevention","title":"SQL Injection Prevention","text":"<p>\u2705 Always Use Parameterized Queries (SQLAlchemy/SQLModel does this automatically):</p> <pre><code># \u2705 SAFE: Parameterized query\nstmt = select(Author).where(Author.name == user_input)\nresult = await session.execute(stmt)\n\n# \u274c NEVER DO THIS: String concatenation\nquery = f\"SELECT * FROM authors WHERE name = '{user_input}'\"\n</code></pre> <p>Input Validation with Pydantic: <pre><code>from pydantic import BaseModel, validator\n\nclass AuthorCreate(BaseModel):\n    name: str\n    bio: str | None = None\n\n    @validator('name')\n    def validate_name(cls, v):\n        if not v or len(v) &gt; 100:\n            raise ValueError('Name must be 1-100 characters')\n        if not v.replace(' ', '').isalnum():\n            raise ValueError('Name must be alphanumeric')\n        return v\n</code></pre></p>"},{"location":"deployment/security/#redis-security","title":"Redis Security","text":"<p><code>docker/redis/redis.conf</code>: <pre><code># Bind to internal network only\nbind 127.0.0.1 172.25.0.1\n\n# Require password\nrequirepass STRONG_REDIS_PASSWORD\n\n# Disable dangerous commands\nrename-command FLUSHDB \"\"\nrename-command FLUSHALL \"\"\nrename-command CONFIG \"CONFIG_SECRET_NAME\"\nrename-command SHUTDOWN \"\"\nrename-command DEBUG \"\"\n\n# Enable SSL/TLS\nport 0  # Disable unencrypted port\ntls-port 6379\ntls-cert-file /path/to/redis.crt\ntls-key-file /path/to/redis.key\ntls-ca-cert-file /path/to/ca.crt\n\n# Memory limits\nmaxmemory 2gb\nmaxmemory-policy allkeys-lru\n\n# Persistence (if needed)\nsave 900 1\nsave 300 10\nsave 60 10000\n</code></pre></p> <p>Application Configuration: <pre><code># app/storage/redis.py\nredis_client = Redis(\n    host=settings.REDIS_IP,\n    port=settings.REDIS_PORT,\n    password=settings.REDIS_PASSWORD,\n    ssl=True,  # Enable SSL in production\n    ssl_cert_reqs='required',\n    ssl_ca_certs='/path/to/ca.crt',\n    socket_connect_timeout=5,\n    socket_timeout=5,\n    decode_responses=True,\n)\n</code></pre></p>"},{"location":"deployment/security/#encryption-at-rest","title":"Encryption at Rest","text":""},{"location":"deployment/security/#database-encryption","title":"Database Encryption","text":"<pre><code># PostgreSQL transparent data encryption (TDE)\n# Requires PostgreSQL with encryption support\n\n# File-level encryption with dm-crypt/LUKS\ncryptsetup luksFormat /dev/sdb\ncryptsetup open /dev/sdb postgres_encrypted\nmkfs.ext4 /dev/mapper/postgres_encrypted\nmount /dev/mapper/postgres_encrypted /var/lib/postgresql/data\n</code></pre>"},{"location":"deployment/security/#secrets-management","title":"Secrets Management","text":"<p>AWS Secrets Manager: <pre><code>import boto3\nfrom botocore.exceptions import ClientError\n\ndef get_secret(secret_name):\n    \"\"\"Retrieve secret from AWS Secrets Manager.\"\"\"\n    client = boto3.client('secretsmanager', region_name='us-east-1')\n\n    try:\n        response = client.get_secret_value(SecretId=secret_name)\n        return response['SecretString']\n    except ClientError as e:\n        raise Exception(f\"Error retrieving secret: {e}\")\n\n# Usage\ndb_password = get_secret('prod/db/password')\n</code></pre></p> <p>HashiCorp Vault: <pre><code>import hvac\n\nclient = hvac.Client(url='https://vault.example.com:8200')\nclient.auth.approle.login(\n    role_id='app-role-id',\n    secret_id='app-secret-id',\n)\n\n# Read secret\nsecret = client.secrets.kv.v2.read_secret_version(\n    path='production/database',\n)\ndb_password = secret['data']['data']['password']\n</code></pre></p>"},{"location":"deployment/security/#application-security","title":"Application Security","text":""},{"location":"deployment/security/#input-validation","title":"Input Validation","text":"<p>Pydantic Models (already implemented): <pre><code>from pydantic import BaseModel, Field, validator\nfrom typing import Literal\n\nclass CreateAuthorInput(BaseModel):\n    name: str = Field(..., min_length=1, max_length=100)\n    bio: str | None = Field(None, max_length=1000)\n    status: Literal['active', 'inactive'] = 'active'\n\n    @validator('name')\n    def sanitize_name(cls, v):\n        # Remove potentially dangerous characters\n        import re\n        v = re.sub(r'[&lt;&gt;\\\"\\'&amp;]', '', v)\n        return v.strip()\n</code></pre></p>"},{"location":"deployment/security/#output-encoding","title":"Output Encoding","text":"<p>XSS Prevention: <pre><code>from html import escape\n\n# Escape user-generated content before rendering\nsafe_bio = escape(author.bio)\n</code></pre></p> <p>Response Headers: <pre><code># app/middlewares/security_headers.py\nfrom starlette.middleware.base import BaseHTTPMiddleware\n\nclass SecurityHeadersMiddleware(BaseHTTPMiddleware):\n    async def dispatch(self, request, call_next):\n        response = await call_next(request)\n\n        # XSS Protection\n        response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n        response.headers[\"X-Frame-Options\"] = \"DENY\"\n        response.headers[\"X-XSS-Protection\"] = \"1; mode=block\"\n\n        # HTTPS Enforcement\n        response.headers[\"Strict-Transport-Security\"] = \"max-age=31536000; includeSubDomains\"\n\n        # CSP\n        response.headers[\"Content-Security-Policy\"] = (\n            \"default-src 'self'; \"\n            \"script-src 'self' 'unsafe-inline' https://cdn.example.com; \"\n            \"style-src 'self' 'unsafe-inline'; \"\n            \"img-src 'self' data: https:; \"\n            \"font-src 'self' data:; \"\n            \"connect-src 'self' wss://api.example.com; \"\n            \"frame-ancestors 'none'\"\n        )\n\n        # Permissions Policy\n        response.headers[\"Permissions-Policy\"] = (\n            \"geolocation=(), \"\n            \"microphone=(), \"\n            \"camera=()\"\n        )\n\n        return response\n</code></pre></p>"},{"location":"deployment/security/#rate-limiting","title":"Rate Limiting","text":"<p>Already implemented in <code>app/middlewares/rate_limit.py</code> and <code>app/utils/rate_limiter.py</code>.</p> <p>Production Configuration: <pre><code># .env.production\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_PER_MINUTE=60  # 1 request per second\nRATE_LIMIT_BURST=10\nWS_MAX_CONNECTIONS_PER_USER=5\nWS_MESSAGE_RATE_LIMIT=100\n</code></pre></p> <p>DDoS Protection: - Use Cloudflare or AWS WAF - Enable Traefik rate limiting as additional layer - Monitor <code>rate_limit_hits_total</code> metric for abuse</p>"},{"location":"deployment/security/#cors-configuration","title":"CORS Configuration","text":"<pre><code># app/__init__.py\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\n        \"https://app.example.com\",\n        \"https://admin.example.com\"\n    ],  # Specific origins only\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\"],\n    allow_headers=[\"*\"],\n    max_age=600,  # Cache preflight requests for 10 minutes\n)\n</code></pre>"},{"location":"deployment/security/#websocket-security","title":"WebSocket Security","text":"<p>Authentication: <pre><code># Already implemented in app/api/ws/websocket.py\nclass PackageAuthWebSocketEndpoint(WebSocketEndpoint):\n    async def on_connect(self, websocket: WebSocket):\n        # 1. Extract token from query params\n        # 2. Validate token with Keycloak\n        # 3. Check rate limits\n        # 4. Accept or reject connection\n</code></pre></p> <p>Message Validation: <pre><code># Already implemented in app/routing.py\nclass PackageRouter:\n    async def handle_request(self, request: RequestModel, user: UserModel):\n        # 1. Validate JSON schema\n        # 2. Check RBAC permissions\n        # 3. Rate limit messages\n        # 4. Sanitize input\n</code></pre></p>"},{"location":"deployment/security/#infrastructure-security","title":"Infrastructure Security","text":""},{"location":"deployment/security/#docker-security","title":"Docker Security","text":"<p>See DOCKER.md for detailed Docker security practices.</p> <p>Key Points: - Run as non-root user - Read-only root filesystem - Drop all capabilities - Use security options (no-new-privileges) - Scan images for vulnerabilities</p>"},{"location":"deployment/security/#secrets-in-docker","title":"Secrets in Docker","text":"<p>Never in Dockerfile or docker-compose.yml: <pre><code># \u274c NEVER DO THIS\nenvironment:\n  - DB_PASSWORD=plaintext_password\n\n# \u2705 Use env_file\nenv_file:\n  - .env.production  # Not committed to git\n\n# \u2705 Or Docker secrets (Swarm)\nsecrets:\n  - db_password\n</code></pre></p>"},{"location":"deployment/security/#vulnerability-scanning","title":"Vulnerability Scanning","text":"<pre><code># Scan Docker images\ndocker scan fastapi-app:latest\n\n# Scan Python dependencies\nmake skjold-scan\n\n# SAST scanning\nmake bandit-scan\n\n# Check for outdated packages\nmake outdated-pkgs-scan\n</code></pre>"},{"location":"deployment/security/#monitoring-auditing","title":"Monitoring &amp; Auditing","text":""},{"location":"deployment/security/#audit-logging","title":"Audit Logging","text":"<p>Already implemented in <code>app/models/user_action.py</code>.</p> <p>What to Log: - Authentication attempts (success/failure) - Authorization failures - Database modifications (CREATE, UPDATE, DELETE) - Admin actions - Configuration changes - API access patterns - Rate limit violations</p> <p>Log Retention: <pre><code>-- Automated cleanup (run daily)\nDELETE FROM user_action_logs\nWHERE timestamp &lt; NOW() - INTERVAL '90 days';\n</code></pre></p> <p>Log Analysis: <pre><code># Grafana Loki queries\n{service=\"shell\"} | json | action=\"login\" | status=\"failed\"\n{service=\"shell\"} | json | action=\"delete\" | user_role=\"admin\"\n{service=\"shell\"} | json |~ \"(?i)(permission denied|unauthorized)\"\n</code></pre></p>"},{"location":"deployment/security/#security-monitoring","title":"Security Monitoring","text":"<p>Prometheus Alerts: <pre><code># prometheus/alerts/security.yml\ngroups:\n  - name: security\n    rules:\n      - alert: HighFailedLoginRate\n        expr: rate(auth_attempts_total{status=\"failed\"}[5m]) &gt; 10\n        for: 5m\n        annotations:\n          summary: \"High rate of failed login attempts\"\n          description: \"{{ $value }} failed logins per second\"\n\n      - alert: RateLimitAbuse\n        expr: rate(rate_limit_hits_total[5m]) &gt; 100\n        for: 5m\n        annotations:\n          summary: \"Potential DDoS attack or abuse\"\n\n      - alert: UnauthorizedAccess\n        expr: increase(http_requests_total{status_code=\"403\"}[5m]) &gt; 50\n        annotations:\n          summary: \"High rate of unauthorized access attempts\"\n</code></pre></p>"},{"location":"deployment/security/#incident-response","title":"Incident Response","text":""},{"location":"deployment/security/#security-incident-playbook","title":"Security Incident Playbook","text":"<p>1. Detection &amp; Analysis (0-30 minutes): - [ ] Alert received (failed logins, data breach, etc.) - [ ] Verify incident is real (not false positive) - [ ] Assess scope and severity - [ ] Activate incident response team</p> <p>2. Containment (30-60 minutes): - [ ] Isolate affected systems - [ ] Block malicious IPs at firewall - [ ] Revoke compromised credentials - [ ] Disable compromised accounts - [ ] Take snapshots/backups of affected systems</p> <p>3. Eradication (1-4 hours): - [ ] Identify root cause - [ ] Remove malware/backdoors - [ ] Patch vulnerabilities - [ ] Update firewall rules - [ ] Force password resets if needed</p> <p>4. Recovery (4-24 hours): - [ ] Restore from clean backups if needed - [ ] Verify system integrity - [ ] Gradual service restoration - [ ] Enhanced monitoring</p> <p>5. Post-Incident (1-7 days): - [ ] Document timeline - [ ] Root cause analysis - [ ] Update security procedures - [ ] Notify affected users (if required) - [ ] Improve detection/prevention</p>"},{"location":"deployment/security/#emergency-contacts","title":"Emergency Contacts","text":"<pre><code># incident_contacts.yml\nprimary:\n  - name: Security Lead\n    phone: +1-xxx-xxx-xxxx\n    email: security@example.com\n\nescalation:\n  - name: CTO\n    phone: +1-xxx-xxx-xxxx\n    email: cto@example.com\n\nexternal:\n  - name: Incident Response Firm\n    phone: +1-xxx-xxx-xxxx\n    email: ir@firm.com\n</code></pre>"},{"location":"deployment/security/#evidence-preservation","title":"Evidence Preservation","text":"<pre><code># Preserve logs\ndocker logs hw-server &gt; incident-logs-$(date +%Y%m%d-%H%M%S).log\n\n# Preserve memory dump\ndocker exec hw-server gcore $(docker exec hw-server pidof python)\n\n# Preserve disk image\ndocker commit hw-server incident-snapshot-$(date +%Y%m%d)\n\n# Preserve network traffic\ntcpdump -i any -w incident-traffic-$(date +%Y%m%d).pcap\n</code></pre>"},{"location":"deployment/security/#compliance","title":"Compliance","text":""},{"location":"deployment/security/#gdpr-compliance","title":"GDPR Compliance","text":"<p>Data Minimization: - Only collect necessary data - Delete data when no longer needed - Implement data retention policies</p> <p>Right to Access: <pre><code>@router.get(\"/users/{user_id}/data\")\nasync def get_user_data(user_id: str):\n    \"\"\"Export all user data (GDPR compliance).\"\"\"\n    # Return all data associated with user\n</code></pre></p> <p>Right to be Forgotten: <pre><code>@router.delete(\"/users/{user_id}/gdpr-delete\")\nasync def gdpr_delete_user(user_id: str):\n    \"\"\"Permanently delete all user data.\"\"\"\n    # Delete from all tables\n    # Anonymize audit logs\n</code></pre></p>"},{"location":"deployment/security/#soc-2-compliance","title":"SOC 2 Compliance","text":"<p>Access Controls: - [ ] MFA for admin accounts - [ ] Principle of least privilege - [ ] Regular access reviews</p> <p>Change Management: - [ ] Code review required - [ ] Deployment approval process - [ ] Rollback procedures documented</p> <p>Monitoring: - [ ] Centralized logging - [ ] Audit trail of all changes - [ ] Security alerts configured</p>"},{"location":"deployment/security/#security-checklist","title":"Security Checklist","text":""},{"location":"deployment/security/#pre-deployment","title":"Pre-Deployment","text":"<ul> <li> All default passwords changed</li> <li> Secrets stored in vault (not in code)</li> <li> SSL/TLS certificates valid</li> <li> Firewall rules configured</li> <li> Database encryption enabled</li> <li> Redis authentication enabled</li> <li> Rate limiting enabled</li> <li> CORS properly configured</li> <li> Security headers configured</li> <li> Audit logging enabled</li> <li> Vulnerability scan passed</li> <li> Penetration testing completed</li> </ul>"},{"location":"deployment/security/#post-deployment","title":"Post-Deployment","text":"<ul> <li> Monitor security alerts</li> <li> Review audit logs daily</li> <li> Apply security patches weekly</li> <li> Rotate credentials monthly</li> <li> Review access controls quarterly</li> <li> Penetration testing annually</li> </ul>"},{"location":"deployment/security/#additional-resources","title":"Additional Resources","text":"<ul> <li>OWASP Top 10</li> <li>CIS Docker Benchmark</li> <li>NIST Cybersecurity Framework</li> <li>Keycloak Security Guide</li> </ul>"},{"location":"deployment/troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide provides solutions to common issues encountered when deploying and operating the FastAPI HTTP/WebSocket application.</p>"},{"location":"deployment/troubleshooting/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Deployment Issues</li> <li>Service Connectivity</li> <li>Authentication &amp; Authorization</li> <li>Performance Issues</li> <li>Database Problems</li> <li>Redis Issues</li> <li>Traefik Routing</li> <li>Docker Container Issues</li> <li>WebSocket Connection Problems</li> <li>Rate Limiting Issues</li> <li>Log Analysis</li> <li>Emergency Procedures</li> </ul>"},{"location":"deployment/troubleshooting/#deployment-issues","title":"Deployment Issues","text":""},{"location":"deployment/troubleshooting/#container-fails-to-start","title":"Container Fails to Start","text":"<p>Symptoms: - Container exits immediately after starting - <code>docker ps</code> shows container not running - Exit code non-zero</p> <p>Diagnosis: <pre><code># Check container logs\ndocker logs hw-server\n\n# Check exit code\ndocker inspect hw-server --format='{{.State.ExitCode}}'\n\n# Check recent events\ndocker events --since 10m\n</code></pre></p> <p>Common Causes &amp; Solutions:</p> <ol> <li>Missing Environment Variables: <pre><code># Check if .env files exist\nls -la .env.production docker/.srv_env docker/.pg_env docker/.kc_env\n\n# Verify required variables are set\ndocker exec hw-server printenv | grep -E \"DATABASE_URL|KEYCLOAK_BASE_URL|REDIS_IP\"\n</code></pre></li> </ol> <p>Fix: Ensure all required variables are set in environment files.</p> <ol> <li>Port Already in Use: <pre><code># Check what's using the port\nsudo netstat -tulpn | grep :8000\n</code></pre></li> </ol> <p>Fix: Stop conflicting service or change port mapping.</p> <ol> <li>Volume Permission Issues: <pre><code># Check volume permissions\ndocker exec hw-server ls -la /app\n\n# Fix ownership\nsudo chown -R 1000:1000 /path/to/volumes\n</code></pre></li> </ol>"},{"location":"deployment/troubleshooting/#database-migration-failures","title":"Database Migration Failures","text":"<p>Symptoms: - Migration command fails - \"Target database is not up to date\" error - Duplicate column/table errors</p> <p>Diagnosis: <pre><code># Check current migration version\ndocker exec hw-server alembic current\n\n# View migration history\ndocker exec hw-server alembic history\n\n# Check for pending migrations\ndocker exec hw-server alembic heads\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Database Out of Sync: <pre><code># Check which migrations are applied\ndocker exec hw-db psql -U prod_user -d fastapi_prod \\\n  -c \"SELECT * FROM alembic_version;\"\n\n# Stamp database at current code version\ndocker exec hw-server alembic stamp head\n\n# Or downgrade and re-apply\ndocker exec hw-server alembic downgrade -1\ndocker exec hw-server alembic upgrade head\n</code></pre></p> </li> <li> <p>Migration Conflicts: <pre><code># Check for multiple heads\ndocker exec hw-server alembic heads\n\n# Merge branches if needed\ndocker exec hw-server alembic merge &lt;revision1&gt; &lt;revision2&gt;\n</code></pre></p> </li> <li> <p>Failed Partial Migration: <pre><code># Manual rollback\ndocker exec hw-db psql -U prod_user -d fastapi_prod \\\n  -c \"BEGIN; -- manually undo changes; COMMIT;\"\n\n# Update alembic_version table\ndocker exec hw-db psql -U prod_user -d fastapi_prod \\\n  -c \"UPDATE alembic_version SET version_num='&lt;previous_revision&gt;';\"\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#ssl-certificate-issues","title":"SSL Certificate Issues","text":"<p>Symptoms: - \"Certificate verify failed\" errors - HTTPS connections rejected - Let's Encrypt challenge fails</p> <p>Diagnosis: <pre><code># Check Traefik logs\ndocker logs hw-traefik | grep -i certificate\n\n# Check certificate status\ndocker exec hw-traefik ls -la /letsencrypt/\n\n# Test certificate\ncurl -vI https://api.example.com 2&gt;&amp;1 | grep -A 10 \"SSL certificate\"\n</code></pre></p> <p>Solutions:</p> <ol> <li>Let's Encrypt Rate Limiting:</li> <li>Wait for rate limit reset (weekly limit: 50 certs per domain)</li> <li> <p>Use staging environment for testing:      <pre><code># traefik.yml\ncertificatesResolvers:\n  letsencrypt:\n    acme:\n      caServer: https://acme-staging-v02.api.letsencrypt.org/directory\n</code></pre></p> </li> <li> <p>DNS Not Propagated: <pre><code># Check DNS resolution\nnslookup api.example.com\ndig api.example.com\n\n# Wait for DNS propagation (up to 48 hours)\n</code></pre></p> </li> <li> <p>Port 80 Not Accessible: <pre><code># Check firewall\nsudo ufw status\nsudo iptables -L -n | grep 80\n\n# Test port 80 access\ncurl -I http://api.example.com/.well-known/acme-challenge/test\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#service-connectivity","title":"Service Connectivity","text":""},{"location":"deployment/troubleshooting/#cannot-connect-to-application","title":"Cannot Connect to Application","text":"<p>Symptoms: - \"Connection refused\" errors - \"No route to host\" - Timeout errors</p> <p>Diagnosis: <pre><code># Check if service is running\ndocker ps | grep hw-server\n\n# Check if port is listening\ndocker exec hw-server netstat -tulpn | grep 8000\n\n# Check health status\ncurl http://localhost:8000/health\n\n# Check Traefik routing\ncurl http://localhost:8080/api/http/routers\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Service Not Running: <pre><code># Restart service\ndocker-compose -f docker/docker-compose.yml restart hw-server\n\n# Check startup logs\ndocker logs hw-server --tail 50\n</code></pre></p> </li> <li> <p>Network Issues: <pre><code># Check network configuration\ndocker network inspect hw-network\n\n# Test connectivity between containers\ndocker exec hw-server ping hw-db\ndocker exec hw-server nc -zv hw-redis 6379\n</code></pre></p> </li> <li> <p>Firewall Blocking: <pre><code># Check firewall rules\nsudo ufw status\n\n# Allow necessary ports\nsudo ufw allow 80/tcp\nsudo ufw allow 443/tcp\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#inter-service-communication-fails","title":"Inter-Service Communication Fails","text":"<p>Symptoms: - Application cannot reach database - Redis connection errors - Keycloak unreachable</p> <p>Diagnosis: <pre><code># Check all services are on same network\ndocker network inspect hw-network | jq '.[0].Containers'\n\n# Test DNS resolution\ndocker exec hw-server nslookup hw-db\ndocker exec hw-server nslookup hw-redis\n\n# Test port connectivity\ndocker exec hw-server nc -zv hw-db 5432\ndocker exec hw-server nc -zv hw-redis 6379\ndocker exec hw-server nc -zv hw-keycloak 8080\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Services Not on Same Network: <pre><code># Ensure all services have same network in docker-compose.yml\nservices:\n  hw-server:\n    networks:\n      - hw-network\n  hw-db:\n    networks:\n      - hw-network\n</code></pre></p> </li> <li> <p>Wrong Service Names: <pre><code># Use container names, not localhost\n# \u274c Wrong: DATABASE_URL=postgresql://localhost:5432/db\n# \u2705 Correct: DATABASE_URL=postgresql://hw-db:5432/db\n</code></pre></p> </li> <li> <p>Restart All Services: <pre><code>docker-compose -f docker/docker-compose.yml down\ndocker-compose -f docker/docker-compose.yml up -d\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"deployment/troubleshooting/#keycloak-authentication-fails","title":"Keycloak Authentication Fails","text":"<p>Symptoms: - \"Invalid token\" errors - \"Unauthorized\" (401) responses - \"Token signature verification failed\"</p> <p>Diagnosis: <pre><code># Check Keycloak is running\ndocker logs hw-keycloak | tail -50\n\n# Test Keycloak health\ncurl http://localhost:8080/health\n\n# Verify token endpoint\ncurl http://localhost:8080/realms/production/.well-known/openid-configuration\n\n# Check application logs for auth errors\ndocker logs hw-server | grep -i \"auth\\|token\\|keycloak\"\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Token Expired: <pre><code># Check token expiration settings in Keycloak\n# Admin Console \u2192 Realm Settings \u2192 Tokens\n# Access Token Lifespan: 5 minutes (default)\n# Refresh Token Lifespan: 30 minutes (default)\n\n# Get new token\ncurl -X POST http://localhost:8080/realms/production/protocol/openid-connect/token \\\n  -d \"client_id=fastapi-app\" \\\n  -d \"client_secret=YOUR_SECRET\" \\\n  -d \"grant_type=password\" \\\n  -d \"username=user@example.com\" \\\n  -d \"password=password\"\n</code></pre></p> </li> <li> <p>Wrong Keycloak Configuration: <pre><code># Verify environment variables\ndocker exec hw-server printenv | grep KEYCLOAK\n\n# Should match:\n# KEYCLOAK_BASE_URL=http://hw-keycloak:8080\n# KEYCLOAK_REALM=production\n# KEYCLOAK_CLIENT_ID=fastapi-app\n</code></pre></p> </li> <li> <p>Client Secret Mismatch: <pre><code># Get client secret from Keycloak\n# Admin Console \u2192 Clients \u2192 fastapi-app \u2192 Credentials\n\n# Update in .env.production\nKEYCLOAK_CLIENT_SECRET=&lt;secret-from-keycloak&gt;\n\n# Restart application\ndocker-compose restart hw-server\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#permission-denied-errors","title":"Permission Denied Errors","text":"<p>Symptoms: - \"Permission denied\" (403) responses - \"Insufficient permissions\" errors - User cannot access expected endpoints</p> <p>Diagnosis: <pre><code># Check user roles in Keycloak\n# Admin Console \u2192 Users \u2192 &lt;user&gt; \u2192 Role Mappings\n\n# Check handler code for required roles\n# WebSocket: @pkg_router.register(PkgID.*, roles=[\"role-name\"])\n# HTTP: dependencies=[Depends(require_roles(\"role-name\"))]\n\n# Check application logs\ndocker logs hw-server | grep -i \"permission\\|rbac\"\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>User Missing Required Role: <pre><code># Add role to user in Keycloak\n# Admin Console \u2192 Users \u2192 &lt;user&gt; \u2192 Role Mappings \u2192 Assign role\n\n# Or via kcadm.sh\ndocker exec hw-keycloak /opt/keycloak/bin/kcadm.sh \\\n  add-roles -r production --uusername user@example.com --rolename admin\n</code></pre></p> </li> <li> <p>Check Handler Role Requirements: <pre><code># Example WebSocket handler\n@pkg_router.register(\n    PkgID.CREATE_AUTHOR,\n    roles=[\"create-author\", \"admin\"]  # Requires BOTH roles\n)\n\n# Example HTTP endpoint\n@router.post(\n    \"/authors\",\n    dependencies=[Depends(require_roles(\"create-author\", \"admin\"))]\n)\n\n# User must have ALL specified roles to access the endpoint\n</code></pre></p> </li> <li> <p>Token Not Decoded Properly: <pre><code># Check token contents\necho \"eyJhbGc...\" | cut -d'.' -f2 | base64 -d | jq\n\n# Verify 'realm_access.roles' field exists\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"deployment/troubleshooting/#slow-response-times","title":"Slow Response Times","text":"<p>Symptoms: - API requests take &gt; 1 second - WebSocket messages delayed - Timeout errors</p> <p>Diagnosis: <pre><code># Check application metrics\ncurl http://localhost:8000/metrics | grep http_request_duration\n\n# Check database query performance\ndocker exec hw-db psql -U prod_user -d fastapi_prod \\\n  -c \"SELECT query, calls, total_time, mean_time FROM pg_stat_statements ORDER BY mean_time DESC LIMIT 10;\"\n\n# Check CPU/memory usage\ndocker stats hw-server hw-db hw-redis\n\n# Check network latency\ndocker exec hw-server ping hw-db\ndocker exec hw-server time nc -zv hw-db 5432\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Database Query Optimization: <pre><code>-- Enable pg_stat_statements\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n\n-- Find slow queries\nSELECT query, calls, total_time, mean_time\nFROM pg_stat_statements\nORDER BY mean_time DESC\nLIMIT 10;\n\n-- Add indexes\nCREATE INDEX idx_author_name ON author(name);\nCREATE INDEX idx_book_author_id ON book(author_id);\n</code></pre></p> </li> <li> <p>Increase Connection Pool: <pre><code># In .env.production\nDB_POOL_SIZE=30  # Increase from 20\nDB_MAX_OVERFLOW=20  # Increase from 10\n\n# Restart application\ndocker-compose restart hw-server\n</code></pre></p> </li> <li> <p>Scale Horizontally: <pre><code># docker-compose.yml\nservices:\n  hw-server:\n    deploy:\n      replicas: 3  # Run 3 instances\n</code></pre></p> </li> <li> <p>Enable Caching: <pre><code># Add Redis caching for expensive queries\nfrom app.storage.redis import RRedis\n\nasync def get_popular_authors():\n    cache_key = \"popular_authors\"\n    cached = await redis.get(cache_key)\n    if cached:\n        return json.loads(cached)\n\n    authors = await fetch_from_db()\n    await redis.setex(cache_key, 300, json.dumps(authors))\n    return authors\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptoms: - OOM (Out of Memory) errors - Container restarts - Memory usage &gt; 90%</p> <p>Diagnosis: <pre><code># Check memory usage\ndocker stats hw-server --no-stream\n\n# Check container memory limit\ndocker inspect hw-server | jq '.[0].HostConfig.Memory'\n\n# Check Python memory usage\ndocker exec hw-server python -c \"import psutil; print(psutil.virtual_memory())\"\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Increase Memory Limit: <pre><code># docker-compose.yml\nservices:\n  hw-server:\n    deploy:\n      resources:\n        limits:\n          memory: 4G  # Increase from 2G\n</code></pre></p> </li> <li> <p>Check for Memory Leaks: <pre><code># Use memory profiler\nfrom memory_profiler import profile\n\n@profile\ndef problematic_function():\n    ...\n\n# Run and check output\ndocker exec hw-server python -m memory_profiler app.py\n</code></pre></p> </li> <li> <p>Reduce Workers: <pre><code># CMD in Dockerfile or docker-compose command\nCMD [\"uvicorn\", \"app:application\", \"--workers\", \"2\"]  # Reduce from 4\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#database-problems","title":"Database Problems","text":""},{"location":"deployment/troubleshooting/#cannot-connect-to-database","title":"Cannot Connect to Database","text":"<p>Symptoms: - \"could not connect to server\" errors - \"FATAL: password authentication failed\" - \"database does not exist\"</p> <p>Diagnosis: <pre><code># Check PostgreSQL is running\ndocker ps | grep hw-db\n\n# Check PostgreSQL logs\ndocker logs hw-db | tail -50\n\n# Test connection from application container\ndocker exec hw-server psql -h hw-db -U prod_user -d fastapi_prod -c \"SELECT 1;\"\n\n# Check connection string\ndocker exec hw-server printenv DATABASE_URL\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Database Not Ready: <pre><code># Wait for database to be healthy\ndocker-compose -f docker/docker-compose.yml up -d hw-db\n\n# Check health status\ndocker inspect hw-db --format='{{.State.Health.Status}}'\n\n# Wait and retry\nsleep 10\ndocker-compose restart hw-server\n</code></pre></p> </li> <li> <p>Wrong Credentials: <pre><code># Verify credentials match\n# .env.production: DATABASE_URL=postgresql://prod_user:PASSWORD@hw-db:5432/fastapi_prod\n# docker/.pg_env: POSTGRES_USER=prod_user, POSTGRES_PASSWORD=PASSWORD\n\n# Reset password if needed\ndocker exec hw-db psql -U postgres \\\n  -c \"ALTER USER prod_user WITH PASSWORD 'new_password';\"\n</code></pre></p> </li> <li> <p>Database Does Not Exist: <pre><code># Create database\ndocker exec hw-db psql -U postgres -c \"CREATE DATABASE fastapi_prod;\"\n\n# Or recreate database container\ndocker-compose down hw-db\ndocker volume rm postgres-hw-data\ndocker-compose up -d hw-db\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#database-locksdeadlocks","title":"Database Locks/Deadlocks","text":"<p>Symptoms: - \"deadlock detected\" errors - Queries hanging indefinitely - \"could not obtain lock\" errors</p> <p>Diagnosis: <pre><code>-- Check active locks\nSELECT locktype, relation::regclass, mode, granted, pid\nFROM pg_locks\nWHERE NOT granted;\n\n-- Check blocking queries\nSELECT blocked_locks.pid AS blocked_pid,\n       blocked_activity.usename AS blocked_user,\n       blocking_locks.pid AS blocking_pid,\n       blocking_activity.usename AS blocking_user,\n       blocked_activity.query AS blocked_statement,\n       blocking_activity.query AS blocking_statement\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Kill Blocking Query: <pre><code>-- Terminate blocking process\nSELECT pg_terminate_backend(&lt;blocking_pid&gt;);\n</code></pre></p> </li> <li> <p>Prevent Long Transactions: <pre><code># Use short-lived transactions\nasync with async_session() as session:\n    async with session.begin():\n        # Keep transaction scope small\n        await session.execute(stmt)\n        # Don't do expensive operations here\n</code></pre></p> </li> <li> <p>Set Statement Timeout: <pre><code>-- Set timeout for long-running queries\nALTER DATABASE fastapi_prod SET statement_timeout = '30s';\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#redis-issues","title":"Redis Issues","text":""},{"location":"deployment/troubleshooting/#cannot-connect-to-redis","title":"Cannot Connect to Redis","text":"<p>Symptoms: - \"Connection refused\" errors - \"NOAUTH Authentication required\" - Rate limiting not working</p> <p>Diagnosis: <pre><code># Check Redis is running\ndocker ps | grep hw-redis\n\n# Test connection\ndocker exec hw-redis redis-cli ping\n\n# Test from application container\ndocker exec hw-server redis-cli -h hw-redis ping\n\n# Check Redis logs\ndocker logs hw-redis | tail -50\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Redis Not Running: <pre><code># Restart Redis\ndocker-compose restart hw-redis\n\n# Check health\ndocker exec hw-redis redis-cli ping\n</code></pre></p> </li> <li> <p>Authentication Required: <pre><code># Check if Redis requires password\ndocker exec hw-redis redis-cli CONFIG GET requirepass\n\n# If yes, ensure REDIS_PASSWORD is set in .env.production\nREDIS_PASSWORD=your_redis_password\n\n# Test with password\ndocker exec hw-redis redis-cli -a your_redis_password ping\n</code></pre></p> </li> <li> <p>Wrong Redis DB: <pre><code># Check which DB application is using\ndocker exec hw-server printenv | grep REDIS\n\n# Should be:\n# MAIN_REDIS_DB=0\n# AUTH_REDIS_DB=1\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#redis-memory-issues","title":"Redis Memory Issues","text":"<p>Symptoms: - \"OOM command not allowed\" errors - Redis crashes - High memory usage</p> <p>Diagnosis: <pre><code># Check Redis memory usage\ndocker exec hw-redis redis-cli INFO memory\n\n# Check max memory setting\ndocker exec hw-redis redis-cli CONFIG GET maxmemory\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Increase Max Memory: <pre><code># docker/redis/redis.conf\nmaxmemory 2gb\n\n# Or set at runtime\ndocker exec hw-redis redis-cli CONFIG SET maxmemory 2gb\n\n# Restart Redis\ndocker-compose restart hw-redis\n</code></pre></p> </li> <li> <p>Configure Eviction Policy: <pre><code># docker/redis/redis.conf\nmaxmemory-policy allkeys-lru  # Evict least recently used keys\n\n# Or set at runtime\ndocker exec hw-redis redis-cli CONFIG SET maxmemory-policy allkeys-lru\n</code></pre></p> </li> <li> <p>Clear Unused Keys: <pre><code># Find keys by pattern\ndocker exec hw-redis redis-cli KEYS \"rate_limit:*\"\n\n# Clear old keys (be careful!)\ndocker exec hw-redis redis-cli FLUSHDB\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#traefik-routing","title":"Traefik Routing","text":""},{"location":"deployment/troubleshooting/#404-not-found-errors","title":"404 Not Found Errors","text":"<p>Symptoms: - Traefik returns 404 for valid endpoints - \"Service not found\" errors</p> <p>Diagnosis: <pre><code># Check Traefik dashboard\ncurl http://localhost:8080/api/http/routers | jq\n\n# Check container labels\ndocker inspect hw-server | jq '.[0].Config.Labels'\n\n# Check Traefik logs\ndocker logs hw-traefik | grep -i error\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Missing Labels: <pre><code># docker-compose.yml\nservices:\n  hw-server:\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.fastapi.rule=Host(`api.example.com`)\"\n      - \"traefik.http.routers.fastapi.entrypoints=websecure\"\n      - \"traefik.http.services.fastapi.loadbalancer.server.port=8000\"\n</code></pre></p> </li> <li> <p>Restart Traefik: <pre><code>docker-compose restart hw-traefik\n\n# Verify routing rules\ncurl http://localhost:8080/api/http/routers\n</code></pre></p> </li> <li> <p>Check Service Discovery: <pre><code># Ensure service is on same network as Traefik\ndocker network inspect hw-network | jq '.[0].Containers'\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#ssltls-redirect-loop","title":"SSL/TLS Redirect Loop","text":"<p>Symptoms: - Browser shows \"too many redirects\" - Infinite redirect between HTTP and HTTPS</p> <p>Solutions:</p> <pre><code># docker-compose.yml - Ensure Traefik knows it's behind a proxy\nservices:\n  hw-server:\n    labels:\n      - \"traefik.http.middlewares.secure-headers.headers.sslproxyheaders.X-Forwarded-Proto=https\"\n      - \"traefik.http.routers.fastapi.middlewares=secure-headers\"\n</code></pre>"},{"location":"deployment/troubleshooting/#docker-container-issues","title":"Docker Container Issues","text":""},{"location":"deployment/troubleshooting/#container-keeps-restarting","title":"Container Keeps Restarting","text":"<p>Symptoms: - Container in restart loop - <code>docker ps</code> shows \"Restarting\" status</p> <p>Diagnosis: <pre><code># Check restart count\ndocker inspect hw-server | jq '.[0].RestartCount'\n\n# Check last exit code\ndocker inspect hw-server | jq '.[0].State.ExitCode'\n\n# View all logs (before restart)\ndocker logs hw-server --timestamps\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Application Crash: <pre><code># Check for Python exceptions\ndocker logs hw-server | grep -i \"exception\\|error\\|traceback\"\n\n# Run container interactively to debug\ndocker run -it --rm --entrypoint /bin/bash hw-server\n</code></pre></p> </li> <li> <p>Health Check Failing: <pre><code># Test health check manually\ndocker exec hw-server curl -f http://localhost:8000/health\n\n# Adjust health check parameters\n# In Dockerfile:\nHEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=5 \\\n  CMD curl -f http://localhost:8000/health || exit 1\n</code></pre></p> </li> <li> <p>Resource Limits: <pre><code># Check if hitting resource limits\ndocker stats hw-server --no-stream\n\n# Increase limits in docker-compose.yml\ndeploy:\n  resources:\n    limits:\n      cpus: '4'\n      memory: 4G\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#volume-permission-issues","title":"Volume Permission Issues","text":"<p>Symptoms: - \"Permission denied\" errors when writing files - Cannot create directories</p> <p>Solutions:</p> <pre><code># Fix volume ownership\ndocker exec --user root hw-server chown -R appuser:appuser /app\n\n# Or set ownership on host\nsudo chown -R 1000:1000 /path/to/volume\n\n# Ensure user ID matches\ndocker exec hw-server id\n# uid=1000(appuser) gid=1000(appuser)\n</code></pre>"},{"location":"deployment/troubleshooting/#websocket-connection-problems","title":"WebSocket Connection Problems","text":""},{"location":"deployment/troubleshooting/#websocket-connection-rejected","title":"WebSocket Connection Rejected","text":"<p>Symptoms: - \"Connection closed: 1006\" - \"Connection closed: 1008 (policy violation)\" - Cannot establish WebSocket connection</p> <p>Diagnosis: <pre><code># Check application logs\ndocker logs hw-server | grep -i websocket\n\n# Test WebSocket connection\nwscat -c ws://localhost:8000/web?access_token=TOKEN\n\n# Check Traefik WebSocket configuration\ncurl http://localhost:8080/api/http/routers | jq '.[] | select(.name==\"fastapi\")'\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Missing Access Token: <pre><code># WebSocket requires token in query string\nwscat -c \"ws://localhost:8000/web?access_token=YOUR_JWT_TOKEN\"\n</code></pre></p> </li> <li> <p>Connection Limit Reached: <pre><code># Check active connections in Redis\ndocker exec hw-redis redis-cli SCARD \"ws_connections:user123\"\n\n# Increase limit in .env.production\nWS_MAX_CONNECTIONS_PER_USER=10  # Increase from 5\n\n# Restart application\ndocker-compose restart hw-server\n</code></pre></p> </li> <li> <p>Traefik Not Forwarding WebSocket: <pre><code># docker-compose.yml\nservices:\n  hw-server:\n    labels:\n      # Ensure WebSocket headers are preserved\n      - \"traefik.http.routers.fastapi.rule=Host(`api.example.com`)\"\n      # Traefik v3 handles WebSocket automatically, but verify:\n      - \"traefik.http.services.fastapi.loadbalancer.passhostheader=true\"\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#websocket-messages-not-received","title":"WebSocket Messages Not Received","text":"<p>Symptoms: - Messages sent but no response - Connection stays open but silent</p> <p>Diagnosis: <pre><code># Check application logs for message processing\ndocker logs hw-server | grep \"pkg_id\\|req_id\"\n\n# Check rate limiting\ndocker logs hw-server | grep \"rate limit\"\n\n# Test with wscat\nwscat -c \"ws://localhost:8000/web?access_token=TOKEN\"\n&gt; {\"pkg_id\": 1, \"req_id\": \"test-123\", \"data\": {}}\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Invalid Message Format: <pre><code>// Correct format\n{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"data\": {}\n}\n</code></pre></p> </li> <li> <p>Handler Not Registered: <pre><code># Check registered handlers\nmake ws-handlers\n\n# Or check logs at startup\ndocker logs hw-server | grep \"Registered handler\"\n</code></pre></p> </li> <li> <p>Rate Limit Hit: <pre><code># Check rate limit settings\ndocker exec hw-server printenv WS_MESSAGE_RATE_LIMIT\n\n# Increase if needed\nWS_MESSAGE_RATE_LIMIT=200  # In .env.production\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#rate-limiting-issues","title":"Rate Limiting Issues","text":""},{"location":"deployment/troubleshooting/#false-positive-rate-limits","title":"False Positive Rate Limits","text":"<p>Symptoms: - Users getting 429 errors incorrectly - Rate limit triggers too quickly</p> <p>Diagnosis: <pre><code># Check rate limit settings\ndocker exec hw-server printenv | grep RATE_LIMIT\n\n# Check Redis rate limit keys\ndocker exec hw-redis redis-cli KEYS \"rate_limit:*\"\n\n# Check specific user's rate limit\ndocker exec hw-redis redis-cli GET \"rate_limit:user:user123\"\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Increase Rate Limits: <pre><code># .env.production\nRATE_LIMIT_PER_MINUTE=120  # Increase from 60\nRATE_LIMIT_BURST=20  # Increase from 10\nWS_MESSAGE_RATE_LIMIT=200  # Increase from 100\n\n# Restart application\ndocker-compose restart hw-server\n</code></pre></p> </li> <li> <p>Clear Rate Limit Keys: <pre><code># Clear specific user\ndocker exec hw-redis redis-cli DEL \"rate_limit:user:user123\"\n\n# Clear all rate limit keys (careful!)\ndocker exec hw-redis redis-cli KEYS \"rate_limit:*\" | \\\n  xargs docker exec hw-redis redis-cli DEL\n</code></pre></p> </li> <li> <p>Exclude Specific Endpoints: <pre><code># app/middlewares/rate_limit.py\nEXCLUDED_PATHS = [\n    r\"^/health$\",\n    r\"^/metrics$\",\n    r\"^/docs$\",\n    r\"^/internal/.*\",  # Add internal endpoints\n]\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#log-analysis","title":"Log Analysis","text":""},{"location":"deployment/troubleshooting/#finding-errors-in-logs","title":"Finding Errors in Logs","text":"<p>Common LogQL Queries:</p> <pre><code># Recent errors\n{service=\"shell\"} | json | level=\"ERROR\"\n\n# Authentication failures\n{service=\"shell\"} | json | logger=~\"app.auth.*\" |~ \"(?i)(failed|invalid|denied)\"\n\n# Database errors\n{service=\"shell\"} | json |~ \"(?i)(database|postgres|sqlalchemy)\" | level=\"ERROR\"\n\n# Slow queries (requires duration_ms field)\n{service=\"shell\"} | json | duration_ms &gt; 1000\n\n# WebSocket errors\n{service=\"shell\"} | json | logger=~\"app.api.ws.*\" | level=\"ERROR\"\n\n# Rate limit violations\n{service=\"shell\"} | json |~ \"(?i)(rate limit|429|too many requests)\"\n\n# Specific user activity\n{service=\"shell\"} | json | user_id=\"user123\"\n\n# Specific endpoint\n{service=\"shell\"} | json | endpoint=~\"/api/authors.*\"\n</code></pre>"},{"location":"deployment/troubleshooting/#analyzing-performance-issues","title":"Analyzing Performance Issues","text":"<pre><code># HTTP request duration\n{service=\"shell\"} | json | logfmt | line_format \"{{.method}} {{.endpoint}} {{.duration_ms}}ms\"\n\n# Database query performance\n{service=\"shell\"} | json |~ \"(?i)query\" | line_format \"{{.message}} {{.duration_ms}}ms\"\n\n# Top error messages\n{service=\"shell\"} | json | level=\"ERROR\" | line_format \"{{.message}}\" | count by message\n</code></pre>"},{"location":"deployment/troubleshooting/#emergency-procedures","title":"Emergency Procedures","text":""},{"location":"deployment/troubleshooting/#application-down","title":"Application Down","text":"<p>Immediate Actions:</p> <ol> <li> <p>Check service health: <pre><code>docker ps | grep hw-\ncurl http://localhost:8000/health\n</code></pre></p> </li> <li> <p>Restart failed services: <pre><code>docker-compose -f docker/docker-compose.yml restart hw-server\n</code></pre></p> </li> <li> <p>Check recent logs: <pre><code>docker logs hw-server --tail 100\ndocker logs hw-traefik --tail 100\n</code></pre></p> </li> <li> <p>If restart fails, rollback: <pre><code>git log --oneline -5\ngit checkout &lt;previous-working-commit&gt;\ndocker-compose down\ndocker-compose up -d\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#database-corruption","title":"Database Corruption","text":"<p>Immediate Actions:</p> <ol> <li> <p>Stop application: <pre><code>docker-compose stop hw-server\n</code></pre></p> </li> <li> <p>Check database integrity: <pre><code>docker exec hw-db pg_dump -U prod_user fastapi_prod &gt; emergency_backup.sql\n</code></pre></p> </li> <li> <p>Restore from backup: <pre><code>docker exec hw-db psql -U postgres -c \"DROP DATABASE fastapi_prod;\"\ndocker exec hw-db psql -U postgres -c \"CREATE DATABASE fastapi_prod;\"\ndocker exec -i hw-db psql -U prod_user fastapi_prod &lt; latest_backup.sql\n</code></pre></p> </li> <li> <p>Restart application: <pre><code>docker-compose start hw-server\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#security-incident","title":"Security Incident","text":"<p>Immediate Actions:</p> <ol> <li> <p>Isolate affected services: <pre><code># Disconnect from network\ndocker network disconnect hw-network hw-server\n</code></pre></p> </li> <li> <p>Review audit logs: <pre><code>docker logs hw-server | grep -i \"suspicious\\|attack\\|unauthorized\"\n</code></pre></p> </li> <li> <p>Block malicious IPs (if applicable): <pre><code>sudo ufw deny from &lt;malicious-ip&gt;\n</code></pre></p> </li> <li> <p>Rotate credentials: <pre><code># Generate new secrets\nopenssl rand -hex 32\n\n# Update .env.production\n# Restart services\ndocker-compose restart\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#complete-system-failure","title":"Complete System Failure","text":"<p>Recovery Steps:</p> <ol> <li> <p>Document current state: <pre><code>docker ps -a &gt; system_state.txt\ndocker logs hw-server &gt; logs_server.txt\ndocker logs hw-db &gt; logs_db.txt\n</code></pre></p> </li> <li> <p>Stop all services: <pre><code>docker-compose -f docker/docker-compose.yml down\n</code></pre></p> </li> <li> <p>Restore from backups: <pre><code># Restore database\ndocker volume rm postgres-hw-data\ndocker volume create postgres-hw-data\ndocker-compose up -d hw-db\ndocker exec -i hw-db psql -U prod_user fastapi_prod &lt; backup.sql\n\n# Restore Redis data if needed\ndocker volume rm redis-hw-data\ndocker volume create redis-hw-data\n</code></pre></p> </li> <li> <p>Start services gradually: <pre><code>docker-compose up -d hw-db hw-redis\nsleep 10\ndocker-compose up -d hw-keycloak\nsleep 10\ndocker-compose up -d hw-server\ndocker-compose up -d hw-traefik\n</code></pre></p> </li> <li> <p>Verify system health: <pre><code>curl http://localhost:8000/health\ndocker ps\ndocker-compose logs --tail 50\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If issues persist after trying these solutions:</p> <ol> <li>Check application logs in Grafana:</li> <li>http://localhost:3000/d/application-logs</li> <li> <p>Filter by service, level, endpoint</p> </li> <li> <p>Review metrics in Prometheus:</p> </li> <li>http://localhost:9090</li> <li> <p>Check for anomalies</p> </li> <li> <p>Consult documentation:</p> </li> <li>Monitoring Guide</li> <li>Backup/Recovery Guide</li> <li> <p>Security Guide</p> </li> <li> <p>Contact support:</p> </li> <li>GitHub Issues: https://github.com/acikabubo/fastapi-http-websocket/issues</li> <li>Internal documentation: Confluence/Wiki</li> <li>On-call rotation: PagerDuty</li> </ol>"},{"location":"deployment/troubleshooting/#additional-resources","title":"Additional Resources","text":"<ul> <li>Docker Documentation</li> <li>PostgreSQL Troubleshooting</li> <li>Redis Troubleshooting</li> <li>Traefik Documentation</li> <li>FastAPI Documentation</li> </ul>"},{"location":"development/","title":"Development","text":"<p>Resources for developers contributing to the project.</p>"},{"location":"development/#development-guides","title":"Development Guides","text":"<ul> <li>Setup - Development environment setup</li> <li>Testing - Writing and running tests</li> <li>Database Migrations - Managing database schema</li> <li>Code Quality - Linting, formatting, and best practices</li> <li>Contributing - Contribution guidelines</li> </ul>"},{"location":"development/#quick-commands","title":"Quick Commands","text":"<p>```bash</p>"},{"location":"development/#run-tests","title":"Run tests","text":"<p>make test</p>"},{"location":"development/#start-development-server","title":"Start development server","text":"<p>make serve</p>"},{"location":"development/#run-linter","title":"Run linter","text":"<p>make ruff-check</p>"},{"location":"development/#create-migration","title":"Create migration","text":"<p>make migration msg=\"add new field\" ```</p>"},{"location":"development/code-quality/","title":"Code Quality","text":""},{"location":"development/code-quality/#overview","title":"Overview","text":"<p>The project maintains high code quality standards through automated tools and pre-commit hooks.</p>"},{"location":"development/code-quality/#code-style","title":"Code Style","text":""},{"location":"development/code-quality/#line-length","title":"Line Length","text":"<p>79 characters maximum (enforced by Ruff)</p>"},{"location":"development/code-quality/#formatting","title":"Formatting","text":"<pre><code># Format code\nuvx ruff format\n\n# Check formatting\nuvx ruff check --config=pyproject.toml\n</code></pre>"},{"location":"development/code-quality/#type-hints","title":"Type Hints","text":"<p>Required on all functions (enforced by mypy --strict):</p> <pre><code>def get_author(author_id: int) -&gt; Author | None:\n    \"\"\"Get author by ID.\"\"\"\n    pass\n</code></pre>"},{"location":"development/code-quality/#docstrings","title":"Docstrings","text":"<p>Required on all public functions, classes, and methods (80% coverage minimum):</p> <pre><code>def create_author(name: str) -&gt; Author:\n    \"\"\"\n    Create a new author.\n\n    Args:\n        name: Author's full name\n\n    Returns:\n        Created author instance\n\n    Raises:\n        ValueError: If name is empty\n    \"\"\"\n    pass\n</code></pre>"},{"location":"development/code-quality/#linting","title":"Linting","text":""},{"location":"development/code-quality/#ruff","title":"Ruff","text":"<pre><code># Check all files\nmake ruff-check\n\n# Auto-fix issues\nuvx ruff check --fix\n</code></pre>"},{"location":"development/code-quality/#mypy","title":"Mypy","text":"<pre><code># Type check\nuvx mypy app/\n</code></pre>"},{"location":"development/code-quality/#interrogate","title":"Interrogate","text":"<pre><code># Check docstring coverage\nuvx interrogate app/\n</code></pre>"},{"location":"development/code-quality/#security","title":"Security","text":""},{"location":"development/code-quality/#bandit","title":"Bandit","text":"<pre><code># SAST scanning\nmake bandit-scan\n</code></pre>"},{"location":"development/code-quality/#skjold","title":"Skjold","text":"<pre><code># Dependency vulnerability scanning\nmake skjold-scan\n</code></pre>"},{"location":"development/code-quality/#dead-code-detection","title":"Dead Code Detection","text":"<pre><code># Find unused code\nmake dead-code-scan\n</code></pre>"},{"location":"development/code-quality/#spell-checking","title":"Spell Checking","text":"<pre><code># Check typos\nuvx typos\n</code></pre>"},{"location":"development/code-quality/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>All checks run automatically on commit:</p> <pre><code># Install hooks\npre-commit install\n\n# Run manually\npre-commit run --all-files\n</code></pre>"},{"location":"development/code-quality/#related","title":"Related","text":"<ul> <li>Testing Guide</li> <li>Contributing Guide</li> </ul>"},{"location":"development/contributing/","title":"Contributing Guide","text":""},{"location":"development/contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository</li> <li>Clone your fork</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Run tests and linting</li> <li>Submit a pull request</li> </ol>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#1-create-feature-branch","title":"1. Create Feature Branch","text":"<pre><code>git checkout -b feature/my-new-feature develop\n</code></pre>"},{"location":"development/contributing/#2-make-changes","title":"2. Make Changes","text":"<p>Follow Code Quality guidelines.</p>"},{"location":"development/contributing/#3-run-tests","title":"3. Run Tests","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=app --cov-report=html\n</code></pre>"},{"location":"development/contributing/#4-commit-changes","title":"4. Commit Changes","text":"<pre><code>git add .\ngit commit -m \"feat: Add new feature\"\n</code></pre> <p>Use conventional commit format: - <code>feat:</code> - New feature - <code>fix:</code> - Bug fix - <code>docs:</code> - Documentation changes - <code>refactor:</code> - Code refactoring - <code>test:</code> - Test changes</p>"},{"location":"development/contributing/#5-push-and-create-pr","title":"5. Push and Create PR","text":"<pre><code>git push origin feature/my-new-feature\n</code></pre> <p>Then create a pull request on GitHub.</p>"},{"location":"development/contributing/#code-review","title":"Code Review","text":"<p>Pull requests require: - \u2705 All tests passing - \u2705 Code coverage maintained - \u2705 Linting checks passing - \u2705 Documentation updated - \u2705 Reviewer approval</p>"},{"location":"development/contributing/#related","title":"Related","text":"<ul> <li>Testing Guide</li> <li>Code Quality</li> </ul>"},{"location":"development/migrations/","title":"Database Migrations with Alembic","text":"<p>This project uses Alembic for database schema migrations. Alembic provides version control for your database schema, allowing safe evolution of the database structure over time.</p>"},{"location":"development/migrations/#overview","title":"Overview","text":"<p>Previous approach: The project previously used <code>SQLModel.metadata.create_all()</code> which had limitations: - \u274c No migration history or rollback capability - \u274c Cannot safely modify existing tables - \u274c Risk of data loss when changing schemas - \u274c No team synchronization for schema changes</p> <p>Current approach: Alembic migrations provide: - \u2705 Version-controlled migration history - \u2705 Safe schema evolution without data loss - \u2705 Rollback support for failed migrations - \u2705 Automatic migration generation from model changes - \u2705 Team synchronization (everyone applies same migrations) - \u2705 Production-safe deployment workflow</p>"},{"location":"development/migrations/#quick-start","title":"Quick Start","text":""},{"location":"development/migrations/#applying-migrations","title":"Applying Migrations","text":"<p>Apply all pending migrations to bring your database up to date:</p> <pre><code>make migrate\n</code></pre> <p>This runs <code>alembic upgrade head</code> and applies all migrations that haven't been applied yet.</p>"},{"location":"development/migrations/#creating-new-migrations","title":"Creating New Migrations","text":"<p>When you modify a SQLModel (add/remove/modify fields), generate a new migration:</p> <pre><code>make migration msg=\"Add email field to Author\"\n</code></pre> <p>This will: 1. Auto-detect changes between your models and current database schema 2. Generate a new migration file in <code>app/storage/migrations/versions/</code> 3. Create both <code>upgrade()</code> and <code>downgrade()</code> functions</p> <p>Important: Always review the generated migration before applying it!</p>"},{"location":"development/migrations/#viewing-migration-status","title":"Viewing Migration Status","text":"<p>Check which migration is currently applied:</p> <pre><code>make migration-current\n</code></pre> <p>View full migration history:</p> <pre><code>make migration-history\n</code></pre>"},{"location":"development/migrations/#rolling-back-migrations","title":"Rolling Back Migrations","text":"<p>Roll back the most recent migration:</p> <pre><code>make rollback\n</code></pre> <p>This runs <code>alembic downgrade -1</code> to revert the last migration.</p>"},{"location":"development/migrations/#migration-workflow","title":"Migration Workflow","text":""},{"location":"development/migrations/#1-modify-your-model","title":"1. Modify Your Model","text":"<p>Edit a model file (e.g., <code>app/models/author.py</code>):</p> <pre><code>class Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    email: str | None = None  # NEW FIELD\n</code></pre>"},{"location":"development/migrations/#2-generate-migration","title":"2. Generate Migration","text":"<pre><code>make migration msg=\"Add email field to Author\"\n</code></pre>"},{"location":"development/migrations/#3-review-generated-migration","title":"3. Review Generated Migration","text":"<p>Check the generated file in <code>app/storage/migrations/versions/</code>:</p> <pre><code>def upgrade() -&gt; None:\n    # ### commands auto generated by Alembic ###\n    op.add_column('author', sa.Column('email', sa.String(), nullable=True))\n    # ### end Alembic commands ###\n\n\ndef downgrade() -&gt; None:\n    # ### commands auto generated by Alembic ###\n    op.drop_column('author', 'email')\n    # ### end Alembic commands ###\n</code></pre> <p>Important checks: - Verify the operations match your intent - Check for data loss risks (e.g., dropping columns) - Ensure nullable constraints are correct - Review default values for new required fields</p>"},{"location":"development/migrations/#4-apply-migration","title":"4. Apply Migration","text":"<pre><code>make migrate\n</code></pre>"},{"location":"development/migrations/#5-if-issues-occur-rollback","title":"5. If Issues Occur, Rollback","text":"<pre><code>make rollback\n</code></pre>"},{"location":"development/migrations/#advanced-usage","title":"Advanced Usage","text":""},{"location":"development/migrations/#manual-migration-creation","title":"Manual Migration Creation","text":"<p>For complex migrations that can't be auto-generated:</p> <pre><code>uv run alembic revision -m \"Custom migration description\"\n</code></pre> <p>Then manually edit the generated file to add your custom operations.</p>"},{"location":"development/migrations/#downgrade-to-specific-version","title":"Downgrade to Specific Version","text":"<pre><code>uv run alembic downgrade &lt;revision_id&gt;\n</code></pre>"},{"location":"development/migrations/#upgrade-to-specific-version","title":"Upgrade to Specific Version","text":"<pre><code>uv run alembic upgrade &lt;revision_id&gt;\n</code></pre>"},{"location":"development/migrations/#stamp-database-without-running-migrations","title":"Stamp Database Without Running Migrations","text":"<p>If you have an existing database that matches a specific migration:</p> <pre><code>make migration-stamp rev=\"&lt;revision_id&gt;\"\n</code></pre> <p>Or stamp to the latest:</p> <pre><code>make migration-stamp rev=\"head\"\n</code></pre> <p>This is useful when: - Migrating from the old <code>create_all()</code> approach to Alembic - Setting up a database that was manually created - Recovering from migration issues</p>"},{"location":"development/migrations/#initial-setup-for-new-developers","title":"Initial Setup (For New Developers)","text":"<ol> <li>Clone the repository</li> <li>Start services: <pre><code>make start  # Starts PostgreSQL, Redis, Keycloak, etc.\n</code></pre></li> <li>Apply migrations: <pre><code>make migrate\n</code></pre></li> </ol> <p>That's it! Your database schema is now up to date.</p>"},{"location":"development/migrations/#production-deployment","title":"Production Deployment","text":""},{"location":"development/migrations/#safe-deployment-process","title":"Safe Deployment Process","text":"<ol> <li> <p>Test migrations locally: <pre><code>make migrate\n</code></pre></p> </li> <li> <p>Review migration on staging environment</p> </li> <li> <p>Backup production database before applying migrations</p> </li> <li> <p>Apply migrations during maintenance window: <pre><code>make migrate\n</code></pre></p> </li> <li> <p>Verify application functionality</p> </li> <li> <p>If issues occur: <pre><code>make rollback\n</code></pre></p> </li> </ol>"},{"location":"development/migrations/#zero-downtime-migrations","title":"Zero-Downtime Migrations","text":"<p>For zero-downtime deployments, follow this pattern:</p> <p>Phase 1: Add new column (nullable) <pre><code># Migration 1: Add nullable column\nemail: str | None = None\n</code></pre></p> <p>Phase 2: Backfill data <pre><code># Migration 2: Populate email field\ndef upgrade():\n    # Custom data migration\n    op.execute(\"UPDATE author SET email = name || '@example.com'\")\n</code></pre></p> <p>Phase 3: Make non-nullable (if needed) <pre><code># Migration 3: Add NOT NULL constraint\ndef upgrade():\n    op.alter_column('author', 'email', nullable=False)\n</code></pre></p>"},{"location":"development/migrations/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/migrations/#target-database-is-not-up-to-date","title":"\"Target database is not up to date\"","text":"<pre><code># Check current version\nmake migration-current\n\n# Apply pending migrations\nmake migrate\n</code></pre>"},{"location":"development/migrations/#cant-locate-revision-identified-by-xyz","title":"\"Can't locate revision identified by 'xyz'\"","text":"<p>The migration file might have been deleted. Check <code>app/storage/migrations/versions/</code> directory.</p>"},{"location":"development/migrations/#failed-multiple-head-revisions-are-present","title":"\"FAILED: Multiple head revisions are present\"","text":"<p>This happens when multiple branches exist in migration history. Merge them:</p> <pre><code>uv run alembic merge heads -m \"Merge migration branches\"\n</code></pre>"},{"location":"development/migrations/#migration-conflicts","title":"Migration Conflicts","text":"<p>If you get conflicts because someone else created a migration:</p> <ol> <li>Pull latest code</li> <li>Regenerate your migration:    <pre><code>rm app/storage/migrations/versions/your_migration.py\nmake migration msg=\"Your description\"\n</code></pre></li> </ol>"},{"location":"development/migrations/#reset-migration-history-development-only","title":"Reset Migration History (Development Only!)","text":"<p>WARNING: This will delete all migration history. Never do this in production!</p> <pre><code># Drop all tables\n# Recreate database\n# Regenerate initial migration\nmake migration msg=\"Initial migration\"\nmake migrate\n</code></pre>"},{"location":"development/migrations/#configuration","title":"Configuration","text":""},{"location":"development/migrations/#database-connection","title":"Database Connection","text":"<p>Alembic automatically uses the database URL from <code>app/settings.py</code>:</p> <pre><code>DATABASE_URL = f\"postgresql+asyncpg://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n</code></pre> <p>This is configured in <code>app/storage/migrations/env.py</code>:</p> <pre><code>config.set_main_option(\"sqlalchemy.url\", app_settings.DATABASE_URL)\n</code></pre>"},{"location":"development/migrations/#adding-new-models","title":"Adding New Models","text":"<p>When you create a new model, import it in <code>app/storage/migrations/env.py</code>:</p> <pre><code>from app.models.author import Author  # noqa: F401\nfrom app.models.book import Book  # noqa: F401  # ADD NEW IMPORTS\n</code></pre> <p>This ensures Alembic can detect the model and generate migrations for it.</p>"},{"location":"development/migrations/#best-practices","title":"Best Practices","text":""},{"location":"development/migrations/#do","title":"\u2705 Do","text":"<ul> <li>Always review generated migrations before applying</li> <li>Test migrations on development/staging before production</li> <li>Backup production database before running migrations</li> <li>Use descriptive migration messages: <code>make migration msg=\"Add user email verification\"</code></li> <li>Keep migrations small and focused on one logical change</li> <li>Commit migration files to version control</li> <li>Add custom data migrations when needed (e.g., backfilling data)</li> </ul>"},{"location":"development/migrations/#dont","title":"\u274c Don't","text":"<ul> <li>Never edit applied migrations - create a new migration instead</li> <li>Never delete migration files that have been applied to production</li> <li>Don't skip reviewing auto-generated migrations</li> <li>Don't make breaking changes without a rollout plan</li> <li>Don't drop columns without checking for data</li> <li>Never use <code>make rollback</code> in production without careful consideration</li> </ul>"},{"location":"development/migrations/#common-operations","title":"Common Operations","text":""},{"location":"development/migrations/#add-a-column","title":"Add a Column","text":"<pre><code># Model change\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    bio: str | None = None  # NEW\n</code></pre> <pre><code>make migration msg=\"Add bio to Author\"\nmake migrate\n</code></pre>"},{"location":"development/migrations/#remove-a-column","title":"Remove a Column","text":"<pre><code># Model change - remove field\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    # bio removed\n</code></pre> <pre><code>make migration msg=\"Remove bio from Author\"\n# Review the migration - it will drop the column!\nmake migrate\n</code></pre>"},{"location":"development/migrations/#rename-a-column","title":"Rename a Column","text":"<p>Alembic can't auto-detect renames (it sees drop + add). Do it manually:</p> <pre><code>def upgrade() -&gt; None:\n    op.alter_column('author', 'name', new_column_name='full_name')\n\ndef downgrade() -&gt; None:\n    op.alter_column('author', 'full_name', new_column_name='name')\n</code></pre>"},{"location":"development/migrations/#change-column-type","title":"Change Column Type","text":"<pre><code># Model change\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str = Field(max_length=200)  # Changed from default\n</code></pre> <pre><code>make migration msg=\"Increase author name length\"\nmake migrate\n</code></pre>"},{"location":"development/migrations/#add-index","title":"Add Index","text":"<pre><code># Model change\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str = Field(index=True)  # Add index\n</code></pre> <pre><code>make migration msg=\"Add index on author name\"\nmake migrate\n</code></pre>"},{"location":"development/migrations/#additional-resources","title":"Additional Resources","text":"<ul> <li>Alembic Documentation</li> <li>SQLModel Documentation</li> <li>Alembic Tutorial</li> <li>Alembic Auto Generate</li> <li>SQLAlchemy Migration Operations</li> </ul>"},{"location":"development/migrations/#support","title":"Support","text":"<p>If you encounter issues with migrations:</p> <ol> <li>Check this documentation</li> <li>Review the Alembic documentation</li> <li>Check migration history: <code>make migration-history</code></li> <li>Verify current version: <code>make migration-current</code></li> <li>Ask the team for help if stuck</li> </ol>"},{"location":"development/setup/","title":"Development Setup","text":""},{"location":"development/setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.13+</li> <li>Docker &amp; Docker Compose</li> <li>Git</li> <li>uv (Python package manager)</li> </ul>"},{"location":"development/setup/#quick-start","title":"Quick Start","text":"<pre><code># Clone repository\ngit clone https://github.com/your-org/fastapi-http-websocket.git\ncd fastapi-http-websocket\n\n# Install dependencies\nuv sync\n\n# Start services (PostgreSQL, Redis, Keycloak)\nmake start\n\n# Run migrations\nmake migrate\n\n# Start development server\nmake serve\n</code></pre>"},{"location":"development/setup/#detailed-setup","title":"Detailed Setup","text":"<p>See Installation Guide for complete instructions.</p>"},{"location":"development/setup/#development-tools","title":"Development Tools","text":"<pre><code># Code quality\nmake ruff-check      # Linting\nmake dead-code-scan  # Find unused code\nuvx mypy app/        # Type checking\n\n# Testing\nuv run pytest                    # Run all tests\nuv run pytest tests/test_foo.py  # Run specific test\n\n# Database\nmake migration msg=\"Add field\"  # Create migration\nmake migrate                     # Apply migrations\nmake rollback                   # Rollback last migration\n</code></pre>"},{"location":"development/setup/#ide-setup","title":"IDE Setup","text":""},{"location":"development/setup/#vscode","title":"VSCode","text":"<p>Install recommended extensions: - Python - Pylance - Ruff - SQLTools</p>"},{"location":"development/setup/#pycharm","title":"PyCharm","text":"<p>Configure interpreter to use uv virtual environment.</p>"},{"location":"development/setup/#related","title":"Related","text":"<ul> <li>Installation Guide</li> <li>Testing Guide</li> <li>Code Quality</li> </ul>"},{"location":"development/testing/","title":"Testing Guide","text":"<p>This guide explains how to debug and test the application after removing the hardcoded authentication bypass.</p>"},{"location":"development/testing/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Getting Valid Tokens</li> <li>Debug Mode (Development Only)</li> <li>Manual Testing</li> <li>Automated Testing with Pytest</li> <li>Testing WebSocket Endpoints</li> </ol>"},{"location":"development/testing/#getting-valid-tokens","title":"Getting Valid Tokens","text":""},{"location":"development/testing/#method-1-using-the-token-helper-script-recommended","title":"Method 1: Using the Token Helper Script (Recommended)","text":"<p>The easiest way to get a valid access token:</p> <pre><code># Get token for user 'acika'\npython scripts/get_token.py acika 12345\n\n# Output will show:\n# === Access Token ===\n# eyJhbGci...\n#\n# === Token Info ===\n# Expires in: 300 seconds\n# User: acika\n# Roles: ['admin', 'get-authors', ...]\n</code></pre> <p>For JSON output: <pre><code>python scripts/get_token.py acika 12345 --json\n</code></pre></p> <p>Include refresh token: <pre><code>python scripts/get_token.py acika 12345 --refresh\n</code></pre></p>"},{"location":"development/testing/#method-2-direct-api-call-to-keycloak","title":"Method 2: Direct API Call to Keycloak","text":"<pre><code>curl -X POST \"http://localhost:8080/realms/HW-App/protocol/openid-connect/token\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"username=acika\" \\\n  -d \"password=12345\" \\\n  -d \"grant_type=password\" \\\n  -d \"client_id=auth-hw-frontend\"\n</code></pre>"},{"location":"development/testing/#method-3-use-keycloak-admin-console","title":"Method 3: Use Keycloak Admin Console","text":"<ol> <li>Navigate to http://localhost:8080</li> <li>Login with admin credentials (admin/admin)</li> <li>Go to your realm \u2192 Users</li> <li>Select a user \u2192 Credentials \u2192 Generate token</li> </ol>"},{"location":"development/testing/#debug-mode-development-only","title":"Debug Mode (Development Only)","text":"<p>For quick local testing, you can enable debug mode to bypass token validation.</p> <p>\u26a0\ufe0f WARNING: NEVER enable DEBUG_AUTH in production!</p>"},{"location":"development/testing/#enable-debug-mode","title":"Enable Debug Mode","text":"<p>Option 1: Environment Variable <pre><code>export DEBUG_AUTH=true\nuvicorn app:application --reload\n</code></pre></p> <p>Option 2: In docker/.srv_env <pre><code># Add to docker/.srv_env\nDEBUG_AUTH=true\n</code></pre></p> <p>Option 3: Override defaults <pre><code># Custom debug user\nexport DEBUG_AUTH=true\nexport DEBUG_AUTH_USERNAME=testuser\nexport DEBUG_AUTH_PASSWORD=testpass\n</code></pre></p> <p>When DEBUG_AUTH is enabled, you'll see a warning in logs: <pre><code>WARNING - DEBUG_AUTH is enabled - using debug credentials. NEVER enable this in production!\n</code></pre></p>"},{"location":"development/testing/#disable-debug-mode","title":"Disable Debug Mode","text":"<pre><code>unset DEBUG_AUTH\n# or\nexport DEBUG_AUTH=false\n</code></pre>"},{"location":"development/testing/#manual-testing","title":"Manual Testing","text":""},{"location":"development/testing/#http-endpoints","title":"HTTP Endpoints","text":"<p>Using cURL: <pre><code># 1. Get token\nTOKEN=$(python scripts/get_token.py acika 12345 | grep -A1 \"Access Token\" | tail -1 | xargs)\n\n# 2. Make authenticated request\ncurl -X GET \"http://localhost:8000/authors\" \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\"\n</code></pre></p> <p>Using VS Code REST Client (api-testing/api.http): <pre><code>@baseUrl = localhost:8000\n\n### GET Request Example\nGET http://{{baseUrl}}/authors\nContent-Type: application/json\nAuthorization: Bearer eyJhbGci...YOUR_TOKEN_HERE...\n</code></pre></p> <p>Using HTTPie: <pre><code>TOKEN=$(python scripts/get_token.py acika 12345 | grep -A1 \"Access Token\" | tail -1 | xargs)\nhttp GET localhost:8000/authors \"Authorization: Bearer $TOKEN\"\n</code></pre></p>"},{"location":"development/testing/#websocket-endpoints","title":"WebSocket Endpoints","text":"<p>Using wscat: <pre><code># Install wscat\nnpm install -g wscat\n\n# Get token\nTOKEN=$(python scripts/get_token.py acika 12345 | grep -A1 \"Access Token\" | tail -1 | xargs)\n\n# Connect\nwscat -c \"ws://localhost:8000/web?Authorization=Bearer $TOKEN\"\n\n# Send message\n{\"pkg_id\": 1, \"req_id\": \"test-123\", \"data\": {}}\n</code></pre></p> <p>Using VS Code REST Client (api-testing/ws.http): <pre><code>WS ws://localhost:8000/web?Authorization=Bearer YOUR_TOKEN_HERE\n\n{\"pkg_id\": 1, \"req_id\": \"123qweasd\"}\n</code></pre></p>"},{"location":"development/testing/#automated-testing-with-pytest","title":"Automated Testing with Pytest","text":""},{"location":"development/testing/#using-mock-authentication-unit-tests","title":"Using Mock Authentication (Unit Tests)","text":"<p>The <code>tests/conftest.py</code> provides fixtures that mock Keycloak:</p> <pre><code>import pytest\nfrom app.schemas.request import RequestModel\nfrom app.api.ws.handlers.author_handler import get_authors_handler\n\n\n@pytest.mark.asyncio\nasync def test_get_authors_with_mock_auth(\n    mock_keycloak_manager, mock_user\n):\n    \"\"\"Test handler with mocked authentication.\"\"\"\n    request = RequestModel(\n        pkg_id=1,\n        req_id=\"test-123\",\n        data={\"filters\": {\"name\": \"Test\"}}\n    )\n\n    response = await get_authors_handler(request)\n\n    assert response.status_code == 0\n    assert isinstance(response.data, list)\n</code></pre>"},{"location":"development/testing/#available-fixtures","title":"Available Fixtures","text":"<ul> <li><code>mock_keycloak_token</code>: Mock token response</li> <li><code>mock_user_data</code>: Mock decoded user data</li> <li><code>mock_user</code>: UserModel instance</li> <li><code>mock_keycloak_manager</code>: Mocked KeycloakManager</li> <li><code>auth_headers</code>: Headers with Bearer token</li> <li><code>admin_user_data</code>: Admin user with full permissions</li> <li><code>limited_user_data</code>: User with limited permissions</li> </ul>"},{"location":"development/testing/#testing-rbac-permissions","title":"Testing RBAC Permissions","text":"<pre><code>@pytest.mark.asyncio\nasync def test_permission_denied_for_limited_user(limited_user_data):\n    \"\"\"Test that users without proper roles are denied.\"\"\"\n    user = UserModel(**limited_user_data)\n    request = RequestModel(pkg_id=1, req_id=\"test-123\", data={})\n\n    response = await pkg_router.handle_request(user, request)\n\n    assert response.status_code == RSPCode.PERMISSION_DENIED\n</code></pre>"},{"location":"development/testing/#integration-tests-with-real-keycloak","title":"Integration Tests with Real Keycloak","text":"<p>For integration tests that actually connect to Keycloak:</p> <pre><code>@pytest.mark.integration\n@pytest.mark.asyncio\nasync def test_real_keycloak_auth():\n    \"\"\"Integration test with real Keycloak instance.\"\"\"\n    from app.managers.keycloak_manager import KeycloakManager\n\n    kc = KeycloakManager()\n    token = kc.login(\"acika\", \"12345\")\n\n    assert \"access_token\" in token\n\n    user_data = kc.openid.decode_token(token[\"access_token\"])\n    assert user_data[\"preferred_username\"] == \"acika\"\n</code></pre> <p>Run integration tests only: <pre><code>uv run pytest -m integration\n</code></pre></p>"},{"location":"development/testing/#testing-websocket-endpoints","title":"Testing WebSocket Endpoints","text":""},{"location":"development/testing/#example-websocket-test","title":"Example WebSocket Test","text":"<pre><code>import pytest\nfrom fastapi.testclient import TestClient\nfrom app import application\n\n\n@pytest.mark.asyncio\nasync def test_websocket_connection(mock_keycloak_manager):\n    \"\"\"Test WebSocket connection with authentication.\"\"\"\n    client = TestClient(application())\n\n    with client.websocket_connect(\n        \"/web?Authorization=Bearer mock_token\"\n    ) as websocket:\n        # Send request\n        websocket.send_json({\n            \"pkg_id\": 1,\n            \"req_id\": \"ws-test-123\",\n            \"data\": {}\n        })\n\n        # Receive response\n        response = websocket.receive_json()\n\n        assert response[\"pkg_id\"] == 1\n        assert response[\"req_id\"] == \"ws-test-123\"\n</code></pre>"},{"location":"development/testing/#makefile-integration","title":"Makefile Integration","text":"<p>Add these helpful commands to your workflow:</p> <pre><code># Get token quickly\nmake get-token USER=acika PASS=12345\n\n# Run tests with coverage\nmake test-with-coverage\n\n# Start server in debug mode\nmake serve-debug\n</code></pre> <p>Add to Makefile: <pre><code>get-token:\n    @python scripts/get_token.py $(USER) $(PASS)\n\ntest-with-coverage:\n    @uv run pytest --cov=app --cov-report=html\n\nserve-debug:\n    @export DEBUG_AUTH=true &amp;&amp; uvicorn app:application --reload\n</code></pre></p>"},{"location":"development/testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/testing/#token-expired","title":"Token Expired","text":"<p>Error: <code>JWT token expired</code></p> <p>Solution: Tokens expire after 5 minutes. Get a fresh token: <pre><code>python scripts/get_token.py acika 12345\n</code></pre></p>"},{"location":"development/testing/#keycloak-not-running","title":"Keycloak Not Running","text":"<p>Error: Connection refused to hw-keycloak:8080</p> <p>Solution: <pre><code>make start  # Start all services including Keycloak\ndocker ps   # Verify hw-keycloak is running\n</code></pre></p>"},{"location":"development/testing/#invalid-credentials","title":"Invalid Credentials","text":"<p>Error: <code>Invalid credentials</code></p> <p>Solution: Verify user exists in Keycloak and credentials are correct: <pre><code># Access Keycloak admin console\nopen http://localhost:8080\n# Login: admin/admin\n# Check Users in HW-App realm\n</code></pre></p>"},{"location":"development/testing/#permission-denied","title":"Permission Denied","text":"<p>Error: <code>No permission for pkg_id X</code></p> <p>Solution: Check handler's <code>roles</code> parameter in <code>@pkg_router.register()</code> decorator and ensure user has required role: <pre><code># See your roles\npython scripts/get_token.py acika 12345\n# Output shows: Roles: ['admin', 'get-authors', ...]\n\n# Check handler code for required roles\n# Example: @pkg_router.register(PkgID.GET_AUTHORS, roles=[\"get-authors\"])\n</code></pre></p>"},{"location":"development/testing/#best-practices","title":"Best Practices","text":"<ol> <li>Use Mock Authentication for Unit Tests: Fast and reliable</li> <li>Use Real Tokens for Integration Tests: Catch real-world issues</li> <li>Never commit tokens: Tokens in git history are security risks</li> <li>Rotate tokens regularly: Even in development</li> <li>Disable DEBUG_AUTH in CI/CD: Force proper authentication in pipelines</li> <li>Test with different user roles: Verify RBAC properly</li> </ol>"},{"location":"development/testing/#example-test-file","title":"Example Test File","text":"<p>See <code>tests/test_auth_example.py</code> for a complete example of testing with authentication.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to the FastAPI HTTP/WebSocket Template! This guide will help you get up and running quickly.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.13+ - Download Python</li> <li>Docker &amp; Docker Compose - Install Docker</li> <li>uv - Python package manager: <code>pip install uv</code></li> <li>Git - Version control</li> </ul>"},{"location":"getting-started/#quick-setup","title":"Quick Setup","text":"<p>Follow these three steps to get started:</p> <ol> <li>Installation - Set up your development environment</li> <li>Quick Start - Create your first endpoints</li> <li>Configuration - Configure services and environment</li> </ol>"},{"location":"getting-started/#what-youll-build","title":"What You'll Build","text":"<p>By the end of this guide, you'll have:</p> <ul> <li>\u2705 A running FastAPI application with HTTP and WebSocket support</li> <li>\u2705 Keycloak authentication with JWT tokens</li> <li>\u2705 PostgreSQL database with migrations</li> <li>\u2705 Redis for caching and rate limiting</li> <li>\u2705 Prometheus metrics and Grafana dashboards</li> <li>\u2705 Full observability stack (logs, metrics, traces)</li> </ul>"},{"location":"getting-started/#learning-path","title":"Learning Path","text":"BeginnersExperienced Developers <ol> <li>Start with Installation</li> <li>Follow the Quick Start guide</li> <li>Learn about Authentication</li> <li>Explore HTTP Endpoints</li> </ol> <ol> <li>Review Architecture Overview</li> <li>Check Design Patterns</li> <li>Jump to API Reference</li> <li>Deploy with Production Guide</li> </ol>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li> <p> Install</p> <p>Set up your development environment</p> <p> Installation Guide</p> </li> <li> <p> Quick Start</p> <p>Build your first endpoints in 10 minutes</p> <p> Quick Start</p> </li> <li> <p> Configure</p> <p>Configure services and environment</p> <p> Configuration</p> </li> </ul>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Learn how to configure the application and its services for different environments.</p>"},{"location":"getting-started/configuration/#environment-files","title":"Environment Files","text":"<p>The project uses multiple environment files:</p> File Purpose Location <code>.env</code> Application configuration Project root <code>docker/.srv_env</code> Service environment Docker directory <code>docker/.pg_env</code> PostgreSQL credentials Docker directory <code>docker/.kc_env</code> Keycloak configuration Docker directory"},{"location":"getting-started/configuration/#application-configuration","title":"Application Configuration","text":""},{"location":"getting-started/configuration/#env-file","title":".env File","text":"<p>Create <code>.env</code> in the project root:</p> <pre><code># ========================================\n# Application Settings\n# ========================================\nENVIRONMENT=development  # development, staging, production\nDEBUG=true\nLOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR, CRITICAL\n\n# ========================================\n# Database Configuration\n# ========================================\nDATABASE_URL=postgresql+asyncpg://fastapi:fastapi@localhost:5432/fastapi\nDB_POOL_SIZE=20\nDB_MAX_OVERFLOW=10\n\n# ========================================\n# Redis Configuration\n# ========================================\nREDIS_IP=localhost\nREDIS_PORT=6379\nREDIS_PASSWORD=  # Leave empty for no auth in development\nMAIN_REDIS_DB=0\nAUTH_REDIS_DB=1\nREDIS_MAX_CONNECTIONS=50\n\n# ========================================\n# Keycloak Configuration\n# ========================================\nKEYCLOAK_BASE_URL=http://localhost:8080\nKEYCLOAK_REALM=development\nKEYCLOAK_CLIENT_ID=fastapi-app\nKEYCLOAK_CLIENT_SECRET=your-client-secret-here\n\nKEYCLOAK_ADMIN_USERNAME=admin\nKEYCLOAK_ADMIN_PASSWORD=admin\n\n# ========================================\n# Security\n# ========================================\nSECRET_KEY=your-secret-key-here  # Generate with: openssl rand -hex 32\nALLOWED_HOSTS=[\"localhost\", \"127.0.0.1\"]\nCORS_ORIGINS=[\"http://localhost:3000\", \"http://localhost:8000\"]\n\n# ========================================\n# Rate Limiting\n# ========================================\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_PER_MINUTE=60\nRATE_LIMIT_BURST=10\nWS_MAX_CONNECTIONS_PER_USER=5\nWS_MESSAGE_RATE_LIMIT=100\n\n# ========================================\n# Monitoring\n# ========================================\nPROMETHEUS_ENABLED=true\nLOKI_URL=http://localhost:3100\n\n# ========================================\n# Logging\n# ========================================\nLOG_CONSOLE_FORMAT=human  # human or json\nAUDIT_QUEUE_MAX_SIZE=10000\n</code></pre>"},{"location":"getting-started/configuration/#docker-services-configuration","title":"Docker Services Configuration","text":""},{"location":"getting-started/configuration/#postgresql-dockerpg_env","title":"PostgreSQL (docker/.pg_env)","text":"<pre><code>POSTGRES_USER=fastapi\nPOSTGRES_PASSWORD=fastapi\nPOSTGRES_DB=fastapi\n</code></pre>"},{"location":"getting-started/configuration/#keycloak-dockerkc_env","title":"Keycloak (docker/.kc_env)","text":"<pre><code>KEYCLOAK_ADMIN=admin\nKEYCLOAK_ADMIN_PASSWORD=admin\n\nKC_DB=postgres\nKC_DB_URL_HOST=hw-db\nKC_DB_URL_DATABASE=keycloak\nKC_DB_URL_PORT=5432\nKC_DB_USERNAME=fastapi\nKC_DB_PASSWORD=fastapi\n\nKC_HOSTNAME=localhost\nKC_HTTP_ENABLED=true\nKC_HOSTNAME_STRICT=false\nKC_PROXY=edge\n\nKC_METRICS_ENABLED=true\nKC_HEALTH_ENABLED=true\n</code></pre>"},{"location":"getting-started/configuration/#application-service-dockersrv_env","title":"Application Service (docker/.srv_env)","text":"<pre><code>LOG_CONSOLE_FORMAT=human  # human for development, json for production\n</code></pre>"},{"location":"getting-started/configuration/#configuration-options","title":"Configuration Options","text":""},{"location":"getting-started/configuration/#database-settings","title":"Database Settings","text":"Variable Default Description <code>DATABASE_URL</code> - PostgreSQL connection string <code>DB_POOL_SIZE</code> 20 Connection pool size <code>DB_MAX_OVERFLOW</code> 10 Max overflow connections"},{"location":"getting-started/configuration/#redis-settings","title":"Redis Settings","text":"Variable Default Description <code>REDIS_IP</code> localhost Redis host <code>REDIS_PORT</code> 6379 Redis port <code>MAIN_REDIS_DB</code> 0 Main Redis database number <code>AUTH_REDIS_DB</code> 1 Auth Redis database number <code>REDIS_MAX_CONNECTIONS</code> 50 Max Redis connections"},{"location":"getting-started/configuration/#rate-limiting","title":"Rate Limiting","text":"Variable Default Description <code>RATE_LIMIT_ENABLED</code> true Enable rate limiting <code>RATE_LIMIT_PER_MINUTE</code> 60 HTTP requests per minute <code>RATE_LIMIT_BURST</code> 10 Burst allowance <code>WS_MAX_CONNECTIONS_PER_USER</code> 5 Max WebSocket connections per user <code>WS_MESSAGE_RATE_LIMIT</code> 100 WebSocket messages per minute"},{"location":"getting-started/configuration/#logging","title":"Logging","text":"Variable Default Description <code>LOG_LEVEL</code> INFO Logging level <code>LOG_CONSOLE_FORMAT</code> human Log format (human/json) <code>AUDIT_QUEUE_MAX_SIZE</code> 10000 Audit log queue size"},{"location":"getting-started/configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"getting-started/configuration/#development","title":"Development","text":"<pre><code>ENVIRONMENT=development\nDEBUG=true\nLOG_LEVEL=DEBUG\nLOG_CONSOLE_FORMAT=human\nRATE_LIMIT_PER_MINUTE=1000  # Higher limits for testing\n</code></pre>"},{"location":"getting-started/configuration/#staging","title":"Staging","text":"<pre><code>ENVIRONMENT=staging\nDEBUG=false\nLOG_LEVEL=INFO\nLOG_CONSOLE_FORMAT=json\nRATE_LIMIT_PER_MINUTE=120\n</code></pre>"},{"location":"getting-started/configuration/#production","title":"Production","text":"<pre><code>ENVIRONMENT=production\nDEBUG=false\nLOG_LEVEL=WARNING\nLOG_CONSOLE_FORMAT=json\nRATE_LIMIT_PER_MINUTE=60\n\n# Use strong secrets\nSECRET_KEY=&lt;generated-with-openssl-rand&gt;\nKEYCLOAK_CLIENT_SECRET=&lt;from-keycloak-admin&gt;\n\n# Use production domains\nKEYCLOAK_BASE_URL=https://auth.example.com\nALLOWED_HOSTS=[\"api.example.com\"]\nCORS_ORIGINS=[\"https://app.example.com\"]\n</code></pre>"},{"location":"getting-started/configuration/#keycloak-configuration","title":"Keycloak Configuration","text":""},{"location":"getting-started/configuration/#creating-a-realm","title":"Creating a Realm","text":"<ol> <li>Access Keycloak admin console: http://localhost:8080</li> <li>Login with admin credentials</li> <li>Create a new realm (e.g., \"development\")</li> <li>Configure realm settings</li> </ol>"},{"location":"getting-started/configuration/#creating-a-client","title":"Creating a Client","text":"<ol> <li>Go to Clients \u2192 Create</li> <li>Set Client ID: <code>fastapi-app</code></li> <li>Enable \"Client authentication\"</li> <li>Set Valid redirect URIs: <code>http://localhost:8000/*</code></li> <li>Set Web origins: <code>http://localhost:8000</code></li> <li>Save and copy the client secret</li> </ol>"},{"location":"getting-started/configuration/#creating-roles","title":"Creating Roles","text":"<ol> <li>Go to Realm roles \u2192 Create role</li> <li>Create roles: <code>admin</code>, <code>user</code>, <code>viewer</code></li> <li>Assign roles to users</li> </ol>"},{"location":"getting-started/configuration/#creating-users","title":"Creating Users","text":"<ol> <li>Go to Users \u2192 Add user</li> <li>Set username and email</li> <li>Go to Credentials tab \u2192 Set password</li> <li>Go to Role mapping \u2192 Assign roles</li> </ol>"},{"location":"getting-started/configuration/#rbac-configuration","title":"RBAC Configuration","text":"<p>Role-based access control is configured directly in handler code using decorators:</p> <p>WebSocket Handlers (<code>app/api/ws/handlers/</code>): <pre><code>@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    roles=[\"get-authors\"]  # Define required roles here\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n</code></pre></p> <p>HTTP Endpoints (<code>app/api/http/</code>): <pre><code>from app.dependencies.permissions import require_roles\n\n@router.get(\n    \"/authors\",\n    dependencies=[Depends(require_roles(\"get-authors\"))]\n)\nasync def get_authors():\n    ...\n</code></pre></p> <p>No external configuration file needed - permissions are co-located with handler code.</p>"},{"location":"getting-started/configuration/#docker-compose-configuration","title":"Docker Compose Configuration","text":"<p>The <code>docker-compose.yml</code> file can be customized for different environments:</p>"},{"location":"getting-started/configuration/#development_1","title":"Development","text":"<pre><code>services:\n  hw-server:\n    volumes:\n      - .:/app  # Mount code for hot reload\n    command: uvicorn app:application --reload\n    environment:\n      - DEBUG=true\n</code></pre>"},{"location":"getting-started/configuration/#production_1","title":"Production","text":"<pre><code>services:\n  hw-server:\n    image: fastapi-app:latest  # Use built image\n    deploy:\n      replicas: 3\n      resources:\n        limits:\n          cpus: '2'\n          memory: 2G\n    environment:\n      - DEBUG=false\n</code></pre>"},{"location":"getting-started/configuration/#monitoring-configuration","title":"Monitoring Configuration","text":""},{"location":"getting-started/configuration/#prometheus-dockerprometheusprometheusyml","title":"Prometheus (docker/prometheus/prometheus.yml)","text":"<pre><code>global:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: 'fastapi'\n    static_configs:\n      - targets: ['hw-server:8000']\n</code></pre>"},{"location":"getting-started/configuration/#grafana-dockergrafanaprovisioning","title":"Grafana (docker/grafana/provisioning/)","text":"<p>Grafana is pre-configured with: - Data sources (Prometheus, Loki) - Dashboards (FastAPI Metrics, Application Logs, Keycloak Metrics) - Default admin credentials: admin/admin</p>"},{"location":"getting-started/configuration/#troubleshooting-configuration","title":"Troubleshooting Configuration","text":""},{"location":"getting-started/configuration/#check-current-configuration","title":"Check Current Configuration","text":"<pre><code># Inside the application\nuv run python -c \"from app.settings import settings; print(settings.model_dump())\"\n\n# Or use IPython\nmake ipython\n&gt;&gt;&gt; from app.settings import settings\n&gt;&gt;&gt; settings.DATABASE_URL\n</code></pre>"},{"location":"getting-started/configuration/#validate-environment-files","title":"Validate Environment Files","text":"<pre><code># Check if all required variables are set\ngrep -v '^#' .env | grep -v '^$' | sort\n\n# Validate docker environment files\nls -la docker/.*.env\n</code></pre>"},{"location":"getting-started/configuration/#common-issues","title":"Common Issues","text":"<p>Issue: <code>DATABASE_URL</code> not found <pre><code># Solution: Ensure .env file exists\ncp .env.example .env\n</code></pre></p> <p>Issue: Keycloak connection refused <pre><code># Solution: Ensure Keycloak is running\ndocker ps | grep keycloak\ndocker logs hw-keycloak\n</code></pre></p> <p>Issue: Redis connection error <pre><code># Solution: Check Redis is accessible\ndocker exec hw-redis redis-cli ping\n</code></pre></p>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Build your first endpoints</li> <li>Authentication Guide - Configure authentication</li> <li>Security Guide - Production security</li> <li>Deployment Guide - Deploy to production</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will walk you through setting up the FastAPI HTTP/WebSocket template for local development.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the following installed:</p> Requirement Version Purpose Python 3.13+ Application runtime Docker 24.0+ Containerization Docker Compose v2+ Service orchestration uv latest Python package manager Git latest Version control"},{"location":"getting-started/installation/#install-uv-python-package-manager","title":"Install uv (Python Package Manager)","text":"<pre><code># Install uv\npip install uv\n\n# Verify installation\nuv --version\n</code></pre>"},{"location":"getting-started/installation/#clone-the-repository","title":"Clone the Repository","text":"<pre><code># Clone the repository\ngit clone https://github.com/acikabubo/fastapi-http-websocket.git\ncd fastapi-http-websocket\n\n# Or if using as a template\ncookiecutter gh:acikabubo/fastapi-http-websocket\n</code></pre>"},{"location":"getting-started/installation/#install-python-dependencies","title":"Install Python Dependencies","text":"<pre><code># Sync all dependencies\nuv sync\n\n# Sync with dev dependencies\nuv sync --all-groups\n\n# Activate virtual environment\nsource .venv/bin/activate  # Linux/macOS\n# OR\n.venv\\Scripts\\activate  # Windows\n</code></pre>"},{"location":"getting-started/installation/#start-infrastructure-services","title":"Start Infrastructure Services","text":"<p>The application requires several infrastructure services. Start them with Docker Compose:</p> <pre><code># Start all services in background\nmake start\n\n# Or using docker-compose directly\ndocker compose -f docker/docker-compose.yml up -d\n</code></pre> <p>This will start:</p> <ul> <li>PostgreSQL (port 5432) - Main database</li> <li>Redis (port 6379) - Cache and rate limiting</li> <li>Keycloak (port 8080) - Authentication server</li> <li>Prometheus (port 9090) - Metrics collection</li> <li>Grafana (port 3000) - Dashboards and visualization</li> <li>Loki (port 3100) - Log aggregation</li> <li>Grafana Alloy - Log collection agent</li> <li>Traefik (ports 80/443/8080) - Reverse proxy</li> </ul>"},{"location":"getting-started/installation/#verify-services","title":"Verify Services","text":"<pre><code># Check all services are running\ndocker ps\n\n# Check service health\ncurl http://localhost:8000/health  # Application (after starting)\ncurl http://localhost:8080/health  # Keycloak\ncurl http://localhost:9090/-/healthy  # Prometheus\n</code></pre>"},{"location":"getting-started/installation/#initialize-the-database","title":"Initialize the Database","text":"<p>Run database migrations to set up the schema:</p> <pre><code># Run migrations\nmake migrate\n\n# Or using alembic directly\nuv run alembic upgrade head\n\n# Verify current migration\nmake migration-current\n</code></pre>"},{"location":"getting-started/installation/#configure-keycloak","title":"Configure Keycloak","text":"<p>Keycloak is pre-configured with a realm export, but you need to verify the configuration:</p> <ol> <li>Access Keycloak Admin Console: http://localhost:8080</li> <li>Login with credentials from <code>docker/.kc_env</code>:</li> <li>Username: <code>admin</code></li> <li>Password: <code>admin</code> (change in production!)</li> <li>Verify Realm: Check that the <code>development</code> realm exists</li> <li>Verify Client: Check that the <code>fastapi-app</code> client is configured</li> </ol>"},{"location":"getting-started/installation/#environment-configuration","title":"Environment Configuration","text":"<p>Create your environment file from the example:</p> <pre><code># Copy example environment file\ncp .env.example .env\n\n# Edit configuration\nnano .env  # or your preferred editor\n</code></pre>"},{"location":"getting-started/installation/#key-environment-variables","title":"Key Environment Variables","text":"<pre><code># Application\nENVIRONMENT=development\nDEBUG=true\nLOG_LEVEL=DEBUG\n\n# Database\nDATABASE_URL=postgresql+asyncpg://fastapi:fastapi@localhost:5432/fastapi\n\n# Redis\nREDIS_IP=localhost\nREDIS_PORT=6379\nMAIN_REDIS_DB=0\nAUTH_REDIS_DB=1\n\n# Keycloak\nKEYCLOAK_BASE_URL=http://localhost:8080\nKEYCLOAK_REALM=development\nKEYCLOAK_CLIENT_ID=fastapi-app\nKEYCLOAK_CLIENT_SECRET=your-client-secret\n\n# Rate Limiting\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_PER_MINUTE=60\nWS_MAX_CONNECTIONS_PER_USER=5\n</code></pre>"},{"location":"getting-started/installation/#start-the-application","title":"Start the Application","text":""},{"location":"getting-started/installation/#option-1-using-make-recommended","title":"Option 1: Using Make (Recommended)","text":"<pre><code># Start with auto-reload\nmake serve\n</code></pre>"},{"location":"getting-started/installation/#option-2-using-uvicorn-directly","title":"Option 2: Using Uvicorn Directly","text":"<pre><code># Start application\nuv run uvicorn app:application --host 0.0.0.0 --port 8000 --reload\n</code></pre>"},{"location":"getting-started/installation/#option-3-using-docker-shell","title":"Option 3: Using Docker Shell","text":"<pre><code># Enter development container\nmake shell\n\n# Inside container\nuvicorn app:application --host 0.0.0.0 --reload\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":""},{"location":"getting-started/installation/#check-application-health","title":"Check Application Health","text":"<pre><code>curl http://localhost:8000/health\n</code></pre> <p>Expected response: <pre><code>{\n  \"status\": \"ok\",\n  \"version\": \"0.1.0\",\n  \"environment\": \"development\"\n}\n</code></pre></p>"},{"location":"getting-started/installation/#access-api-documentation","title":"Access API Documentation","text":"<p>Open in your browser:</p> <ul> <li>OpenAPI/Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> </ul>"},{"location":"getting-started/installation/#access-monitoring-dashboards","title":"Access Monitoring Dashboards","text":"<ul> <li>Grafana: http://localhost:3000 (admin/admin)</li> <li>FastAPI Metrics dashboard</li> <li>Application Logs dashboard</li> <li>Keycloak Metrics dashboard</li> <li>Prometheus: http://localhost:9090</li> <li>Traefik Dashboard: http://localhost:8080</li> </ul>"},{"location":"getting-started/installation/#development-tools","title":"Development Tools","text":""},{"location":"getting-started/installation/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Install pre-commit hooks for code quality:</p> <pre><code># Install pre-commit\nuv run pre-commit install\n\n# Run hooks manually\nuv run pre-commit run --all-files\n</code></pre>"},{"location":"getting-started/installation/#code-quality-checks","title":"Code Quality Checks","text":"<pre><code># Run linter\nmake ruff-check\n\n# Run security scan\nmake bandit-scan\n\n# Check for dead code\nmake dead-code-scan\n\n# Run tests\nmake test\n\n# Run tests with coverage\nmake test-coverage\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#services-not-starting","title":"Services Not Starting","text":"<pre><code># Check logs\ndocker compose -f docker/docker-compose.yml logs\n\n# Restart services\nmake stop\nmake start\n</code></pre>"},{"location":"getting-started/installation/#database-connection-issues","title":"Database Connection Issues","text":"<pre><code># Check PostgreSQL is running\ndocker ps | grep postgres\n\n# Check database logs\ndocker logs hw-db\n\n# Recreate database\ndocker compose -f docker/docker-compose.yml down -v\ndocker compose -f docker/docker-compose.yml up -d hw-db\nmake migrate\n</code></pre>"},{"location":"getting-started/installation/#port-already-in-use","title":"Port Already in Use","text":"<pre><code># Check what's using the port\nsudo lsof -i :8000  # Linux/macOS\nnetstat -ano | findstr :8000  # Windows\n\n# Stop conflicting process or change port\nuvicorn app:application --port 8001\n</code></pre>"},{"location":"getting-started/installation/#redis-connection-issues","title":"Redis Connection Issues","text":"<pre><code># Test Redis connection\ndocker exec hw-redis redis-cli ping\n\n# Check Redis logs\ndocker logs hw-redis\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that you have everything installed:</p> <ol> <li>Quick Start Guide - Create your first endpoints</li> <li>Configuration Guide - Customize your setup</li> <li>Authentication Guide - Set up auth</li> </ol>"},{"location":"getting-started/installation/#clean-up","title":"Clean Up","text":"<p>When you're done developing:</p> <pre><code># Stop all services\nmake stop\n\n# Remove all containers and volumes\ndocker compose -f docker/docker-compose.yml down -v\n\n# Clean up Docker resources\ndocker system prune -f\n</code></pre>"},{"location":"getting-started/installation/#additional-resources","title":"Additional Resources","text":"<ul> <li>Development Guide</li> <li>Testing Guide</li> <li>Docker Deployment</li> <li>Troubleshooting Guide</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get your first HTTP and WebSocket endpoints running in 10 minutes.</p> <p>Prerequisites</p> <p>Make sure you've completed the Installation guide before proceeding.</p>"},{"location":"getting-started/quickstart/#start-the-application","title":"Start the Application","text":"<pre><code># Start infrastructure services\nmake start\n\n# Start the application with auto-reload\nmake serve\n</code></pre> <p>The application should now be running at http://localhost:8000</p>"},{"location":"getting-started/quickstart/#your-first-http-endpoint","title":"Your First HTTP Endpoint","text":"<p>Let's create a simple HTTP endpoint to manage books.</p>"},{"location":"getting-started/quickstart/#1-create-the-model","title":"1. Create the Model","text":"<p>Create <code>app/models/book.py</code>:</p> <pre><code>from sqlmodel import Field, SQLModel\n\nclass Book(SQLModel, table=True):\n    \"\"\"Book model.\"\"\"\n\n    id: int | None = Field(default=None, primary_key=True)\n    title: str = Field(index=True)\n    author: str\n    isbn: str = Field(unique=True)\n    published_year: int\n</code></pre>"},{"location":"getting-started/quickstart/#2-create-a-migration","title":"2. Create a Migration","text":"<pre><code>make migration msg=\"add book model\"\nmake migrate\n</code></pre>"},{"location":"getting-started/quickstart/#3-create-the-repository","title":"3. Create the Repository","text":"<p>Create <code>app/repositories/book_repository.py</code>:</p> <pre><code>from app.models.book import Book\nfrom app.repositories.base_repository import BaseRepository\n\nclass BookRepository(BaseRepository[Book]):\n    \"\"\"Repository for Book operations.\"\"\"\n    pass\n</code></pre>"},{"location":"getting-started/quickstart/#4-create-http-endpoints","title":"4. Create HTTP Endpoints","text":"<p>Create <code>app/api/http/book.py</code>:</p> <pre><code>from fastapi import APIRouter, Depends, HTTPException, status\nfrom app.models.book import Book\nfrom app.repositories.book_repository import BookRepository\nfrom app.storage.db import async_session\n\nrouter = APIRouter(prefix=\"/books\", tags=[\"books\"])\n\n@router.post(\"/\", response_model=Book, status_code=status.HTTP_201_CREATED)\nasync def create_book(book: Book):\n    \"\"\"Create a new book.\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        return await repo.create(book)\n\n@router.get(\"/\", response_model=list[Book])\nasync def get_books():\n    \"\"\"Get all books.\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        return await repo.get_all()\n\n@router.get(\"/{book_id}\", response_model=Book)\nasync def get_book(book_id: int):\n    \"\"\"Get book by ID.\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        book = await repo.get_by_id(book_id)\n        if not book:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"Book not found\"\n            )\n        return book\n</code></pre>"},{"location":"getting-started/quickstart/#5-test-the-endpoint","title":"5. Test the Endpoint","text":"<pre><code># Create a book\ncurl -X POST http://localhost:8000/books/ \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"title\": \"Clean Code\",\n    \"author\": \"Robert C. Martin\",\n    \"isbn\": \"978-0132350884\",\n    \"published_year\": 2008\n  }'\n\n# Get all books\ncurl http://localhost:8000/books/\n\n# Get specific book\ncurl http://localhost:8000/books/1\n</code></pre> <p>Or visit the interactive API docs: http://localhost:8000/docs</p>"},{"location":"getting-started/quickstart/#your-first-websocket-handler","title":"Your First WebSocket Handler","text":"<p>Let's create a WebSocket handler to get books.</p>"},{"location":"getting-started/quickstart/#1-add-package-id","title":"1. Add Package ID","text":"<p>Edit <code>app/api/ws/constants.py</code>:</p> <pre><code>class PkgID(IntEnum):\n    \"\"\"WebSocket package IDs.\"\"\"\n    # ... existing handlers ...\n    GET_BOOKS = 100\n    CREATE_BOOK = 101\n</code></pre>"},{"location":"getting-started/quickstart/#2-create-websocket-handler","title":"2. Create WebSocket Handler","text":"<p>Create <code>app/api/ws/handlers/book.py</code>:</p> <pre><code>from app.routing import pkg_router\nfrom app.api.ws.constants import PkgID\nfrom app.schemas.models import RequestModel, ResponseModel\nfrom app.repositories.book_repository import BookRepository\nfrom app.storage.db import async_session\n\n@pkg_router.register(PkgID.GET_BOOKS)\nasync def get_books_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Get all books via WebSocket.\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        books = await repo.get_all()\n\n        return ResponseModel.success(\n            request.pkg_id,\n            request.req_id,\n            data=[book.model_dump() for book in books]\n        )\n\n@pkg_router.register(PkgID.CREATE_BOOK)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Create a book via WebSocket.\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        book_data = request.data\n        book = Book(**book_data)\n        created_book = await repo.create(book)\n\n        return ResponseModel.success(\n            request.pkg_id,\n            request.req_id,\n            data=created_book.model_dump()\n        )\n</code></pre>"},{"location":"getting-started/quickstart/#3-test-websocket-handler","title":"3. Test WebSocket Handler","text":"<p>Using <code>wscat</code> or any WebSocket client:</p> <pre><code># Install wscat (if needed)\nnpm install -g wscat\n\n# Connect (replace TOKEN with actual JWT token from Keycloak)\nwscat -c \"ws://localhost:8000/web?access_token=YOUR_TOKEN\"\n\n# Send message\n{\"pkg_id\": 100, \"req_id\": \"test-001\", \"data\": {}}\n\n# Expected response\n{\n  \"pkg_id\": 100,\n  \"req_id\": \"test-001\",\n  \"status_code\": 0,\n  \"data\": [...]\n}\n</code></pre>"},{"location":"getting-started/quickstart/#add-rbac-permissions","title":"Add RBAC Permissions","text":"<p>Add role requirements directly to your handler decorators:</p> <p>WebSocket Handler (<code>app/api/ws/handlers/book_handler.py</code>): <pre><code>@pkg_router.register(\n    PkgID.GET_BOOKS,\n    json_schema=GetBooksModel,\n    roles=[\"get-books\"]  # Define required roles\n)\nasync def get_books_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n\n@pkg_router.register(\n    PkgID.CREATE_BOOK,\n    json_schema=CreateBookModel,\n    roles=[\"create-book\", \"admin\"]  # Multiple roles = user must have ALL\n)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n</code></pre></p> <p>HTTP Endpoint (<code>app/api/http/book.py</code>): <pre><code>from app.dependencies.permissions import require_roles\n\n@router.get(\n    \"/books\",\n    dependencies=[Depends(require_roles(\"get-books\"))]\n)\nasync def get_books():\n    ...\n\n@router.post(\n    \"/books\",\n    dependencies=[Depends(require_roles(\"create-book\", \"admin\"))]\n)\nasync def create_book(book: Book):\n    ...\n</code></pre></p> <p>Now only users with appropriate roles can access these endpoints!</p>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Congratulations! You've created your first HTTP and WebSocket endpoints. Next, learn about:</p> <ul> <li>Authentication - Secure your endpoints</li> <li>Rate Limiting - Protect against abuse</li> <li>Database Operations - Advanced database patterns</li> <li>Testing - Write tests for your endpoints</li> </ul>"},{"location":"getting-started/quickstart/#see-also","title":"See Also","text":"<ul> <li>HTTP API Guide</li> <li>WebSocket API Guide</li> <li>Design Patterns</li> </ul>"},{"location":"guides/","title":"User Guides","text":"<p>Step-by-step guides for common tasks and features.</p>"},{"location":"guides/#available-guides","title":"Available Guides","text":"<ul> <li>Authentication - Keycloak integration and JWT tokens</li> <li>HTTP Endpoints - Creating REST API endpoints</li> <li>WebSocket Handlers - Building WebSocket handlers</li> <li>Rate Limiting - Implementing rate limits</li> <li>Audit Logging - Tracking user actions</li> <li>Database Operations - Working with PostgreSQL</li> <li>Monitoring - Observability and metrics</li> </ul>"},{"location":"guides/audit-logging/","title":"User Action Logging and Audit Trail","text":"<p>This guide explains how to use and maintain the user action logging (audit logging) system in this FastAPI application.</p>"},{"location":"guides/audit-logging/#overview","title":"Overview","text":"<p>The audit logging system tracks user activities for security, compliance, debugging, and analytics purposes. It captures comprehensive information about user actions across both HTTP and WebSocket endpoints.</p>"},{"location":"guides/audit-logging/#architecture","title":"Architecture","text":"<p>The system uses a database-first approach with the following components:</p> <ul> <li>UserAction Model (<code>app/models/user_action.py</code>): SQLModel storing audit records</li> <li>AuditLogger (<code>app/utils/audit_logger.py</code>): Utility functions for logging actions</li> <li>AuditMiddleware (<code>app/middlewares/audit_middleware.py</code>): HTTP request logging</li> <li>WebSocket Integration: Manual logging in WebSocket handlers</li> </ul>"},{"location":"guides/audit-logging/#what-gets-logged","title":"What Gets Logged","text":""},{"location":"guides/audit-logging/#essential-information","title":"Essential Information","text":"<p>Every action log captures:</p> Field Description Example <code>timestamp</code> When the action occurred (UTC) <code>2025-11-27T14:32:15.123456Z</code> <code>user_id</code> Keycloak user ID <code>sub</code> field from JWT <code>username</code> Human-readable username <code>preferred_username</code> <code>user_roles</code> Roles at time of action <code>[\"admin\", \"user\"]</code> <code>action_type</code> HTTP method or WebSocket PkgID <code>POST</code>, <code>GET</code>, <code>PkgID.GET_AUTHORS</code> <code>resource</code> Resource accessed/modified <code>/api/authors/123</code>, <code>Author:123</code> <code>outcome</code> Result of the action <code>success</code>, <code>error</code>, <code>permission_denied</code> <code>ip_address</code> Client IP (proxy-aware) <code>192.168.1.100</code> <code>user_agent</code> Browser/client info <code>Mozilla/5.0 ...</code>"},{"location":"guides/audit-logging/#optional-contextual-data","title":"Optional Contextual Data","text":"<ul> <li><code>request_id</code>: Correlation ID for distributed tracing</li> <li><code>request_data</code>: Sanitized request payload</li> <li><code>response_status</code>: HTTP status code</li> <li><code>error_message</code>: Error details for failures</li> <li><code>duration_ms</code>: Request processing time</li> </ul>"},{"location":"guides/audit-logging/#using-the-audit-logger","title":"Using the Audit Logger","text":""},{"location":"guides/audit-logging/#in-http-endpoints","title":"In HTTP Endpoints","text":"<p>HTTP requests are automatically logged by <code>AuditMiddleware</code>. No manual logging required for standard endpoints.</p> <pre><code>from fastapi import APIRouter\n\nrouter = APIRouter()\n\n@router.post(\"/authors\")\nasync def create_author(author: AuthorCreate):\n    # Middleware automatically logs this action\n    return await Author.create(...)\n</code></pre>"},{"location":"guides/audit-logging/#in-websocket-handlers","title":"In WebSocket Handlers","text":"<p>WebSocket actions require manual logging:</p> <pre><code>from app.utils.audit_logger import log_user_action\nfrom app.api.ws.models import RequestModel, ResponseModel\n\n@pkg_router.register(PkgID.CREATE_AUTHOR, json_schema=CreateAuthorSchema)\nasync def create_author_handler(request: RequestModel) -&gt; ResponseModel:\n    try:\n        # Perform action\n        author = await Author.create(...)\n\n        # Log successful action\n        await log_user_action(\n            user_id=request.user.id,\n            username=request.user.username,\n            user_roles=request.user.roles,\n            action_type=f\"WS:{request.pkg_id.name}\",\n            resource=f\"Author:{author.id}\",\n            outcome=\"success\",\n            ip_address=request.ip_address,\n            request_id=request.req_id,\n            request_data=request.data,\n            duration_ms=request.duration_ms\n        )\n\n        return ResponseModel.success(...)\n    except Exception as e:\n        # Log failed action\n        await log_user_action(\n            user_id=request.user.id,\n            username=request.user.username,\n            user_roles=request.user.roles,\n            action_type=f\"WS:{request.pkg_id.name}\",\n            resource=\"Author\",\n            outcome=\"error\",\n            error_message=str(e),\n            ip_address=request.ip_address,\n            request_id=request.req_id\n        )\n        raise\n</code></pre>"},{"location":"guides/audit-logging/#logging-permission-denials","title":"Logging Permission Denials","text":"<p>RBAC permission denials are automatically logged by the middleware and WebSocket permission checks.</p>"},{"location":"guides/audit-logging/#sensitive-data-handling","title":"Sensitive Data Handling","text":""},{"location":"guides/audit-logging/#never-log","title":"Never Log","text":"<p>\u26a0\ufe0f DO NOT log these fields: - Passwords or password hashes - Full credit card numbers - Personal health information (PHI) - Full access tokens or API keys - Social security numbers or national IDs - Private encryption keys</p>"},{"location":"guides/audit-logging/#data-sanitization","title":"Data Sanitization","text":"<p>The <code>sanitize_data()</code> function automatically redacts sensitive fields:</p> <pre><code>from app.utils.audit_logger import sanitize_data\n\ndata = {\n    \"username\": \"john\",\n    \"password\": \"secret123\",\n    \"email\": \"john@example.com\",\n    \"token\": \"Bearer xyz...\"\n}\n\nsanitized = sanitize_data(data)\n# Result: {\n#     \"username\": \"john\",\n#     \"password\": \"[REDACTED]\",\n#     \"email\": \"john@example.com\",\n#     \"token\": \"[REDACTED]\"\n# }\n</code></pre> <p>Default redacted fields: - <code>password</code>, <code>passwd</code>, <code>pwd</code> - <code>token</code>, <code>access_token</code>, <code>refresh_token</code> - <code>secret</code>, <code>api_key</code>, <code>private_key</code> - <code>ssn</code>, <code>social_security_number</code> - <code>credit_card</code>, <code>card_number</code>, <code>cvv</code></p>"},{"location":"guides/audit-logging/#querying-audit-logs","title":"Querying Audit Logs","text":""},{"location":"guides/audit-logging/#using-the-api-admin-only","title":"Using the API (Admin Only)","text":"<pre><code># Get audit logs with filters\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/api/audit-logs?page=1&amp;per_page=20&amp;user_id=abc123&amp;outcome=error\"\n\n# Filter by date range\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/api/audit-logs?start_date=2025-01-01&amp;end_date=2025-01-31\"\n\n# Filter by action type\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/api/audit-logs?action_type=POST\"\n</code></pre>"},{"location":"guides/audit-logging/#direct-database-queries","title":"Direct Database Queries","text":"<pre><code>from sqlmodel import select\nfrom app.models.user_action import UserAction\nfrom app.storage.db import async_session\n\n# Get all actions by a user in date range\nasync with async_session() as session:\n    stmt = (\n        select(UserAction)\n        .where(UserAction.user_id == \"user123\")\n        .where(UserAction.timestamp &gt;= start_date)\n        .where(UserAction.timestamp &lt;= end_date)\n        .order_by(UserAction.timestamp.desc())\n    )\n    actions = (await session.exec(stmt)).all()\n\n# Get failed login attempts\nasync with async_session() as session:\n    stmt = (\n        select(UserAction)\n        .where(UserAction.action_type == \"POST\")\n        .where(UserAction.resource.like(\"%/auth/login%\"))\n        .where(UserAction.outcome == \"error\")\n        .order_by(UserAction.timestamp.desc())\n        .limit(100)\n    )\n    failed_logins = (await session.exec(stmt)).all()\n\n# Get permission denied events\nasync with async_session() as session:\n    stmt = (\n        select(UserAction)\n        .where(UserAction.outcome == \"permission_denied\")\n        .order_by(UserAction.timestamp.desc())\n    )\n    denied = (await session.exec(stmt)).all()\n\n# Get actions on a specific resource\nasync with async_session() as session:\n    stmt = (\n        select(UserAction)\n        .where(UserAction.resource == \"Author:123\")\n        .order_by(UserAction.timestamp.desc())\n    )\n    author_actions = (await session.exec(stmt)).all()\n</code></pre>"},{"location":"guides/audit-logging/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guides/audit-logging/#1-security-incident-investigation","title":"1. Security Incident Investigation","text":"<p>Track what a compromised user did:</p> <pre><code>actions = await session.exec(\n    select(UserAction)\n    .where(UserAction.user_id == compromised_user_id)\n    .where(UserAction.timestamp &gt;= incident_start)\n    .where(UserAction.timestamp &lt;= incident_end)\n    .order_by(UserAction.timestamp.asc())\n)\n</code></pre>"},{"location":"guides/audit-logging/#2-failed-authentication-monitoring","title":"2. Failed Authentication Monitoring","text":"<p>Detect brute force attempts:</p> <pre><code>failed_logins = await session.exec(\n    select(UserAction)\n    .where(UserAction.resource.like(\"%/auth/login%\"))\n    .where(UserAction.outcome == \"error\")\n    .where(UserAction.timestamp &gt;= datetime.utcnow() - timedelta(hours=1))\n    .order_by(UserAction.timestamp.desc())\n)\n</code></pre>"},{"location":"guides/audit-logging/#3-user-activity-timeline","title":"3. User Activity Timeline","text":"<p>Generate activity report for a user:</p> <pre><code>timeline = await session.exec(\n    select(UserAction)\n    .where(UserAction.user_id == user_id)\n    .order_by(UserAction.timestamp.desc())\n    .limit(100)\n)\n</code></pre>"},{"location":"guides/audit-logging/#4-resource-access-audit","title":"4. Resource Access Audit","text":"<p>See who accessed a sensitive resource:</p> <pre><code>access_log = await session.exec(\n    select(UserAction)\n    .where(UserAction.resource.like(\"Author:sensitive_id%\"))\n    .order_by(UserAction.timestamp.desc())\n)\n</code></pre>"},{"location":"guides/audit-logging/#performance-considerations","title":"Performance Considerations","text":""},{"location":"guides/audit-logging/#database-indexes","title":"Database Indexes","text":"<p>The following indexes are created automatically:</p> <ul> <li><code>user_id</code> - Fast user-specific queries</li> <li><code>timestamp</code> - Date range filtering</li> <li><code>action_type</code> - Action type filtering</li> <li><code>outcome</code> - Error/success filtering</li> <li><code>request_id</code> - Request correlation</li> <li>Composite index on <code>(user_id, timestamp)</code> - Optimized user timeline queries</li> </ul>"},{"location":"guides/audit-logging/#best-practices","title":"Best Practices","text":"<ol> <li>Asynchronous logging: All logging is async to avoid blocking requests</li> <li>Pagination: Always use pagination when querying large result sets</li> <li>Date range limits: Limit queries to reasonable time windows (e.g., 30 days)</li> <li>Archival: Implement log archival for records older than retention period</li> <li>Partitioning: Consider table partitioning by date for very large deployments</li> </ol>"},{"location":"guides/audit-logging/#compliance-features","title":"Compliance Features","text":""},{"location":"guides/audit-logging/#gdpr","title":"GDPR","text":"<p>Right to be Forgotten: <pre><code># Delete all logs for a user\nawait session.exec(delete(UserAction).where(UserAction.user_id == user_id))\n</code></pre></p> <p>Data Export: <pre><code># Export user's activity history\nactions = await session.exec(\n    select(UserAction).where(UserAction.user_id == user_id)\n)\nexport_data = [action.model_dump() for action in actions]\n</code></pre></p>"},{"location":"guides/audit-logging/#hipaa","title":"HIPAA","text":"<ul> <li>All logs containing PHI are encrypted at rest (PostgreSQL encryption)</li> <li>6-year retention requirement enforced by archival policy</li> <li>Access to audit logs restricted to admin role</li> </ul>"},{"location":"guides/audit-logging/#sox","title":"SOX","text":"<ul> <li>Immutable logs (no UPDATE capability in the model)</li> <li>Financial transaction logs retained indefinitely</li> <li>Audit trail for all data modifications</li> </ul>"},{"location":"guides/audit-logging/#pci-dss","title":"PCI-DSS","text":"<ul> <li>Cardholder data access logged (if applicable)</li> <li>1-year minimum retention enforced</li> </ul>"},{"location":"guides/audit-logging/#configuration","title":"Configuration","text":"<p>Environment variables in <code>app/settings.py</code>:</p> <pre><code># Audit logging settings\nAUDIT_LOG_ENABLED: bool = True  # Enable/disable audit logging\nAUDIT_LOG_RETENTION_DAYS: int = 365  # Log retention period\nAUDIT_LOG_EXCLUDED_PATHS: list[str] = [\n    \"/health\",\n    \"/metrics\",\n    \"/docs\",\n    \"/openapi.json\"\n]\n</code></pre>"},{"location":"guides/audit-logging/#excluded-paths","title":"Excluded Paths","text":"<p>The following paths are not logged to reduce noise:</p> <ul> <li><code>/health</code> - Health check endpoint</li> <li><code>/metrics</code> - Prometheus metrics</li> <li><code>/docs</code> - API documentation</li> <li><code>/openapi.json</code> - OpenAPI schema</li> <li><code>/static/*</code> - Static files</li> </ul>"},{"location":"guides/audit-logging/#monitoring","title":"Monitoring","text":"<p>Prometheus metrics track audit logging performance:</p> <pre><code># Total audit logs created\naudit_logs_total{outcome}\n\n# Audit log creation duration\naudit_log_duration_seconds\n\n# Audit log errors\naudit_log_errors_total{error_type}\n</code></pre>"},{"location":"guides/audit-logging/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/audit-logging/#logs-not-appearing","title":"Logs not appearing","text":"<ol> <li>Check <code>AUDIT_LOG_ENABLED</code> setting</li> <li>Verify user is authenticated (unauthenticated requests not logged)</li> <li>Check if path is in <code>AUDIT_LOG_EXCLUDED_PATHS</code></li> <li>Review application logs for errors</li> </ol>"},{"location":"guides/audit-logging/#performance-issues","title":"Performance issues","text":"<ol> <li>Verify database indexes exist</li> <li>Check query date ranges (avoid unbounded queries)</li> <li>Use pagination for large result sets</li> <li>Consider archiving old logs</li> </ol>"},{"location":"guides/audit-logging/#storage-growth","title":"Storage growth","text":"<ol> <li>Implement log archival (move old logs to cold storage)</li> <li>Adjust retention policy</li> <li>Enable log compression</li> <li>Consider external logging service for high-volume scenarios</li> </ol>"},{"location":"guides/audit-logging/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements to consider:</p> <ul> <li>Log streaming: Real-time log streaming to SIEM tools</li> <li>Anomaly detection: ML-based detection of unusual patterns</li> <li>Log encryption: Per-record encryption for sensitive actions</li> <li>Export formats: CSV/JSON export functionality</li> <li>Compliance reports: Automated compliance report generation</li> <li>Log integrity: Cryptographic checksums to detect tampering</li> </ul>"},{"location":"guides/audit-logging/#related-documentation","title":"Related Documentation","text":"<ul> <li>Authentication Guide</li> <li>Testing Guide</li> <li>Database Migrations</li> </ul>"},{"location":"guides/authentication/","title":"Authentication Guide","text":"<p>Complete guide to authentication in the FastAPI HTTP/WebSocket application.</p>"},{"location":"guides/authentication/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Quick Start</li> <li>Keycloak Setup</li> <li>Getting Tokens</li> <li>Using Tokens</li> <li>Development Workflow</li> <li>Troubleshooting</li> </ol>"},{"location":"guides/authentication/#overview","title":"Overview","text":"<p>This application uses Keycloak for authentication with JWT (JSON Web Tokens). All endpoints except those in <code>EXCLUDED_PATHS</code> require authentication.</p>"},{"location":"guides/authentication/#authentication-flow","title":"Authentication Flow","text":"<pre><code>1. User authenticates with Keycloak (username/password)\n2. Keycloak returns JWT access token\n3. Client includes token in every request\n4. Server validates token and extracts user info + roles\n5. RBAC checks if user has required role for endpoint\n6. Request proceeds or returns 403 Forbidden\n</code></pre>"},{"location":"guides/authentication/#key-components","title":"Key Components","text":"<ul> <li>Keycloak: OpenID Connect / OAuth 2.0 provider</li> <li>JWT Tokens: Contain user identity and roles</li> <li>RBAC: Role-based access control for endpoints</li> <li>Middleware: Validates tokens on every request</li> </ul>"},{"location":"guides/authentication/#quick-start","title":"Quick Start","text":""},{"location":"guides/authentication/#get-a-token","title":"Get a Token","text":"<pre><code># Using the helper script\npython scripts/get_token.py &lt;username&gt; &lt;password&gt;\n\n# Example:\npython scripts/get_token.py acika 12345\n</code></pre> <p>Copy the access token from the output.</p>"},{"location":"guides/authentication/#use-the-token","title":"Use the Token","text":"<p>HTTP Request (with curl): <pre><code>curl -H \"Authorization: Bearer YOUR_TOKEN_HERE\" \\\n  http://localhost:8000/authors\n</code></pre></p> <p>WebSocket Connection: <pre><code>const ws = new WebSocket('ws://localhost:8000/web?Authorization=Bearer YOUR_TOKEN_HERE');\n</code></pre></p>"},{"location":"guides/authentication/#keycloak-setup","title":"Keycloak Setup","text":""},{"location":"guides/authentication/#configuration","title":"Configuration","text":"<p>Set these environment variables (or use defaults from <code>app/settings.py</code>):</p> <pre><code># Keycloak server\nKEYCLOAK_BASE_URL=http://hw-keycloak:8080/\n\n# Realm and client\nKEYCLOAK_REALM=your-realm\nKEYCLOAK_CLIENT_ID=your-client-id\n\n# Admin credentials (for token generation scripts)\nKEYCLOAK_ADMIN_USERNAME=admin\nKEYCLOAK_ADMIN_PASSWORD=admin-password\n</code></pre>"},{"location":"guides/authentication/#docker-setup","title":"Docker Setup","text":"<p>Start Keycloak with docker-compose:</p> <pre><code>make start  # Starts all services including Keycloak\n</code></pre>"},{"location":"guides/authentication/#manual-setup","title":"Manual Setup","text":"<ol> <li>Access Keycloak Admin Console: http://localhost:8080/</li> <li>Create a realm (e.g., \"my-app\")</li> <li>Create a client:</li> <li>Client ID: \"fastapi-client\"</li> <li>Access Type: \"confidential\" or \"public\"</li> <li>Valid Redirect URIs: \"*\" (for development)</li> <li>Create users and assign roles</li> <li>Update <code>.env</code> with your configuration</li> </ol>"},{"location":"guides/authentication/#getting-tokens","title":"Getting Tokens","text":""},{"location":"guides/authentication/#option-1-helper-script-recommended","title":"Option 1: Helper Script (Recommended)","text":"<pre><code>python scripts/get_token.py USERNAME PASSWORD\n\n# Options:\npython scripts/get_token.py USERNAME PASSWORD --json    # Full JSON response\npython scripts/get_token.py USERNAME PASSWORD --refresh # Include refresh token\n</code></pre> <p>Output: <pre><code>Access Token:\neyJhbGciOiJSUzI1NiIsInR5cC...\n\nExpires in: 300 seconds\n</code></pre></p>"},{"location":"guides/authentication/#option-2-direct-api-call","title":"Option 2: Direct API Call","text":"<pre><code>curl -X POST \"http://localhost:8080/realms/YOUR_REALM/protocol/openid-connect/token\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"client_id=YOUR_CLIENT_ID\" \\\n  -d \"username=USERNAME\" \\\n  -d \"password=PASSWORD\" \\\n  -d \"grant_type=password\"\n</code></pre>"},{"location":"guides/authentication/#option-3-python-code","title":"Option 3: Python Code","text":"<pre><code>from app.managers.keycloak_manager import KeycloakManager\n\nkc = KeycloakManager()\ntoken_response = kc.login(\"username\", \"password\")\naccess_token = token_response[\"access_token\"]\n</code></pre>"},{"location":"guides/authentication/#using-tokens","title":"Using Tokens","text":""},{"location":"guides/authentication/#http-requests","title":"HTTP Requests","text":""},{"location":"guides/authentication/#with-curl","title":"With curl","text":"<pre><code>TOKEN=\"your-access-token-here\"\n\n# GET request\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  http://localhost:8000/authors\n\n# POST request\ncurl -X POST \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"New Author\"}' \\\n  http://localhost:8000/authors\n</code></pre>"},{"location":"guides/authentication/#with-python-requests","title":"With Python requests","text":"<pre><code>import requests\n\ntoken = \"your-access-token\"\nheaders = {\"Authorization\": f\"Bearer {token}\"}\n\n# GET\nresponse = requests.get(\"http://localhost:8000/authors\", headers=headers)\n\n# POST\nresponse = requests.post(\n    \"http://localhost:8000/authors\",\n    headers=headers,\n    json={\"name\": \"New Author\"}\n)\n</code></pre>"},{"location":"guides/authentication/#with-httpie","title":"With httpie","text":"<pre><code>http GET localhost:8000/authors \\\n  Authorization:\"Bearer YOUR_TOKEN\"\n</code></pre>"},{"location":"guides/authentication/#websocket-connections","title":"WebSocket Connections","text":""},{"location":"guides/authentication/#javascript","title":"JavaScript","text":"<pre><code>// Token in query parameter\nconst token = \"your-access-token\";\nconst ws = new WebSocket(`ws://localhost:8000/web?Authorization=Bearer ${token}`);\n\nws.onopen = () =&gt; {\n    console.log('Connected');\n\n    // Send request\n    ws.send(JSON.stringify({\n        pkg_id: 1,\n        req_id: crypto.randomUUID(),\n        data: {}\n    }));\n};\n\nws.onmessage = (event) =&gt; {\n    const response = JSON.parse(event.data);\n    console.log('Response:', response);\n};\n</code></pre>"},{"location":"guides/authentication/#python","title":"Python","text":"<pre><code>import asyncio\nimport json\nimport uuid\nimport websockets\n\nasync def test_websocket():\n    token = \"your-access-token\"\n    uri = f\"ws://localhost:8000/web?Authorization=Bearer {token}\"\n\n    async with websockets.connect(uri) as websocket:\n        # Send request\n        request = {\n            \"pkg_id\": 1,\n            \"req_id\": str(uuid.uuid4()),\n            \"data\": {}\n        }\n        await websocket.send(json.dumps(request))\n\n        # Receive response\n        response = await websocket.recv()\n        print(json.loads(response))\n\nasyncio.run(test_websocket())\n</code></pre>"},{"location":"guides/authentication/#development-workflow","title":"Development Workflow","text":""},{"location":"guides/authentication/#1-start-services","title":"1. Start Services","text":"<pre><code>make start  # Start PostgreSQL, Redis, Keycloak\nmake serve  # Start FastAPI app\n</code></pre>"},{"location":"guides/authentication/#2-get-token","title":"2. Get Token","text":"<pre><code>python scripts/get_token.py acika 12345\n</code></pre>"},{"location":"guides/authentication/#3-test-endpoints","title":"3. Test Endpoints","text":"<p>Option A: VS Code REST Client (<code>api-testing/api.http</code>): <pre><code>### Get Authors\nGET http://localhost:8000/authors\nAuthorization: Bearer YOUR_TOKEN_HERE\n</code></pre></p> <p>Option B: curl: <pre><code>TOKEN=\"your-token\"\ncurl -H \"Authorization: Bearer $TOKEN\" http://localhost:8000/authors\n</code></pre></p> <p>Option C: Python script: <pre><code># test_auth.py\nimport requests\n\ntoken = \"your-token\"\nresponse = requests.get(\n    \"http://localhost:8000/authors\",\n    headers={\"Authorization\": f\"Bearer {token}\"}\n)\nprint(response.json())\n</code></pre></p>"},{"location":"guides/authentication/#4-automated-tests","title":"4. Automated Tests","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run specific test\nuv run pytest tests/test_auth_example.py::TestMockAuthentication::test_valid_user_has_permission\n</code></pre>"},{"location":"guides/authentication/#token-management","title":"Token Management","text":""},{"location":"guides/authentication/#token-expiration","title":"Token Expiration","text":"<p>Tokens expire after a configured time (default: 300 seconds / 5 minutes).</p> <p>Handling Expiration: 1. HTTP: Re-authenticate and get new token 2. WebSocket: Connection closes, client must reconnect with new token</p> <p>Check Token Validity: <pre><code>import jwt\nfrom datetime import datetime\n\ntoken = \"your-token\"\ndecoded = jwt.decode(token, options={\"verify_signature\": False})\nexp_timestamp = decoded[\"exp\"]\nexp_time = datetime.fromtimestamp(exp_timestamp)\n\nprint(f\"Token expires at: {exp_time}\")\nprint(f\"Is expired: {datetime.now() &gt; exp_time}\")\n</code></pre></p>"},{"location":"guides/authentication/#refresh-tokens","title":"Refresh Tokens","text":"<pre><code># Get refresh token\npython scripts/get_token.py USERNAME PASSWORD --refresh\n\n# Use refresh token to get new access token\ncurl -X POST \"http://localhost:8080/realms/YOUR_REALM/protocol/openid-connect/token\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"client_id=YOUR_CLIENT_ID\" \\\n  -d \"refresh_token=YOUR_REFRESH_TOKEN\" \\\n  -d \"grant_type=refresh_token\"\n</code></pre>"},{"location":"guides/authentication/#roles-and-permissions","title":"Roles and Permissions","text":""},{"location":"guides/authentication/#understanding-roles","title":"Understanding Roles","text":"<p>Roles determine what endpoints a user can access. Roles are: 1. Defined in Keycloak 2. Included in JWT token 3. Checked by RBAC on each request</p>"},{"location":"guides/authentication/#current-roles","title":"Current Roles","text":"<p>Roles are defined in handler decorators throughout the codebase. Common roles include: - <code>get-authors</code> - View author list - <code>create-author</code> - Create new authors - <code>admin</code> - Administrative access</p> <p>Finding Role Requirements: Check the handler code to see required roles: <pre><code># WebSocket handler example\n@pkg_router.register(PkgID.GET_AUTHORS, roles=[\"get-authors\"])\n\n# HTTP endpoint example\n@router.get(\"/authors\", dependencies=[Depends(require_roles(\"get-authors\"))])\n</code></pre></p>"},{"location":"guides/authentication/#checking-user-roles","title":"Checking User Roles","text":"<p>Roles are in the JWT token: <pre><code>import jwt\n\ntoken = \"your-token\"\ndecoded = jwt.decode(token, options={\"verify_signature\": False})\n\n# Realm roles\nrealm_roles = decoded[\"realm_access\"][\"roles\"]\n\n# Client roles\nclient_roles = decoded[\"resource_access\"][\"your-client\"][\"roles\"]\n</code></pre></p>"},{"location":"guides/authentication/#adding-roles-in-keycloak","title":"Adding Roles in Keycloak","text":"<ol> <li>Go to Keycloak Admin Console</li> <li>Select your realm</li> <li>Go to \"Roles\" \u2192 \"Add Role\"</li> <li>Create role (e.g., \"get-authors\")</li> <li>Go to \"Users\" \u2192 Select user \u2192 \"Role Mappings\"</li> <li>Assign role to user</li> </ol>"},{"location":"guides/authentication/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/authentication/#401-unauthorized","title":"\"401 Unauthorized\"","text":"<p>Cause: Missing or invalid token</p> <p>Solutions: 1. Check token is included in request 2. Verify token hasn't expired 3. Get fresh token 4. Check Authorization header format: <code>Bearer YOUR_TOKEN</code></p>"},{"location":"guides/authentication/#403-forbidden","title":"\"403 Forbidden\"","text":"<p>Cause: Valid token but insufficient permissions</p> <p>Solutions: 1. Check user has required role in Keycloak 2. Verify handler's required roles in decorator (e.g., <code>@pkg_router.register(roles=[\"admin\"])</code>) 3. Check RBAC logs: <code>logger.info(\"Permission denied...\")</code></p>"},{"location":"guides/authentication/#token-expired","title":"\"Token Expired\"","text":"<p>Cause: Token validity period elapsed</p> <p>Solutions: 1. Get new token: <code>python scripts/get_token.py USERNAME PASSWORD</code> 2. Use refresh token to get new access token 3. For development, increase token lifetime in Keycloak</p>"},{"location":"guides/authentication/#websocket-connection-fails","title":"WebSocket Connection Fails","text":"<p>Cause: Token in wrong format or expired</p> <p>Solutions: 1. Ensure query param format: <code>?Authorization=Bearer TOKEN</code> 2. Verify token is valid (not expired) 3. Check server logs for authentication errors</p>"},{"location":"guides/authentication/#connection-closed","title":"\"Connection Closed\"","text":"<p>Cause: Token expired during connection</p> <p>Solutions: 1. WebSocket closes when token expires 2. Client must reconnect with fresh token 3. Implement automatic reconnection logic</p>"},{"location":"guides/authentication/#keycloak-not-available","title":"Keycloak Not Available","text":"<p>Cause: Keycloak service not running</p> <p>Solutions: <pre><code># Check Keycloak status\ndocker ps | grep keycloak\n\n# Start Keycloak\nmake start\n\n# Check Keycloak logs\ndocker logs hw-keycloak\n</code></pre></p>"},{"location":"guides/authentication/#testing-authentication","title":"Testing Authentication","text":""},{"location":"guides/authentication/#unit-tests-with-mocks","title":"Unit Tests with Mocks","text":"<pre><code>import pytest\nfrom unittest.mock import patch\n\n@pytest.fixture\ndef mock_keycloak_token():\n    \"\"\"Mock Keycloak token response.\"\"\"\n    return {\n        \"access_token\": \"mock-token-12345\",\n        \"expires_in\": 300,\n        \"refresh_token\": \"mock-refresh\",\n        \"token_type\": \"Bearer\"\n    }\n\ndef test_endpoint_with_auth(client, mock_keycloak_token):\n    \"\"\"Test endpoint with mocked authentication.\"\"\"\n    with patch('app.auth.AuthBackend.authenticate'):\n        response = client.get(\n            \"/authors\",\n            headers={\"Authorization\": f\"Bearer {mock_keycloak_token['access_token']}\"}\n        )\n        assert response.status_code == 200\n</code></pre>"},{"location":"guides/authentication/#integration-tests-with-real-keycloak","title":"Integration Tests with Real Keycloak","text":"<pre><code>import pytest\n\n@pytest.mark.integration\ndef test_real_authentication():\n    \"\"\"Test with real Keycloak instance.\"\"\"\n    from app.managers.keycloak_manager import KeycloakManager\n\n    kc = KeycloakManager()\n    token = kc.login(\"testuser\", \"testpass\")\n\n    # Use token in request\n    response = requests.get(\n        \"http://localhost:8000/authors\",\n        headers={\"Authorization\": f\"Bearer {token['access_token']}\"}\n    )\n    assert response.status_code == 200\n</code></pre> <p>See Testing Guide for more details.</p>"},{"location":"guides/authentication/#security-best-practices","title":"Security Best Practices","text":""},{"location":"guides/authentication/#production-checklist","title":"Production Checklist","text":"<ul> <li> Use HTTPS for all connections</li> <li> Set short token expiration times</li> <li> Rotate client secrets regularly</li> <li> Use strong passwords in Keycloak</li> <li> Disable debug authentication bypass</li> <li> Configure proper CORS policies</li> <li> Enable Keycloak audit logging</li> <li> Use refresh tokens for long sessions</li> <li> Implement rate limiting</li> <li> Monitor for suspicious activity</li> </ul>"},{"location":"guides/authentication/#token-storage","title":"Token Storage","text":"<p>Browser: - Store in memory (JavaScript variable) - Or use httpOnly cookies - Never localStorage (XSS risk)</p> <p>Mobile: - Use secure keychain/keystore - Encrypt if in local storage</p> <p>Server-to-Server: - Environment variables - Secret management system - Never commit to git</p>"},{"location":"guides/authentication/#related-documentation","title":"Related Documentation","text":"<ul> <li>Testing Guide - How to test with authentication</li> <li>Quick Start - Quick authentication reference</li> <li>Architecture Overview - System architecture</li> <li>CLAUDE.md - Development guidelines</li> </ul>"},{"location":"guides/authentication/#additional-resources","title":"Additional Resources","text":""},{"location":"guides/authentication/#keycloak-documentation","title":"Keycloak Documentation","text":"<ul> <li>Getting Started</li> <li>Securing Applications</li> <li>Server Administration</li> </ul>"},{"location":"guides/authentication/#jwt-resources","title":"JWT Resources","text":"<ul> <li>JWT.io - Decode and verify tokens</li> <li>JWT Best Practices</li> </ul>"},{"location":"guides/authentication/#oauth-20-openid-connect","title":"OAuth 2.0 / OpenID Connect","text":"<ul> <li>OAuth 2.0 RFC</li> <li>OpenID Connect Spec</li> </ul>"},{"location":"guides/database/","title":"Database Operations","text":""},{"location":"guides/database/#overview","title":"Overview","text":"<p>The application uses PostgreSQL with async SQLModel/SQLAlchemy for database operations.</p>"},{"location":"guides/database/#configuration","title":"Configuration","text":"<p>Database configuration in <code>app/settings.py</code>:</p> <pre><code>POSTGRES_SERVER: str = \"localhost\"\nPOSTGRES_PORT: int = 5432\nPOSTGRES_USER: str = \"postgres\"\nPOSTGRES_PASSWORD: str = \"postgres\"\nPOSTGRES_DB: str = \"app_db\"\n\n# Connection pool\nPOOL_SIZE: int = 5\nMAX_OVERFLOW: int = 10\n</code></pre>"},{"location":"guides/database/#session-management","title":"Session Management","text":""},{"location":"guides/database/#getting-a-session","title":"Getting a Session","text":"<p>Use the async context manager:</p> <pre><code>from app.storage.db import async_session\n\nasync with async_session() as session:\n    async with session.begin():\n        # Database operations here\n        result = await session.execute(select(Author))\n</code></pre>"},{"location":"guides/database/#dependency-injection","title":"Dependency Injection","text":"<p>For HTTP endpoints, use <code>SessionDep</code>:</p> <pre><code>from app.dependencies import SessionDep\n\n@router.get(\"/authors\")\nasync def get_authors(session: SessionDep) -&gt; list[Author]:\n    \"\"\"Session is automatically provided and cleaned up.\"\"\"\n    result = await session.execute(select(Author))\n    return list(result.scalars().all())\n</code></pre>"},{"location":"guides/database/#models","title":"Models","text":""},{"location":"guides/database/#defining-models","title":"Defining Models","text":"<pre><code>from sqlmodel import Field, SQLModel\n\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str = Field(index=True)\n    created_at: datetime = Field(default_factory=datetime.utcnow)\n</code></pre>"},{"location":"guides/database/#async-relationships","title":"Async Relationships","text":"<p>For models with relationships, inherit from <code>BaseModel</code>:</p> <pre><code>from app.models.base import BaseModel\nfrom sqlmodel import Relationship\n\nclass Author(BaseModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    books: list[\"Book\"] = Relationship(back_populates=\"author\")\n\nclass Book(BaseModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    title: str\n    author_id: int = Field(foreign_key=\"author.id\")\n    author: Author = Relationship(back_populates=\"books\")\n</code></pre>"},{"location":"guides/database/#eager-loading","title":"Eager Loading","text":"<pre><code>from sqlalchemy.orm import selectinload\n\n# Load author with all books\nstmt = select(Author).options(selectinload(Author.books))\nresult = await session.execute(stmt)\nauthor = result.scalar_one()\n\n# Relationship already loaded\nbooks = author.books  # No await needed!\n</code></pre>"},{"location":"guides/database/#crud-operations","title":"CRUD Operations","text":""},{"location":"guides/database/#create","title":"Create","text":"<pre><code>from app.storage.db import async_session\n\nasync with async_session() as session:\n    async with session.begin():\n        author = Author(name=\"John Doe\")\n        session.add(author)\n        await session.flush()  # Get ID\n        await session.refresh(author)\n        return author\n</code></pre>"},{"location":"guides/database/#read","title":"Read","text":"<pre><code>from sqlmodel import select\n\n# Get by ID\nasync with async_session() as session:\n    author = await session.get(Author, 1)\n\n# Query with filters\nasync with async_session() as session:\n    stmt = select(Author).where(Author.name == \"John Doe\")\n    result = await session.execute(stmt)\n    author = result.scalar_one_or_none()\n\n# Get all\nasync with async_session() as session:\n    result = await session.execute(select(Author))\n    authors = list(result.scalars().all())\n</code></pre>"},{"location":"guides/database/#update","title":"Update","text":"<pre><code>async with async_session() as session:\n    async with session.begin():\n        author = await session.get(Author, 1)\n        if author:\n            author.name = \"Jane Doe\"\n            session.add(author)\n            await session.flush()\n            await session.refresh(author)\n</code></pre>"},{"location":"guides/database/#delete","title":"Delete","text":"<pre><code>async with async_session() as session:\n    async with session.begin():\n        author = await session.get(Author, 1)\n        if author:\n            await session.delete(author)\n</code></pre>"},{"location":"guides/database/#repository-pattern","title":"Repository Pattern","text":""},{"location":"guides/database/#using-repositories","title":"Using Repositories","text":"<p>Encapsulate database logic in repositories:</p> <pre><code>from app.repositories.author_repository import AuthorRepository\n\nasync with async_session() as session:\n    repo = AuthorRepository(session)\n\n    # Create\n    author = await repo.create(Author(name=\"John Doe\"))\n\n    # Read\n    author = await repo.get_by_id(1)\n    authors = await repo.get_all()\n    john = await repo.get_by_name(\"John\")\n\n    # Update\n    author.name = \"Jane Doe\"\n    await repo.update(author)\n\n    # Delete\n    await repo.delete(author)\n</code></pre>"},{"location":"guides/database/#custom-queries","title":"Custom Queries","text":"<p>Add repository methods for complex queries:</p> <pre><code>class AuthorRepository(BaseRepository[Author]):\n    async def search_by_name(self, pattern: str) -&gt; list[Author]:\n        \"\"\"Search authors by name pattern.\"\"\"\n        stmt = select(Author).where(Author.name.ilike(f\"%{pattern}%\"))\n        result = await self.session.execute(stmt)\n        return list(result.scalars().all())\n</code></pre>"},{"location":"guides/database/#pagination","title":"Pagination","text":""},{"location":"guides/database/#using-get_paginated_results","title":"Using get_paginated_results","text":"<pre><code>from app.storage.db import get_paginated_results\n\nresults, meta = await get_paginated_results(\n    Author,\n    page=1,\n    per_page=20,\n    filters={\"name\": \"John\"}\n)\n\n# meta contains: page, per_page, total, pages\n</code></pre>"},{"location":"guides/database/#custom-pagination","title":"Custom Pagination","text":"<pre><code>from sqlmodel import select, func\n\nasync def get_paginated_authors(page: int, per_page: int):\n    async with async_session() as session:\n        # Count total\n        count_stmt = select(func.count(Author.id))\n        total = (await session.execute(count_stmt)).scalar_one()\n\n        # Get page\n        offset = (page - 1) * per_page\n        stmt = select(Author).offset(offset).limit(per_page)\n        result = await session.execute(stmt)\n        items = list(result.scalars().all())\n\n        return items, {\n            \"page\": page,\n            \"per_page\": per_page,\n            \"total\": total,\n            \"pages\": (total + per_page - 1) // per_page\n        }\n</code></pre>"},{"location":"guides/database/#transactions","title":"Transactions","text":""},{"location":"guides/database/#automatic-transactions","title":"Automatic Transactions","text":"<p>Using <code>session.begin()</code>:</p> <pre><code>async with async_session() as session:\n    async with session.begin():\n        # All operations in one transaction\n        author = Author(name=\"John\")\n        session.add(author)\n        await session.flush()\n\n        book = Book(title=\"Book\", author_id=author.id)\n        session.add(book)\n        # Commits automatically on exit\n</code></pre>"},{"location":"guides/database/#manual-commitrollback","title":"Manual Commit/Rollback","text":"<pre><code>async with async_session() as session:\n    try:\n        author = Author(name=\"John\")\n        session.add(author)\n        await session.commit()\n    except Exception:\n        await session.rollback()\n        raise\n</code></pre>"},{"location":"guides/database/#migrations","title":"Migrations","text":""},{"location":"guides/database/#create-migration","title":"Create Migration","text":"<pre><code>make migration msg=\"Add email to Author\"\n</code></pre>"},{"location":"guides/database/#apply-migrations","title":"Apply Migrations","text":"<pre><code>make migrate\n</code></pre>"},{"location":"guides/database/#rollback","title":"Rollback","text":"<pre><code>make rollback\n</code></pre> <p>See Database Migrations for full guide.</p>"},{"location":"guides/database/#error-handling","title":"Error Handling","text":""},{"location":"guides/database/#integrityerror","title":"IntegrityError","text":"<pre><code>from sqlalchemy.exc import IntegrityError\n\ntry:\n    author = Author(name=\"John\")\n    session.add(author)\n    await session.commit()\nexcept IntegrityError as e:\n    await session.rollback()\n    logger.error(f\"Constraint violation: {e}\")\n    raise HTTPException(status_code=400, detail=\"Duplicate entry\")\n</code></pre>"},{"location":"guides/database/#noresultfound","title":"NoResultFound","text":"<pre><code>from sqlalchemy.exc import NoResultFound\n\ntry:\n    stmt = select(Author).where(Author.id == 999)\n    author = (await session.execute(stmt)).scalar_one()\nexcept NoResultFound:\n    raise HTTPException(status_code=404, detail=\"Author not found\")\n</code></pre>"},{"location":"guides/database/#best-practices","title":"Best Practices","text":""},{"location":"guides/database/#1-always-use-sessions-as-context-managers","title":"1. Always Use Sessions as Context Managers","text":"<pre><code># \u2705 Good\nasync with async_session() as session:\n    async with session.begin():\n        # operations\n\n# \u274c Bad\nsession = async_session()\n# operations\nawait session.close()  # Easy to forget!\n</code></pre>"},{"location":"guides/database/#2-use-repositories","title":"2. Use Repositories","text":"<pre><code># \u2705 Good - testable, reusable\nrepo = AuthorRepository(session)\nauthors = await repo.get_all()\n\n# \u274c Bad - logic in handlers\nresult = await session.execute(select(Author))\nauthors = list(result.scalars().all())\n</code></pre>"},{"location":"guides/database/#3-eager-load-relationships","title":"3. Eager Load Relationships","text":"<pre><code># \u2705 Good - one query\nstmt = select(Author).options(selectinload(Author.books))\nauthors = (await session.execute(stmt)).scalars().all()\n\n# \u274c Bad - N+1 queries\nauthors = (await session.execute(select(Author))).scalars().all()\nfor author in authors:\n    books = await author.awaitable_attrs.books  # Separate query!\n</code></pre>"},{"location":"guides/database/#4-use-transactions","title":"4. Use Transactions","text":"<pre><code># \u2705 Good - atomic operation\nasync with session.begin():\n    author = Author(name=\"John\")\n    session.add(author)\n    await session.flush()\n\n    book = Book(author_id=author.id)\n    session.add(book)\n\n# \u274c Bad - partial commits possible\nauthor = Author(name=\"John\")\nsession.add(author)\nawait session.commit()\n\nbook = Book(author_id=author.id)\nsession.add(book)\nawait session.commit()  # If this fails, author still created!\n</code></pre>"},{"location":"guides/database/#performance","title":"Performance","text":""},{"location":"guides/database/#connection-pooling","title":"Connection Pooling","text":"<p>Adjust pool size in settings:</p> <pre><code>POOL_SIZE: int = 10\nMAX_OVERFLOW: int = 20\n</code></pre>"},{"location":"guides/database/#query-optimization","title":"Query Optimization","text":"<pre><code># Use select() for better performance\nstmt = select(Author).where(Author.name == \"John\")\n\n# Use indexes\nclass Author(SQLModel, table=True):\n    name: str = Field(index=True)  # Indexed!\n\n# Limit results\nstmt = select(Author).limit(100)\n</code></pre>"},{"location":"guides/database/#testing","title":"Testing","text":""},{"location":"guides/database/#test-with-in-memory-database","title":"Test with In-Memory Database","text":"<pre><code>import pytest\nfrom sqlmodel import create_engine, Session\n\n@pytest.fixture\ndef session():\n    engine = create_engine(\"sqlite:///:memory:\")\n    SQLModel.metadata.create_all(engine)\n    with Session(engine) as session:\n        yield session\n</code></pre>"},{"location":"guides/database/#mock-repository","title":"Mock Repository","text":"<pre><code>from unittest.mock import AsyncMock\n\n@pytest.fixture\ndef mock_repo():\n    repo = AsyncMock()\n    repo.get_by_id.return_value = Author(id=1, name=\"Test\")\n    return repo\n</code></pre>"},{"location":"guides/database/#related","title":"Related","text":"<ul> <li>Database Migrations</li> <li>Design Patterns</li> <li>Testing Guide</li> </ul>"},{"location":"guides/design-patterns-reference/","title":"Design Patterns Quick Reference","text":"<p>Quick lookup guide for implementing Repository + Command + DI patterns</p>"},{"location":"guides/design-patterns-reference/#checklist-adding-a-new-feature","title":"\ud83d\udccb Checklist: Adding a New Feature","text":"<ul> <li> Create model in <code>app/models/</code></li> <li> Create repository in <code>app/repositories/</code></li> <li> Create commands in <code>app/commands/</code></li> <li> Add repository dependency in <code>app/dependencies.py</code></li> <li> Create HTTP endpoint in <code>app/api/http/</code></li> <li> Create WebSocket handler in <code>app/api/ws/handlers/</code></li> <li> Write tests</li> </ul>"},{"location":"guides/design-patterns-reference/#quick-start-template","title":"\ud83d\ude80 Quick Start Template","text":""},{"location":"guides/design-patterns-reference/#1-model-data-structure","title":"1. Model (Data Structure)","text":"<pre><code># app/models/book.py\nfrom sqlmodel import Field, SQLModel\n\nclass Book(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    title: str\n    author_id: int\n    # Keep simple - no business logic!\n</code></pre>"},{"location":"guides/design-patterns-reference/#2-repository-data-access","title":"2. Repository (Data Access)","text":"<pre><code># app/repositories/book_repository.py\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom app.models.book import Book\nfrom app.repositories.base import BaseRepository\n\nclass BookRepository(BaseRepository[Book]):\n    def __init__(self, session: AsyncSession):\n        super().__init__(session, Book)\n\n    # Add custom queries\n    async def get_by_title(self, title: str) -&gt; Book | None:\n        from sqlmodel import select\n        stmt = select(Book).where(Book.title == title)\n        result = await self.session.exec(stmt)\n        return result.first()\n</code></pre>"},{"location":"guides/design-patterns-reference/#3-commands-business-logic","title":"3. Commands (Business Logic)","text":"<pre><code># app/commands/book_commands.py\nfrom pydantic import BaseModel\nfrom app.commands.base import BaseCommand\nfrom app.models.book import Book\nfrom app.repositories.book_repository import BookRepository\n\n# Input/Output models\nclass GetBooksInput(BaseModel):\n    title: str | None = None\n    author_id: int | None = None\n\nclass CreateBookInput(BaseModel):\n    title: str\n    author_id: int\n\n# Commands\nclass GetBooksCommand(BaseCommand[GetBooksInput, list[Book]]):\n    def __init__(self, repository: BookRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: GetBooksInput) -&gt; list[Book]:\n        filters = {}\n        if input_data.title:\n            filters[\"title\"] = input_data.title\n        if input_data.author_id:\n            filters[\"author_id\"] = input_data.author_id\n        return await self.repository.get_all(**filters)\n\nclass CreateBookCommand(BaseCommand[CreateBookInput, Book]):\n    def __init__(self, repository: BookRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: CreateBookInput) -&gt; Book:\n        # Business logic: Check for duplicates\n        existing = await self.repository.get_by_title(input_data.title)\n        if existing:\n            raise ValueError(f\"Book '{input_data.title}' already exists\")\n\n        book = Book(**input_data.model_dump())\n        return await self.repository.create(book)\n</code></pre>"},{"location":"guides/design-patterns-reference/#4-dependencies","title":"4. Dependencies","text":"<pre><code># app/dependencies.py\ndef get_book_repository(session: SessionDep) -&gt; BookRepository:\n    return BookRepository(session)\n\nBookRepoDep = Annotated[BookRepository, Depends(get_book_repository)]\n</code></pre>"},{"location":"guides/design-patterns-reference/#5-http-endpoint","title":"5. HTTP Endpoint","text":"<pre><code># app/api/http/book.py\nfrom fastapi import APIRouter, status\nfrom app.commands.book_commands import CreateBookCommand, CreateBookInput\nfrom app.dependencies import BookRepoDep, RBACDep\nfrom app.models.book import Book\n\nrouter = APIRouter(prefix=\"/books\", tags=[\"books\"])\n\n@router.post(\"\", response_model=Book, status_code=status.HTTP_201_CREATED)\nasync def create_book(\n    data: CreateBookInput,\n    repo: BookRepoDep,\n    rbac: RBACDep,\n) -&gt; Book:\n    try:\n        command = CreateBookCommand(repo)\n        return await command.execute(data)\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n</code></pre>"},{"location":"guides/design-patterns-reference/#6-websocket-handler","title":"6. WebSocket Handler","text":"<pre><code># app/api/ws/handlers/book_handlers.py\nfrom app.api.ws.constants import PkgID, RSPCode\nfrom app.commands.book_commands import CreateBookCommand, CreateBookInput\nfrom app.repositories.book_repository import BookRepository\nfrom app.routing import pkg_router\nfrom app.schemas.request import RequestModel\nfrom app.schemas.response import ResponseModel\nfrom app.storage.db import async_session\n\n@pkg_router.register(PkgID.CREATE_BOOK, roles=[\"create-book\"])\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    try:\n        async with async_session() as session:\n            async with session.begin():\n                repo = BookRepository(session)\n                command = CreateBookCommand(repo)\n                input_data = CreateBookInput(**request.data)\n                book = await command.execute(input_data)\n\n                return ResponseModel(\n                    pkg_id=request.pkg_id,\n                    req_id=request.req_id,\n                    data=book.model_dump()\n                )\n    except ValueError as e:\n        return ResponseModel.err_msg(\n            request.pkg_id,\n            request.req_id,\n            msg=str(e),\n            status_code=RSPCode.INVALID_DATA\n        )\n</code></pre>"},{"location":"guides/design-patterns-reference/#testing-templates","title":"\ud83e\uddea Testing Templates","text":""},{"location":"guides/design-patterns-reference/#repository-test","title":"Repository Test","text":"<pre><code># tests/test_book_repository.py\nimport pytest\nfrom unittest.mock import AsyncMock, MagicMock\nfrom app.repositories.book_repository import BookRepository\n\n@pytest.fixture\ndef mock_session():\n    session = AsyncMock()\n    session.add = MagicMock()\n    session.flush = AsyncMock()\n    session.exec = AsyncMock()\n    return session\n\n@pytest.mark.asyncio\nasync def test_create_book(mock_session):\n    repo = BookRepository(mock_session)\n    book = Book(title=\"Test\", author_id=1)\n\n    created = await repo.create(book)\n\n    assert created == book\n    mock_session.add.assert_called_once_with(book)\n    mock_session.flush.assert_called_once()\n</code></pre>"},{"location":"guides/design-patterns-reference/#command-test","title":"Command Test","text":"<pre><code># tests/test_book_commands.py\nimport pytest\nfrom unittest.mock import AsyncMock\nfrom app.commands.book_commands import CreateBookCommand, CreateBookInput\n\n@pytest.mark.asyncio\nasync def test_create_book_command():\n    mock_repo = AsyncMock()\n    mock_repo.get_by_title.return_value = None  # No duplicate\n    mock_repo.create.return_value = Book(id=1, title=\"New\", author_id=1)\n\n    command = CreateBookCommand(mock_repo)\n    result = await command.execute(CreateBookInput(title=\"New\", author_id=1))\n\n    assert result.title == \"New\"\n    mock_repo.create.assert_called_once()\n\n@pytest.mark.asyncio\nasync def test_create_duplicate_book():\n    mock_repo = AsyncMock()\n    mock_repo.get_by_title.return_value = Book(id=1, title=\"Existing\", author_id=1)\n\n    command = CreateBookCommand(mock_repo)\n\n    with pytest.raises(ValueError, match=\"already exists\"):\n        await command.execute(CreateBookInput(title=\"Existing\", author_id=1))\n</code></pre>"},{"location":"guides/design-patterns-reference/#common-patterns","title":"\ud83d\udcdd Common Patterns","text":""},{"location":"guides/design-patterns-reference/#pagination-in-commands","title":"Pagination in Commands","text":"<pre><code>class GetBooksInput(BaseModel):\n    page: int = 1\n    per_page: int = 20\n    title: str | None = None\n\nclass GetBooksCommand(BaseCommand[GetBooksInput, tuple[list[Book], MetadataModel]]):\n    async def execute(self, input_data: GetBooksInput):\n        from app.storage.db import get_paginated_results\n\n        filters = {}\n        if input_data.title:\n            filters[\"title\"] = input_data.title\n\n        results, meta = await get_paginated_results(\n            Book,\n            page=input_data.page,\n            per_page=input_data.per_page,\n            filters=filters\n        )\n        return results, meta\n</code></pre>"},{"location":"guides/design-patterns-reference/#transactions-in-commands","title":"Transactions in Commands","text":"<pre><code>class CreateBookWithAuthorsCommand(BaseCommand[CreateBookInput, Book]):\n    def __init__(\n        self,\n        book_repo: BookRepository,\n        author_repo: AuthorRepository\n    ):\n        self.book_repo = book_repo\n        self.author_repo = author_repo\n\n    async def execute(self, input_data: CreateBookInput) -&gt; Book:\n        # All operations in same transaction (same session)\n        # If any fails, all rollback\n        author = await self.author_repo.get_by_id(input_data.author_id)\n        if not author:\n            raise ValueError(\"Author not found\")\n\n        book = Book(**input_data.model_dump())\n        return await self.book_repo.create(book)\n</code></pre>"},{"location":"guides/design-patterns-reference/#update-pattern","title":"Update Pattern","text":"<pre><code>class UpdateBookInput(BaseModel):\n    id: int\n    title: str\n\nclass UpdateBookCommand(BaseCommand[UpdateBookInput, Book]):\n    async def execute(self, input_data: UpdateBookInput) -&gt; Book:\n        # Get existing\n        book = await self.repository.get_by_id(input_data.id)\n        if not book:\n            raise ValueError(f\"Book {input_data.id} not found\")\n\n        # Check for conflicts\n        existing = await self.repository.get_by_title(input_data.title)\n        if existing and existing.id != input_data.id:\n            raise ValueError(f\"Title '{input_data.title}' already exists\")\n\n        # Update\n        book.title = input_data.title\n        return await self.repository.update(book)\n</code></pre>"},{"location":"guides/design-patterns-reference/#delete-pattern","title":"Delete Pattern","text":"<pre><code>class DeleteBookCommand(BaseCommand[int, None]):\n    async def execute(self, book_id: int) -&gt; None:\n        book = await self.repository.get_by_id(book_id)\n        if not book:\n            raise ValueError(f\"Book {book_id} not found\")\n\n        await self.repository.delete(book)\n</code></pre>"},{"location":"guides/design-patterns-reference/#decision-tree","title":"\ud83c\udfaf Decision Tree","text":""},{"location":"guides/design-patterns-reference/#when-to-create-a-new-command","title":"When to Create a New Command?","text":"<pre><code>Is it a distinct business operation? \u2192 YES \u2192 Create new command\n                                    \u2192 NO  \u2192 Add to existing command\n\nDoes it have different validation rules? \u2192 YES \u2192 Create new command\n                                         \u2192 NO  \u2192 Use existing command\n\nIs it used in multiple places? \u2192 YES \u2192 Definitely create command\n                               \u2192 NO  \u2192 Still create it (future-proof)\n</code></pre>"},{"location":"guides/design-patterns-reference/#when-to-add-custom-repository-methods","title":"When to Add Custom Repository Methods?","text":"<pre><code>Is it a common query pattern? \u2192 YES \u2192 Add to repository\n                             \u2192 NO  \u2192 Use base repository methods\n\nDoes it need complex joins? \u2192 YES \u2192 Add to repository\n                           \u2192 NO  \u2192 Use get_all() with filters\n\nIs it specific to one entity? \u2192 YES \u2192 Add to specific repository\n                              \u2192 NO  \u2192 Consider a service layer\n</code></pre>"},{"location":"guides/design-patterns-reference/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"guides/design-patterns-reference/#common-issues","title":"Common Issues","text":"<p>Issue: Circular import errors <pre><code># \u274c Don't import from __init__.py\nfrom app.repositories import AuthorRepository\n\n# \u2705 Import directly from module\nfrom app.repositories.author_repository import AuthorRepository\n</code></pre></p> <p>Issue: Session not flushed <pre><code># \u274c Forgot to flush\nasync def create(self, entity):\n    self.session.add(entity)\n    return entity  # ID not set!\n\n# \u2705 Always flush\nasync def create(self, entity):\n    self.session.add(entity)\n    await self.session.flush()  # ID now set\n    await self.session.refresh(entity)\n    return entity\n</code></pre></p> <p>Issue: Can't mock dependencies in tests <pre><code># \u274c Direct instantiation\nrepo = AuthorRepository(session)\n\n# \u2705 Use dependency override\napp.dependency_overrides[get_author_repository] = lambda: MockRepo()\n</code></pre></p>"},{"location":"guides/design-patterns-reference/#see-also","title":"\ud83d\udcda See Also","text":"<ul> <li>Full Design Patterns Guide</li> <li>Testing Guide</li> <li>Example: Author Implementation</li> <li>Issue #29</li> </ul> <p>Last Updated: 2025-12-05</p>"},{"location":"guides/http-endpoints/","title":"Creating HTTP Endpoints","text":""},{"location":"guides/http-endpoints/#overview","title":"Overview","text":"<p>This guide shows how to create new HTTP endpoints using FastAPI with proper authentication, authorization, and the Repository + Command pattern.</p>"},{"location":"guides/http-endpoints/#quick-start","title":"Quick Start","text":""},{"location":"guides/http-endpoints/#1-define-the-model","title":"1. Define the Model","text":"<pre><code># app/models/book.py\nfrom sqlmodel import Field, SQLModel\n\nclass Book(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    title: str\n    author_id: int\n</code></pre>"},{"location":"guides/http-endpoints/#2-create-repository","title":"2. Create Repository","text":"<pre><code># app/repositories/book_repository.py\nfrom app.models.book import Book\nfrom app.repositories.base import BaseRepository\n\nclass BookRepository(BaseRepository[Book]):\n    def __init__(self, session: AsyncSession):\n        super().__init__(session, Book)\n</code></pre>"},{"location":"guides/http-endpoints/#3-create-commands","title":"3. Create Commands","text":"<pre><code># app/commands/book_commands.py\nfrom pydantic import BaseModel\nfrom app.commands.base import BaseCommand\n\nclass CreateBookInput(BaseModel):\n    title: str\n    author_id: int\n\nclass CreateBookCommand(BaseCommand[CreateBookInput, Book]):\n    def __init__(self, repository: BookRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: CreateBookInput) -&gt; Book:\n        book = Book(**input_data.model_dump())\n        return await self.repository.create(book)\n</code></pre>"},{"location":"guides/http-endpoints/#4-add-dependency","title":"4. Add Dependency","text":"<pre><code># app/dependencies.py\ndef get_book_repository(session: SessionDep) -&gt; BookRepository:\n    return BookRepository(session)\n\nBookRepoDep = Annotated[BookRepository, Depends(get_book_repository)]\n</code></pre>"},{"location":"guides/http-endpoints/#5-create-router","title":"5. Create Router","text":"<pre><code># app/api/http/book.py\nfrom fastapi import APIRouter, Depends, status\nfrom app.commands.book_commands import CreateBookCommand, CreateBookInput\nfrom app.dependencies import BookRepoDep\nfrom app.dependencies.permissions import require_roles\n\nrouter = APIRouter(prefix=\"/books\", tags=[\"books\"])\n\n@router.post(\"\", response_model=Book, status_code=status.HTTP_201_CREATED)\nasync def create_book(\n    data: CreateBookInput,\n    repo: BookRepoDep,\n) -&gt; Book:\n    \"\"\"Create a new book.\"\"\"\n    command = CreateBookCommand(repo)\n    return await command.execute(data)\n\n@router.get(\"\", response_model=list[Book])\nasync def get_books(\n    repo: BookRepoDep,\n    dependencies=[Depends(require_roles(\"view-books\"))]\n) -&gt; list[Book]:\n    \"\"\"Get all books (requires 'view-books' role).\"\"\"\n    return await repo.get_all()\n</code></pre>"},{"location":"guides/http-endpoints/#adding-authentication","title":"Adding Authentication","text":""},{"location":"guides/http-endpoints/#public-endpoints","title":"Public Endpoints","text":"<p>No decorator needed - endpoint is public:</p> <pre><code>@router.get(\"/health\")\nasync def health_check():\n    \"\"\"Public health check endpoint.\"\"\"\n    return {\"status\": \"healthy\"}\n</code></pre>"},{"location":"guides/http-endpoints/#protected-endpoints","title":"Protected Endpoints","text":"<p>Use <code>require_roles()</code> dependency:</p> <pre><code>@router.get(\n    \"/books\",\n    dependencies=[Depends(require_roles(\"view-books\"))]\n)\nasync def get_books(repo: BookRepoDep) -&gt; list[Book]:\n    \"\"\"Requires 'view-books' role.\"\"\"\n    return await repo.get_all()\n</code></pre>"},{"location":"guides/http-endpoints/#multiple-roles","title":"Multiple Roles","text":"<p>Require ALL specified roles:</p> <pre><code>@router.delete(\n    \"/books/{book_id}\",\n    dependencies=[Depends(require_roles(\"delete-books\", \"admin\"))]\n)\nasync def delete_book(book_id: int, repo: BookRepoDep):\n    \"\"\"Requires BOTH 'delete-books' AND 'admin' roles.\"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(status_code=404, detail=\"Book not found\")\n    await repo.delete(book)\n    return {\"message\": \"Book deleted\"}\n</code></pre>"},{"location":"guides/http-endpoints/#request-validation","title":"Request Validation","text":""},{"location":"guides/http-endpoints/#path-parameters","title":"Path Parameters","text":"<pre><code>@router.get(\"/books/{book_id}\")\nasync def get_book(book_id: int, repo: BookRepoDep) -&gt; Book:\n    \"\"\"Get book by ID.\"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(status_code=404, detail=\"Book not found\")\n    return book\n</code></pre>"},{"location":"guides/http-endpoints/#query-parameters","title":"Query Parameters","text":"<pre><code>@router.get(\"/books\")\nasync def get_books(\n    repo: BookRepoDep,\n    title: str | None = None,\n    author_id: int | None = None,\n) -&gt; list[Book]:\n    \"\"\"Get books with optional filters.\"\"\"\n    filters = {}\n    if title:\n        filters[\"title\"] = title\n    if author_id:\n        filters[\"author_id\"] = author_id\n    return await repo.get_all(**filters)\n</code></pre>"},{"location":"guides/http-endpoints/#request-body","title":"Request Body","text":"<pre><code>class UpdateBookInput(BaseModel):\n    title: str\n    author_id: int\n\n@router.put(\"/books/{book_id}\")\nasync def update_book(\n    book_id: int,\n    data: UpdateBookInput,\n    repo: BookRepoDep,\n) -&gt; Book:\n    \"\"\"Update book.\"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(status_code=404, detail=\"Book not found\")\n\n    book.title = data.title\n    book.author_id = data.author_id\n    return await repo.update(book)\n</code></pre>"},{"location":"guides/http-endpoints/#pagination","title":"Pagination","text":"<pre><code>from app.storage.db import get_paginated_results\n\n@router.get(\"/books/paginated\")\nasync def get_books_paginated(\n    page: int = 1,\n    per_page: int = 20,\n) -&gt; dict:\n    \"\"\"Get paginated books.\"\"\"\n    results, meta = await get_paginated_results(\n        Book,\n        page=page,\n        per_page=per_page\n    )\n    return {\n        \"items\": [book.model_dump() for book in results],\n        \"meta\": meta.model_dump()\n    }\n</code></pre>"},{"location":"guides/http-endpoints/#error-handling","title":"Error Handling","text":"<pre><code>from fastapi import HTTPException\n\n@router.post(\"/books\")\nasync def create_book(data: CreateBookInput, repo: BookRepoDep) -&gt; Book:\n    \"\"\"Create book with error handling.\"\"\"\n    try:\n        command = CreateBookCommand(repo)\n        return await command.execute(data)\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Failed to create book: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n</code></pre>"},{"location":"guides/http-endpoints/#response-models","title":"Response Models","text":""},{"location":"guides/http-endpoints/#custom-response-models","title":"Custom Response Models","text":"<pre><code>class BookResponse(BaseModel):\n    id: int\n    title: str\n    author_name: str\n\n@router.get(\"/books/{book_id}\", response_model=BookResponse)\nasync def get_book(book_id: int, repo: BookRepoDep) -&gt; BookResponse:\n    \"\"\"Get book with custom response.\"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(status_code=404, detail=\"Book not found\")\n\n    return BookResponse(\n        id=book.id,\n        title=book.title,\n        author_name=\"...\"  # Load from relationship\n    )\n</code></pre>"},{"location":"guides/http-endpoints/#testing","title":"Testing","text":"<pre><code>from fastapi.testclient import TestClient\n\ndef test_create_book(client: TestClient):\n    \"\"\"Test book creation.\"\"\"\n    response = client.post(\n        \"/books\",\n        json={\"title\": \"Test Book\", \"author_id\": 1},\n        headers={\"Authorization\": f\"Bearer {token}\"}\n    )\n    assert response.status_code == 201\n    assert response.json()[\"title\"] == \"Test Book\"\n</code></pre>"},{"location":"guides/http-endpoints/#related","title":"Related","text":"<ul> <li>Design Patterns Guide</li> <li>WebSocket Handlers</li> <li>Authentication Guide</li> <li>Testing Guide</li> </ul>"},{"location":"guides/monitoring/","title":"Monitoring Setup Guide","text":"<p>This application includes comprehensive observability with Prometheus metrics for monitoring and Grafana Loki for centralized log aggregation.</p>"},{"location":"guides/monitoring/#quick-start","title":"Quick Start","text":""},{"location":"guides/monitoring/#1-view-raw-metrics","title":"1. View Raw Metrics","text":"<p>Start your FastAPI application and navigate to: <pre><code>http://localhost:8000/metrics\n</code></pre></p> <p>You'll see Prometheus text format metrics like: <pre><code># HELP http_requests_total Total HTTP requests\n# TYPE http_requests_total counter\nhttp_requests_total{method=\"GET\",endpoint=\"/health\",status_code=\"200\"} 42.0\n\n# HELP ws_connections_active Active WebSocket connections\n# TYPE ws_connections_active gauge\nws_connections_active 5.0\n</code></pre></p>"},{"location":"guides/monitoring/#2-using-docker-compose-recommended","title":"2. Using Docker Compose (Recommended)","text":"<p>Start the full observability stack with your application:</p> <pre><code>cd docker\ndocker-compose up -d\n</code></pre> <p>Access the monitoring and logging tools: - Application: http://localhost:8000 - Prometheus UI: http://localhost:9090 - Grafana: http://localhost:3000 (admin/admin) - Loki API: http://localhost:3100 - Metrics Endpoint: http://localhost:8000/metrics</p>"},{"location":"guides/monitoring/#available-metrics","title":"Available Metrics","text":""},{"location":"guides/monitoring/#http-metrics","title":"HTTP Metrics","text":"<ul> <li><code>http_requests_total</code> - Total number of HTTP requests (counter)</li> <li>Labels: method, endpoint, status_code</li> <li><code>http_request_duration_seconds</code> - HTTP request duration (histogram)</li> <li>Labels: method, endpoint</li> <li>Buckets: 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0</li> <li><code>http_requests_in_progress</code> - In-progress HTTP requests (gauge)</li> <li>Labels: method, endpoint</li> </ul>"},{"location":"guides/monitoring/#websocket-metrics","title":"WebSocket Metrics","text":"<ul> <li><code>ws_connections_active</code> - Active WebSocket connections (gauge)</li> <li><code>ws_connections_total</code> - Total WebSocket connections (counter)</li> <li>Labels: status (accepted, rejected_auth, rejected_limit)</li> <li><code>ws_messages_received_total</code> - Total WebSocket messages received (counter)</li> <li><code>ws_messages_sent_total</code> - Total WebSocket messages sent (counter)</li> <li><code>ws_message_processing_duration_seconds</code> - Message processing duration (histogram)</li> <li>Labels: pkg_id</li> </ul>"},{"location":"guides/monitoring/#database-metrics-for-future-instrumentation","title":"Database Metrics (for future instrumentation)","text":"<ul> <li><code>db_query_duration_seconds</code> - Database query duration (histogram)</li> <li>Labels: operation</li> <li><code>db_connections_active</code> - Active database connections (gauge)</li> <li><code>db_query_errors_total</code> - Database query errors (counter)</li> <li>Labels: operation, error_type</li> </ul>"},{"location":"guides/monitoring/#redis-metrics-for-future-instrumentation","title":"Redis Metrics (for future instrumentation)","text":"<ul> <li><code>redis_operations_total</code> - Total Redis operations (counter)</li> <li>Labels: operation</li> <li><code>redis_operation_duration_seconds</code> - Redis operation duration (histogram)</li> <li>Labels: operation</li> </ul>"},{"location":"guides/monitoring/#authentication-rate-limiting","title":"Authentication &amp; Rate Limiting","text":"<ul> <li><code>auth_attempts_total</code> - Authentication attempts (counter)</li> <li>Labels: status</li> <li><code>auth_token_validations_total</code> - Token validations (counter)</li> <li>Labels: status</li> <li><code>rate_limit_hits_total</code> - Rate limit hits (counter)</li> <li>Labels: limit_type</li> </ul>"},{"location":"guides/monitoring/#application-metrics","title":"Application Metrics","text":"<ul> <li><code>app_errors_total</code> - Application errors (counter)</li> <li>Labels: error_type, handler</li> <li><code>app_info</code> - Application info (gauge)</li> <li>Labels: version, python_version, environment</li> </ul>"},{"location":"guides/monitoring/#prometheus-queries","title":"Prometheus Queries","text":""},{"location":"guides/monitoring/#useful-promql-queries","title":"Useful PromQL Queries","text":"<p>Request rate (requests per second): <pre><code>rate(http_requests_total[5m])\n</code></pre></p> <p>95<sup>th</sup> percentile request duration: <pre><code>histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\n</code></pre></p> <p>Error rate: <pre><code>rate(http_requests_total{status_code=~\"5..\"}[5m])\n</code></pre></p> <p>WebSocket connection rate: <pre><code>rate(ws_connections_total[5m])\n</code></pre></p> <p>Rate limit hit rate: <pre><code>rate(rate_limit_hits_total[5m])\n</code></pre></p> <p>Average message processing time: <pre><code>rate(ws_message_processing_duration_seconds_sum[5m]) / rate(ws_message_processing_duration_seconds_count[5m])\n</code></pre></p>"},{"location":"guides/monitoring/#grafana-setup","title":"Grafana Setup","text":""},{"location":"guides/monitoring/#1-add-prometheus-data-source","title":"1. Add Prometheus Data Source","text":"<ol> <li>Login to Grafana at http://localhost:3000 (admin/admin)</li> <li>Go to Configuration \u2192 Data Sources</li> <li>Click \"Add data source\"</li> <li>Select \"Prometheus\"</li> <li>Set URL to <code>http://prometheus:9090</code></li> <li>Click \"Save &amp; Test\"</li> </ol>"},{"location":"guides/monitoring/#2-pre-configured-dashboards","title":"2. Pre-configured Dashboards","text":"<p>The project includes comprehensive pre-configured dashboards that are automatically provisioned when you start Grafana:</p> <p>Available Dashboards:</p> <ol> <li>FastAPI Metrics (<code>docker/grafana/provisioning/dashboards/fastapi-metrics.json</code>)</li> <li>HTTP request rate and duration</li> <li>WebSocket connections and message rate</li> <li>Rate limit metrics</li> <li>Application info and errors</li> <li> <p>Auto-provisioned on Grafana startup</p> </li> <li> <p>Application Logs (<code>docker/grafana/provisioning/dashboards/application-logs.json</code>)</p> </li> <li>Log volume by service</li> <li>Error logs and trends</li> <li>Service-specific log panels</li> <li> <p>Auto-provisioned on Grafana startup</p> </li> <li> <p>Keycloak Metrics (<code>docker/grafana/provisioning/dashboards/keycloak-metrics.json</code>)</p> </li> <li>Authentication metrics</li> <li>JVM and performance stats</li> <li> <p>Auto-provisioned on Grafana startup</p> </li> <li> <p>Traefik Metrics (<code>docker/grafana/provisioning/dashboards/traefik-metrics.json</code>)</p> </li> <li>Reverse proxy metrics</li> <li>Request routing stats</li> <li>Auto-provisioned on Grafana startup</li> </ol> <p>Accessing Dashboards: After starting the stack with <code>docker-compose up -d</code>, dashboards are automatically available at: - http://localhost:3000/dashboards (Browse all dashboards)</p>"},{"location":"guides/monitoring/#3-create-custom-panels","title":"3. Create Custom Panels","text":"<p>Example panel configurations:</p> <p>Error Rate Panel: <pre><code>{\n  \"expr\": \"rate(http_requests_total{status_code=~\\\"5..\\\"}[5m])\",\n  \"legendFormat\": \"{{method}} {{endpoint}} - {{status_code}}\"\n}\n</code></pre></p> <p>WebSocket Active Connections: <pre><code>{\n  \"expr\": \"ws_connections_active\",\n  \"legendFormat\": \"Active Connections\"\n}\n</code></pre></p>"},{"location":"guides/monitoring/#alerts","title":"Alerts","text":""},{"location":"guides/monitoring/#example-alert-rules","title":"Example Alert Rules","text":"<p>Create <code>prometheus-alerts.yml</code>:</p> <pre><code>groups:\n  - name: fastapi_alerts\n    interval: 30s\n    rules:\n      - alert: HighErrorRate\n        expr: rate(http_requests_total{status_code=~\"5..\"}[5m]) &gt; 0.05\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High error rate detected\"\n          description: \"Error rate is {{ $value }} requests/second\"\n\n      - alert: HighLatency\n        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) &gt; 1\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High latency detected\"\n          description: \"95th percentile latency is {{ $value }}s\"\n\n      - alert: RateLimitExceeded\n        expr: rate(rate_limit_hits_total[5m]) &gt; 10\n        for: 2m\n        labels:\n          severity: info\n        annotations:\n          summary: \"Rate limits being hit frequently\"\n          description: \"Rate limit hit rate: {{ $value }} hits/second\"\n</code></pre> <p>Update <code>prometheus.yml</code> to include alerts: <pre><code>rule_files:\n  - \"prometheus-alerts.yml\"\n\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets: ['alertmanager:9093']\n</code></pre></p>"},{"location":"guides/monitoring/#custom-metrics-in-code","title":"Custom Metrics in Code","text":""},{"location":"guides/monitoring/#adding-custom-metrics","title":"Adding Custom Metrics","text":"<pre><code>from app.utils.metrics import http_requests_total, db_query_duration_seconds\n\n# Increment counter\nhttp_requests_total.labels(\n    method=\"POST\",\n    endpoint=\"/api/custom\",\n    status_code=201\n).inc()\n\n# Observe histogram\ndb_query_duration_seconds.labels(operation=\"select\").observe(0.045)\n</code></pre>"},{"location":"guides/monitoring/#creating-new-metrics","title":"Creating New Metrics","text":"<p>Add to <code>app/utils/metrics.py</code>:</p> <pre><code>from prometheus_client import Counter\n\ncustom_events_total = Counter(\n    'custom_events_total',\n    'Total custom events',\n    ['event_type', 'status']\n)\n\n# Usage\ncustom_events_total.labels(event_type='user_action', status='success').inc()\n</code></pre>"},{"location":"guides/monitoring/#production-considerations","title":"Production Considerations","text":""},{"location":"guides/monitoring/#1-metric-cardinality","title":"1. Metric Cardinality","text":"<p>Avoid high-cardinality labels (e.g., user IDs, timestamps). Use aggregated labels instead:</p> <p>\u274c Bad: <pre><code>requests.labels(user_id=user.id)  # Unbounded cardinality\n</code></pre></p> <p>\u2705 Good: <pre><code>requests.labels(user_type=user.role)  # Bounded cardinality\n</code></pre></p>"},{"location":"guides/monitoring/#2-performance","title":"2. Performance","text":"<ul> <li>Metrics collection has minimal overhead (~microseconds per metric)</li> <li>Use histograms for latency tracking (pre-configured buckets)</li> <li>Consider sampling for very high-traffic endpoints if needed</li> </ul>"},{"location":"guides/monitoring/#3-retention","title":"3. Retention","text":"<p>Configure Prometheus retention in <code>docker-compose.yml</code>:</p> <pre><code>command:\n  - '--storage.tsdb.retention.time=30d'\n  - '--storage.tsdb.retention.size=10GB'\n</code></pre>"},{"location":"guides/monitoring/#4-security","title":"4. Security","text":"<p>For production: - Enable authentication on Prometheus and Grafana - Use TLS for metrics endpoints - Restrict network access to monitoring tools - Consider using read-only Prometheus API tokens</p>"},{"location":"guides/monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/monitoring/#metrics-not-appearing","title":"Metrics not appearing","text":"<ol> <li> <p>Check <code>/metrics</code> endpoint is accessible:    <pre><code>curl http://localhost:8000/metrics\n</code></pre></p> </li> <li> <p>Verify Prometheus is scraping:</p> </li> <li>Go to http://localhost:9090/targets</li> <li> <p>Check if <code>fastapi-app</code> target is UP</p> </li> <li> <p>Check Prometheus logs:    <pre><code>docker logs hw-prometheus\n</code></pre></p> </li> </ol>"},{"location":"guides/monitoring/#grafana-dashboard-shows-no-data","title":"Grafana dashboard shows no data","text":"<ol> <li>Verify data source connection:</li> <li> <p>Configuration \u2192 Data Sources \u2192 Prometheus \u2192 Test</p> </li> <li> <p>Check time range in dashboard (top right)</p> </li> <li> <p>Verify metrics exist in Prometheus:</p> </li> <li>Go to Prometheus \u2192 Graph</li> <li>Enter metric name and execute</li> </ol>"},{"location":"guides/monitoring/#high-memory-usage","title":"High memory usage","text":"<p>If Prometheus uses too much memory:</p> <ol> <li> <p>Reduce retention time:    <pre><code>--storage.tsdb.retention.time=15d\n</code></pre></p> </li> <li> <p>Reduce scrape frequency in <code>prometheus.yml</code>:    <pre><code>scrape_interval: 30s  # Instead of 15s\n</code></pre></p> </li> <li> <p>Review metric cardinality:    <pre><code>count({__name__=~\".+\"}) by (__name__)\n</code></pre></p> </li> </ol>"},{"location":"guides/monitoring/#centralized-logging-with-loki","title":"Centralized Logging with Loki","text":""},{"location":"guides/monitoring/#overview","title":"Overview","text":"<p>Grafana Loki provides centralized log aggregation for all Docker containers. Promtail collects logs from Docker containers and ships them to Loki for storage and querying.</p>"},{"location":"guides/monitoring/#architecture","title":"Architecture","text":"<pre><code>Docker Containers \u2192 Promtail \u2192 Loki \u2192 Grafana\n                      \u2193\n                 /var/run/docker.sock\n</code></pre> <ul> <li>Loki: Log aggregation system (similar to Prometheus but for logs)</li> <li>Promtail: Log collection agent that reads Docker container logs</li> <li>Grafana: Visualization layer for both metrics and logs</li> </ul>"},{"location":"guides/monitoring/#viewing-logs-in-grafana","title":"Viewing Logs in Grafana","text":""},{"location":"guides/monitoring/#1-using-the-logs-dashboard","title":"1. Using the Logs Dashboard","text":"<ol> <li>Navigate to Grafana: http://localhost:3000</li> <li>Go to Dashboards \u2192 Application Logs</li> <li>The dashboard includes:</li> <li>Log volume by service</li> <li>Log level distribution (ERROR, WARNING, INFO)</li> <li>Error logs panel</li> <li>Error rate trends</li> <li>Service-specific log panels</li> </ol>"},{"location":"guides/monitoring/#2-using-explore-ad-hoc-queries","title":"2. Using Explore (Ad-hoc Queries)","text":"<ol> <li>Go to Explore \u2192 Select \"Loki\" datasource</li> <li>Use LogQL to query logs</li> </ol>"},{"location":"guides/monitoring/#logql-query-examples","title":"LogQL Query Examples","text":"<p>Basic Queries:</p> <pre><code># All logs from shell service (FastAPI)\n{service=\"shell\"}\n\n# All logs from specific container\n{container=\"hw-shell\"}\n\n# Logs from multiple services\n{service=~\"shell|hw-db|hw-keycloak\"}\n</code></pre> <p>Filtering by Content:</p> <pre><code># All error logs\n{service=\"shell\"} |= \"ERROR\"\n\n# Case-insensitive error search\n{service=\"shell\"} |~ \"(?i)(error|exception)\"\n\n# Filter out health checks\n{service=\"shell\"} != \"GET /health\"\n\n# Python tracebacks\n{service=\"shell\"} |= \"Traceback\"\n</code></pre> <p>JSON Log Parsing:</p> <pre><code># Parse JSON logs and filter by level\n{service=\"shell\"} | json | level=\"ERROR\"\n\n# Extract specific JSON field\n{service=\"shell\"} | json | line_format \"{{.message}}\"\n\n# Filter by nested JSON field\n{service=\"shell\"} | json | error!=\"\"\n</code></pre> <p>Advanced Queries:</p> <pre><code># Count log lines per service\nsum by (service) (count_over_time({job=\"docker\"}[5m]))\n\n# Error rate per service\nsum by (service) (rate({job=\"docker\"} |~ \"(?i)error\" [5m]))\n\n# Top 10 error messages\ntopk(10, sum by (service) (count_over_time({job=\"docker\"} |~ \"(?i)error\" [1h])))\n\n# Filter by multiple conditions\n{service=\"shell\"}\n  | json\n  | level=\"ERROR\"\n  | line_format \"{{.timestamp}} - {{.message}}\"\n</code></pre> <p>Time-based Queries:</p> <pre><code># Logs in the last 5 minutes\n{service=\"shell\"} [5m]\n\n# Log volume rate\nrate({service=\"shell\"}[1m])\n\n# Count over time window\ncount_over_time({service=\"shell\"}[10m])\n</code></pre>"},{"location":"guides/monitoring/#log-retention","title":"Log Retention","text":"<p>By default, logs are retained for 7 days (168 hours). This is configured in docker/loki/loki-config.yml:</p> <pre><code>limits_config:\n  reject_old_samples_max_age: 168h  # 7 days\n\ncompactor:\n  retention_enabled: true\n  retention_delete_delay: 2h\n</code></pre> <p>To change retention: 1. Edit <code>docker/loki/loki-config.yml</code> 2. Update <code>reject_old_samples_max_age</code> value (e.g., <code>720h</code> for 30 days) 3. Restart Loki: <code>docker-compose restart loki</code></p>"},{"location":"guides/monitoring/#log-collection-configuration","title":"Log Collection Configuration","text":"<p>Promtail is configured to collect logs from all Docker containers in this project. Configuration is in docker/promtail/promtail-config.yml.</p> <p>What gets collected: - Container logs (stdout/stderr) - Service name from Docker Compose labels - Log stream (stdout vs stderr) - Container ID and name - Timestamps</p> <p>What gets filtered out: - Health check requests (<code>GET /health</code>) - Empty log lines</p>"},{"location":"guides/monitoring/#structured-logging-with-loki-integration","title":"Structured Logging with Loki Integration","text":"<p>This application uses structured JSON logging with automatic Loki integration. Logs are sent to Loki in JSON format with contextual fields for easy filtering.</p>"},{"location":"guides/monitoring/#built-in-features","title":"Built-in Features","text":"<p>The application automatically includes: - Correlation ID tracking: Each request gets a unique ID - Contextual fields: endpoint, method, status_code, user_id - JSON formatting: All logs sent to Loki are in JSON format - Human-readable console: Development logs are human-readable - Multiple handlers: Console, file, and Loki handlers</p>"},{"location":"guides/monitoring/#configuration","title":"Configuration","text":"<p>Loki integration is controlled via environment variables (see app/settings.py):</p> <pre><code># Enable/disable Loki integration\nLOKI_ENABLED=true\n\n# Loki server URL (inside Docker network)\nLOKI_URL=http://loki:3100\n\n# Log level (DEBUG, INFO, WARNING, ERROR)\nLOG_LEVEL=INFO\n\n# Environment tag for filtering\nENVIRONMENT=development\n</code></pre>"},{"location":"guides/monitoring/#basic-usage","title":"Basic Usage","text":"<p>Simply use the standard Python logger:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\n# Basic logging (automatically includes request_id, endpoint, user_id, etc.)\nlogger.info(\"Processing author creation\")\nlogger.warning(\"Rate limit approaching threshold\")\nlogger.error(\"Database connection failed\", exc_info=True)\n</code></pre>"},{"location":"guides/monitoring/#adding-custom-context","title":"Adding Custom Context","text":"<p>Add custom contextual fields to all logs within a request:</p> <pre><code>from app.logging import set_log_context, logger\n\n# In your endpoint or handler\nset_log_context(\n    operation=\"create_author\",\n    author_id=123,\n    ip_address=request.client.host\n)\n\nlogger.info(\"Author created successfully\")\n# Log will include: operation, author_id, ip_address, plus auto fields\n</code></pre>"},{"location":"guides/monitoring/#example-log-output","title":"Example Log Output","text":"<p>Console (Human-readable): <pre><code>2025-12-16 14:30:45 - [a1b2c3d4] INFO: Processing author creation\n2025-12-16 14:30:45 - [a1b2c3d4] INFO: app.api.http.author.create_author:42 - Author created successfully\n</code></pre></p> <p>Loki (JSON): <pre><code>{\n  \"timestamp\": \"2025-12-16T14:30:45.123Z\",\n  \"level\": \"INFO\",\n  \"logger\": \"app.api.http.author\",\n  \"message\": \"Author created successfully\",\n  \"module\": \"author\",\n  \"function\": \"create_author\",\n  \"line\": 42,\n  \"request_id\": \"a1b2c3d4\",\n  \"endpoint\": \"/api/authors\",\n  \"method\": \"POST\",\n  \"status_code\": 201,\n  \"user_id\": \"user-123\",\n  \"environment\": \"development\"\n}\n</code></pre></p>"},{"location":"guides/monitoring/#query-examples-for-structured-logs","title":"Query Examples for Structured Logs","text":"<p>Once logs are in Loki, you can query them using LogQL:</p> <pre><code># All requests from specific user\n{application=\"fastapi-app\"} | json | user_id=\"user-123\"\n\n# Failed requests (5xx status codes)\n{application=\"fastapi-app\"} | json | status_code &gt;= 500\n\n# Slow requests (custom field)\n{application=\"fastapi-app\"} | json | duration_ms &gt; 1000\n\n# Errors for specific endpoint\n{application=\"fastapi-app\"} | json | level=\"ERROR\" | endpoint=\"/api/authors\"\n\n# Requests by correlation ID (trace single request)\n{application=\"fastapi-app\"} | json | request_id=\"a1b2c3d4\"\n</code></pre>"},{"location":"guides/monitoring/#websocket-logging","title":"WebSocket Logging","text":"<p>For WebSocket handlers, manually add context:</p> <pre><code>from app.logging import set_log_context, logger\n\nasync def handle_websocket_message(request: RequestModel):\n    # Add WebSocket-specific context\n    set_log_context(\n        pkg_id=request.pkg_id,\n        req_id=request.req_id,\n        user_id=request.data.get(\"user_id\")\n    )\n\n    logger.info(f\"Processing WebSocket request {request.pkg_id}\")\n    # Process request...\n</code></pre>"},{"location":"guides/monitoring/#best-practices","title":"Best Practices","text":"<p>\u2705 Do: - Use logger.info() for normal operations - Use logger.warning() for recoverable issues - Use logger.error() with exc_info=True for exceptions - Add contextual fields with set_log_context() - Use correlation IDs to trace requests</p> <p>\u274c Don't: - Log sensitive data (passwords, tokens, PII) - Log at DEBUG level in production - Create new loggers without using logging.getLogger(name) - Include large objects in log messages (they're truncated anyway)</p>"},{"location":"guides/monitoring/#correlating-logs-with-metrics","title":"Correlating Logs with Metrics","text":"<p>In Grafana, you can correlate metrics spikes with logs:</p> <ol> <li>From Metrics Dashboard to Logs:</li> <li>Click on a metric spike in Prometheus dashboard</li> <li>Select \"Explore\" \u2192 Switch to Loki datasource</li> <li> <p>Logs from the same time range will appear</p> </li> <li> <p>From Logs to Metrics:</p> </li> <li>Find an error in logs</li> <li>Note the timestamp</li> <li>Switch to Prometheus datasource</li> <li> <p>Query metrics around that timestamp</p> </li> <li> <p>Split View:</p> </li> <li>Use Grafana's split view (Explore \u2192 Split)</li> <li>Prometheus on one side, Loki on the other</li> <li>Same time range for correlation</li> </ol>"},{"location":"guides/monitoring/#troubleshooting-loki","title":"Troubleshooting Loki","text":""},{"location":"guides/monitoring/#no-logs-appearing","title":"No logs appearing","text":"<ol> <li> <p>Check Promtail is running: <pre><code>docker ps | grep promtail\ndocker logs hw-promtail\n</code></pre></p> </li> <li> <p>Verify Promtail can access Docker socket: <pre><code>docker exec hw-promtail ls -la /var/run/docker.sock\n</code></pre></p> </li> <li> <p>Check Promtail targets: <pre><code>curl http://localhost:9080/targets\n</code></pre></p> </li> <li> <p>Verify Loki is receiving logs: <pre><code>curl http://localhost:3100/loki/api/v1/label\ncurl http://localhost:3100/loki/api/v1/label/service/values\n</code></pre></p> </li> </ol>"},{"location":"guides/monitoring/#logs-are-delayed","title":"Logs are delayed","text":"<ul> <li>Promtail buffers logs before sending to Loki</li> <li>Default refresh interval: 5 seconds</li> <li>Check Promtail logs for errors: <code>docker logs hw-promtail</code></li> </ul>"},{"location":"guides/monitoring/#high-loki-memory-usage","title":"High Loki memory usage","text":"<ol> <li> <p>Reduce retention period in <code>loki-config.yml</code>:    <pre><code>limits_config:\n  reject_old_samples_max_age: 72h  # 3 days instead of 7\n</code></pre></p> </li> <li> <p>Limit ingestion rate:    <pre><code>limits_config:\n  ingestion_rate_mb: 5  # Reduce from 10MB\n  ingestion_burst_size_mb: 10  # Reduce from 20MB\n</code></pre></p> </li> <li> <p>Filter noisy logs in <code>promtail-config.yml</code>:    <pre><code>pipeline_stages:\n  - drop:\n      expression: '.*DEBUG.*'\n      drop_counter_reason: debug_logs\n</code></pre></p> </li> </ol>"},{"location":"guides/monitoring/#cannot-query-old-logs","title":"Cannot query old logs","text":"<ul> <li>Check retention settings in <code>loki-config.yml</code></li> <li>Verify compactor is running:   <pre><code>docker logs hw-loki | grep compactor\n</code></pre></li> </ul>"},{"location":"guides/monitoring/#loki-api-usage","title":"Loki API Usage","text":"<p>Query logs programmatically:</p> <pre><code># Query logs via API\ncurl -G -s \"http://localhost:3100/loki/api/v1/query_range\" \\\n  --data-urlencode 'query={service=\"shell\"} |= \"error\"' \\\n  --data-urlencode \"start=$(date -d '1 hour ago' +%s)000000000\" \\\n  --data-urlencode \"end=$(date +%s)000000000\" \\\n  | jq '.data.result'\n\n# Get label values\ncurl -s \"http://localhost:3100/loki/api/v1/label/service/values\" | jq\n\n# Get all labels\ncurl -s \"http://localhost:3100/loki/api/v1/labels\" | jq\n</code></pre>"},{"location":"guides/monitoring/#logql-vs-promql","title":"LogQL vs PromQL","text":"Feature PromQL (Metrics) LogQL (Logs) Data type Time-series metrics Log lines Query <code>rate(http_requests_total[5m])</code> <code>{service=\"shell\"} \\|= \"error\"</code> Aggregation <code>sum by (method)</code> <code>count_over_time()</code> Filtering Label matchers Text search + JSON parsing Output Numbers Log lines + counts"},{"location":"guides/monitoring/#additional-resources","title":"Additional Resources","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Documentation</li> <li>Grafana Loki Documentation</li> <li>LogQL Documentation</li> <li>PromQL Cheat Sheet</li> <li>FastAPI Best Practices</li> </ul>"},{"location":"guides/rate-limiting/","title":"Rate Limiting","text":""},{"location":"guides/rate-limiting/#overview","title":"Overview","text":"<p>The application implements Redis-based rate limiting for both HTTP and WebSocket connections to prevent abuse and ensure fair resource allocation.</p>"},{"location":"guides/rate-limiting/#configuration","title":"Configuration","text":"<p>Rate limiting is configured in <code>app/settings.py</code>:</p> <pre><code># HTTP Rate Limiting\nRATE_LIMIT_ENABLED: bool = True\nRATE_LIMIT_PER_MINUTE: int = 60  # Requests per minute\nRATE_LIMIT_BURST: int = 10       # Burst allowance\n\n# WebSocket Rate Limiting\nWS_MAX_CONNECTIONS_PER_USER: int = 5     # Max concurrent connections\nWS_MESSAGE_RATE_LIMIT: int = 100          # Messages per minute\n</code></pre>"},{"location":"guides/rate-limiting/#http-rate-limiting","title":"HTTP Rate Limiting","text":""},{"location":"guides/rate-limiting/#implementation","title":"Implementation","text":"<p>HTTP endpoints are protected by <code>RateLimitMiddleware</code>:</p> <p>Location: <code>app/middlewares/rate_limit.py</code></p> <p>Algorithm: Sliding window with Redis sorted sets</p> <p>Key: <code>user:{user_id}</code> or <code>ip:{ip_address}</code> for unauthenticated requests</p>"},{"location":"guides/rate-limiting/#response-headers","title":"Response Headers","text":"<p>All HTTP responses include rate limit information:</p> <pre><code>X-RateLimit-Limit: 60\nX-RateLimit-Remaining: 45\nX-RateLimit-Reset: 1705320000\n</code></pre>"},{"location":"guides/rate-limiting/#rate-limit-exceeded","title":"Rate Limit Exceeded","text":"<p>When limit is exceeded, returns <code>429 Too Many Requests</code>:</p> <pre><code>{\n  \"detail\": \"Rate limit exceeded. Try again in 30 seconds.\"\n}\n</code></pre>"},{"location":"guides/rate-limiting/#excluded-paths","title":"Excluded Paths","text":"<p>Some endpoints bypass rate limiting:</p> <ul> <li><code>/health</code> - Health checks</li> <li><code>/metrics</code> - Prometheus metrics</li> <li><code>/docs</code> - API documentation</li> <li><code>/redoc</code> - Alternative API docs</li> <li><code>/openapi.json</code> - OpenAPI schema</li> </ul>"},{"location":"guides/rate-limiting/#websocket-rate-limiting","title":"WebSocket Rate Limiting","text":""},{"location":"guides/rate-limiting/#connection-limiting","title":"Connection Limiting","text":"<p>Maximum Connections: 5 per user (configurable)</p> <p>Implementation: <code>ConnectionLimiter</code> in <code>app/utils/rate_limiter.py</code></p> <p>Enforcement: On connection in <code>PackageAuthWebSocketEndpoint.on_connect()</code></p> <p>Rejection Code: <code>1008</code> (Policy Violation)</p> <pre><code># Connection rejected\nws.close(1008, \"Maximum concurrent connections exceeded\")\n</code></pre>"},{"location":"guides/rate-limiting/#message-rate-limiting","title":"Message Rate Limiting","text":"<p>Limit: 100 messages per minute (configurable)</p> <p>Implementation: <code>RateLimiter</code> in <code>app/utils/rate_limiter.py</code></p> <p>Enforcement: In <code>Web.on_receive()</code> before message processing</p> <p>Error Response:</p> <pre><code>{\n  \"pkg_id\": 0,\n  \"req_id\": \"...\",\n  \"status_code\": 1,\n  \"data\": {\"msg\": \"Rate limit exceeded\"}\n}\n</code></pre>"},{"location":"guides/rate-limiting/#client-implementation","title":"Client Implementation","text":""},{"location":"guides/rate-limiting/#http-clients","title":"HTTP Clients","text":""},{"location":"guides/rate-limiting/#handle-rate-limits","title":"Handle Rate Limits","text":"<pre><code>import time\nimport requests\n\ndef api_call_with_retry(url, headers, max_retries=3):\n    \"\"\"Make API call with automatic retry on rate limit.\"\"\"\n    for attempt in range(max_retries):\n        response = requests.get(url, headers=headers)\n\n        if response.status_code == 429:\n            retry_after = int(response.headers.get('Retry-After', 60))\n            print(f\"Rate limited. Waiting {retry_after}s...\")\n            time.sleep(retry_after)\n            continue\n\n        return response\n\n    raise Exception(\"Max retries exceeded\")\n</code></pre>"},{"location":"guides/rate-limiting/#check-remaining-limit","title":"Check Remaining Limit","text":"<pre><code>response = requests.get(url, headers=headers)\n\nremaining = int(response.headers.get('X-RateLimit-Remaining', 0))\nif remaining &lt; 5:\n    print(f\"Warning: Only {remaining} requests remaining\")\n    time.sleep(1)  # Slow down\n</code></pre>"},{"location":"guides/rate-limiting/#websocket-clients","title":"WebSocket Clients","text":""},{"location":"guides/rate-limiting/#monitor-connection-count","title":"Monitor Connection Count","text":"<pre><code>let activeConnections = 0;\nconst MAX_CONNECTIONS = 5;\n\nfunction connect() {\n  if (activeConnections &gt;= MAX_CONNECTIONS) {\n    console.error('Max connections reached');\n    return;\n  }\n\n  const ws = new WebSocket(`ws://localhost:8000/web?token=${token}`);\n\n  ws.onopen = () =&gt; {\n    activeConnections++;\n  };\n\n  ws.onclose = (event) =&gt; {\n    activeConnections--;\n\n    if (event.code === 1008) {\n      console.error('Connection rejected: Rate limit exceeded');\n    }\n  };\n}\n</code></pre>"},{"location":"guides/rate-limiting/#throttle-messages","title":"Throttle Messages","text":"<pre><code>const messageQueue = [];\nconst MESSAGE_RATE = 100; // per minute\nconst MESSAGE_INTERVAL = 60000 / MESSAGE_RATE; // ms between messages\n\nsetInterval(() =&gt; {\n  if (messageQueue.length &gt; 0 &amp;&amp; ws.readyState === WebSocket.OPEN) {\n    const message = messageQueue.shift();\n    ws.send(JSON.stringify(message));\n  }\n}, MESSAGE_INTERVAL);\n\nfunction sendMessage(data) {\n  messageQueue.push(data);\n}\n</code></pre>"},{"location":"guides/rate-limiting/#rate-limiter-implementation","title":"Rate Limiter Implementation","text":""},{"location":"guides/rate-limiting/#sliding-window-algorithm","title":"Sliding Window Algorithm","text":"<pre><code>async def check_rate_limit(\n    self,\n    key: str,\n    limit: int,\n    window_seconds: int,\n    burst: int = 0\n) -&gt; tuple[bool, int]:\n    \"\"\"\n    Check if request is within rate limit.\n\n    Args:\n        key: Rate limit key (e.g., \"user:123\")\n        limit: Max requests in window\n        window_seconds: Time window in seconds\n        burst: Additional burst allowance\n\n    Returns:\n        (is_allowed, remaining_requests)\n    \"\"\"\n    now = time.time()\n    window_start = now - window_seconds\n\n    # Remove old entries\n    await redis.zremrangebyscore(key, '-inf', window_start)\n\n    # Count requests in current window\n    current_count = await redis.zcard(key)\n\n    max_allowed = limit + burst\n\n    if current_count &gt;= max_allowed:\n        return False, 0\n\n    # Add current request\n    await redis.zadd(key, {str(uuid.uuid4()): now})\n\n    # Set expiry\n    await redis.expire(key, window_seconds * 2)\n\n    remaining = max_allowed - current_count - 1\n    return True, remaining\n</code></pre>"},{"location":"guides/rate-limiting/#connection-limiter","title":"Connection Limiter","text":"<pre><code>async def add_connection(\n    self,\n    user_id: str,\n    connection_id: str\n) -&gt; bool:\n    \"\"\"\n    Add connection and check limit.\n\n    Args:\n        user_id: User identifier\n        connection_id: Unique connection identifier\n\n    Returns:\n        True if connection allowed, False if limit exceeded\n    \"\"\"\n    key = f\"ws:connections:{user_id}\"\n\n    # Add connection to set\n    await redis.sadd(key, connection_id)\n\n    # Count connections\n    count = await redis.scard(key)\n\n    if count &gt; self.max_connections:\n        # Remove and reject\n        await redis.srem(key, connection_id)\n        return False\n\n    return True\n</code></pre>"},{"location":"guides/rate-limiting/#monitoring","title":"Monitoring","text":""},{"location":"guides/rate-limiting/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Rate limit violations are tracked:</p> <pre><code># Rate limit hits\nrate_limit_hits_total{limit_type=\"http\"} 123\nrate_limit_hits_total{limit_type=\"ws_connection\"} 5\nrate_limit_hits_total{limit_type=\"ws_message\"} 45\n</code></pre>"},{"location":"guides/rate-limiting/#logs","title":"Logs","text":"<p>Rate limit events are logged:</p> <pre><code>logger.warning(\n    f\"Rate limit exceeded for user {user_id}\",\n    extra={\n        \"user_id\": user_id,\n        \"limit_type\": \"http\",\n        \"current_count\": current_count,\n        \"limit\": limit\n    }\n)\n</code></pre>"},{"location":"guides/rate-limiting/#tuning","title":"Tuning","text":""},{"location":"guides/rate-limiting/#adjusting-limits","title":"Adjusting Limits","text":"<p>Edit <code>app/settings.py</code> or set environment variables:</p> <pre><code># HTTP\nexport RATE_LIMIT_PER_MINUTE=120\nexport RATE_LIMIT_BURST=20\n\n# WebSocket\nexport WS_MAX_CONNECTIONS_PER_USER=10\nexport WS_MESSAGE_RATE_LIMIT=200\n</code></pre>"},{"location":"guides/rate-limiting/#per-endpoint-limits","title":"Per-Endpoint Limits","text":"<p>Currently not supported - all endpoints share same limit. To implement:</p> <ol> <li>Add endpoint-specific configuration</li> <li>Modify middleware to check endpoint</li> <li>Use different Redis keys per endpoint</li> </ol>"},{"location":"guides/rate-limiting/#testing","title":"Testing","text":""},{"location":"guides/rate-limiting/#test-rate-limiting","title":"Test Rate Limiting","text":"<pre><code>import pytest\n\n@pytest.mark.asyncio\nasync def test_rate_limit():\n    \"\"\"Test rate limiting blocks excess requests.\"\"\"\n    rate_limiter = RateLimiter(redis)\n\n    # Make requests up to limit\n    for i in range(60):\n        allowed, remaining = await rate_limiter.check_rate_limit(\n            key=\"test:user\",\n            limit=60,\n            window_seconds=60\n        )\n        assert allowed is True\n\n    # Next request should be blocked\n    allowed, remaining = await rate_limiter.check_rate_limit(\n        key=\"test:user\",\n        limit=60,\n        window_seconds=60\n    )\n    assert allowed is False\n    assert remaining == 0\n</code></pre>"},{"location":"guides/rate-limiting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/rate-limiting/#redis-connection-issues","title":"Redis Connection Issues","text":"<p>If rate limiting fails due to Redis errors: - HTTP middleware fails open (allows requests) - WebSocket connection limiter fails closed (denies connections)</p>"},{"location":"guides/rate-limiting/#high-false-positives","title":"High False Positives","text":"<p>If legitimate users hit limits: 1. Increase <code>RATE_LIMIT_PER_MINUTE</code> 2. Increase <code>RATE_LIMIT_BURST</code> for traffic spikes 3. Implement per-user or per-role limits</p>"},{"location":"guides/rate-limiting/#performance-issues","title":"Performance Issues","text":"<p>If Redis becomes bottleneck: 1. Use Redis cluster for horizontal scaling 2. Implement local caching with eventual consistency 3. Use approximate counting algorithms</p>"},{"location":"guides/rate-limiting/#related","title":"Related","text":"<ul> <li>HTTP API</li> <li>WebSocket API</li> <li>Monitoring Guide</li> </ul>"},{"location":"guides/websocket-handlers/","title":"Creating WebSocket Handlers","text":""},{"location":"guides/websocket-handlers/#overview","title":"Overview","text":"<p>This guide shows how to create new WebSocket handlers using the package-based routing system with proper authentication and authorization.</p>"},{"location":"guides/websocket-handlers/#quick-start","title":"Quick Start","text":""},{"location":"guides/websocket-handlers/#1-add-package-id","title":"1. Add Package ID","text":"<pre><code># app/api/ws/constants.py\nclass PkgID(IntEnum):\n    GET_AUTHORS = 1\n    GET_PAGINATED_AUTHORS = 2\n    CREATE_BOOK = 3  # Add new PkgID\n</code></pre>"},{"location":"guides/websocket-handlers/#2-create-handler","title":"2. Create Handler","text":"<pre><code># app/api/ws/handlers/book_handlers.py\nfrom app.api.ws.constants import PkgID, RSPCode\nfrom app.commands.book_commands import CreateBookCommand, CreateBookInput\nfrom app.repositories.book_repository import BookRepository\nfrom app.routing import pkg_router\nfrom app.schemas.request import RequestModel\nfrom app.schemas.response import ResponseModel\nfrom app.storage.db import async_session\n\n@pkg_router.register(\n    PkgID.CREATE_BOOK,\n    roles=[\"create-book\"]  # Required role\n)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Create a new book via WebSocket.\"\"\"\n    try:\n        async with async_session() as session:\n            async with session.begin():\n                repo = BookRepository(session)\n                command = CreateBookCommand(repo)\n                input_data = CreateBookInput(**request.data)\n                book = await command.execute(input_data)\n\n                return ResponseModel.success(\n                    pkg_id=request.pkg_id,\n                    req_id=request.req_id,\n                    data=book.model_dump()\n                )\n    except ValueError as e:\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=str(e),\n            status_code=RSPCode.INVALID_DATA\n        )\n    except Exception as e:\n        logger.error(f\"Handler error: {e}\", exc_info=True)\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=\"Internal error\",\n            status_code=RSPCode.ERROR\n        )\n</code></pre>"},{"location":"guides/websocket-handlers/#3-verify-registration","title":"3. Verify Registration","text":"<pre><code>make ws-handlers\n</code></pre>"},{"location":"guides/websocket-handlers/#handler-registration","title":"Handler Registration","text":""},{"location":"guides/websocket-handlers/#basic-handler","title":"Basic Handler","text":"<pre><code>@pkg_router.register(PkgID.GET_BOOKS)\nasync def get_books_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Public handler (no authentication required).\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        books = await repo.get_all()\n        return ResponseModel.success(\n            request.pkg_id,\n            request.req_id,\n            data=[b.model_dump() for b in books]\n        )\n</code></pre>"},{"location":"guides/websocket-handlers/#handler-with-rbac","title":"Handler with RBAC","text":"<pre><code>@pkg_router.register(\n    PkgID.DELETE_BOOK,\n    roles=[\"delete-book\", \"admin\"]  # Requires BOTH roles\n)\nasync def delete_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Protected handler - requires 'delete-book' AND 'admin' roles.\"\"\"\n    # Handler logic\n    pass\n</code></pre>"},{"location":"guides/websocket-handlers/#handler-with-json-schema-validation","title":"Handler with JSON Schema Validation","text":"<pre><code>from pydantic import BaseModel\n\nclass CreateBookSchema(BaseModel):\n    title: str\n    author_id: int\n\n@pkg_router.register(\n    PkgID.CREATE_BOOK,\n    json_schema=CreateBookSchema,\n    roles=[\"create-book\"]\n)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Handler with automatic schema validation.\"\"\"\n    # request.data is already validated against CreateBookSchema\n    pass\n</code></pre>"},{"location":"guides/websocket-handlers/#request-handling","title":"Request Handling","text":""},{"location":"guides/websocket-handlers/#accessing-request-data","title":"Accessing Request Data","text":"<pre><code>async def handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Access request data.\"\"\"\n    pkg_id = request.pkg_id  # Package ID\n    req_id = request.req_id  # Request UUID\n    data = request.data     # Request payload (dict)\n\n    # Extract specific fields\n    book_id = data.get(\"id\")\n    filters = data.get(\"filters\", {})\n</code></pre>"},{"location":"guides/websocket-handlers/#using-commands","title":"Using Commands","text":"<p>Reuse business logic from HTTP endpoints:</p> <pre><code>@pkg_router.register(PkgID.CREATE_BOOK)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Handler using command pattern.\"\"\"\n    async with async_session() as session:\n        async with session.begin():\n            repo = BookRepository(session)\n            command = CreateBookCommand(repo)  # Same command as HTTP!\n            input_data = CreateBookInput(**request.data)\n            book = await command.execute(input_data)\n\n            return ResponseModel.success(\n                request.pkg_id,\n                request.req_id,\n                data=book.model_dump()\n            )\n</code></pre>"},{"location":"guides/websocket-handlers/#response-handling","title":"Response Handling","text":""},{"location":"guides/websocket-handlers/#success-response","title":"Success Response","text":"<pre><code>return ResponseModel.success(\n    pkg_id=request.pkg_id,\n    req_id=request.req_id,\n    data=[{\"id\": 1, \"title\": \"Book\"}]\n)\n</code></pre>"},{"location":"guides/websocket-handlers/#error-response","title":"Error Response","text":"<pre><code>return ResponseModel.err_msg(\n    pkg_id=request.pkg_id,\n    req_id=request.req_id,\n    msg=\"Book not found\",\n    status_code=RSPCode.ERROR\n)\n</code></pre>"},{"location":"guides/websocket-handlers/#paginated-response","title":"Paginated Response","text":"<pre><code>from app.storage.db import get_paginated_results\n\nresults, meta = await get_paginated_results(\n    Book,\n    page=request.data.get(\"page\", 1),\n    per_page=request.data.get(\"per_page\", 20)\n)\n\nreturn ResponseModel.success(\n    request.pkg_id,\n    request.req_id,\n    data=[r.model_dump() for r in results],\n    meta=meta\n)\n</code></pre>"},{"location":"guides/websocket-handlers/#error-handling","title":"Error Handling","text":""},{"location":"guides/websocket-handlers/#database-errors","title":"Database Errors","text":"<pre><code>from sqlalchemy.exc import IntegrityError\n\ntry:\n    book = await repo.create(book)\nexcept IntegrityError:\n    return ResponseModel.err_msg(\n        request.pkg_id,\n        request.req_id,\n        msg=\"Book already exists\",\n        status_code=RSPCode.INVALID_DATA\n    )\n</code></pre>"},{"location":"guides/websocket-handlers/#validation-errors","title":"Validation Errors","text":"<pre><code>from pydantic import ValidationError\n\ntry:\n    input_data = CreateBookInput(**request.data)\nexcept ValidationError as e:\n    return ResponseModel.err_msg(\n        request.pkg_id,\n        request.req_id,\n        msg=str(e),\n        status_code=RSPCode.INVALID_DATA\n    )\n</code></pre>"},{"location":"guides/websocket-handlers/#testing","title":"Testing","text":"<pre><code>import pytest\nfrom unittest.mock import AsyncMock\n\n@pytest.mark.asyncio\nasync def test_create_book_handler():\n    \"\"\"Test WebSocket handler.\"\"\"\n    # Mock repository\n    mock_repo = AsyncMock()\n    mock_repo.create.return_value = Book(id=1, title=\"Test\")\n\n    # Create request\n    request = RequestModel(\n        pkg_id=PkgID.CREATE_BOOK,\n        req_id=\"test-uuid\",\n        data={\"title\": \"Test\", \"author_id\": 1}\n    )\n\n    # Call handler\n    response = await create_book_handler(request)\n\n    # Verify response\n    assert response.status_code == RSPCode.OK\n    assert response.data[\"title\"] == \"Test\"\n</code></pre>"},{"location":"guides/websocket-handlers/#broadcasting","title":"Broadcasting","text":"<p>Send messages to all connected clients:</p> <pre><code>from app.managers.websocket_connection_manager import connection_manager\n\n# In handler\nawait connection_manager.broadcast({\n    \"pkg_id\": PkgID.BOOK_CREATED,\n    \"req_id\": \"00000000-0000-0000-0000-000000000000\",\n    \"data\": book.model_dump()\n})\n</code></pre>"},{"location":"guides/websocket-handlers/#generator-script","title":"Generator Script","text":"<p>Generate new handler from template:</p> <pre><code>make new-ws-handlers\n</code></pre> <p>Follow the prompts to create a new handler file.</p>"},{"location":"guides/websocket-handlers/#related","title":"Related","text":"<ul> <li>WebSocket API</li> <li>Design Patterns Guide</li> <li>HTTP Endpoints</li> <li>Testing Guide</li> </ul>"}]}