{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"FastAPI HTTP/WebSocket Template","text":"<p>A production-ready FastAPI template with comprehensive HTTP and WebSocket support, including authentication, RBAC, rate limiting, audit logging, and monitoring.</p> <ul> <li> <p> Quick Start</p> <p>Get up and running in 5 minutes</p> <p> Getting Started</p> </li> <li> <p> Production Ready</p> <p>Deploy to production with confidence</p> <p> Deployment Guide</p> </li> <li> <p> Secure by Default</p> <p>Built-in authentication, RBAC, and rate limiting</p> <p> Security Guide</p> </li> <li> <p> Observable</p> <p>Prometheus metrics, Grafana dashboards, and structured logging</p> <p> Monitoring Guide</p> </li> </ul>"},{"location":"#features","title":"Features","text":""},{"location":"#dual-protocol-support","title":"Dual Protocol Support","text":"<ul> <li>\u2705 HTTP REST API - FastAPI-powered REST endpoints with OpenAPI documentation</li> <li>\u2705 WebSocket Handlers - Package-based WebSocket routing with JSON message format</li> <li>\u2705 Unified Business Logic - Share code between protocols using Repository + Command pattern</li> </ul>"},{"location":"#authentication-authorization","title":"Authentication &amp; Authorization","text":"<ul> <li>\u2705 Keycloak Integration - Enterprise-grade authentication with JWT tokens</li> <li>\u2705 RBAC System - Decorator-based role access control co-located with handlers</li> <li>\u2705 Token Validation - Automatic token verification and user extraction</li> <li>\u2705 Session Management - Redis-backed session tracking</li> </ul>"},{"location":"#rate-limiting-security","title":"Rate Limiting &amp; Security","text":"<ul> <li>\u2705 HTTP Rate Limiting - Sliding window algorithm per user/IP</li> <li>\u2705 WebSocket Rate Limiting - Connection and message rate limits</li> <li>\u2705 Redis-Backed - Distributed rate limiting across instances</li> <li>\u2705 Configurable Limits - Per-endpoint and per-user limits</li> </ul>"},{"location":"#database-persistence","title":"Database &amp; Persistence","text":"<ul> <li>\u2705 PostgreSQL - Async SQLModel/SQLAlchemy integration</li> <li>\u2705 Database Migrations - Alembic for schema versioning</li> <li>\u2705 Connection Pooling - Optimized connection management</li> <li>\u2705 Repository Pattern - Testable data access layer</li> </ul>"},{"location":"#monitoring-observability","title":"Monitoring &amp; Observability","text":"<ul> <li>\u2705 Prometheus Metrics - HTTP/WebSocket request metrics, database queries, rate limits</li> <li>\u2705 Grafana Dashboards - Pre-built dashboards for FastAPI, Keycloak, and logs</li> <li>\u2705 Structured Logging - JSON logs with correlation IDs</li> <li>\u2705 Loki Integration - Centralized log aggregation</li> </ul>"},{"location":"#audit-compliance","title":"Audit &amp; Compliance","text":"<ul> <li>\u2705 User Action Logging - Track all user actions with context</li> <li>\u2705 Async Queue Processing - Non-blocking audit log writes</li> <li>\u2705 Searchable Logs - Query audit trail with filters</li> <li>\u2705 Retention Policies - Configurable log retention</li> </ul>"},{"location":"#developer-experience","title":"Developer Experience","text":"<ul> <li>\u2705 Type Safety - Full mypy --strict compliance</li> <li>\u2705 Code Quality - Pre-commit hooks with ruff, mypy, interrogate</li> <li>\u2705 Testing - Pytest with async support, 66% coverage</li> <li>\u2705 Docker Support - Full development environment via docker-compose</li> <li>\u2705 Hot Reload - Uvicorn auto-reload during development</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>graph TB\n    Client[Client] --&gt;|HTTP/WS| Traefik[Traefik Reverse Proxy]\n    Traefik --&gt;|:8000| App[FastAPI Application]\n\n    App --&gt;|Auth| KC[Keycloak]\n    App --&gt;|Data| PG[(PostgreSQL)]\n    App --&gt;|Cache/Rate Limit| Redis[(Redis)]\n\n    App --&gt;|Metrics| Prom[Prometheus]\n    Prom --&gt;|Dashboard| Grafana[Grafana]\n    App --&gt;|Logs| Loki[Loki]\n    Loki --&gt;|Query| Grafana\n\n    style App fill:#4051b5,stroke:#333,stroke-width:2px,color:#fff\n    style Traefik fill:#37abc8,stroke:#333,stroke-width:2px,color:#fff</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":""},{"location":"#http-endpoint","title":"HTTP Endpoint","text":"<pre><code>from fastapi import APIRouter, Depends\nfrom app.dependencies import AuthorRepoDep\nfrom app.commands.author_commands import CreateAuthorCommand\nfrom app.schemas.author import CreateAuthorInput\n\nrouter = APIRouter()\n\n@router.post(\"/authors\")\nasync def create_author(\n    data: CreateAuthorInput,\n    repo: AuthorRepoDep\n) -&gt; Author:\n    \"\"\"Create a new author.\"\"\"\n    command = CreateAuthorCommand(repo)\n    return await command.execute(data)\n</code></pre>"},{"location":"#websocket-handler","title":"WebSocket Handler","text":"<pre><code>from app.routing import pkg_router\nfrom app.api.ws.constants import PkgID\nfrom app.schemas.models import RequestModel, ResponseModel\n\n@pkg_router.register(PkgID.GET_AUTHORS)\nasync def get_authors(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Get list of authors via WebSocket.\"\"\"\n    async with async_session() as session:\n        repo = AuthorRepository(session)\n        authors = await repo.get_all()\n\n        return ResponseModel.success(\n            request.pkg_id,\n            request.req_id,\n            data=[a.model_dump() for a in authors]\n        )\n</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":"<p>This template is ideal for applications requiring:</p> <ul> <li>Real-time Communication - Chat apps, live dashboards, collaborative tools</li> <li>IoT/Device Management - Device telemetry, command &amp; control</li> <li>Trading/Financial - Order management, market data streaming</li> <li>Gaming - Multiplayer game servers, lobby systems</li> <li>Monitoring - Real-time alerts, log streaming</li> </ul>"},{"location":"#technology-stack","title":"Technology Stack","text":"Component Technology Purpose Web Framework FastAPI 0.121+ High-performance async API framework ASGI Server Uvicorn Production ASGI server Database PostgreSQL 13+ Primary data store ORM SQLModel Type-safe database models Cache/Queue Redis 7+ Rate limiting, sessions, caching Authentication Keycloak Enterprise SSO and identity management Reverse Proxy Traefik v3 Load balancing, SSL termination Metrics Prometheus Time-series metrics collection Dashboards Grafana Visualization and alerting Logging Loki + Grafana Alloy Log aggregation and querying Container Docker + Compose Development and deployment"},{"location":"#project-status","title":"Project Status","text":"<ul> <li>\u2705 Production Ready - Battle-tested patterns and best practices</li> <li>\u2705 Type Safe - Full mypy compliance with strict mode</li> <li>\u2705 Well Tested - 66% coverage (target: 80%+)</li> <li>\u2705 Documented - Comprehensive guides and API reference</li> <li>\u2705 Observable - Full monitoring and logging stack</li> <li>\u2705 Secure - Authentication, RBAC, rate limiting, audit logs</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li> <p>New to the project?</p> <p>Start with the Installation Guide to set up your development environment.</p> </li> <li> <p>Ready to build?</p> <p>Follow the Quick Start to create your first endpoints.</p> </li> <li> <p>Deploying to production?</p> <p>Check out the Production Deployment Guide.</p> </li> <li> <p>Want to contribute?</p> <p>Read the Contributing Guide to get started.</p> </li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#support","title":"Support","text":"<ul> <li>\ud83d\udcd6 Documentation</li> <li>\ud83d\udc1b Issue Tracker</li> <li>\ud83d\udcac Discussions</li> </ul>"},{"location":"DOCUMENTATION_AUDIT_REPORT/","title":"Documentation Audit Report","text":"<p>Generated: 2026-01-12 Status: Comprehensive codebase vs documentation comparison</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#executive-summary","title":"Executive Summary","text":"<p>After a thorough comparison of the codebase against all documentation, I've identified 27 significant documentation gaps across middleware, utilities, API endpoints, and configuration settings. This report prioritizes these gaps and provides actionable recommendations.</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#critical-findings","title":"Critical Findings","text":""},{"location":"DOCUMENTATION_AUDIT_REPORT/#high-priority-user-facing-production-impact","title":"\ud83d\udd34 High Priority (User-Facing, Production Impact)","text":"<ol> <li>Missing Middleware Documentation (3 components)</li> <li><code>audit_middleware.py</code> - Critical for compliance and audit tracking</li> <li><code>correlation_id.py</code> - Essential for request tracing across services</li> <li> <p><code>logging_context.py</code> - Key for structured logging context</p> </li> <li> <p>Undocumented Configuration Settings (14 settings)</p> </li> <li>Circuit breaker settings (already have guide, need config doc integration)</li> <li>Profiling settings (<code>PROFILING_*</code>)</li> <li>Audit logging settings (<code>AUDIT_*</code>)</li> <li>Security settings (<code>TRUSTED_PROXIES</code>, <code>ALLOWED_HOSTS</code>, <code>MAX_REQUEST_BODY_SIZE</code>)</li> <li> <p>Database pool settings (<code>DB_POOL_*</code>)</p> </li> <li> <p>Missing API Reference Documentation</p> </li> <li>No docs_site/api-reference/ documentation for ANY HTTP endpoints</li> <li>5 HTTP endpoint modules undocumented:<ul> <li><code>/api/audit-logs</code> - audit_logs.py</li> <li><code>/api/authors</code> - author.py</li> <li><code>/health</code> - health.py</li> <li><code>/metrics</code> - metrics.py</li> <li><code>/api/profiling</code> - profiling.py</li> </ul> </li> </ol>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#medium-priority-developer-experience","title":"\ud83d\udfe1 Medium Priority (Developer Experience)","text":"<ol> <li>Undocumented Utilities (3 modules)</li> <li><code>audit_logger.py</code> - Queue-based audit logging implementation</li> <li><code>error_handler.py</code> - Error handling utilities</li> <li> <p><code>file_io.py</code> - JSON schema loading utilities</p> </li> <li> <p>Incomplete Monitoring Documentation</p> </li> <li>Circuit breaker metrics need integration into monitoring guide</li> <li>Missing Grafana panel descriptions for some metrics</li> <li> <p>Prometheus alert documentation incomplete</p> </li> <li> <p>Architecture Documentation Gaps</p> </li> <li>Circuit breaker not mentioned in architecture overview</li> <li>Request flow doesn't show middleware stack clearly</li> <li>No resilience patterns documentation</li> </ol>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#low-priority-nice-to-have","title":"\ud83d\udfe2 Low Priority (Nice to Have)","text":"<ol> <li>Missing Examples</li> <li>No example client code for HTTP endpoints</li> <li>Limited WebSocket client examples</li> <li> <p>No end-to-end integration examples</p> </li> <li> <p>Incomplete Troubleshooting</p> </li> <li>Circuit breaker troubleshooting done, but general troubleshooting incomplete</li> <li>No runbooks for common issues</li> <li>Missing debugging guides</li> </ol>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#detailed-gap-analysis","title":"Detailed Gap Analysis","text":""},{"location":"DOCUMENTATION_AUDIT_REPORT/#1-middleware-documentation-gaps","title":"1. Middleware Documentation Gaps","text":"<p>Missing from CLAUDE.md:</p> Middleware Purpose Priority Impact <code>audit_middleware.py</code> Intercepts requests/responses for audit logging High Compliance features undocumented <code>correlation_id.py</code> Adds X-Correlation-ID header for request tracing High Distributed tracing not documented <code>logging_context.py</code> Sets logging context from request data High Structured logging incomplete <p>Recommendation: Add dedicated section in CLAUDE.md under \"Core Components\" \u2192 \"Middleware Stack\"</p> <p>Documented Middleware (\u2705 Complete): - <code>prometheus.py</code> - Metrics collection - <code>rate_limit.py</code> - Rate limiting - <code>request_size_limit.py</code> - Request size validation - <code>security_headers.py</code> - Security headers</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#2-utilities-documentation-gaps","title":"2. Utilities Documentation Gaps","text":"<p>Missing from CLAUDE.md:</p> Utility Purpose Priority Impact <code>audit_logger.py</code> Async queue-based audit log writer High Core audit feature undocumented <code>error_handler.py</code> Error handling utilities and formatters Medium Error handling patterns unclear <code>file_io.py</code> JSON schema loading from files Low Internal utility, low user impact <p>Documented Utilities (\u2705 Complete): - <code>error_formatter.py</code> - Error response formatting - <code>ip_utils.py</code> - IP address extraction and validation - <code>pagination_cache.py</code> - Pagination count caching - <code>profiling.py</code> - Scalene profiling integration - <code>protobuf_converter.py</code> - Protobuf \u2194 Pydantic conversion - <code>query_monitor.py</code> - Slow query detection - <code>rate_limiter.py</code> - Rate limiting logic - <code>token_cache.py</code> - JWT token claim caching</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#3-configuration-documentation-gaps","title":"3. Configuration Documentation Gaps","text":"<p>Settings in Code but NOT in docs_site/getting-started/configuration.md:</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#environment-security-5-settings","title":"Environment &amp; Security (5 settings)","text":"<ul> <li><code>ENV</code> - Environment type (dev/staging/production) - CRITICAL</li> <li><code>ALLOWED_HOSTS</code> - Host header validation</li> <li><code>TRUSTED_PROXIES</code> - X-Forwarded-For validation</li> <li><code>MAX_REQUEST_BODY_SIZE</code> - Request size limit</li> <li><code>EXCLUDED_PATHS</code> - Paths excluded from auth</li> </ul>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#audit-logging-5-settings","title":"Audit Logging (5 settings)","text":"<ul> <li><code>AUDIT_LOG_ENABLED</code> - Enable/disable audit logging</li> <li><code>AUDIT_LOG_RETENTION_DAYS</code> - Retention policy</li> <li><code>AUDIT_QUEUE_MAX_SIZE</code> - Queue size limit</li> <li><code>AUDIT_BATCH_SIZE</code> - Batch write size</li> <li><code>AUDIT_BATCH_TIMEOUT</code> - Batch timeout</li> </ul>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#profiling-3-settings","title":"Profiling (3 settings)","text":"<ul> <li><code>PROFILING_ENABLED</code> - Enable Scalene profiling</li> <li><code>PROFILING_OUTPUT_DIR</code> - Output directory</li> <li><code>PROFILING_INTERVAL_SECONDS</code> - Profiling interval</li> </ul>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#database-pool-4-settings","title":"Database Pool (4 settings)","text":"<ul> <li><code>DB_POOL_SIZE</code> - Connection pool size</li> <li><code>DB_MAX_OVERFLOW</code> - Max overflow connections</li> <li><code>DB_POOL_RECYCLE</code> - Connection recycle time</li> <li><code>DB_POOL_PRE_PING</code> - Enable connection health checks</li> </ul>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#logging-4-settings","title":"Logging (4 settings)","text":"<ul> <li><code>LOG_LEVEL</code> - Logging level</li> <li><code>LOG_FILE_PATH</code> - Error log file path</li> <li><code>LOG_CONSOLE_FORMAT</code> - Console format (json/human)</li> <li><code>LOG_EXCLUDED_PATHS</code> - Paths excluded from access logs</li> </ul>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#circuit-breaker-4-settings-has-guide-needs-config-doc","title":"Circuit Breaker (4 settings) - HAS GUIDE, NEEDS CONFIG DOC","text":"<ul> <li><code>CIRCUIT_BREAKER_ENABLED</code></li> <li><code>KEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX</code></li> <li><code>KEYCLOAK_CIRCUIT_BREAKER_TIMEOUT</code></li> <li><code>REDIS_CIRCUIT_BREAKER_FAIL_MAX</code></li> <li><code>REDIS_CIRCUIT_BREAKER_TIMEOUT</code></li> </ul> <p>Total: ~30 settings with NO configuration documentation</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#4-api-reference-documentation-gaps","title":"4. API Reference Documentation Gaps","text":"<p>CRITICAL: No <code>docs_site/api-reference/http-api.md</code> file exists!</p> <p>Undocumented HTTP Endpoints:</p> Endpoint Module Methods Purpose <code>/api/audit-logs</code> audit_logs.py GET Query audit logs <code>/api/authors</code> author.py GET, POST, PUT, DELETE Author CRUD operations <code>/health</code> health.py GET Health check endpoint <code>/metrics</code> metrics.py GET Prometheus metrics <code>/api/profiling/*</code> profiling.py GET, DELETE Profiling management <p>Undocumented WebSocket Handlers: - <code>author_handlers.py</code> - Author operations via WebSocket - Package router mechanism not fully documented</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#5-monitoring-observability-gaps","title":"5. Monitoring &amp; Observability Gaps","text":""},{"location":"DOCUMENTATION_AUDIT_REPORT/#metrics-documentation-status","title":"Metrics Documentation Status","text":"<p>Fully Documented: - HTTP metrics (http.py) - \u2705 In CLAUDE.md - WebSocket metrics (websocket.py) - \u2705 In CLAUDE.md - Database metrics (database.py) - \u2705 In CLAUDE.md - Redis metrics (redis.py) - \u2705 In CLAUDE.md - Auth metrics (auth.py) - \u2705 In CLAUDE.md - Audit metrics (audit.py) - \u2705 In CLAUDE.md - Circuit breaker metrics (circuit_breaker.py) - \u2705 Has dedicated guide</p> <p>Needs Integration: - Circuit breaker metrics need to be added to <code>docs_site/guides/monitoring.md</code> - Grafana panels 28-30 need descriptions in monitoring guide - Prometheus alerts need documentation in monitoring guide</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Existing Dashboards: 1. <code>fastapi-metrics.json</code> - Main application dashboard (30 panels) 2. <code>keycloak-metrics.json</code> - Keycloak monitoring (9 panels) 3. <code>audit-logs</code> - Audit log database queries (5 panels)</p> <p>Missing Dashboard Documentation: - Panel-by-panel descriptions in monitoring guide - Dashboard navigation guide - Query examples for custom panels</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#prometheus-alerts","title":"Prometheus Alerts","text":"<p>Alert Groups: - application_alerts (4 alerts) - \u2705 Documented - database_alerts (2 alerts) - \u26a0\ufe0f Partially documented - redis_alerts (1 alert) - \u26a0\ufe0f Partially documented - websocket_alerts (2 alerts) - \u26a0\ufe0f Partially documented - audit_alerts (2 alerts) - \u26a0\ufe0f Partially documented - rate_limit_alerts (1 alert) - \u26a0\ufe0f Partially documented - authentication_alerts (8 alerts) - \u26a0\ufe0f Partially documented - keycloak_alerts (2 alerts) - \u26a0\ufe0f Partially documented - circuit_breaker_alerts (3 alerts) - \u2705 Fully documented in guide</p> <p>Gap: Alert documentation exists in prometheus/alerts.yml but not in user-facing docs</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#6-architecture-documentation-gaps","title":"6. Architecture Documentation Gaps","text":"<p>docs_site/architecture/overview.md needs: - Middleware stack diagram and description - Circuit breaker in resilience section - Request flow with middleware - Error handling architecture - Audit logging architecture</p> <p>CLAUDE.md architecture section needs: - Correlation ID tracking - Logging context propagation - Audit middleware flow</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#7-troubleshooting-gaps","title":"7. Troubleshooting Gaps","text":"<p>docs_site/deployment/troubleshooting.md needs: - Circuit breaker troubleshooting (link to guide) - Audit log queue overflow - Redis connection issues - Keycloak authentication failures - Database connection pool exhaustion - Profiling issues</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#recommendations-by-priority","title":"Recommendations by Priority","text":""},{"location":"DOCUMENTATION_AUDIT_REPORT/#immediate-actions-next-1-2-days","title":"Immediate Actions (Next 1-2 Days)","text":"<ol> <li> <p>Create API Reference Documentation <pre><code>File: docs_site/api-reference/http-api.md\nContent:\n- Document all 5 HTTP endpoint modules\n- Include request/response examples\n- Document error responses\n- Add authentication requirements\n</code></pre></p> </li> <li> <p>Update Configuration Documentation <pre><code>File: docs_site/getting-started/configuration.md\nContent:\n- Add all 30+ missing settings\n- Group by category (Security, Audit, Profiling, etc.)\n- Provide default values\n- Add tuning guidelines\n- Link to feature-specific guides (circuit breaker, etc.)\n</code></pre></p> </li> <li> <p>Document Missing Middleware <pre><code>File: CLAUDE.md\nSection: Core Components \u2192 Middleware\nContent:\n- audit_middleware.py - How audit logging intercepts requests\n- correlation_id.py - Request tracing with X-Correlation-ID\n- logging_context.py - Structured logging context setup\n</code></pre></p> </li> </ol>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#short-term-actions-next-week","title":"Short-Term Actions (Next Week)","text":"<ol> <li> <p>Update Monitoring Guide <pre><code>File: docs_site/guides/monitoring.md\nContent:\n- Add circuit breaker metrics section\n- Document all Grafana panels (30 in fastapi-metrics)\n- Add Prometheus alert reference\n- Link to circuit breaker guide\n</code></pre></p> </li> <li> <p>Update Architecture Documentation <pre><code>File: docs_site/architecture/overview.md\nContent:\n- Add middleware stack section\n- Add circuit breaker to resilience\n- Update request flow diagrams\n</code></pre></p> </li> <li> <p>Document Missing Utilities <pre><code>File: CLAUDE.md\nContent:\n- audit_logger.py - Async audit log queue\n- error_handler.py - Error handling patterns\n</code></pre></p> </li> </ol>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#medium-term-actions-next-2-weeks","title":"Medium-Term Actions (Next 2 Weeks)","text":"<ol> <li> <p>Enhance Troubleshooting Guide <pre><code>File: docs_site/deployment/troubleshooting.md\nContent:\n- Common issues and solutions\n- Runbooks for critical alerts\n- Debug procedures\n</code></pre></p> </li> <li> <p>Add Code Examples <pre><code>Files: docs_site/examples/\nContent:\n- HTTP client examples\n- WebSocket client examples\n- Integration test examples\n</code></pre></p> </li> </ol>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#documentation-coverage-metrics","title":"Documentation Coverage Metrics","text":"Category Total Documented Coverage Gap Middlewares 7 4 57% 3 missing Utilities 11 8 73% 3 missing Managers 3 3 100% \u2705 Complete Metrics Modules 7 7 100% \u2705 Complete Configuration Settings ~55 ~25 45% ~30 missing HTTP Endpoints 5 0 0% 5 missing WebSocket Handlers 1 0 0% 1 missing Overall Estimate ~90 ~47 52% ~43 gaps"},{"location":"DOCUMENTATION_AUDIT_REPORT/#priority-matrix","title":"Priority Matrix","text":"<pre><code>High Impact, High Urgency:\n\u251c\u2500\u2500 API Reference Documentation (5 endpoints)\n\u251c\u2500\u2500 Configuration Documentation (30+ settings)\n\u2514\u2500\u2500 Missing Middleware Docs (3 components)\n\nHigh Impact, Medium Urgency:\n\u251c\u2500\u2500 Monitoring Guide Updates (circuit breaker integration)\n\u251c\u2500\u2500 Architecture Documentation (middleware stack, resilience)\n\u2514\u2500\u2500 Troubleshooting Guide Enhancement\n\nMedium Impact, Medium Urgency:\n\u251c\u2500\u2500 Utility Documentation (3 utilities)\n\u2514\u2500\u2500 Examples and Quickstarts\n\nLow Impact, Low Urgency:\n\u251c\u2500\u2500 Advanced Topics\n\u2514\u2500\u2500 Video Tutorials\n</code></pre>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#success-metrics","title":"Success Metrics","text":"<p>Target State (4 weeks): - Configuration documentation: 45% \u2192 95% - API reference: 0% \u2192 100% - Middleware documentation: 57% \u2192 100% - Overall documentation coverage: 52% \u2192 85%</p>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#next-steps","title":"Next Steps","text":"<ol> <li>\u2705 Circuit breaker documentation - COMPLETED</li> <li>\ud83d\udd04 API reference documentation - IN PROGRESS (create file)</li> <li>\ud83d\udd04 Configuration documentation - IN PROGRESS (add missing settings)</li> <li>\u23f3 Middleware documentation - PENDING</li> <li>\u23f3 Monitoring guide updates - PENDING</li> <li>\u23f3 Architecture updates - PENDING</li> </ol>"},{"location":"DOCUMENTATION_AUDIT_REPORT/#appendix-tools-for-continuous-documentation","title":"Appendix: Tools for Continuous Documentation","text":"<p>Suggested Scripts: <pre><code># Check for undocumented Python modules\nfind app/ -name \"*.py\" -type f | while read f; do\n  grep -q \"$(basename $f)\" CLAUDE.md docs_site/ -r || echo \"Undocumented: $f\"\ndone\n\n# Check for undocumented settings\ngrep \"^    [A-Z_]*:\" app/settings.py | while read setting; do\n  grep -q \"$(echo $setting | cut -d: -f1)\" docs_site/getting-started/configuration.md || echo \"Undocumented setting: $setting\"\ndone\n\n# Check for undocumented metrics\nfind app/utils/metrics/ -name \"*.py\" | while read f; do\n  grep -q \"$(basename $f)\" docs_site/guides/monitoring.md || echo \"Undocumented metrics: $f\"\ndone\n</code></pre></p> <p>Report Status: Complete Action Required: Review and prioritize recommendations Estimated Effort: 2-4 weeks for full documentation coverage</p>"},{"location":"circuit-breaker-implementation-summary/","title":"Circuit Breaker Documentation Update Summary","text":""},{"location":"circuit-breaker-implementation-summary/#overview","title":"Overview","text":"<p>This document summarizes the comprehensive documentation updates made for the circuit breaker pattern implementation in the FastAPI HTTP &amp; WebSocket application.</p>"},{"location":"circuit-breaker-implementation-summary/#completed-work","title":"Completed Work","text":""},{"location":"circuit-breaker-implementation-summary/#1-dedicated-circuit-breaker-guide-created","title":"1. \u2705 Dedicated Circuit Breaker Guide Created","text":"<p>File: <code>docs_site/guides/circuit-breaker.md</code></p> <p>Content: - Complete overview of circuit breaker pattern with state diagram - Detailed explanation of all three states (CLOSED, OPEN, HALF-OPEN) - Protected services documentation (Keycloak and Redis) - Configuration guidelines with tuning recommendations - Prometheus metrics documentation with example queries - Grafana dashboard panel descriptions - Alert descriptions and thresholds - Error handling examples for HTTP and WebSocket - Client-side handling examples (JavaScript) - Comprehensive troubleshooting section - Best practices and production checklist - Links to additional resources</p> <p>Impact: Users now have a complete guide to understand, configure, monitor, and troubleshoot circuit breakers.</p>"},{"location":"circuit-breaker-implementation-summary/#2-grafana-dashboard-panels-added","title":"2. \u2705 Grafana Dashboard Panels Added","text":"<p>File: <code>docker/grafana/provisioning/dashboards/fastapi-metrics.json</code></p> <p>Panels Added: - Panel 28 - Circuit Breaker State (Timeseries)   - Shows real-time circuit breaker state for Keycloak and Redis   - Color-coded: Green (CLOSED), Red (OPEN), Yellow (HALF-OPEN)   - Step-after line interpolation for clear state transitions</p> <ul> <li>Panel 29 - Circuit Breaker Failure Rate (Timeseries)</li> <li>Tracks failure rates per service</li> <li>Displays mean, max, and sum statistics</li> <li> <p>Helps identify when services are experiencing issues</p> </li> <li> <p>Panel 30 - Circuit Breaker State Changes (Timeseries, Bar chart)</p> </li> <li>Shows state transition counts over 5-minute windows</li> <li>Identifies flapping (service instability)</li> <li>Threshold indicators: Green (&lt; 5), Yellow (5-10), Red (&gt; 10)</li> </ul> <p>Impact: Circuit breaker health is now fully visualizable in Grafana.</p>"},{"location":"circuit-breaker-implementation-summary/#3-prometheus-alerts-added","title":"3. \u2705 Prometheus Alerts Added","text":"<p>File: <code>docker/prometheus/alerts.yml</code></p> <p>Alerts Added: - CircuitBreakerOpen (Critical)   - Triggers when circuit breaker stays open &gt; 2 minutes   - Indicates prolonged service unavailability   - Severity: Critical</p> <ul> <li>CircuitBreakerFlapping (Warning)</li> <li>Triggers when &gt; 10 state changes in 5 minutes</li> <li>Indicates unstable service or misconfigured circuit breaker</li> <li> <p>Severity: Warning</p> </li> <li> <p>HighCircuitBreakerFailureRate (Warning)</p> </li> <li>Triggers when failure rate &gt; 5/minute for 3 minutes</li> <li>Indicates service degradation</li> <li>Severity: Warning</li> </ul> <p>Impact: Operations teams will be proactively notified of circuit breaker issues.</p>"},{"location":"circuit-breaker-implementation-summary/#4-readmemd-updated","title":"4. \u2705 README.md Updated","text":"<p>File: <code>README.md</code></p> <p>Changes: - Added \"Resilience: Circuit breaker pattern for Keycloak and Redis with fail-fast protection\" to Production Features - Updated monitoring description to include Circuit Breakers - Updated alerting description to mention circuit breaker alerts</p> <p>Impact: Project overview now highlights resilience features.</p>"},{"location":"circuit-breaker-implementation-summary/#5-guides-index-updated","title":"5. \u2705 Guides Index Updated","text":"<p>File: <code>docs_site/guides/index.md</code></p> <p>Changes: - Added link to Circuit Breaker guide in the guides list</p> <p>Impact: Circuit breaker guide is discoverable from the guides index.</p>"},{"location":"circuit-breaker-implementation-summary/#remaining-work","title":"Remaining Work","text":""},{"location":"circuit-breaker-implementation-summary/#6-configuration-documentation","title":"6. \u23f3 Configuration Documentation","text":"<p>File: <code>docs_site/getting-started/configuration.md</code></p> <p>Needed: - Add circuit breaker configuration section with all environment variables - Document <code>CIRCUIT_BREAKER_ENABLED</code>, <code>*_FAIL_MAX</code>, <code>*_TIMEOUT</code> settings - Provide tuning guidance for different environments (dev, staging, production) - Link to the comprehensive circuit breaker guide</p> <p>Priority: High - Users need to know how to configure circuit breakers</p>"},{"location":"circuit-breaker-implementation-summary/#7-architecture-overview","title":"7. \u23f3 Architecture Overview","text":"<p>File: <code>docs_site/architecture/overview.md</code></p> <p>Needed: - Mention circuit breaker in resilience/reliability section - Add to request flow documentation - Explain how circuit breaker protects external service calls - Link to detailed circuit breaker guide</p> <p>Priority: Medium - Architecture docs should be comprehensive</p>"},{"location":"circuit-breaker-implementation-summary/#8-monitoring-guide","title":"8. \u23f3 Monitoring Guide","text":"<p>File: <code>docs_site/guides/monitoring.md</code></p> <p>Needed: - Add circuit breaker metrics to list of available metrics - Include Grafana dashboard panel descriptions - Document how to interpret circuit breaker metrics - Link to circuit breaker guide for troubleshooting</p> <p>Priority: High - Monitoring setup should include circuit breakers</p>"},{"location":"circuit-breaker-implementation-summary/#9-troubleshooting-guide","title":"9. \u23f3 Troubleshooting Guide","text":"<p>File: <code>docs_site/deployment/troubleshooting.md</code></p> <p>Needed: - Add \"Circuit Breaker Open\" error section - Add \"Circuit Breaker Flapping\" troubleshooting - Document recovery procedures - Link to comprehensive circuit breaker guide</p> <p>Priority: High - Operations teams need troubleshooting guidance</p>"},{"location":"circuit-breaker-implementation-summary/#10-claudemd-updates","title":"10. \u23f3 CLAUDE.md Updates","text":"<p>File: <code>CLAUDE.md</code></p> <p>Needed: - Update documentation requirements section to mention circuit breaker docs - Add example of proper circuit breaker documentation - Reference the circuit breaker guide as an example of complete feature documentation</p> <p>Priority: Medium - Developer guide should reference best practices</p>"},{"location":"circuit-breaker-implementation-summary/#impact-summary","title":"Impact Summary","text":""},{"location":"circuit-breaker-implementation-summary/#before-this-work","title":"Before This Work","text":"<ul> <li>\u274c No dedicated circuit breaker guide</li> <li>\u274c No Grafana visualizations for circuit breaker health</li> <li>\u274c No alerts for circuit breaker events</li> <li>\u274c Circuit breaker not mentioned in README features</li> <li>\u274c No user-facing documentation for configuration/troubleshooting</li> </ul>"},{"location":"circuit-breaker-implementation-summary/#after-this-work-current-state","title":"After This Work (Current State)","text":"<ul> <li>\u2705 Comprehensive 400+ line circuit breaker guide with examples</li> <li>\u2705 3 Grafana panels for complete circuit breaker observability</li> <li>\u2705 3 Prometheus alerts covering critical scenarios</li> <li>\u2705 README updated to highlight resilience feature</li> <li>\u2705 Guide discoverable from documentation index</li> <li>\u23f3 5 additional documentation files need minor updates</li> </ul>"},{"location":"circuit-breaker-implementation-summary/#implementation-quality","title":"Implementation Quality","text":"<p>Code Quality: \u2b50\u2b50\u2b50\u2b50\u2b50 Excellent - Proper use of pybreaker library - Clean listener implementation - Comprehensive metrics tracking - Good test coverage (8 tests in test_circuit_breaker.py) - Proper error propagation</p> <p>Documentation Quality: \u2b50\u2b50\u2b50\u2b50 Very Good (was \u2b50 Poor) - Comprehensive user-facing guide created \u2705 - Metrics fully documented with examples \u2705 - Troubleshooting section included \u2705 - Grafana dashboards configured \u2705 - Prometheus alerts configured \u2705 - Missing: Integration with other docs (5 files)</p> <p>Monitoring &amp; Alerting: \u2b50\u2b50\u2b50\u2b50\u2b50 Excellent - 3 Prometheus metrics exported - 3 Grafana panels configured - 3 alert rules defined - Complete observability stack</p>"},{"location":"circuit-breaker-implementation-summary/#quick-reference","title":"Quick Reference","text":""},{"location":"circuit-breaker-implementation-summary/#files-createdmodified","title":"Files Created/Modified","text":"<p>Created: - <code>docs_site/guides/circuit-breaker.md</code> - Complete user guide (400+ lines) - <code>CIRCUIT_BREAKER_DOCUMENTATION_SUMMARY.md</code> - This file</p> <p>Modified: - <code>docker/grafana/provisioning/dashboards/fastapi-metrics.json</code> - Added 3 panels (IDs: 28, 29, 30) - <code>docker/prometheus/alerts.yml</code> - Added circuit_breaker_alerts group with 3 alerts - <code>README.md</code> - Updated Production Features section - <code>docs_site/guides/index.md</code> - Added circuit breaker guide link - <code>app/managers/keycloak_manager.py</code> - Added metrics initialization - <code>app/storage/redis.py</code> - Added metrics initialization</p>"},{"location":"circuit-breaker-implementation-summary/#metrics-exposed","title":"Metrics Exposed","text":"<pre><code>circuit_breaker_state{service=\"keycloak\"}  # 0=closed, 1=open, 2=half_open\ncircuit_breaker_state{service=\"redis\"}\n\ncircuit_breaker_state_changes_total{service, from_state, to_state}\n\ncircuit_breaker_failures_total{service}\n</code></pre>"},{"location":"circuit-breaker-implementation-summary/#alerts-configured","title":"Alerts Configured","text":"<pre><code>CircuitBreakerOpen (critical) - CB open &gt; 2 minutes\nCircuitBreakerFlapping (warning) - &gt; 10 state changes in 5 minutes\nHighCircuitBreakerFailureRate (warning) - &gt; 5 failures/minute\n</code></pre>"},{"location":"circuit-breaker-implementation-summary/#grafana-panels","title":"Grafana Panels","text":"<pre><code>Panel 28: Circuit Breaker State - Real-time state visualization\nPanel 29: Circuit Breaker Failure Rate - Failure trends\nPanel 30: Circuit Breaker State Changes - Flapping detection\n</code></pre>"},{"location":"circuit-breaker-implementation-summary/#next-steps-for-complete-documentation-coverage","title":"Next Steps for Complete Documentation Coverage","text":"<ol> <li>High Priority (User-facing, operational):</li> <li>Update configuration documentation with circuit breaker settings</li> <li>Update monitoring guide with circuit breaker metrics</li> <li> <p>Update troubleshooting guide with circuit breaker section</p> </li> <li> <p>Medium Priority (Architecture/context):</p> </li> <li>Update architecture overview to mention circuit breakers</li> <li> <p>Update CLAUDE.md to reference circuit breaker docs as example</p> </li> <li> <p>Optional:</p> </li> <li>Add circuit breaker section to production deployment guide</li> <li>Create video/screencast demonstrating circuit breaker behavior</li> <li>Add chaos engineering tests specifically for circuit breaker scenarios</li> </ol>"},{"location":"circuit-breaker-implementation-summary/#commands-for-testing","title":"Commands for Testing","text":""},{"location":"circuit-breaker-implementation-summary/#view-metrics","title":"View Metrics","text":"<pre><code>curl -s http://localhost:8000/metrics | grep circuit_breaker\n</code></pre>"},{"location":"circuit-breaker-implementation-summary/#monitor-state-changes","title":"Monitor State Changes","text":"<pre><code>watch -n 1 'curl -s http://localhost:8000/metrics | grep circuit_breaker_state'\n</code></pre>"},{"location":"circuit-breaker-implementation-summary/#check-grafana-dashboard","title":"Check Grafana Dashboard","text":"<pre><code>http://localhost:3000/d/fastapi-metrics (panels 28-30)\n</code></pre>"},{"location":"circuit-breaker-implementation-summary/#check-prometheus-alerts","title":"Check Prometheus Alerts","text":"<pre><code>http://localhost:9090/alerts (filter: circuit_breaker)\n</code></pre>"},{"location":"circuit-breaker-implementation-summary/#simulate-failure-testing","title":"Simulate Failure (Testing)","text":"<pre><code># Stop Keycloak to trigger circuit breaker\ndocker stop hw-keycloak\n\n# Watch circuit breaker open\nwatch -n 1 'curl -s http://localhost:8000/metrics | grep circuit_breaker_state{service=\\\"keycloak\\\"}'\n\n# Restart Keycloak\ndocker start hw-keycloak\n</code></pre>"},{"location":"circuit-breaker-implementation-summary/#documentation-metrics","title":"Documentation Metrics","text":"<ul> <li>Lines of documentation added: 400+ (circuit-breaker.md)</li> <li>Grafana panels added: 3</li> <li>Prometheus alerts added: 3</li> <li>Files modified: 6</li> <li>Files created: 2</li> <li>Remaining files to update: 5</li> <li>Documentation coverage: ~75% complete (was 10%)</li> </ul>"},{"location":"circuit-breaker-implementation-summary/#conclusion","title":"Conclusion","text":"<p>The circuit breaker implementation now has comprehensive user-facing documentation, monitoring, and alerting. The remaining work involves integrating circuit breaker mentions into existing documentation files (configuration, architecture, monitoring, troubleshooting, CLAUDE.md).</p> <p>Current state: Production-ready with excellent observability Documentation state: Very good (from poor), 5 minor updates remaining User readiness: Users can now configure, monitor, and troubleshoot circuit breakers</p> <p>The dedicated circuit breaker guide (<code>docs_site/guides/circuit-breaker.md</code>) serves as the canonical reference and should be linked from the remaining documentation files.</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete reference documentation for HTTP and WebSocket APIs.</p>"},{"location":"api-reference/#api-documentation","title":"API Documentation","text":"<ul> <li>HTTP API - REST endpoint reference</li> <li>WebSocket API - WebSocket handler reference</li> <li>Response Models - Response format specifications</li> <li>Exceptions - Error handling and status codes</li> </ul>"},{"location":"api-reference/#interactive-documentation","title":"Interactive Documentation","text":"<p>When running locally, visit:</p> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> <li>OpenAPI JSON: http://localhost:8000/openapi.json</li> </ul>"},{"location":"api-reference/exceptions/","title":"Exception Handling","text":""},{"location":"api-reference/exceptions/#overview","title":"Overview","text":"<p>This document describes the exception handling patterns used in the application.</p>"},{"location":"api-reference/exceptions/#http-exceptions","title":"HTTP Exceptions","text":""},{"location":"api-reference/exceptions/#fastapi-httpexception","title":"FastAPI HTTPException","text":"<p>Used for HTTP endpoints:</p> <pre><code>from fastapi import HTTPException\n\nraise HTTPException(status_code=404, detail=\"Author not found\")\n</code></pre>"},{"location":"api-reference/exceptions/#common-http-exceptions","title":"Common HTTP Exceptions","text":"<p>401 Unauthorized: <pre><code>raise HTTPException(status_code=401, detail=\"Not authenticated\")\n</code></pre></p> <p>403 Forbidden: <pre><code>raise HTTPException(status_code=403, detail=\"Forbidden\")\n</code></pre></p> <p>404 Not Found: <pre><code>raise HTTPException(status_code=404, detail=\"Resource not found\")\n</code></pre></p> <p>422 Validation Error:</p> <p>Automatically raised by Pydantic for invalid data.</p> <p>500 Internal Server Error:</p> <p>Unhandled exceptions are caught and returned as 500 errors.</p>"},{"location":"api-reference/exceptions/#websocket-exceptions","title":"WebSocket Exceptions","text":""},{"location":"api-reference/exceptions/#error-response-pattern","title":"Error Response Pattern","text":"<p>WebSocket handlers return error responses instead of raising exceptions:</p> <pre><code>try:\n    # Handler logic\n    return ResponseModel.success(...)\nexcept ValueError as e:\n    return ResponseModel.err_msg(\n        pkg_id=request.pkg_id,\n        req_id=request.req_id,\n        msg=str(e),\n        status_code=RSPCode.INVALID_DATA\n    )\nexcept Exception as e:\n    logger.error(f\"Handler error: {e}\", exc_info=True)\n    return ResponseModel.err_msg(\n        pkg_id=request.pkg_id,\n        req_id=request.req_id,\n        msg=\"Internal error\",\n        status_code=RSPCode.ERROR\n    )\n</code></pre>"},{"location":"api-reference/exceptions/#connection-exceptions","title":"Connection Exceptions","text":"<p>WebSocketDisconnect:</p> <p>Raised when client disconnects:</p> <pre><code>from starlette.websockets import WebSocketDisconnect\n\ntry:\n    data = await websocket.receive_text()\nexcept WebSocketDisconnect:\n    # Clean up connection\n    await on_disconnect(websocket, 1000)\n</code></pre>"},{"location":"api-reference/exceptions/#custom-exceptions","title":"Custom Exceptions","text":""},{"location":"api-reference/exceptions/#database-exceptions","title":"Database Exceptions","text":"<pre><code>from sqlalchemy.exc import IntegrityError\n\ntry:\n    await session.commit()\nexcept IntegrityError as e:\n    await session.rollback()\n    logger.error(f\"Database constraint violation: {e}\")\n    raise HTTPException(status_code=400, detail=\"Duplicate entry\")\n</code></pre>"},{"location":"api-reference/exceptions/#validation-exceptions","title":"Validation Exceptions","text":"<pre><code>from pydantic import ValidationError\n\ntry:\n    data = InputModel(**request.data)\nexcept ValidationError as e:\n    return ResponseModel.err_msg(\n        pkg_id=request.pkg_id,\n        req_id=request.req_id,\n        msg=str(e),\n        status_code=RSPCode.INVALID_DATA\n    )\n</code></pre>"},{"location":"api-reference/exceptions/#error-logging","title":"Error Logging","text":"<p>All exceptions are logged with full context:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\ntry:\n    # Operation\n    pass\nexcept Exception as e:\n    logger.error(\n        f\"Operation failed: {e}\",\n        exc_info=True,\n        extra={\"user_id\": user.sub, \"pkg_id\": request.pkg_id}\n    )\n</code></pre>"},{"location":"api-reference/exceptions/#best-practices","title":"Best Practices","text":"<ol> <li>Use specific exceptions - Catch specific exception types</li> <li>Log with context - Include user_id, request_id, etc.</li> <li>Return user-friendly messages - Don't expose internal details</li> <li>Clean up resources - Use try-finally or context managers</li> <li>Handle async exceptions - Use proper async exception handling</li> </ol>"},{"location":"api-reference/exceptions/#related","title":"Related","text":"<ul> <li>HTTP API Error Handling</li> <li>WebSocket API Error Handling</li> </ul>"},{"location":"api-reference/http-api/","title":"HTTP API Documentation","text":""},{"location":"api-reference/http-api/#overview","title":"Overview","text":"<p>This FastAPI application provides RESTful HTTP endpoints with OpenAPI/Swagger documentation. All endpoints support JSON request/response format and include automatic validation via Pydantic models.</p>"},{"location":"api-reference/http-api/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000\nhttps://localhost:8000 (production with TLS)\n</code></pre>"},{"location":"api-reference/http-api/#authentication","title":"Authentication","text":"<p>Most endpoints require authentication via Keycloak access token passed in the Authorization header:</p> <pre><code>Authorization: Bearer &lt;access_token&gt;\n</code></pre>"},{"location":"api-reference/http-api/#obtaining-access-token","title":"Obtaining Access Token","text":"<p>Endpoint: <code>POST /login</code></p> <p>Request: <pre><code>curl -X POST http://localhost:8000/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"username\": \"your_username\",\n    \"password\": \"your_password\"\n  }'\n</code></pre></p> <p>Response: <pre><code>{\n  \"access_token\": \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"expires_in\": 300,\n  \"refresh_expires_in\": 1800,\n  \"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"token_type\": \"Bearer\",\n  \"scope\": \"profile email\"\n}\n</code></pre></p> <p>Token Expiration: - Access tokens: 300 seconds (5 minutes) - Refresh tokens: 1800 seconds (30 minutes)</p>"},{"location":"api-reference/http-api/#rate-limiting","title":"Rate Limiting","text":"<p>HTTP endpoints are rate-limited to prevent abuse:</p> <p>Default Limits: - 60 requests per minute per user/IP - Burst allowance: 10 additional requests</p> <p>Rate Limit Headers:</p> <p>All responses include rate limit information:</p> <pre><code>X-RateLimit-Limit: 60\nX-RateLimit-Remaining: 45\nX-RateLimit-Reset: 1705320000\n</code></pre> <p>Rate Limit Exceeded Response:</p> <p>Status Code: <code>429 Too Many Requests</code></p> <pre><code>{\n  \"detail\": \"Rate limit exceeded. Try again in 30 seconds.\"\n}\n</code></pre>"},{"location":"api-reference/http-api/#endpoints","title":"Endpoints","text":""},{"location":"api-reference/http-api/#health-check","title":"Health Check","text":""},{"location":"api-reference/http-api/#get-health","title":"GET /health","text":"<p>Check the health status of the application and its dependencies.</p> <p>This endpoint verifies: - Database connectivity (PostgreSQL) - Redis connectivity - WebSocket system health (active connections, metrics)</p> <p>Authentication: Not required</p> <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"status\": \"healthy\",\n  \"database\": \"healthy\",\n  \"redis\": \"healthy\",\n  \"websocket\": {\n    \"status\": \"healthy\",\n    \"active_connections\": 5\n  }\n}\n</code></pre> <p>Unhealthy Response: <code>503 Service Unavailable</code></p> <pre><code>{\n  \"status\": \"unhealthy\",\n  \"database\": \"unhealthy\",\n  \"redis\": \"healthy\",\n  \"websocket\": {\n    \"status\": \"healthy\",\n    \"active_connections\": 3\n  }\n}\n</code></pre> <p>Health Status Fields:</p> Field Description <code>status</code> Overall health status (healthy/unhealthy) <code>database</code> PostgreSQL database status <code>redis</code> Redis cache status <code>websocket.status</code> WebSocket system status <code>websocket.active_connections</code> Number of active WebSocket connections <p>Example:</p> <pre><code>curl http://localhost:8000/health\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\nresponse = requests.get('http://localhost:8000/health')\nhealth = response.json()\n\nif health['status'] == 'healthy':\n    print(\"\u2713 All systems operational\")\n    print(f\"  Active WebSocket connections: {health['websocket']['active_connections']}\")\nelse:\n    print(\"\u2717 System unhealthy\")\n    if health['database'] == 'unhealthy':\n        print(\"  - Database is down\")\n    if health['redis'] == 'unhealthy':\n        print(\"  - Redis is down\")\n</code></pre>"},{"location":"api-reference/http-api/#authors-endpoints","title":"Authors Endpoints","text":"<p>These endpoints demonstrate the Repository + Command + Dependency Injection pattern. Business logic is encapsulated in commands, making it reusable across HTTP and WebSocket handlers.</p>"},{"location":"api-reference/http-api/#get-authors","title":"GET /authors","text":"<p>Retrieve a list of authors with optional filtering.</p> <p>Authentication: Required (Role: <code>get-authors</code>)</p> <p>Query Parameters:</p> Parameter Type Required Description <code>id</code> integer No Filter by author ID <code>name</code> string No Filter by exact author name <code>search</code> string No Search by name (case-insensitive, partial match) <p>Response: <code>200 OK</code></p> <pre><code>[\n  {\n    \"id\": 1,\n    \"name\": \"John Doe\"\n  },\n  {\n    \"id\": 2,\n    \"name\": \"Jane Smith\"\n  }\n]\n</code></pre> <p>Empty Result:</p> <pre><code>[]\n</code></pre> <p>Example:</p> <pre><code># Get all authors\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  http://localhost:8000/authors\n\n# Filter by exact name\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/authors?name=John%20Doe\"\n\n# Search by partial name\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/authors?search=John\"\n\n# Filter by ID\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/authors?id=1\"\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\nresponse = requests.get(\n    'http://localhost:8000/authors',\n    headers={'Authorization': f'Bearer {token}'},\n    params={'search': 'John'}\n)\n\nauthors = response.json()\nfor author in authors:\n    print(f\"{author['id']}: {author['name']}\")\n</code></pre>"},{"location":"api-reference/http-api/#post-authors","title":"POST /authors","text":"<p>Create a new author.</p> <p>Authentication: Required (Role: <code>create-author</code>)</p> <p>Request Body:</p> <pre><code>{\n  \"name\": \"John Doe\"\n}\n</code></pre> <p>Response: <code>201 Created</code></p> <pre><code>{\n  \"id\": 1,\n  \"name\": \"John Doe\"\n}\n</code></pre> <p>Error Responses:</p> Status Code Reason Response 401 Unauthorized <code>{\"detail\": \"Not authenticated\"}</code> 403 Permission denied <code>{\"detail\": \"Forbidden\"}</code> 409 Duplicate author name <code>{\"detail\": \"Author with name 'John Doe' already exists\"}</code> 422 Validation error <code>{\"detail\": [...validation errors...]}</code> 500 Database error <code>{\"detail\": \"Internal server error\"}</code> <p>Example:</p> <pre><code>curl -X POST http://localhost:8000/authors \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"John Doe\"}'\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\nresponse = requests.post(\n    'http://localhost:8000/authors',\n    headers={'Authorization': f'Bearer {token}'},\n    json={'name': 'John Doe'}\n)\n\nif response.status_code == 201:\n    author = response.json()\n    print(f\"Created author with ID: {author['id']}\")\n</code></pre>"},{"location":"api-reference/http-api/#put-authorsauthor_id","title":"PUT /authors/{author_id}","text":"<p>Update an existing author.</p> <p>Authentication: Required (Role: <code>update-author</code>)</p> <p>Path Parameters:</p> Parameter Type Required Description <code>author_id</code> integer Yes ID of author to update <p>Request Body:</p> <pre><code>{\n  \"name\": \"Jane Doe\"\n}\n</code></pre> <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"id\": 1,\n  \"name\": \"Jane Doe\"\n}\n</code></pre> <p>Error Responses:</p> Status Code Reason Response 401 Unauthorized <code>{\"detail\": \"Not authenticated\"}</code> 403 Permission denied <code>{\"detail\": \"Forbidden\"}</code> 404 Author not found <code>{\"detail\": \"Author with ID 1 not found\"}</code> 409 Name conflict <code>{\"detail\": \"Author with name 'Jane Doe' already exists\"}</code> 422 Validation error <code>{\"detail\": [...validation errors...]}</code> <p>Example:</p> <pre><code>curl -X PUT http://localhost:8000/authors/1 \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"Jane Doe\"}'\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\nresponse = requests.put(\n    'http://localhost:8000/authors/1',\n    headers={'Authorization': f'Bearer {token}'},\n    json={'name': 'Jane Doe'}\n)\n\nif response.status_code == 200:\n    author = response.json()\n    print(f\"Updated author: {author['name']}\")\n</code></pre>"},{"location":"api-reference/http-api/#delete-authorsauthor_id","title":"DELETE /authors/{author_id}","text":"<p>Delete an author.</p> <p>Authentication: Required (Role: <code>delete-author</code>)</p> <p>Path Parameters:</p> Parameter Type Required Description <code>author_id</code> integer Yes ID of author to delete <p>Response: <code>204 No Content</code></p> <p>(Empty response body)</p> <p>Error Responses:</p> Status Code Reason Response 401 Unauthorized <code>{\"detail\": \"Not authenticated\"}</code> 403 Permission denied <code>{\"detail\": \"Forbidden\"}</code> 404 Author not found <code>{\"detail\": \"Author with ID 1 not found\"}</code> <p>Example:</p> <pre><code>curl -X DELETE http://localhost:8000/authors/1 \\\n  -H \"Authorization: Bearer $TOKEN\"\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\nresponse = requests.delete(\n    'http://localhost:8000/authors/1',\n    headers={'Authorization': f'Bearer {token}'}\n)\n\nif response.status_code == 204:\n    print(\"Author deleted successfully\")\n</code></pre>"},{"location":"api-reference/http-api/#get-authorspaginated","title":"GET /authors/paginated","text":"<p>Retrieve a paginated list of authors with optional filtering.</p> <p>Authentication: Required (Role: <code>get-authors</code>)</p> <p>Query Parameters:</p> Parameter Type Required Default Description <code>page</code> integer No 1 Page number (&gt;=1) <code>per_page</code> integer No 20 Items per page (&gt;=1) <code>id</code> integer No - Filter by author ID <code>name</code> string No - Filter by author name <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": 1,\n      \"name\": \"John Doe\"\n    },\n    {\n      \"id\": 2,\n      \"name\": \"Jane Smith\"\n    }\n  ],\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 42,\n    \"pages\": 3\n  }\n}\n</code></pre> <p>Metadata Fields:</p> Field Description <code>page</code> Current page number <code>per_page</code> Number of items per page <code>total</code> Total number of items matching filters <code>pages</code> Total number of pages <p>Example:</p> <pre><code># Get first page (default 20 items)\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  http://localhost:8000/authors/paginated\n\n# Get specific page with custom page size\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/authors/paginated?page=2&amp;per_page=10\"\n\n# Paginate with filters\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/authors/paginated?page=1&amp;per_page=10&amp;name=Smith\"\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\ndef get_all_authors(token):\n    \"\"\"Fetch all authors using pagination.\"\"\"\n    all_authors = []\n    page = 1\n\n    while True:\n        response = requests.get(\n            'http://localhost:8000/authors/paginated',\n            headers={'Authorization': f'Bearer {token}'},\n            params={'page': page, 'per_page': 100}\n        )\n\n        data = response.json()\n        all_authors.extend(data['items'])\n\n        if page &gt;= data['meta']['pages']:\n            break\n\n        page += 1\n\n    return all_authors\n</code></pre>"},{"location":"api-reference/http-api/#audit-logs-endpoints","title":"Audit Logs Endpoints","text":"<p>These endpoints provide access to the audit trail of user actions. All endpoints are restricted to administrators only.</p>"},{"location":"api-reference/http-api/#get-audit-logs","title":"GET /audit-logs","text":"<p>Retrieve paginated audit logs with optional filters.</p> <p>Authentication: Required (Role: <code>admin</code>)</p> <p>Query Parameters:</p> Parameter Type Required Default Description <code>page</code> integer No 1 Page number (&gt;=1) <code>per_page</code> integer No 20 Items per page (1-100) <code>user_id</code> string No - Filter by Keycloak user ID <code>username</code> string No - Filter by username <code>action_type</code> string No - Filter by action type (GET, POST, WS:*, etc.) <code>resource</code> string No - Filter by resource <code>outcome</code> string No - Filter by outcome (success, error, permission_denied) <code>start_date</code> datetime No - Filter by start date (ISO 8601) <code>end_date</code> datetime No - Filter by end date (ISO 8601) <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": 1,\n      \"timestamp\": \"2025-01-12T14:30:00Z\",\n      \"user_id\": \"abc-123-def\",\n      \"username\": \"john.doe\",\n      \"action_type\": \"POST\",\n      \"resource\": \"/api/authors\",\n      \"outcome\": \"success\",\n      \"ip_address\": \"192.168.1.100\",\n      \"request_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"response_status\": 201,\n      \"duration_ms\": 45\n    }\n  ],\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 150,\n    \"pages\": 8\n  }\n}\n</code></pre> <p>Example:</p> <pre><code># Get all audit logs (first page)\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  http://localhost:8000/audit-logs\n\n# Filter by user\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/audit-logs?username=john.doe\"\n\n# Filter by outcome\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/audit-logs?outcome=error\"\n\n# Filter by date range\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/audit-logs?start_date=2025-01-01T00:00:00Z&amp;end_date=2025-01-12T23:59:59Z\"\n\n# Combine filters\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/audit-logs?username=john.doe&amp;action_type=POST&amp;page=2\"\n</code></pre> <p>Python Example:</p> <pre><code>import requests\nfrom datetime import datetime, timedelta\n\n# Get failed actions for specific user in last 24 hours\nstart_date = (datetime.now() - timedelta(days=1)).isoformat()\n\nresponse = requests.get(\n    'http://localhost:8000/audit-logs',\n    headers={'Authorization': f'Bearer {admin_token}'},\n    params={\n        'username': 'john.doe',\n        'outcome': 'error',\n        'start_date': start_date\n    }\n)\n\nlogs = response.json()\nfor log in logs['items']:\n    print(f\"{log['timestamp']}: {log['action_type']} {log['resource']} - {log['outcome']}\")\n</code></pre>"},{"location":"api-reference/http-api/#get-audit-logslog_id","title":"GET /audit-logs/{log_id}","text":"<p>Retrieve a specific audit log entry by ID.</p> <p>Authentication: Required (Role: <code>admin</code>)</p> <p>Path Parameters:</p> Parameter Type Required Description <code>log_id</code> integer Yes ID of the audit log entry <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"id\": 1,\n  \"timestamp\": \"2025-01-12T14:30:00Z\",\n  \"user_id\": \"abc-123-def\",\n  \"username\": \"john.doe\",\n  \"user_roles\": [\"user\", \"create-author\"],\n  \"action_type\": \"POST\",\n  \"resource\": \"/api/authors\",\n  \"outcome\": \"success\",\n  \"ip_address\": \"192.168.1.100\",\n  \"user_agent\": \"Mozilla/5.0...\",\n  \"request_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"request_data\": {\"name\": \"New Author\"},\n  \"response_status\": 201,\n  \"error_message\": null,\n  \"duration_ms\": 45\n}\n</code></pre> <p>Error Responses:</p> Status Code Reason Response 404 Log entry not found <code>{\"detail\": \"Audit log not found\"}</code> <p>Example:</p> <pre><code>curl -H \"Authorization: Bearer $TOKEN\" \\\n  http://localhost:8000/audit-logs/1\n</code></pre>"},{"location":"api-reference/http-api/#get-audit-logsuseruser_id","title":"GET /audit-logs/user/{user_id}","text":"<p>Retrieve all audit logs for a specific user.</p> <p>Authentication: Required (Role: <code>admin</code>)</p> <p>Path Parameters:</p> Parameter Type Required Description <code>user_id</code> string Yes Keycloak user ID <p>Query Parameters:</p> Parameter Type Required Default Description <code>page</code> integer No 1 Page number (&gt;=1) <code>per_page</code> integer No 20 Items per page (1-100) <code>start_date</code> datetime No - Filter by start date (ISO 8601) <code>end_date</code> datetime No - Filter by end date (ISO 8601) <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": 1,\n      \"timestamp\": \"2025-01-12T14:30:00Z\",\n      \"user_id\": \"abc-123-def\",\n      \"username\": \"john.doe\",\n      \"action_type\": \"POST\",\n      \"resource\": \"/api/authors\",\n      \"outcome\": \"success\",\n      \"response_status\": 201,\n      \"duration_ms\": 45\n    }\n  ],\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 42,\n    \"pages\": 3\n  }\n}\n</code></pre> <p>Example:</p> <pre><code># Get all logs for user\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  http://localhost:8000/audit-logs/user/abc-123-def\n\n# Filter by date range\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/audit-logs/user/abc-123-def?start_date=2025-01-01T00:00:00Z\"\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\n# Track user activity over time\nresponse = requests.get(\n    f'http://localhost:8000/audit-logs/user/{user_id}',\n    headers={'Authorization': f'Bearer {admin_token}'},\n    params={'per_page': 100}\n)\n\nlogs = response.json()\nprint(f\"Total actions: {logs['meta']['total']}\")\nprint(f\"Success rate: {sum(1 for log in logs['items'] if log['outcome'] == 'success') / len(logs['items']) * 100:.1f}%\")\n</code></pre>"},{"location":"api-reference/http-api/#profiling-endpoints","title":"Profiling Endpoints","text":"<p>These endpoints provide access to Scalene performance profiling reports. Used for performance analysis and optimization.</p>"},{"location":"api-reference/http-api/#get-apiprofilingstatus","title":"GET /api/profiling/status","text":"<p>Get current profiling configuration and status.</p> <p>Authentication: Not required</p> <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"enabled\": false,\n  \"scalene_installed\": false,\n  \"output_directory\": \"profiling_reports\",\n  \"interval_seconds\": 30,\n  \"python_version\": \"3.13.0\",\n  \"command\": \"scalene --html --outfile report.html -- uvicorn app:application\"\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/api/profiling/status\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\nresponse = requests.get('http://localhost:8000/api/profiling/status')\nstatus = response.json()\n\nif not status['scalene_installed']:\n    print(\"Scalene is not installed. Install with: pip install scalene\")\nelif not status['enabled']:\n    print(\"Profiling is disabled. Enable with: PROFILING_ENABLED=true\")\nelse:\n    print(f\"Profiling enabled. Reports saved to: {status['output_directory']}\")\n</code></pre>"},{"location":"api-reference/http-api/#get-apiprofilingreports","title":"GET /api/profiling/reports","text":"<p>List all available profiling reports.</p> <p>Authentication: Not required</p> <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"reports\": [\n    {\n      \"filename\": \"websocket_profile_20250123_143000.html\",\n      \"path\": \"profiling_reports/websocket_profile_20250123_143000.html\",\n      \"size_bytes\": 125000,\n      \"created_at\": 1706019000\n    }\n  ],\n  \"total_count\": 1\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/api/profiling/reports\n</code></pre> <p>Python Example:</p> <pre><code>import requests\nfrom datetime import datetime\n\nresponse = requests.get('http://localhost:8000/api/profiling/reports')\ndata = response.json()\n\nprint(f\"Total reports: {data['total_count']}\")\nfor report in data['reports']:\n    created = datetime.fromtimestamp(report['created_at'])\n    size_mb = report['size_bytes'] / 1024 / 1024\n    print(f\"  {report['filename']} - {size_mb:.2f}MB - {created}\")\n</code></pre>"},{"location":"api-reference/http-api/#get-apiprofilingreportsfilename","title":"GET /api/profiling/reports/{filename}","text":"<p>Download a specific profiling report.</p> <p>Authentication: Not required</p> <p>Path Parameters:</p> Parameter Type Required Description <code>filename</code> string Yes Name of the report file (e.g., websocket_profile_20250123_143000.html) <p>Response: <code>200 OK</code></p> <p>Returns HTML file containing the Scalene profiling report.</p> <p>Error Responses:</p> Status Code Reason Response 400 Invalid filename <code>{\"detail\": \"Invalid filename\"}</code> 404 Report not found <code>{\"detail\": \"Report 'filename' not found\"}</code> <p>Example:</p> <pre><code># Download report\ncurl http://localhost:8000/api/profiling/reports/websocket_profile_20250123_143000.html \\\n  -o report.html\n\n# Open in browser\nopen report.html\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\n# Download and save report\nfilename = \"websocket_profile_20250123_143000.html\"\nresponse = requests.get(f'http://localhost:8000/api/profiling/reports/{filename}')\n\nwith open(filename, 'wb') as f:\n    f.write(response.content)\n\nprint(f\"Report saved to: {filename}\")\n</code></pre>"},{"location":"api-reference/http-api/#delete-apiprofilingreportsfilename","title":"DELETE /api/profiling/reports/{filename}","text":"<p>Delete a specific profiling report.</p> <p>Authentication: Not required</p> <p>Path Parameters:</p> Parameter Type Required Description <code>filename</code> string Yes Name of the report file to delete <p>Response: <code>200 OK</code></p> <pre><code>{\n  \"message\": \"Report deleted successfully\",\n  \"filename\": \"websocket_profile_20250123_143000.html\"\n}\n</code></pre> <p>Error Responses:</p> Status Code Reason Response 400 Invalid filename <code>{\"detail\": \"Invalid filename\"}</code> 404 Report not found <code>{\"detail\": \"Report 'filename' not found\"}</code> <p>Example:</p> <pre><code>curl -X DELETE http://localhost:8000/api/profiling/reports/websocket_profile_20250123_143000.html\n</code></pre> <p>Python Example:</p> <pre><code>import requests\n\n# Delete old profiling reports\nresponse = requests.get('http://localhost:8000/api/profiling/reports')\nreports = response.json()['reports']\n\nfor report in reports:\n    # Delete reports older than 7 days\n    age_days = (time.time() - report['created_at']) / 86400\n    if age_days &gt; 7:\n        delete_response = requests.delete(\n            f\"http://localhost:8000/api/profiling/reports/{report['filename']}\"\n        )\n        print(f\"Deleted: {report['filename']}\")\n</code></pre>"},{"location":"api-reference/http-api/#metrics-endpoint","title":"Metrics Endpoint","text":""},{"location":"api-reference/http-api/#get-metrics","title":"GET /metrics","text":"<p>Retrieve Prometheus metrics for monitoring.</p> <p>Authentication: Not required</p> <p>Content-Type: <code>text/plain; version=0.0.4</code></p> <p>Response: <code>200 OK</code></p> <pre><code># HELP http_requests_total Total number of HTTP requests\n# TYPE http_requests_total counter\nhttp_requests_total{method=\"GET\",endpoint=\"/authors\",status_code=\"200\"} 1234.0\n\n# HELP http_request_duration_seconds HTTP request duration in seconds\n# TYPE http_request_duration_seconds histogram\nhttp_request_duration_seconds_bucket{method=\"GET\",endpoint=\"/authors\",le=\"0.005\"} 100.0\n\n# HELP ws_connections_active Active WebSocket connections\n# TYPE ws_connections_active gauge\nws_connections_active 5.0\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/metrics\n</code></pre>"},{"location":"api-reference/http-api/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/http-api/#standard-error-response-format","title":"Standard Error Response Format","text":"<p>All error responses follow this structure:</p> <pre><code>{\n  \"detail\": \"Error message describing what went wrong\"\n}\n</code></pre>"},{"location":"api-reference/http-api/#http-status-codes","title":"HTTP Status Codes","text":"Code Name Description 200 OK Request successful 401 Unauthorized Missing or invalid authentication token 403 Forbidden User lacks required permissions 404 Not Found Resource not found 422 Unprocessable Entity Validation error in request data 429 Too Many Requests Rate limit exceeded 500 Internal Server Error Server-side error occurred 503 Service Unavailable Service or dependency unhealthy"},{"location":"api-reference/http-api/#validation-errors-422","title":"Validation Errors (422)","text":"<p>Pydantic validation errors include detailed field-level information:</p> <pre><code>{\n  \"detail\": [\n    {\n      \"type\": \"string_type\",\n      \"loc\": [\"body\", \"name\"],\n      \"msg\": \"Input should be a valid string\",\n      \"input\": 123\n    }\n  ]\n}\n</code></pre> <p>Fields: - <code>type</code>: Type of validation error - <code>loc</code>: Location of error (path to field) - <code>msg</code>: Human-readable error message - <code>input</code>: The invalid input value</p>"},{"location":"api-reference/http-api/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<p>Endpoints are protected by role-based access control defined in handler decorators using the <code>require_roles()</code> dependency.</p> <p>Implementation: <pre><code>from app.dependencies.permissions import require_roles\n\n@router.get(\"/authors\", dependencies=[Depends(require_roles(\"get-authors\"))])\nasync def get_authors():\n    ...\n</code></pre></p> <p>Common Roles:</p> Role Description Example Usage <code>get-authors</code> View author list GET /api/authors <code>create-author</code> Create new authors POST /api/authors <code>admin</code> Administrative privileges DELETE operations, admin endpoints <p>Permission Denied Response: <code>403 Forbidden</code></p> <pre><code>{\n  \"detail\": \"Forbidden\"\n}\n</code></pre>"},{"location":"api-reference/http-api/#openapiswagger-documentation","title":"OpenAPI/Swagger Documentation","text":"<p>Interactive API documentation is available at:</p> <p>Swagger UI: http://localhost:8000/docs</p> <p>ReDoc: http://localhost:8000/redoc</p> <p>OpenAPI JSON: http://localhost:8000/openapi.json</p> <p>These provide: - Interactive request testing - Request/response schema documentation - Example values - Authentication configuration</p>"},{"location":"api-reference/http-api/#best-practices","title":"Best Practices","text":""},{"location":"api-reference/http-api/#1-token-management","title":"1. Token Management","text":"<pre><code>import requests\nfrom datetime import datetime, timedelta\n\nclass APIClient:\n    def __init__(self, base_url):\n        self.base_url = base_url\n        self.token = None\n        self.token_expiry = None\n\n    def login(self, username, password):\n        response = requests.post(\n            f'{self.base_url}/login',\n            json={'username': username, 'password': password}\n        )\n        data = response.json()\n\n        self.token = data['access_token']\n        self.token_expiry = datetime.now() + timedelta(seconds=data['expires_in'])\n\n    def _ensure_authenticated(self):\n        if not self.token or datetime.now() &gt;= self.token_expiry:\n            raise Exception('Token expired or missing')\n\n    def get_authors(self, **filters):\n        self._ensure_authenticated()\n        response = requests.get(\n            f'{self.base_url}/authors',\n            headers={'Authorization': f'Bearer {self.token}'},\n            params=filters\n        )\n        response.raise_for_status()\n        return response.json()\n</code></pre>"},{"location":"api-reference/http-api/#2-error-handling","title":"2. Error Handling","text":"<pre><code>import requests\nfrom requests.exceptions import RequestException\n\ndef safe_api_call(func):\n    def wrapper(*args, **kwargs):\n        try:\n            response = func(*args, **kwargs)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.HTTPError as e:\n            if e.response.status_code == 401:\n                print(\"Authentication failed\")\n            elif e.response.status_code == 403:\n                print(\"Permission denied\")\n            elif e.response.status_code == 429:\n                print(\"Rate limit exceeded\")\n            else:\n                print(f\"HTTP error: {e}\")\n        except RequestException as e:\n            print(f\"Request failed: {e}\")\n        return None\n\n    return wrapper\n\n@safe_api_call\ndef get_authors(token):\n    return requests.get(\n        'http://localhost:8000/authors',\n        headers={'Authorization': f'Bearer {token}'}\n    )\n</code></pre>"},{"location":"api-reference/http-api/#3-pagination-handling","title":"3. Pagination Handling","text":"<pre><code>def fetch_all_pages(token, endpoint, per_page=100):\n    \"\"\"\n    Fetch all pages from a paginated endpoint.\n\n    Args:\n        token: Authentication token\n        endpoint: API endpoint URL\n        per_page: Items per page\n\n    Yields:\n        Individual items from all pages\n    \"\"\"\n    page = 1\n\n    while True:\n        response = requests.get(\n            endpoint,\n            headers={'Authorization': f'Bearer {token}'},\n            params={'page': page, 'per_page': per_page}\n        )\n        response.raise_for_status()\n\n        data = response.json()\n\n        for item in data['items']:\n            yield item\n\n        if page &gt;= data['meta']['pages']:\n            break\n\n        page += 1\n\n# Usage\nfor author in fetch_all_pages(token, 'http://localhost:8000/authors_paginated'):\n    print(f\"{author['id']}: {author['name']}\")\n</code></pre>"},{"location":"api-reference/http-api/#4-rate-limiting","title":"4. Rate Limiting","text":"<pre><code>import time\nfrom functools import wraps\n\ndef rate_limit_handler(func):\n    \"\"\"Decorator to handle rate limiting with automatic retry.\"\"\"\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        max_retries = 3\n        retry_count = 0\n\n        while retry_count &lt; max_retries:\n            try:\n                response = func(*args, **kwargs)\n\n                # Check rate limit headers\n                remaining = int(response.headers.get('X-RateLimit-Remaining', 0))\n\n                if remaining &lt; 5:\n                    # Approaching limit, slow down\n                    time.sleep(1)\n\n                return response\n\n            except requests.exceptions.HTTPError as e:\n                if e.response.status_code == 429:\n                    retry_after = int(e.response.headers.get('Retry-After', 60))\n                    print(f\"Rate limited. Waiting {retry_after}s...\")\n                    time.sleep(retry_after)\n                    retry_count += 1\n                else:\n                    raise\n\n        raise Exception(\"Max retries exceeded for rate limiting\")\n\n    return wrapper\n\n@rate_limit_handler\ndef get_authors_safe(token):\n    return requests.get(\n        'http://localhost:8000/authors',\n        headers={'Authorization': f'Bearer {token}'}\n    )\n</code></pre>"},{"location":"api-reference/http-api/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api-reference/http-api/#1-use-pagination","title":"1. Use Pagination","text":"<p>For large datasets, always use paginated endpoints:</p> <pre><code># Good: Paginated request\nresponse = requests.get(\n    'http://localhost:8000/authors_paginated',\n    params={'page': 1, 'per_page': 50}\n)\n\n# Avoid: Non-paginated request for large datasets\nresponse = requests.get('http://localhost:8000/authors')  # May return thousands\n</code></pre>"},{"location":"api-reference/http-api/#2-filter-early","title":"2. Filter Early","text":"<p>Apply filters to reduce data transfer:</p> <pre><code># Good: Filter on server\nresponse = requests.get(\n    'http://localhost:8000/authors',\n    params={'name': 'Smith'}\n)\n\n# Avoid: Fetch all and filter on client\nresponse = requests.get('http://localhost:8000/authors')\nauthors = [a for a in response.json() if 'Smith' in a['name']]\n</code></pre>"},{"location":"api-reference/http-api/#3-reuse-connections","title":"3. Reuse Connections","text":"<p>Use session objects for multiple requests:</p> <pre><code>session = requests.Session()\nsession.headers.update({'Authorization': f'Bearer {token}'})\n\n# Reuses underlying TCP connection\nfor i in range(10):\n    response = session.get('http://localhost:8000/authors')\n</code></pre>"},{"location":"api-reference/http-api/#monitoring","title":"Monitoring","text":""},{"location":"api-reference/http-api/#health-checks","title":"Health Checks","text":"<p>Implement periodic health checks for service monitoring:</p> <pre><code>import requests\nimport time\n\ndef monitor_service(url, interval=30):\n    \"\"\"Monitor service health.\"\"\"\n    while True:\n        try:\n            response = requests.get(f'{url}/health', timeout=5)\n            health = response.json()\n\n            if health['status'] != 'healthy':\n                alert(f\"Service unhealthy: {health}\")\n\n        except Exception as e:\n            alert(f\"Health check failed: {e}\")\n\n        time.sleep(interval)\n</code></pre>"},{"location":"api-reference/http-api/#metrics-integration","title":"Metrics Integration","text":"<p>Scrape Prometheus metrics for monitoring:</p> <pre><code># prometheus.yml\nscrape_configs:\n  - job_name: 'fastapi-app'\n    static_configs:\n      - targets: ['localhost:8000']\n    metrics_path: '/metrics'\n    scrape_interval: 15s\n</code></pre>"},{"location":"api-reference/http-api/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api-reference/http-api/#authentication-issues","title":"Authentication Issues","text":"<p>Problem: 401 Unauthorized</p> <p>Solutions: 1. Verify token hasn't expired (check <code>exp</code> claim) 2. Ensure token is in Authorization header: <code>Bearer &lt;token&gt;</code> 3. Check Keycloak server is accessible 4. Verify username/password are correct</p>"},{"location":"api-reference/http-api/#rate-limiting_1","title":"Rate Limiting","text":"<p>Problem: 429 Too Many Requests</p> <p>Solutions: 1. Implement exponential backoff 2. Check <code>X-RateLimit-Reset</code> header for retry time 3. Reduce request frequency 4. Cache responses when possible</p>"},{"location":"api-reference/http-api/#validation-errors","title":"Validation Errors","text":"<p>Problem: 422 Unprocessable Entity</p> <p>Solutions: 1. Review validation error details in response 2. Check field types match schema 3. Ensure required fields are present 4. Validate data before sending</p>"},{"location":"api-reference/http-api/#database-errors","title":"Database Errors","text":"<p>Problem: 500 Internal Server Error</p> <p>Solutions: 1. Check <code>/health</code> endpoint for database status 2. Review server logs for detailed errors 3. Verify database connection configuration 4. Contact system administrator if persistent</p>"},{"location":"api-reference/http-api/#support","title":"Support","text":"<p>For additional help: - Interactive documentation: http://localhost:8000/docs - Health status: http://localhost:8000/health - Enable debug logging: <code>LOG_LEVEL=DEBUG</code> - Check application logs for detailed error traces</p>"},{"location":"api-reference/response-models/","title":"Response Models","text":""},{"location":"api-reference/response-models/#overview","title":"Overview","text":"<p>This document describes the standard response models used across both HTTP and WebSocket APIs.</p>"},{"location":"api-reference/response-models/#http-response-models","title":"HTTP Response Models","text":""},{"location":"api-reference/response-models/#standard-response","title":"Standard Response","text":"<p>HTTP endpoints return data directly with appropriate status codes:</p> <pre><code>{\n  \"id\": 1,\n  \"name\": \"John Doe\"\n}\n</code></pre>"},{"location":"api-reference/response-models/#paginated-response","title":"Paginated Response","text":"<p>Paginated endpoints return data with metadata:</p> <pre><code>{\n  \"items\": [...],\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 42,\n    \"pages\": 3\n  }\n}\n</code></pre>"},{"location":"api-reference/response-models/#error-response","title":"Error Response","text":"<pre><code>{\n  \"detail\": \"Error message\"\n}\n</code></pre>"},{"location":"api-reference/response-models/#websocket-response-models","title":"WebSocket Response Models","text":""},{"location":"api-reference/response-models/#responsemodel","title":"ResponseModel","text":"<p>All WebSocket responses use the <code>ResponseModel</code> structure:</p> <pre><code>class ResponseModel(BaseModel):\n    pkg_id: int\n    req_id: str\n    status_code: int\n    data: dict | list | None = None\n    meta: MetadataModel | None = None\n</code></pre> <p>Example Success Response:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 0,\n  \"data\": [{\"id\": 1, \"name\": \"John Doe\"}],\n  \"meta\": null\n}\n</code></pre> <p>Example Error Response:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 2,\n  \"data\": {\"msg\": \"Invalid data\"},\n  \"meta\": null\n}\n</code></pre>"},{"location":"api-reference/response-models/#metadatamodel","title":"MetadataModel","text":"<p>Pagination metadata for WebSocket responses:</p> <pre><code>class MetadataModel(BaseModel):\n    page: int\n    per_page: int\n    total: int\n    pages: int\n</code></pre> <p>Example:</p> <pre><code>{\n  \"page\": 1,\n  \"per_page\": 20,\n  \"total\": 42,\n  \"pages\": 3\n}\n</code></pre>"},{"location":"api-reference/response-models/#helper-methods","title":"Helper Methods","text":""},{"location":"api-reference/response-models/#responsemodelsuccess","title":"ResponseModel.success()","text":"<p>Create a success response:</p> <pre><code>return ResponseModel.success(\n    pkg_id=request.pkg_id,\n    req_id=request.req_id,\n    data=[author.model_dump() for author in authors]\n)\n</code></pre>"},{"location":"api-reference/response-models/#responsemodelerr_msg","title":"ResponseModel.err_msg()","text":"<p>Create an error response:</p> <pre><code>return ResponseModel.err_msg(\n    pkg_id=request.pkg_id,\n    req_id=request.req_id,\n    msg=\"Author not found\",\n    status_code=RSPCode.ERROR\n)\n</code></pre>"},{"location":"api-reference/response-models/#response-status-codes","title":"Response Status Codes","text":"<p>See WebSocket API for complete list of response codes.</p>"},{"location":"api-reference/response-models/#related","title":"Related","text":"<ul> <li>HTTP API - HTTP endpoints and responses</li> <li>WebSocket API - WebSocket message format</li> </ul>"},{"location":"api-reference/websocket-api/","title":"WebSocket API Documentation","text":""},{"location":"api-reference/websocket-api/#overview","title":"Overview","text":"<p>This FastAPI application provides a WebSocket API for real-time bidirectional communication. The WebSocket endpoint uses a package-based routing system where requests are dispatched to handlers based on Package IDs (PkgID).</p>"},{"location":"api-reference/websocket-api/#connection","title":"Connection","text":""},{"location":"api-reference/websocket-api/#endpoint","title":"Endpoint","text":"<pre><code>ws://localhost:8000/web\nwss://localhost:8000/web (for production with TLS)\n</code></pre>"},{"location":"api-reference/websocket-api/#authentication","title":"Authentication","text":"<p>Authentication is required via Keycloak access token passed as a query parameter:</p> <pre><code>ws://localhost:8000/web?token=&lt;your_access_token&gt;\n</code></pre> <p>Connection Limits: - Maximum concurrent connections per user: 5 (configurable via <code>WS_MAX_CONNECTIONS_PER_USER</code>) - Exceeding this limit results in connection rejection with code <code>1008</code> (Policy Violation)</p>"},{"location":"api-reference/websocket-api/#rate-limiting","title":"Rate Limiting","text":"<p>Message Rate Limits: - Default: 100 messages per minute per user (configurable via <code>WS_MESSAGE_RATE_LIMIT</code>) - Exceeding rate limit returns error response with <code>RSPCode.ERROR</code></p>"},{"location":"api-reference/websocket-api/#message-format","title":"Message Format","text":""},{"location":"api-reference/websocket-api/#request-message","title":"Request Message","text":"<p>All client requests must follow this JSON structure:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"method\": \"\",\n  \"data\": {}\n}\n</code></pre> <p>Fields:</p> Field Type Required Description <code>pkg_id</code> integer Yes Package identifier routing request to specific handler (see PkgID Reference) <code>req_id</code> string (UUID) Yes Unique request identifier for tracking responses <code>method</code> string No Optional method name (handler-specific, defaults to empty string) <code>data</code> object No Request payload containing handler-specific parameters (defaults to <code>{}</code>)"},{"location":"api-reference/websocket-api/#response-message","title":"Response Message","text":"<p>All server responses follow this JSON structure:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 0,\n  \"meta\": null,\n  \"data\": []\n}\n</code></pre> <p>Fields:</p> Field Type Description <code>pkg_id</code> integer Same as request pkg_id, identifies the handler that processed the request <code>req_id</code> string (UUID) Same as request req_id, for request/response correlation <code>status_code</code> integer Response code indicating operation result (see RSPCode Reference) <code>meta</code> object/null Optional metadata (e.g., pagination info) <code>data</code> object/array/null Response payload containing results or error details"},{"location":"api-reference/websocket-api/#package-id-reference-pkgid","title":"Package ID Reference (PkgID)","text":"PkgID Name Description Required Role 1 <code>GET_AUTHORS</code> Retrieve list of authors with optional filters <code>user</code> 2 <code>GET_PAGINATED_AUTHORS</code> Retrieve paginated list of authors <code>user</code> 3 <code>THIRD</code> Reserved for future use TBD"},{"location":"api-reference/websocket-api/#handler-details","title":"Handler Details","text":""},{"location":"api-reference/websocket-api/#1-get_authors-pkgid-1","title":"1. GET_AUTHORS (PkgID: 1)","text":"<p>Retrieves a list of authors with optional filtering.</p> <p>Request Data Schema:</p> <pre><code>{\n  \"filters\": {\n    \"id\": 123,        // optional: filter by author ID\n    \"name\": \"John\"    // optional: filter by author name (case-insensitive, partial match)\n  }\n}\n</code></pre> <p>Success Response:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 0,\n  \"meta\": null,\n  \"data\": [\n    {\n      \"id\": 1,\n      \"name\": \"John Doe\"\n    },\n    {\n      \"id\": 2,\n      \"name\": \"Jane Smith\"\n    }\n  ]\n}\n</code></pre> <p>Example Request:</p> <pre><code>const ws = new WebSocket('ws://localhost:8000/web?token=YOUR_TOKEN');\n\nws.onopen = () =&gt; {\n  ws.send(JSON.stringify({\n    pkg_id: 1,\n    req_id: crypto.randomUUID(),\n    method: \"\",\n    data: {\n      filters: {\n        name: \"John\"\n      }\n    }\n  }));\n};\n\nws.onmessage = (event) =&gt; {\n  const response = JSON.parse(event.data);\n  console.log('Authors:', response.data);\n};\n</code></pre> <p>Error Responses:</p> status_code Reason data.msg 1 Database error \"Database error occurred\" 2 Invalid filter parameters \"Invalid filter parameters\" 3 Permission denied \"Permission denied\""},{"location":"api-reference/websocket-api/#2-get_paginated_authors-pkgid-2","title":"2. GET_PAGINATED_AUTHORS (PkgID: 2)","text":"<p>Retrieves a paginated list of authors with optional filtering.</p> <p>Request Data Schema:</p> <pre><code>{\n  \"page\": 1,           // required: page number (&gt;=1)\n  \"per_page\": 20,      // required: items per page (&gt;=1)\n  \"filters\": {\n    \"id\": 123,         // optional: filter by author ID\n    \"name\": \"John\"     // optional: filter by author name\n  }\n}\n</code></pre> <p>Success Response:</p> <pre><code>{\n  \"pkg_id\": 2,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 0,\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 42,\n    \"pages\": 3\n  },\n  \"data\": [\n    {\n      \"id\": 1,\n      \"name\": \"John Doe\"\n    },\n    {\n      \"id\": 2,\n      \"name\": \"Jane Smith\"\n    }\n  ]\n}\n</code></pre> <p>Example Request:</p> <pre><code>ws.send(JSON.stringify({\n  pkg_id: 2,\n  req_id: crypto.randomUUID(),\n  method: \"\",\n  data: {\n    page: 1,\n    per_page: 20,\n    filters: {\n      name: \"Smith\"\n    }\n  }\n}));\n</code></pre> <p>Error Responses:</p> status_code Reason data.msg 1 Database error \"Database error occurred\" 2 Invalid pagination parameters \"Invalid pagination parameters\" 3 Permission denied \"Permission denied\""},{"location":"api-reference/websocket-api/#response-code-reference-rspcode","title":"Response Code Reference (RSPCode)","text":"Code Name Description 0 <code>OK</code> Operation completed successfully 1 <code>ERROR</code> General error occurred 2 <code>INVALID_DATA</code> Provided data is invalid or malformed 3 <code>PERMISSION_DENIED</code> User lacks required permissions for the operation"},{"location":"api-reference/websocket-api/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/websocket-api/#client-side-error-handling","title":"Client-Side Error Handling","text":"<pre><code>ws.onmessage = (event) =&gt; {\n  const response = JSON.parse(event.data);\n\n  if (response.status_code !== 0) {\n    // Handle error\n    switch (response.status_code) {\n      case 1:\n        console.error('Server error:', response.data.msg);\n        break;\n      case 2:\n        console.error('Invalid data:', response.data.msg);\n        // Validate and retry with corrected data\n        break;\n      case 3:\n        console.error('Permission denied:', response.data.msg);\n        // User needs different role or authentication\n        break;\n      default:\n        console.error('Unknown error:', response);\n    }\n    return;\n  }\n\n  // Success - process data\n  console.log('Success:', response.data);\n};\n\nws.onerror = (error) =&gt; {\n  console.error('WebSocket error:', error);\n};\n\nws.onclose = (event) =&gt; {\n  if (event.code === 1008) {\n    console.error('Connection rejected: Maximum concurrent connections exceeded');\n  } else if (event.code === 1003) {\n    console.error('Connection closed: Invalid message format');\n  } else {\n    console.log('Connection closed:', event.code, event.reason);\n  }\n};\n</code></pre>"},{"location":"api-reference/websocket-api/#common-connection-close-codes","title":"Common Connection Close Codes","text":"Code Reason Description 1000 Normal Closure Connection closed normally 1003 Unsupported Data Invalid message format 1008 Policy Violation Connection limit exceeded or rate limit violation 4001 Unauthorized Invalid or expired authentication token"},{"location":"api-reference/websocket-api/#broadcast-messages","title":"Broadcast Messages","text":"<p>The server may send unsolicited broadcast messages to all connected clients:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"00000000-0000-0000-0000-000000000000\",\n  \"data\": {\n    \"event\": \"update\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n  }\n}\n</code></pre> <p>Identifying Broadcasts: - <code>req_id</code> will be <code>00000000-0000-0000-0000-000000000000</code> (UUID with int=0) - Not correlated to any client request</p>"},{"location":"api-reference/websocket-api/#authentication_1","title":"Authentication","text":""},{"location":"api-reference/websocket-api/#obtaining-access-token","title":"Obtaining Access Token","text":"<p>Use the HTTP <code>/login</code> endpoint or Keycloak direct grant flow:</p> <pre><code>curl -X POST http://localhost:8000/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"username\": \"your_username\",\n    \"password\": \"your_password\"\n  }'\n</code></pre> <p>Response:</p> <pre><code>{\n  \"access_token\": \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"expires_in\": 300,\n  \"refresh_expires_in\": 1800,\n  \"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"token_type\": \"Bearer\"\n}\n</code></pre>"},{"location":"api-reference/websocket-api/#token-expiration","title":"Token Expiration","text":"<ul> <li>Access tokens expire after 5 minutes (300 seconds) by default</li> <li>Client must handle reconnection with refreshed token</li> <li>Monitor <code>exp</code> claim in JWT payload</li> </ul>"},{"location":"api-reference/websocket-api/#csrf-protection","title":"CSRF Protection","text":"<p>WebSocket connections are protected against Cross-Site WebSocket Hijacking (CSWSH) attacks through Origin header validation.</p>"},{"location":"api-reference/websocket-api/#how-it-works","title":"How It Works","text":"<p>Before accepting a WebSocket connection, the server validates the <code>Origin</code> header:</p> <ol> <li>If <code>ALLOWED_WS_ORIGINS</code> contains <code>\"*\"</code> \u2192 all origins permitted (development only)</li> <li>If no <code>Origin</code> header \u2192 same-origin request, allowed</li> <li>If origin matches an entry in <code>ALLOWED_WS_ORIGINS</code> \u2192 permitted</li> <li>Otherwise \u2192 connection rejected with code <code>1008</code> (Policy Violation)</li> </ol>"},{"location":"api-reference/websocket-api/#configuration","title":"Configuration","text":"<p>Configure allowed origins in your environment:</p> <pre><code># Development (.env.dev) - Allow all origins\nALLOWED_WS_ORIGINS=[\"*\"]\n\n# Production (.env.production) - Restrict to your domains\nALLOWED_WS_ORIGINS=[\"https://app.example.com\", \"https://admin.example.com\"]\n</code></pre>"},{"location":"api-reference/websocket-api/#attack-scenario-prevented","title":"Attack Scenario Prevented","text":"<pre><code>1. Attacker hosts malicious site: evil.com\n2. User visits evil.com while authenticated to your app\n3. evil.com attempts WebSocket connection to your server\n4. Server checks Origin header: \"https://evil.com\"\n5. Origin not in allowed list \u2192 connection rejected with code 1008\n</code></pre>"},{"location":"api-reference/websocket-api/#client-side-handling","title":"Client-Side Handling","text":"<p>Handle CSRF rejection in your WebSocket <code>onclose</code> handler:</p> <pre><code>ws.onclose = (event) =&gt; {\n  if (event.code === 1008) {\n    console.error('Connection rejected: Origin not allowed (CSRF protection)');\n    // This typically means you're connecting from an unauthorized domain\n  }\n};\n</code></pre>"},{"location":"api-reference/websocket-api/#security-recommendations","title":"Security Recommendations","text":"<ol> <li>Never use <code>[\"*\"]</code> in production - Always specify exact allowed origins</li> <li>Use HTTPS origins - Match the protocol used by your frontend</li> <li>Include all frontend domains - Add each domain that needs WebSocket access</li> <li>Update on domain changes - Keep <code>ALLOWED_WS_ORIGINS</code> in sync with your deployments</li> </ol>"},{"location":"api-reference/websocket-api/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<p>Each handler requires specific roles defined in its <code>@pkg_router.register()</code> decorator. Users must have the required role in their Keycloak token to access handlers.</p> <p>Implementation: <pre><code>@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    roles=[\"get-authors\"]  # Required roles\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n</code></pre></p> <p>Common Roles: - <code>get-authors</code>: View author list - <code>create-author</code>: Create new authors - <code>admin</code>: Administrative privileges</p> <p>Finding Role Requirements: Check the handler code in <code>app/api/ws/handlers/</code> to see which roles are required for each <code>PkgID</code>.</p>"},{"location":"api-reference/websocket-api/#best-practices","title":"Best Practices","text":""},{"location":"api-reference/websocket-api/#1-request-id-management","title":"1. Request ID Management","text":"<p>Always generate unique UUIDs for each request to correlate responses:</p> <pre><code>function generateRequestId() {\n  return crypto.randomUUID();\n}\n\nconst requestMap = new Map();\n\nfunction sendRequest(pkgId, data) {\n  const reqId = generateRequestId();\n  requestMap.set(reqId, { pkgId, timestamp: Date.now() });\n\n  ws.send(JSON.stringify({\n    pkg_id: pkgId,\n    req_id: reqId,\n    data: data\n  }));\n\n  return reqId;\n}\n\nws.onmessage = (event) =&gt; {\n  const response = JSON.parse(event.data);\n  const request = requestMap.get(response.req_id);\n\n  if (request) {\n    requestMap.delete(response.req_id);\n    // Process response with context\n  }\n};\n</code></pre>"},{"location":"api-reference/websocket-api/#2-connection-management","title":"2. Connection Management","text":"<p>Implement reconnection logic with exponential backoff:</p> <pre><code>let reconnectAttempts = 0;\nconst maxReconnectAttempts = 5;\n\nfunction connect() {\n  const ws = new WebSocket(`ws://localhost:8000/web?token=${token}`);\n\n  ws.onclose = (event) =&gt; {\n    if (reconnectAttempts &lt; maxReconnectAttempts) {\n      const delay = Math.min(1000 * Math.pow(2, reconnectAttempts), 30000);\n      setTimeout(() =&gt; {\n        reconnectAttempts++;\n        connect();\n      }, delay);\n    }\n  };\n\n  ws.onopen = () =&gt; {\n    reconnectAttempts = 0;\n  };\n}\n</code></pre>"},{"location":"api-reference/websocket-api/#3-token-refresh","title":"3. Token Refresh","text":"<p>Proactively refresh tokens before expiration:</p> <pre><code>function scheduleTokenRefresh(expiresIn) {\n  // Refresh 30 seconds before expiration\n  const refreshDelay = (expiresIn - 30) * 1000;\n\n  setTimeout(async () =&gt; {\n    const newToken = await refreshAccessToken();\n    // Reconnect with new token\n    ws.close(1000, 'Token refresh');\n    connect(newToken);\n  }, refreshDelay);\n}\n</code></pre>"},{"location":"api-reference/websocket-api/#4-message-validation","title":"4. Message Validation","text":"<p>Always validate responses before processing:</p> <pre><code>function isValidResponse(response) {\n  return (\n    response &amp;&amp;\n    typeof response.pkg_id === 'number' &amp;&amp;\n    typeof response.req_id === 'string' &amp;&amp;\n    typeof response.status_code === 'number'\n  );\n}\n\nws.onmessage = (event) =&gt; {\n  try {\n    const response = JSON.parse(event.data);\n    if (!isValidResponse(response)) {\n      console.error('Invalid response format:', response);\n      return;\n    }\n    // Process valid response\n  } catch (error) {\n    console.error('Failed to parse response:', error);\n  }\n};\n</code></pre>"},{"location":"api-reference/websocket-api/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api-reference/websocket-api/#rate-limiting_1","title":"Rate Limiting","text":"<p>To avoid hitting rate limits: - Batch requests when possible - Implement client-side throttling - Cache frequently requested data - Use pagination for large datasets</p>"},{"location":"api-reference/websocket-api/#connection-pooling","title":"Connection Pooling","text":"<p>For multi-user applications: - Reuse connections across requests - Implement connection pooling - Monitor connection count per user - Close idle connections</p>"},{"location":"api-reference/websocket-api/#pagination","title":"Pagination","text":"<p>For large result sets: - Always use paginated endpoints (<code>GET_PAGINATED_AUTHORS</code>) - Request reasonable page sizes (20-100 items) - Implement infinite scroll or pagination UI - Cache previous pages on client</p>"},{"location":"api-reference/websocket-api/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api-reference/websocket-api/#connection-refused","title":"Connection Refused","text":"<p>Problem: WebSocket connection fails with 403 Forbidden</p> <p>Solutions: - Verify token is valid and not expired - Check token is passed in query parameter: <code>?token=...</code> - Ensure user has required roles in Keycloak</p>"},{"location":"api-reference/websocket-api/#rate-limit-exceeded","title":"Rate Limit Exceeded","text":"<p>Problem: Receiving <code>RSPCode.ERROR</code> frequently</p> <p>Solutions: - Implement client-side rate limiting - Reduce message frequency - Check <code>WS_MESSAGE_RATE_LIMIT</code> server configuration</p>"},{"location":"api-reference/websocket-api/#invalid-data-errors","title":"Invalid Data Errors","text":"<p>Problem: Receiving <code>RSPCode.INVALID_DATA</code></p> <p>Solutions: - Validate data schema before sending - Check required fields are present - Ensure data types match schema - Review handler-specific documentation</p>"},{"location":"api-reference/websocket-api/#connection-drops","title":"Connection Drops","text":"<p>Problem: WebSocket disconnects frequently</p> <p>Solutions: - Implement reconnection logic - Check network stability - Monitor server logs for errors - Verify token hasn't expired</p>"},{"location":"api-reference/websocket-api/#support","title":"Support","text":"<p>For issues or questions: - Check application logs for detailed error messages - Review Keycloak configuration for authentication issues - Check handler decorator for RBAC requirements (e.g., <code>@pkg_router.register(roles=[...])</code>) - Enable debug logging: Set <code>LOG_LEVEL=DEBUG</code> in environment</p>"},{"location":"architecture/","title":"Architecture","text":"<p>Learn about the system architecture, design patterns, and technical decisions.</p>"},{"location":"architecture/#contents","title":"Contents","text":"<ul> <li>Overview - System architecture and component interactions</li> <li>Design Patterns - Repository, Command, and Dependency Injection patterns</li> <li>Request Flow - HTTP and WebSocket request processing</li> <li>RBAC System - Role-based access control implementation</li> </ul>"},{"location":"architecture/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>graph TB\n    Client[Client] --&gt;|HTTP/WS| Traefik[Traefik]\n    Traefik --&gt; App[FastAPI App]\n    App --&gt; PG[(PostgreSQL)]\n    App --&gt; Redis[(Redis)]\n    App --&gt; KC[Keycloak]</code></pre> <p>See Overview for detailed architecture documentation.</p>"},{"location":"architecture/database-schema/","title":"Database Schema","text":"<p>This document provides a comprehensive overview of the application's database schema, including entity-relationship diagrams, table structures, migration workflows, and best practices.</p>"},{"location":"architecture/database-schema/#overview","title":"Overview","text":"<p>The application uses PostgreSQL as its relational database with SQLModel (built on SQLAlchemy 2.0) for ORM functionality and Alembic for schema migrations. All models support async operations using SQLAlchemy's async engine.</p>"},{"location":"architecture/database-schema/#technology-stack","title":"Technology Stack","text":"<ul> <li>Database: PostgreSQL 17.2</li> <li>ORM: SQLModel 0.0.22 (SQLAlchemy 2.0+ async)</li> <li>Migrations: Alembic 1.14.0</li> <li>Connection Pooling: SQLAlchemy async engine with connection pool</li> <li>Session Management: AsyncSession with context managers</li> </ul>"},{"location":"architecture/database-schema/#entity-relationship-diagram","title":"Entity-Relationship Diagram","text":"<p>The database schema consists of two primary tables: <code>author</code> (example domain entity) and <code>user_actions</code> (audit logs).</p> <pre><code>erDiagram\n    author {\n        INTEGER id PK \"Auto-increment primary key\"\n        VARCHAR name \"Author name\"\n    }\n\n    user_actions {\n        INTEGER id PK \"Auto-increment primary key\"\n        TIMESTAMP timestamp \"UTC timestamp with index\"\n        VARCHAR user_id \"Keycloak user ID (indexed)\"\n        VARCHAR username \"Username (indexed)\"\n        JSON user_roles \"User roles array\"\n        VARCHAR action_type \"HTTP method or WS PkgID (indexed)\"\n        VARCHAR resource \"Resource accessed\"\n        VARCHAR outcome \"success, error, permission_denied (indexed)\"\n        VARCHAR ip_address \"Client IP (IPv4/IPv6)\"\n        TEXT user_agent \"Browser/client user agent\"\n        VARCHAR request_id \"Correlation UUID (indexed)\"\n        JSON request_data \"Sanitized request payload\"\n        INTEGER response_status \"HTTP or WebSocket status code\"\n        TEXT error_message \"Error details if failed\"\n        INTEGER duration_ms \"Processing duration in milliseconds\"\n    }</code></pre>"},{"location":"architecture/database-schema/#database-indexes","title":"Database Indexes","text":"<p>Efficient query performance is achieved through strategic indexing:</p> <p><code>author</code> table: - Primary key: <code>id</code> (auto-increment)</p> <p><code>user_actions</code> table: - Primary key: <code>id</code> (auto-increment) - Single-column indexes:   - <code>timestamp</code> - For time-range queries   - <code>user_id</code> - For user activity lookups   - <code>username</code> - For filtering by username   - <code>action_type</code> - For action type filtering   - <code>outcome</code> - For filtering by success/error/denied   - <code>request_id</code> - For request correlation - Composite indexes:   - <code>idx_user_timestamp</code> (<code>user_id</code>, <code>timestamp</code>) - User activity timeline   - <code>idx_user_action</code> (<code>user_id</code>, <code>action_type</code>) - User-specific action filtering</p>"},{"location":"architecture/database-schema/#table-schemas","title":"Table Schemas","text":""},{"location":"architecture/database-schema/#author-table","title":"<code>author</code> Table","text":"<p>Domain entity representing authors in the system. This is a simple example table demonstrating the Repository + Command pattern.</p> Column Type Constraints Description <code>id</code> INTEGER PRIMARY KEY, AUTO_INCREMENT Unique identifier <code>name</code> VARCHAR NOT NULL Author name <p>Model Definition: app/models/author.py</p> <p>Key Features: - Inherits from <code>BaseModel</code> for async relationship support - Clean data model without Active Record methods - Database operations handled by <code>AuthorRepository</code> - Used in examples for demonstrating CRUD operations</p> <p>Example Usage: <pre><code>from app.models.author import Author\nfrom app.repositories.author_repository import AuthorRepository\nfrom app.storage.db import async_session\n\nasync with async_session() as session:\n    repo = AuthorRepository(session)\n    author = await repo.create(Author(name=\"J.R.R. Tolkien\"))\n</code></pre></p>"},{"location":"architecture/database-schema/#user_actions-table","title":"<code>user_actions</code> Table","text":"<p>Comprehensive audit log for tracking all user activities across the application. Critical for security, compliance, debugging, and analytics.</p> Column Type Constraints Description <code>id</code> INTEGER PRIMARY KEY, AUTO_INCREMENT Unique log entry identifier <code>timestamp</code> TIMESTAMP WITH TIMEZONE NOT NULL, INDEXED UTC timestamp when action occurred <code>user_id</code> VARCHAR(255) NOT NULL, INDEXED Keycloak user ID (sub claim from JWT) <code>username</code> VARCHAR(255) NOT NULL, INDEXED Human-readable username (preferred_username) <code>user_roles</code> JSON NOT NULL Array of roles user had at time of action <code>action_type</code> VARCHAR(100) NOT NULL, INDEXED HTTP method (GET, POST) or WebSocket PkgID <code>resource</code> VARCHAR(500) NOT NULL Resource accessed (URL path or entity ID) <code>outcome</code> VARCHAR(50) NOT NULL, INDEXED Result: success, error, permission_denied <code>ip_address</code> VARCHAR(45) NULLABLE Client IP address (IPv4 or IPv6) <code>user_agent</code> TEXT NULLABLE Browser/client user agent string <code>request_id</code> VARCHAR(100) NULLABLE, INDEXED UUID for request correlation across services <code>request_data</code> JSON NULLABLE Sanitized request payload (sensitive data redacted) <code>response_status</code> INTEGER NULLABLE HTTP status code or WebSocket response code <code>error_message</code> TEXT NULLABLE Error details if action failed <code>duration_ms</code> INTEGER NULLABLE Request processing duration in milliseconds <p>Model Definition: app/models/user_action.py</p> <p>Key Features: - Immutable audit trail (insert-only, no updates/deletes) - JSON columns for flexible data storage - Comprehensive indexing for fast queries - Timezone-aware timestamps (UTC) - Proxy-aware IP address tracking - Request correlation via <code>request_id</code></p> <p>Example Queries:</p> <pre><code>-- Find all failed actions for a specific user\nSELECT timestamp, action_type, resource, error_message\nFROM user_actions\nWHERE username = 'acika'\n  AND outcome IN ('error', 'permission_denied')\n  AND timestamp &gt; NOW() - INTERVAL '24 hours'\nORDER BY timestamp DESC;\n\n-- Analyze slow operations (&gt;1 second)\nSELECT action_type, AVG(duration_ms), MAX(duration_ms), COUNT(*)\nFROM user_actions\nWHERE duration_ms &gt; 1000\n  AND timestamp &gt; NOW() - INTERVAL '7 days'\nGROUP BY action_type\nORDER BY AVG(duration_ms) DESC;\n\n-- Track user activity timeline\nSELECT\n  DATE_TRUNC('hour', timestamp) AS hour,\n  COUNT(*) AS events,\n  COUNT(CASE WHEN outcome = 'error' THEN 1 END) AS errors\nFROM user_actions\nWHERE user_id = 'user-uuid-here'\n  AND timestamp &gt; NOW() - INTERVAL '24 hours'\nGROUP BY hour\nORDER BY hour;\n</code></pre>"},{"location":"architecture/database-schema/#database-migrations","title":"Database Migrations","text":""},{"location":"architecture/database-schema/#migration-system","title":"Migration System","text":"<p>The application uses Alembic for schema version control. All schema changes are managed through migration files stored in app/storage/migrations/versions/.</p> <pre><code>graph LR\n    A[Modify SQLModel] --&gt; B[Generate Migration]\n    B --&gt; C[Review Migration File]\n    C --&gt; D{Changes OK?}\n    D --&gt;|No| E[Edit Migration]\n    D --&gt;|Yes| F[Apply Migration]\n    E --&gt; F\n    F --&gt; G[Test Database]\n    G --&gt; H{Tests Pass?}\n    H --&gt;|No| I[Rollback]\n    H --&gt;|Yes| J[Commit Changes]\n    I --&gt; E</code></pre>"},{"location":"architecture/database-schema/#migration-workflow","title":"Migration Workflow","text":""},{"location":"architecture/database-schema/#1-creating-new-migrations","title":"1. Creating New Migrations","text":"<p>When you modify a SQLModel (add/remove/change columns), generate a migration:</p> <pre><code># Generate migration after model changes\nmake migration msg=\"Add email field to Author\"\n\n# Or use alembic directly\nalembic -c app/storage/alembic.ini revision --autogenerate -m \"Add email field to Author\"\n</code></pre> <p>This creates a new file in <code>app/storage/migrations/versions/</code> with upgrade/downgrade logic.</p>"},{"location":"architecture/database-schema/#2-reviewing-migrations","title":"2. Reviewing Migrations","text":"<p>CRITICAL: Always review generated migrations before applying them.</p> <pre><code># View the generated migration file\ncat app/storage/migrations/versions/XXXX_description.py\n\n# Check migration structure\nuv run pytest tests/test_migrations.py -v\n</code></pre> <p>Common issues to check: - Verify column types are correct - Check for unintended table drops - Ensure indexes are created efficiently - Validate foreign key constraints - Review data migrations (if any)</p>"},{"location":"architecture/database-schema/#3-applying-migrations","title":"3. Applying Migrations","text":"<pre><code># Apply all pending migrations\nmake migrate\n\n# Or use alembic directly\nalembic -c app/storage/alembic.ini upgrade head\n\n# Apply specific number of migrations\nalembic -c app/storage/alembic.ini upgrade +1\n</code></pre>"},{"location":"architecture/database-schema/#4-rolling-back-migrations","title":"4. Rolling Back Migrations","text":"<p>If a migration causes issues:</p> <pre><code># Rollback last migration\nmake rollback\n\n# Or use alembic directly\nalembic -c app/storage/alembic.ini downgrade -1\n\n# Rollback to specific revision\nalembic -c app/storage/alembic.ini downgrade &lt;revision_id&gt;\n</code></pre>"},{"location":"architecture/database-schema/#5-viewing-migration-history","title":"5. Viewing Migration History","text":"<pre><code># View migration history\nmake migration-history\n\n# Check current database version\nmake migration-current\n\n# Show pending migrations\nalembic -c app/storage/alembic.ini current\nalembic -c app/storage/alembic.ini heads\n</code></pre>"},{"location":"architecture/database-schema/#existing-migrations","title":"Existing Migrations","text":"<p>The application has the following migrations (in chronological order):</p> <ol> <li><code>94cef3eb6eae</code> - \"Add user_actions table for audit logging\"</li> <li>Creates <code>user_actions</code> table with all columns</li> <li>Adds indexes: <code>timestamp</code>, <code>user_id</code>, <code>username</code>, <code>action_type</code>, <code>outcome</code>, <code>request_id</code></li> <li> <p>Adds composite indexes: <code>idx_user_timestamp</code>, <code>idx_user_action</code></p> </li> <li> <p><code>b857e3e16921</code> - \"Add author table\"</p> </li> <li>Creates <code>author</code> table</li> <li>Simple structure: <code>id</code> (PK) and <code>name</code></li> </ol>"},{"location":"architecture/database-schema/#migration-testing","title":"Migration Testing","text":"<p>Migrations are automatically tested to ensure they can be applied and rolled back cleanly.</p> <p>Automated Testing: <pre><code># Run migration tests manually\nmake test-migrations\n\n# Run pytest-based structure tests\nuv run pytest tests/test_migrations.py -v\n</code></pre></p> <p>What Gets Tested: 1. Upgrade/Downgrade Cycle - Migrations can be applied and reverted 2. Migration Structure - All revision IDs are unique 3. Docstrings - All migrations have descriptive docstrings 4. No Conflicts - No branching conflicts in migration history 5. Dependencies - All migrations (except first) have <code>down_revision</code></p> <p>Pre-commit Hook: Migration structure tests run automatically when migration files are modified during commit. The hook prevents commits if migrations have structural issues.</p>"},{"location":"architecture/database-schema/#adding-new-models","title":"Adding New Models","text":"<p>When creating a new SQLModel table, you must import it in the migrations environment:</p> <p>File: app/storage/migrations/env.py</p> <pre><code># Import all models for Alembic autogenerate\nfrom app.models.author import Author  # noqa: F401\nfrom app.models.user_action import UserAction  # noqa: F401\nfrom app.models.your_new_model import YourNewModel  # noqa: F401  # ADD THIS\n</code></pre> <p>Without this import, Alembic won't detect your new model when generating migrations.</p>"},{"location":"architecture/database-schema/#database-connection-management","title":"Database Connection Management","text":""},{"location":"architecture/database-schema/#connection-configuration","title":"Connection Configuration","text":"<p>Database connections are configured via environment variables in <code>docker/.db_env</code>:</p> <pre><code># PostgreSQL Configuration\nPOSTGRES_USER=postgres\nPOSTGRES_PASSWORD=hwdev123!@#\nPOSTGRES_DB=hwdb\n\n# Connection Settings (app/settings.py)\nDB_HOST=hw-db\nDB_PORT=5432\nDB_NAME=hwdb\nDB_USER=postgres\nDB_PASSWORD=hwdev123!@#\n</code></pre>"},{"location":"architecture/database-schema/#connection-url-format","title":"Connection URL Format","text":"<pre><code>postgresql+asyncpg://user:password@host:port/database\n</code></pre> <p>Example: <code>postgresql+asyncpg://postgres:hwdev123!@#@hw-db:5432/hwdb</code></p>"},{"location":"architecture/database-schema/#async-engine-and-session","title":"Async Engine and Session","text":"<p>The application uses SQLAlchemy's async engine with connection pooling:</p> <pre><code>from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nfrom sqlalchemy.orm import sessionmaker\nfrom app.settings import settings\n\n# Create async engine with connection pool\nengine = create_async_engine(\n    settings.SQLALCHEMY_DATABASE_URI,\n    echo=False,  # Set to True for SQL query logging\n    pool_size=20,\n    max_overflow=10,\n    pool_pre_ping=True,  # Verify connections before use\n)\n\n# Async session factory\nasync_session = sessionmaker(\n    engine,\n    class_=AsyncSession,\n    expire_on_commit=False,\n)\n</code></pre>"},{"location":"architecture/database-schema/#session-usage-patterns","title":"Session Usage Patterns","text":"<p>HTTP Endpoints: <pre><code>from app.storage.db import async_session\n\n@router.post(\"/authors\")\nasync def create_author(author: Author) -&gt; Author:\n    async with async_session() as session:\n        async with session.begin():  # Automatic commit on success\n            session.add(author)\n            await session.flush()\n            await session.refresh(author)\n            return author\n</code></pre></p> <p>WebSocket Handlers: <pre><code>async def my_handler(request: RequestModel) -&gt; ResponseModel:\n    async with async_session() as session:\n        repo = MyModelRepository(session)\n        items = await repo.get_all()\n        return ResponseModel.success(\n            request.pkg_id,\n            request.req_id,\n            data=[item.model_dump() for item in items]\n        )\n</code></pre></p> <p>Repository Pattern: <pre><code>from app.repositories.author_repository import AuthorRepository\n\nasync with async_session() as session:\n    repo = AuthorRepository(session)\n    authors = await repo.get_all()\n</code></pre></p>"},{"location":"architecture/database-schema/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"architecture/database-schema/#query-monitoring","title":"Query Monitoring","text":"<p>The application includes automatic slow query detection to identify performance bottlenecks.</p> <p>How It Works: - SQLAlchemy event listeners track query execution time - Queries exceeding 100ms threshold are logged as warnings - Metrics exported to Prometheus for monitoring</p> <p>Configuration: <pre><code># app/utils/query_monitor.py\nSLOW_QUERY_THRESHOLD = 0.1  # 100ms\n</code></pre></p> <p>Prometheus Metrics: - <code>db_query_duration_seconds{operation=\"select|insert|update|delete\"}</code> - Query duration histogram - <code>db_slow_queries_total{operation=\"select|insert|update|delete\"}</code> - Slow query counter</p> <p>Example Log: <pre><code>WARNING - Slow query detected: 0.245s [SELECT] Statement: SELECT * FROM authors WHERE ...\n</code></pre></p>"},{"location":"architecture/database-schema/#pagination-count-caching","title":"Pagination Count Caching","text":"<p>For large tables, <code>COUNT(*)</code> queries can be expensive. The application caches pagination counts in Redis.</p> <p>How It Works: 1. First request: Execute <code>COUNT(*)</code> query, cache result in Redis (5-minute TTL) 2. Subsequent requests: Return cached count (99% faster) 3. After data changes: Invalidate cache for that model</p> <p>Usage: <pre><code>from app.storage.db import get_paginated_results\n\n# Cached count (default)\nresults, meta = await get_paginated_results(\n    Author,\n    page=1,\n    per_page=20\n)\n\n# Skip count entirely (for infinite scroll)\nresults, meta = await get_paginated_results(\n    Author,\n    page=1,\n    per_page=20,\n    skip_count=True  # meta.total will be 0\n)\n</code></pre></p> <p>Cache Invalidation: <pre><code>from app.utils.pagination_cache import invalidate_count_cache\nfrom app.repositories.author_repository import AuthorRepository\n\nasync def create_author(author: Author, repo: AuthorRepository) -&gt; Author:\n    result = await repo.create(author)\n    await invalidate_count_cache(\"Author\")  # Invalidate cache\n    return result\n</code></pre></p> <p>Performance Comparison:</p> Table Size Without Cache With Cache Improvement 1,000 rows 5ms 1ms 80% faster 10,000 rows 45ms 1ms 98% faster 100,000 rows 450ms 1ms 99.8% faster"},{"location":"architecture/database-schema/#database-indexes_1","title":"Database Indexes","text":"<p>Strategic indexing is critical for query performance:</p> <p>Best Practices: 1. Index frequently filtered columns: <code>WHERE</code>, <code>JOIN</code>, <code>ORDER BY</code> clauses 2. Composite indexes for common queries: <code>(user_id, timestamp)</code> for user timelines 3. Avoid over-indexing: Each index slows down writes 4. Use partial indexes: For conditional queries (<code>WHERE status = 'active'</code>) 5. Monitor index usage: PostgreSQL <code>pg_stat_user_indexes</code> view</p> <p>Example Indexes: <pre><code>-- Single-column index\nCREATE INDEX idx_user_id ON user_actions(user_id);\n\n-- Composite index (order matters!)\nCREATE INDEX idx_user_timestamp ON user_actions(user_id, timestamp);\n\n-- Partial index (only active users)\nCREATE INDEX idx_active_users ON users(email) WHERE status = 'active';\n</code></pre></p>"},{"location":"architecture/database-schema/#eager-loading-relationships","title":"Eager Loading Relationships","text":"<p>Prevent N+1 query problems by eager loading relationships:</p> <pre><code>from sqlalchemy.orm import selectinload\n\n# Bad: N+1 queries (1 for authors + N for each author's books)\nauthors = await session.exec(select(Author))\nfor author in authors:\n    books = await author.awaitable_attrs.books  # Separate query per author\n\n# Good: 2 optimized queries (1 for authors + 1 for all books)\nstmt = select(Author).options(selectinload(Author.books))\nauthors = await session.exec(stmt)\nfor author in authors:\n    books = author.books  # Already loaded, no query\n</code></pre> <p>Loading Strategies: - <code>selectinload()</code> - Separate optimized SELECT query (best for one-to-many) - <code>joinedload()</code> - Single query with JOIN (best for many-to-one) - <code>subqueryload()</code> - Subquery approach (for complex relationships)</p>"},{"location":"architecture/database-schema/#async-relationship-handling","title":"Async Relationship Handling","text":"<p>All table models that may have relationships inherit from <code>BaseModel</code>, which includes SQLAlchemy's <code>AsyncAttrs</code> mixin.</p>"},{"location":"architecture/database-schema/#basemodel-pattern","title":"BaseModel Pattern","text":"<pre><code>from sqlalchemy.ext.asyncio import AsyncAttrs\nfrom sqlmodel import SQLModel\n\nclass BaseModel(SQLModel, AsyncAttrs):\n    \"\"\"Base model with async relationship support.\"\"\"\n    pass\n\n# All models inherit from BaseModel\nclass Author(BaseModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    books: list[\"Book\"] = Relationship(back_populates=\"author\")\n</code></pre>"},{"location":"architecture/database-schema/#accessing-relationships","title":"Accessing Relationships","text":"<p>Preferred: Eager Loading (Best Performance) <pre><code>from sqlalchemy.orm import selectinload\n\nstmt = select(Author).options(selectinload(Author.books))\nauthor = await session.execute(stmt).scalar_one()\nbooks = author.books  # Already loaded, no await needed\n</code></pre></p> <p>Alternative: Lazy Loading (When Needed) <pre><code>author = await session.get(Author, 1)\nbooks = await author.awaitable_attrs.books  # Awaitable accessor\n</code></pre></p> <p>Rule of Thumb: - \u2705 Use eager loading (<code>selectinload</code>, <code>joinedload</code>) for better performance - \u26a0\ufe0f Use <code>awaitable_attrs</code> only for dynamic relationship access</p>"},{"location":"architecture/database-schema/#database-initialization","title":"Database Initialization","text":""},{"location":"architecture/database-schema/#application-startup","title":"Application Startup","text":"<p>Database initialization happens automatically on application startup with retry logic:</p> <pre><code># app/storage/db.py\nasync def wait_and_init_db():\n    \"\"\"Wait for database and run migrations with retry logic.\"\"\"\n    for attempt in range(DB_MAX_RETRIES):\n        try:\n            # Test connection\n            async with engine.begin() as conn:\n                await conn.execute(text(\"SELECT 1\"))\n\n            # Run migrations\n            alembic_cfg = Config(\"app/storage/alembic.ini\")\n            command.upgrade(alembic_cfg, \"head\")\n\n            logger.info(\"Database initialized successfully\")\n            return\n        except Exception as e:\n            if attempt &lt; DB_MAX_RETRIES - 1:\n                await asyncio.sleep(DB_RETRY_DELAY_SECONDS)\n            else:\n                raise\n</code></pre> <p>Retry Configuration: - <code>DB_MAX_RETRIES = 5</code> - Maximum connection attempts - <code>DB_RETRY_DELAY_SECONDS = 5</code> - Delay between retries</p>"},{"location":"architecture/database-schema/#docker-compose-health-checks","title":"Docker Compose Health Checks","text":"<p>PostgreSQL container includes health checks to ensure readiness:</p> <pre><code>hw-db:\n  image: postgres:17.2-alpine\n  healthcheck:\n    test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n    interval: 10s\n    timeout: 5s\n    retries: 5\n</code></pre> <p>Application waits for database health check before starting:</p> <pre><code>shell:\n  depends_on:\n    hw-db:\n      condition: service_healthy\n</code></pre>"},{"location":"architecture/database-schema/#best-practices","title":"Best Practices","text":""},{"location":"architecture/database-schema/#model-design","title":"Model Design","text":"<ol> <li>Inherit from BaseModel: All table models should extend <code>BaseModel</code> for async support</li> <li>Use type hints: Full type annotations for all columns</li> <li>Document models: Comprehensive docstrings explaining purpose and attributes</li> <li>Avoid Active Record: Keep models as data containers, use repositories for operations</li> <li>Use Field constraints: Leverage <code>max_length</code>, <code>index</code>, <code>unique</code>, <code>nullable</code></li> </ol>"},{"location":"architecture/database-schema/#session-management","title":"Session Management","text":"<ol> <li>Always use context managers: <code>async with async_session() as session:</code></li> <li>Pass sessions to methods: Don't create sessions inside models</li> <li>Use transactions explicitly: <code>async with session.begin():</code></li> <li>Avoid long-lived sessions: Keep session scope minimal</li> <li>Don't mix sync and async: Use async methods consistently</li> </ol>"},{"location":"architecture/database-schema/#migration-management","title":"Migration Management","text":"<ol> <li>Review all migrations: Never blindly apply autogenerated migrations</li> <li>Test migrations locally: Use <code>make test-migrations</code> before committing</li> <li>Write reversible migrations: Always implement <code>downgrade()</code></li> <li>Use descriptive messages: Clear migration names for easy identification</li> <li>Backup before production migrations: Always have a rollback plan</li> </ol>"},{"location":"architecture/database-schema/#performance","title":"Performance","text":"<ol> <li>Use eager loading: Prevent N+1 queries with <code>selectinload()</code></li> <li>Index strategically: Balance read performance vs write overhead</li> <li>Cache expensive queries: Use Redis for pagination counts</li> <li>Monitor slow queries: Set up alerts for queries &gt;100ms</li> <li>Use database connection pooling: Configure <code>pool_size</code> and <code>max_overflow</code></li> </ol>"},{"location":"architecture/database-schema/#security","title":"Security","text":"<ol> <li>Sanitize audit data: Redact sensitive information before logging</li> <li>Use parameterized queries: Never build SQL strings with user input</li> <li>Validate input: Use Pydantic models for request validation</li> <li>Limit exposed data: Only return necessary columns in API responses</li> <li>Rotate credentials: Regularly update database passwords</li> </ol>"},{"location":"architecture/database-schema/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/database-schema/#common-issues","title":"Common Issues","text":"<p>1. \"MissingGreenlet\" Error</p> <p>Symptom: <code>sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called</code></p> <p>Cause: Accessing lazy-loaded relationships without <code>await</code></p> <p>Solution: <pre><code># Bad\nbooks = author.books  # MissingGreenlet error\n\n# Good (eager loading)\nstmt = select(Author).options(selectinload(Author.books))\nauthor = await session.execute(stmt).scalar_one()\nbooks = author.books\n\n# Or (lazy loading)\nbooks = await author.awaitable_attrs.books\n</code></pre></p> <p>2. Migration Conflicts</p> <p>Symptom: <code>alembic.util.exc.CommandError: Multiple head revisions are present</code></p> <p>Cause: Conflicting migrations from multiple branches</p> <p>Solution: <pre><code># View all heads\nalembic heads\n\n# Merge heads\nalembic merge heads -m \"Merge migration branches\"\n</code></pre></p> <p>3. Connection Pool Exhausted</p> <p>Symptom: <code>TimeoutError: QueuePool limit of size X overflow Y reached</code></p> <p>Cause: Not closing sessions or holding sessions too long</p> <p>Solution: <pre><code># Always use context managers\nasync with async_session() as session:\n    # Your code here\n    pass\n# Session automatically closed here\n</code></pre></p> <p>4. Slow Pagination on Large Tables</p> <p>Symptom: Slow API responses for paginated endpoints</p> <p>Cause: Expensive <code>COUNT(*)</code> queries on large tables</p> <p>Solution: <pre><code># Enable count caching\nresults, meta = await get_paginated_results(\n    Model,\n    page=1,\n    per_page=20\n)  # Automatically uses Redis cache\n\n# Or skip count for infinite scroll\nresults, meta = await get_paginated_results(\n    Model,\n    page=1,\n    per_page=20,\n    skip_count=True\n)\n</code></pre></p>"},{"location":"architecture/database-schema/#diagnostic-queries","title":"Diagnostic Queries","text":"<pre><code>-- Check table sizes\nSELECT\n  schemaname,\n  tablename,\n  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size\nFROM pg_tables\nWHERE schemaname = 'public'\nORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;\n\n-- Check index usage\nSELECT\n  schemaname,\n  tablename,\n  indexname,\n  idx_scan AS index_scans,\n  idx_tup_read AS tuples_read,\n  idx_tup_fetch AS tuples_fetched\nFROM pg_stat_user_indexes\nORDER BY idx_scan DESC;\n\n-- Find unused indexes\nSELECT\n  schemaname,\n  tablename,\n  indexname\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\n  AND indexname NOT LIKE '%_pkey';\n\n-- Check active connections\nSELECT\n  state,\n  COUNT(*)\nFROM pg_stat_activity\nGROUP BY state;\n</code></pre>"},{"location":"architecture/database-schema/#related-documentation","title":"Related Documentation","text":"<ul> <li>Database Migrations Guide - Detailed migration workflow</li> <li>Repository Pattern - Database access patterns</li> <li>Performance Optimization - Query optimization techniques</li> <li>Docker Services - PostgreSQL container configuration</li> <li>Monitoring - Database metrics and alerting</li> </ul>"},{"location":"architecture/design-patterns/","title":"Design Patterns Guide","text":"<p>Status: \u2705 Implemented Date: 2025-12-05 Issue: #29</p>"},{"location":"architecture/design-patterns/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Why These Patterns?</li> <li>Pattern 1: Dependency Injection</li> <li>Pattern 2: Repository Pattern</li> <li>Pattern 3: Command Pattern</li> <li>Complete Example: Author Feature</li> <li>Testing Strategies</li> <li>Migration Guide</li> <li>Best Practices</li> </ul>"},{"location":"architecture/design-patterns/#overview","title":"Overview","text":"<p>This guide explains the modern design patterns implemented in this FastAPI application. These patterns improve code quality through:</p> <ul> <li>Testability - Easy to mock and test in isolation</li> <li>Reusability - Share logic across HTTP and WebSocket handlers</li> <li>Maintainability - Clear separation of concerns</li> <li>Type Safety - Full type hints and IDE support</li> <li>Flexibility - Easy to swap implementations</li> </ul>"},{"location":"architecture/design-patterns/#pattern-summary","title":"Pattern Summary","text":"Pattern Purpose Location Dependency Injection Manage dependencies without singletons <code>app/dependencies.py</code> Repository Abstract data access <code>app/repositories/</code> Command Encapsulate business logic <code>app/commands/</code>"},{"location":"architecture/design-patterns/#why-these-patterns","title":"Why These Patterns?","text":""},{"location":"architecture/design-patterns/#problems-with-old-approach","title":"Problems with Old Approach","text":""},{"location":"architecture/design-patterns/#singleton-pattern-metaclass","title":"\u274c Singleton Pattern (Metaclass)","text":"<pre><code># OLD: app/managers/rbac_manager.py\nfrom app.utils.singleton import SingletonMeta\n\nclass RBACManager(metaclass=SingletonMeta):\n    def __init__(self):\n        self.config = load_config()\n\n# Usage - hidden dependency!\nrbac = RBACManager()  # Always returns same instance\n</code></pre> <p>Problems: - Hard to test (global mutable state) - Can't override/mock easily - Hidden dependencies - Not compatible with FastAPI's DI</p>"},{"location":"architecture/design-patterns/#active-record-pattern","title":"\u274c Active Record Pattern","text":"<pre><code># OLD: app/models/author.py\nclass Author(SQLModel, table=True):\n    id: int | None = None\n    name: str\n\n    @classmethod\n    async def create(cls, session: AsyncSession, author: \"Author\"):\n        # Data access mixed with model definition\n        session.add(author)\n        await session.flush()\n        return author\n</code></pre> <p>Problems: - Violates Single Responsibility Principle - Can't test business logic without database - Hard to swap data sources - Business logic tied to data structure</p>"},{"location":"architecture/design-patterns/#current-pattern-repository-command-dependency-injection","title":"\u2705 Current Pattern: Repository + Command + Dependency Injection","text":"<pre><code>graph LR\n    Handler[HTTP/WebSocket&lt;br/&gt;Handler] --&gt; Command[Command&lt;br/&gt;Business Logic]\n    Command --&gt; Repository[Repository&lt;br/&gt;Data Access]\n    Repository --&gt; DB[(Database)]\n\n    DI[Dependency&lt;br/&gt;Injection] -.-&gt; Repository\n    DI -.-&gt; Command\n\n    style Handler fill:#cce5ff\n    style Command fill:#d4edda\n    style Repository fill:#fff3cd\n    style DB fill:#f8d7da\n    style DI fill:#e1f5ff,stroke-dasharray: 5 5</code></pre> <p>Clean separation of concerns: <pre><code>Repository (data access) \u2192 Command (business logic) \u2192 Handler (protocol)\n</code></pre></p> <p>Benefits: - Reusable business logic across HTTP and WebSocket - Easy to test without database - Clear separation of concerns</p>"},{"location":"architecture/design-patterns/#pattern-1-dependency-injection","title":"Pattern 1: Dependency Injection","text":""},{"location":"architecture/design-patterns/#overview_1","title":"Overview","text":"<p>Replace singleton pattern with FastAPI's dependency injection system.</p>"},{"location":"architecture/design-patterns/#implementation","title":"Implementation","text":"<p>File: <code>app/dependencies.py</code></p> <pre><code>from functools import lru_cache\nfrom typing import Annotated\nfrom fastapi import Depends\nfrom app.managers.rbac_manager import RBACManager\n\n# Use @lru_cache for singleton behavior\n@lru_cache\ndef get_rbac_manager() -&gt; RBACManager:\n    \"\"\"Get cached RBAC manager instance.\"\"\"\n    return RBACManager()\n\n# Type-safe dependency annotation\nRBACDep = Annotated[RBACManager, Depends(get_rbac_manager)]\n</code></pre>"},{"location":"architecture/design-patterns/#usage","title":"Usage","text":"<p>HTTP Handler: <pre><code>from app.dependencies import RBACDep, AuthorRepoDep\n\n@router.get(\"/authors\")\nasync def get_authors(\n    rbac: RBACDep,  # Injected automatically!\n    repo: AuthorRepoDep,\n) -&gt; list[Author]:\n    # Dependencies are explicitly declared\n    return await repo.get_all()\n</code></pre></p> <p>WebSocket Handler: <pre><code># WebSocket can't use Depends(), so instantiate manually\nasync def ws_handler(request: RequestModel):\n    async with async_session() as session:\n        repo = AuthorRepository(session)\n        # Use repository...\n</code></pre></p>"},{"location":"architecture/design-patterns/#testing","title":"Testing","text":"<pre><code>def test_endpoint():\n    # Override dependency for testing\n    app.dependency_overrides[get_rbac_manager] = lambda: MockRBAC()\n\n    # Test with mocked dependency\n    response = client.get(\"/authors\")\n</code></pre>"},{"location":"architecture/design-patterns/#benefits","title":"Benefits","text":"<p>\u2705 Testable - Can override with mocks \u2705 Explicit - Dependencies clearly declared \u2705 Type-safe - IDE autocomplete and type checking \u2705 Flexible - Easy to swap implementations</p>"},{"location":"architecture/design-patterns/#pattern-2-repository-pattern","title":"Pattern 2: Repository Pattern","text":""},{"location":"architecture/design-patterns/#overview_2","title":"Overview","text":"<p>Separate data access logic from business logic by encapsulating all database operations in repository classes.</p>"},{"location":"architecture/design-patterns/#implementation_1","title":"Implementation","text":"<p>Base Repository: <code>app/repositories/base.py</code></p> <pre><code>from typing import Generic, Type, TypeVar\nfrom sqlmodel import select\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\nT = TypeVar(\"T\")\n\nclass BaseRepository(Generic[T]):\n    \"\"\"Generic repository with common CRUD operations.\"\"\"\n\n    def __init__(self, session: AsyncSession, model: Type[T]):\n        self.session = session\n        self.model = model\n\n    async def get_by_id(self, id: int) -&gt; T | None:\n        return await self.session.get(self.model, id)\n\n    async def get_all(self, **filters) -&gt; list[T]:\n        stmt = select(self.model)\n        for key, value in filters.items():\n            if value is not None:\n                stmt = stmt.where(getattr(self.model, key) == value)\n        result = await self.session.exec(stmt)\n        return list(result.all())\n\n    async def create(self, entity: T) -&gt; T:\n        self.session.add(entity)\n        await self.session.flush()\n        await self.session.refresh(entity)\n        return entity\n\n    async def update(self, entity: T) -&gt; T:\n        self.session.add(entity)\n        await self.session.flush()\n        await self.session.refresh(entity)\n        return entity\n\n    async def delete(self, entity: T) -&gt; None:\n        await self.session.delete(entity)\n        await self.session.flush()\n\n    async def exists(self, **filters) -&gt; bool:\n        stmt = select(self.model)\n        for key, value in filters.items():\n            if value is not None:\n                stmt = stmt.where(getattr(self.model, key) == value)\n        result = await self.session.exec(stmt)\n        return result.first() is not None\n</code></pre> <p>Specific Repository: <code>app/repositories/author_repository.py</code></p> <pre><code>from app.models.author import Author\nfrom app.repositories.base import BaseRepository\n\nclass AuthorRepository(BaseRepository[Author]):\n    \"\"\"Repository for Author entity with specialized queries.\"\"\"\n\n    def __init__(self, session: AsyncSession):\n        super().__init__(session, Author)\n\n    async def get_by_name(self, name: str) -&gt; Author | None:\n        \"\"\"Get author by exact name match.\"\"\"\n        stmt = select(Author).where(Author.name == name)\n        result = await self.session.exec(stmt)\n        return result.first()\n\n    async def search_by_name(self, name_pattern: str) -&gt; list[Author]:\n        \"\"\"Search authors by name pattern (case-insensitive).\"\"\"\n        stmt = select(Author).where(Author.name.ilike(f\"%{name_pattern}%\"))\n        result = await self.session.exec(stmt)\n        return list(result.all())\n</code></pre>"},{"location":"architecture/design-patterns/#usage_1","title":"Usage","text":"<pre><code># In handler\nasync with async_session() as session:\n    repo = AuthorRepository(session)\n\n    # Use repository methods\n    author = await repo.get_by_id(1)\n    all_authors = await repo.get_all()\n    johns = await repo.search_by_name(\"John\")\n    exists = await repo.exists(name=\"John Doe\")\n</code></pre>"},{"location":"architecture/design-patterns/#testing_1","title":"Testing","text":"<pre><code>@pytest.mark.asyncio\nasync def test_repository():\n    # Mock session\n    mock_session = AsyncMock()\n    mock_session.get.return_value = Author(id=1, name=\"Test\")\n\n    repo = AuthorRepository(mock_session)\n    author = await repo.get_by_id(1)\n\n    assert author.name == \"Test\"\n    mock_session.get.assert_called_once_with(Author, 1)\n</code></pre>"},{"location":"architecture/design-patterns/#benefits_1","title":"Benefits","text":"<p>\u2705 Abstraction - Hide database details \u2705 Reusable - Use same repository in multiple handlers \u2705 Testable - Mock session, not database \u2705 Maintainable - Change queries in one place</p>"},{"location":"architecture/design-patterns/#pattern-3-command-pattern","title":"Pattern 3: Command Pattern","text":""},{"location":"architecture/design-patterns/#overview_3","title":"Overview","text":"<p>Encapsulate business operations as command objects that can be reused across different handler types (HTTP, WebSocket).</p>"},{"location":"architecture/design-patterns/#implementation_2","title":"Implementation","text":"<p>Base Command: <code>app/commands/base.py</code></p> <pre><code>from abc import ABC, abstractmethod\nfrom typing import Generic, TypeVar\n\nTInput = TypeVar(\"TInput\")\nTOutput = TypeVar(\"TOutput\")\n\nclass BaseCommand(ABC, Generic[TInput, TOutput]):\n    \"\"\"Base command for business operations.\"\"\"\n\n    @abstractmethod\n    async def execute(self, input_data: TInput) -&gt; TOutput:\n        \"\"\"Execute the command with input data.\"\"\"\n        pass\n</code></pre> <p>Specific Command: <code>app/commands/author_commands.py</code></p> <pre><code>from pydantic import BaseModel\nfrom app.commands.base import BaseCommand\nfrom app.repositories.author_repository import AuthorRepository\n\n# Input/Output models\nclass GetAuthorsInput(BaseModel):\n    id: int | None = None\n    name: str | None = None\n    search_term: str | None = None\n\n# Command implementation\nclass GetAuthorsCommand(BaseCommand[GetAuthorsInput, list[Author]]):\n    \"\"\"Command to get authors with optional filtering.\"\"\"\n\n    def __init__(self, repository: AuthorRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: GetAuthorsInput) -&gt; list[Author]:\n        # Business logic here\n        if input_data.search_term:\n            return await self.repository.search_by_name(input_data.search_term)\n\n        filters = {}\n        if input_data.id is not None:\n            filters[\"id\"] = input_data.id\n        if input_data.name is not None:\n            filters[\"name\"] = input_data.name\n\n        return await self.repository.get_all(**filters)\n\n\nclass CreateAuthorCommand(BaseCommand[CreateAuthorInput, Author]):\n    \"\"\"Command to create a new author.\"\"\"\n\n    def __init__(self, repository: AuthorRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: CreateAuthorInput) -&gt; Author:\n        # Business logic: Check for duplicates\n        existing = await self.repository.get_by_name(input_data.name)\n        if existing:\n            raise ValueError(f\"Author '{input_data.name}' already exists\")\n\n        author = Author(name=input_data.name)\n        return await self.repository.create(author)\n</code></pre>"},{"location":"architecture/design-patterns/#usage_2","title":"Usage","text":"<p>HTTP Handler: <pre><code>@router.get(\"/authors\")\nasync def get_authors(\n    repo: AuthorRepoDep,\n    search: str | None = None,\n) -&gt; list[Author]:\n    command = GetAuthorsCommand(repo)\n    input_data = GetAuthorsInput(search_term=search)\n    return await command.execute(input_data)\n</code></pre></p> <p>WebSocket Handler: <pre><code>@pkg_router.register(PkgID.GET_AUTHORS)\nasync def get_authors_ws(request: RequestModel) -&gt; ResponseModel:\n    async with async_session() as session:\n        repo = AuthorRepository(session)\n        command = GetAuthorsCommand(repo)  # Same command!\n        input_data = GetAuthorsInput(**request.data)\n        authors = await command.execute(input_data)\n\n        return ResponseModel(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            data=[a.model_dump() for a in authors]\n        )\n</code></pre></p> <p>Key Point: Same business logic (<code>GetAuthorsCommand</code>) used in both protocols! \ud83c\udfaf</p>"},{"location":"architecture/design-patterns/#testing_2","title":"Testing","text":"<pre><code>@pytest.mark.asyncio\nasync def test_command():\n    # Mock repository\n    mock_repo = AsyncMock()\n    mock_repo.get_by_name.return_value = None\n    mock_repo.create.return_value = Author(id=1, name=\"New\")\n\n    # Test command with mock\n    command = CreateAuthorCommand(mock_repo)\n    input_data = CreateAuthorInput(name=\"New\")\n    result = await command.execute(input_data)\n\n    assert result.name == \"New\"\n    mock_repo.get_by_name.assert_called_once_with(\"New\")\n    mock_repo.create.assert_called_once()\n</code></pre>"},{"location":"architecture/design-patterns/#benefits_2","title":"Benefits","text":"<p>\u2705 Reusable - Same logic in HTTP and WebSocket \u2705 Testable - Mock repository, not database \u2705 Maintainable - Change logic in one place \u2705 Composable - Commands can call other commands</p>"},{"location":"architecture/design-patterns/#complete-example-author-feature","title":"Complete Example: Author Feature","text":""},{"location":"architecture/design-patterns/#architecture-flow","title":"Architecture Flow","text":"<pre><code>HTTP Request \u2192 Router \u2192 Command \u2192 Repository \u2192 Database\n                  \u2193         \u2193           \u2193\n            Dependencies  Business    Data\n            Injected      Logic       Access\n</code></pre>"},{"location":"architecture/design-patterns/#step-by-step-implementation","title":"Step-by-Step Implementation","text":""},{"location":"architecture/design-patterns/#1-define-models","title":"1. Define Models","text":"<pre><code># app/models/author.py\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    # No business logic methods!\n</code></pre>"},{"location":"architecture/design-patterns/#2-create-repository","title":"2. Create Repository","text":"<pre><code># app/repositories/author_repository.py\nclass AuthorRepository(BaseRepository[Author]):\n    def __init__(self, session: AsyncSession):\n        super().__init__(session, Author)\n\n    async def get_by_name(self, name: str) -&gt; Author | None:\n        # Custom query\n        ...\n</code></pre>"},{"location":"architecture/design-patterns/#3-create-commands","title":"3. Create Commands","text":"<pre><code># app/commands/author_commands.py\nclass CreateAuthorInput(BaseModel):\n    name: str\n\nclass CreateAuthorCommand(BaseCommand[CreateAuthorInput, Author]):\n    def __init__(self, repository: AuthorRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: CreateAuthorInput) -&gt; Author:\n        # Business logic with validation\n        ...\n</code></pre>"},{"location":"architecture/design-patterns/#4-setup-dependencies","title":"4. Setup Dependencies","text":"<pre><code># app/dependencies.py\ndef get_author_repository(session: SessionDep) -&gt; AuthorRepository:\n    return AuthorRepository(session)\n\nAuthorRepoDep = Annotated[AuthorRepository, Depends(get_author_repository)]\n</code></pre>"},{"location":"architecture/design-patterns/#5-create-http-endpoint","title":"5. Create HTTP Endpoint","text":"<pre><code># app/api/http/author.py\n@router.post(\"/authors\", status_code=201)\nasync def create_author(\n    data: CreateAuthorInput,\n    repo: AuthorRepoDep,\n) -&gt; Author:\n    command = CreateAuthorCommand(repo)\n    return await command.execute(data)\n</code></pre>"},{"location":"architecture/design-patterns/#6-create-websocket-handler","title":"6. Create WebSocket Handler","text":"<pre><code># app/api/ws/handlers/author_handlers.py\n@pkg_router.register(PkgID.CREATE_AUTHOR)\nasync def create_author_ws(request: RequestModel) -&gt; ResponseModel:\n    async with async_session() as session:\n        repo = AuthorRepository(session)\n        command = CreateAuthorCommand(repo)  # Same command!\n        input_data = CreateAuthorInput(**request.data)\n        author = await command.execute(input_data)\n\n        return ResponseModel(..., data=author.model_dump())\n</code></pre>"},{"location":"architecture/design-patterns/#testing-strategies","title":"Testing Strategies","text":""},{"location":"architecture/design-patterns/#1-repository-tests","title":"1. Repository Tests","text":"<pre><code>@pytest.fixture\ndef mock_session():\n    session = AsyncMock(spec=AsyncSession)\n    session.add = MagicMock()\n    session.flush = AsyncMock()\n    session.exec = AsyncMock()\n    return session\n\n@pytest.mark.asyncio\nasync def test_create(mock_session):\n    repo = AuthorRepository(mock_session)\n    author = Author(name=\"Test\")\n\n    created = await repo.create(author)\n\n    mock_session.add.assert_called_once_with(author)\n    mock_session.flush.assert_called_once()\n</code></pre>"},{"location":"architecture/design-patterns/#2-command-tests","title":"2. Command Tests","text":"<pre><code>@pytest.mark.asyncio\nasync def test_create_command():\n    mock_repo = AsyncMock()\n    mock_repo.get_by_name.return_value = None\n    mock_repo.create.return_value = Author(id=1, name=\"New\")\n\n    command = CreateAuthorCommand(mock_repo)\n    result = await command.execute(CreateAuthorInput(name=\"New\"))\n\n    assert result.id == 1\n    mock_repo.create.assert_called_once()\n</code></pre>"},{"location":"architecture/design-patterns/#3-handler-tests","title":"3. Handler Tests","text":"<pre><code>def test_http_endpoint(client):\n    # Override dependency\n    app.dependency_overrides[get_author_repository] = lambda: MockRepo()\n\n    response = client.post(\"/authors\", json={\"name\": \"Test\"})\n    assert response.status_code == 201\n</code></pre>"},{"location":"architecture/design-patterns/#migration-guide","title":"Migration Guide","text":""},{"location":"architecture/design-patterns/#for-new-features","title":"For New Features","text":"<p>Use the new patterns from the start:</p> <ol> <li>Create Repository extending <code>BaseRepository</code></li> <li>Create Commands for business logic</li> <li>Setup Dependencies in <code>app/dependencies.py</code></li> <li>Create HTTP/WebSocket handlers using commands</li> </ol>"},{"location":"architecture/design-patterns/#for-existing-features","title":"For Existing Features","text":"<p>Gradual migration approach:</p> <ol> <li>Create repository for data access</li> <li>Create commands for business logic</li> <li>Create new endpoints using new patterns</li> <li>Keep old endpoints for backward compatibility</li> <li>Migrate clients to use new endpoints</li> <li>Remove old endpoints once migration complete</li> </ol>"},{"location":"architecture/design-patterns/#example-implementation","title":"Example Implementation","text":"<pre><code># Current pattern: Repository + Command\n@router.get(\"/books\")\nasync def get_books(repo: BookRepoDep):\n    command = GetBooksCommand(repo)\n    return await command.execute(GetBooksInput())\n</code></pre>"},{"location":"architecture/design-patterns/#best-practices","title":"Best Practices","text":""},{"location":"architecture/design-patterns/#1-keep-models-simple","title":"1. Keep Models Simple","text":"<p>\u274c Don't add business logic to models: <pre><code>class Author(SQLModel, table=True):\n    async def validate_unique_name(self):  # \u274c No!\n        ...\n</code></pre></p> <p>\u2705 Do keep models as data containers: <pre><code>class Author(SQLModel, table=True):\n    id: int | None = None\n    name: str\n    # Just data, no logic\n</code></pre></p>"},{"location":"architecture/design-patterns/#2-use-commands-for-business-logic","title":"2. Use Commands for Business Logic","text":"<p>\u274c Don't put logic in handlers: <pre><code>@router.post(\"/authors\")\nasync def create_author(data: dict):\n    # Validation logic here  # \u274c No!\n    if len(data[\"name\"]) &lt; 2:\n        raise ValueError(\"Too short\")\n    ...\n</code></pre></p> <p>\u2705 Do encapsulate in commands: <pre><code>class CreateAuthorCommand:\n    async def execute(self, input_data):\n        # Validation and business logic here  # \u2705 Yes!\n        ...\n</code></pre></p>"},{"location":"architecture/design-patterns/#3-type-everything","title":"3. Type Everything","text":"<pre><code># \u2705 Full type hints\nclass GetAuthorsCommand(BaseCommand[GetAuthorsInput, list[Author]]):\n    def __init__(self, repository: AuthorRepository) -&gt; None:\n        self.repository = repository\n\n    async def execute(self, input_data: GetAuthorsInput) -&gt; list[Author]:\n        ...\n</code></pre>"},{"location":"architecture/design-patterns/#4-test-in-isolation","title":"4. Test in Isolation","text":"<pre><code># \u2705 Test command without database\nasync def test_command():\n    mock_repo = AsyncMock()  # No real database!\n    command = CreateAuthorCommand(mock_repo)\n    result = await command.execute(CreateAuthorInput(name=\"Test\"))\n    assert result.name == \"Test\"\n</code></pre>"},{"location":"architecture/design-patterns/#references","title":"References","text":"<ul> <li>Repository Pattern - Martin Fowler</li> <li>Command Pattern - Refactoring Guru</li> <li>Dependency Injection in FastAPI</li> <li>Issue #29</li> </ul> <p>Last Updated: 2025-12-05 Author: Claude Code Status: \u2705 Active</p>"},{"location":"architecture/docker-services/","title":"Docker Services Architecture","text":"<p>Last Updated: 2025-12-28</p> <p>This document provides a comprehensive overview of the Docker services that compose the application stack, including their connections, port mappings, and Traefik routing configuration.</p>"},{"location":"architecture/docker-services/#service-topology","title":"Service Topology","text":"<pre><code>graph TB\n    subgraph \"External Access\"\n        CLIENT[Clients&lt;br/&gt;Browsers, Apps, CLI]\n    end\n\n    subgraph \"Reverse Proxy\"\n        TRAEFIK[Traefik&lt;br/&gt;Container: traefik&lt;br/&gt;Ports: 80, 443, 8080]\n    end\n\n    subgraph \"Application Services\"\n        FASTAPI[FastAPI Application&lt;br/&gt;Container: hw-server&lt;br/&gt;Port: 8000&lt;br/&gt;Host: api.localhost]\n        SHELL[Dev Shell&lt;br/&gt;Container: hw-server-shell]\n    end\n\n    subgraph \"Authentication\"\n        KEYCLOAK[Keycloak&lt;br/&gt;Container: hw-keycloak&lt;br/&gt;Port: 9000/9999&lt;br/&gt;Host: keycloak.localhost]\n    end\n\n    subgraph \"Data Layer\"\n        POSTGRES[PostgreSQL&lt;br/&gt;Container: hw-db&lt;br/&gt;Port: 5432]\n        REDIS[Redis&lt;br/&gt;Container: hw-redis&lt;br/&gt;Port: 6379]\n    end\n\n    subgraph \"Monitoring Stack\"\n        PROMETHEUS[Prometheus&lt;br/&gt;Container: hw-prometheus&lt;br/&gt;Port: 9090&lt;br/&gt;Host: prometheus.localhost]\n        GRAFANA[Grafana&lt;br/&gt;Container: hw-grafana&lt;br/&gt;Port: 3000&lt;br/&gt;Host: grafana.localhost]\n        LOKI[Loki&lt;br/&gt;Container: hw-loki&lt;br/&gt;Port: 3100]\n        ALLOY[Grafana Alloy&lt;br/&gt;Container: hw-alloy&lt;br/&gt;Port: 12345]\n    end\n\n    CLIENT --&gt;|HTTP/HTTPS| TRAEFIK\n\n    TRAEFIK --&gt;|api.localhost| FASTAPI\n    TRAEFIK --&gt;|keycloak.localhost| KEYCLOAK\n    TRAEFIK --&gt;|prometheus.localhost| PROMETHEUS\n    TRAEFIK --&gt;|grafana.localhost| GRAFANA\n    TRAEFIK --&gt;|traefik.localhost| TRAEFIK\n\n    FASTAPI --&gt;|Auth| KEYCLOAK\n    FASTAPI --&gt;|Data| POSTGRES\n    FASTAPI --&gt;|Cache/Rate Limit| REDIS\n    FASTAPI --&gt;|Metrics| PROMETHEUS\n    FASTAPI --&gt;|Logs| ALLOY\n\n    KEYCLOAK --&gt;|Data| POSTGRES\n    KEYCLOAK --&gt;|Metrics| PROMETHEUS\n\n    SHELL -.-&gt;|Dev Access| POSTGRES\n    SHELL -.-&gt;|Dev Access| REDIS\n\n    ALLOY --&gt;|Push Logs| LOKI\n    PROMETHEUS --&gt;|Query| GRAFANA\n    LOKI --&gt;|Query| GRAFANA\n\n    TRAEFIK --&gt;|Metrics| PROMETHEUS\n\n    style TRAEFIK fill:#bbf,stroke:#333,stroke-width:2px\n    style FASTAPI fill:#f9f,stroke:#333,stroke-width:4px\n    style KEYCLOAK fill:#fbf,stroke:#333,stroke-width:2px\n    style POSTGRES fill:#bfb,stroke:#333,stroke-width:2px\n    style REDIS fill:#fbb,stroke:#333,stroke-width:2px</code></pre>"},{"location":"architecture/docker-services/#network-configuration","title":"Network Configuration","text":"<p>All services are connected via a single Docker bridge network: <code>hw-network</code></p> <p>This allows services to communicate using container names as hostnames (e.g., <code>hw-server:8000</code>, <code>hw-db:5432</code>).</p>"},{"location":"architecture/docker-services/#port-mappings","title":"Port Mappings","text":""},{"location":"architecture/docker-services/#external-ports-host-container","title":"External Ports (Host \u2192 Container)","text":"Service Host Port Container Port Protocol Description Traefik 80 80 HTTP HTTP traffic Traefik 443 443 HTTPS HTTPS traffic (TLS) Traefik 8080 8080 HTTP Traefik dashboard PostgreSQL 5432 5432 TCP Database (dev access) Redis 6379 6379 TCP Cache (dev access) Keycloak 9999 9000 HTTP Keycloak metrics Prometheus 9090 9090 HTTP Prometheus UI Grafana 3000 3000 HTTP Grafana dashboards"},{"location":"architecture/docker-services/#internal-ports-container-to-container","title":"Internal Ports (Container-to-Container)","text":"Service Internal Port Used By Purpose FastAPI 8000 Traefik Application API Keycloak 8080 Traefik Keycloak console Loki 3100 Alloy, Grafana Log aggregation Alloy 12345 Browser (optional) Alloy UI"},{"location":"architecture/docker-services/#traefik-routing-configuration","title":"Traefik Routing Configuration","text":""},{"location":"architecture/docker-services/#http-routers","title":"HTTP Routers","text":"<pre><code>graph LR\n    CLIENT[Client Request] --&gt; TRAEFIK{Traefik&lt;br/&gt;Reverse Proxy}\n\n    TRAEFIK --&gt;|Host: api.localhost| FASTAPI[FastAPI:8000]\n    TRAEFIK --&gt;|Host: keycloak.localhost| KEYCLOAK[Keycloak:8080]\n    TRAEFIK --&gt;|Host: prometheus.localhost| PROMETHEUS[Prometheus:9090]\n    TRAEFIK --&gt;|Host: grafana.localhost| GRAFANA[Grafana:3000]\n    TRAEFIK --&gt;|Host: traefik.localhost| DASHBOARD[Traefik Dashboard:8080]\n\n    style TRAEFIK fill:#bbf,stroke:#333,stroke-width:2px</code></pre>"},{"location":"architecture/docker-services/#traefik-labels-configuration","title":"Traefik Labels Configuration","text":""},{"location":"architecture/docker-services/#fastapi-service","title":"FastAPI Service","text":"<pre><code>traefik.enable: \"true\"\n\n# Main HTTP router\ntraefik.http.routers.fastapi.rule: \"Host(`api.localhost`)\"\ntraefik.http.routers.fastapi.entrypoints: \"web\"\ntraefik.http.routers.fastapi.service: \"fastapi\"\ntraefik.http.routers.fastapi.middlewares: \"secure-headers@file,gzip-compress@file\"\n\n# Service definition\ntraefik.http.services.fastapi.loadbalancer.server.port: \"8000\"\ntraefik.http.services.fastapi.loadbalancer.healthcheck.path: \"/health\"\ntraefik.http.services.fastapi.loadbalancer.healthcheck.interval: \"30s\"\n\n# WebSocket router (separate for /web endpoint)\ntraefik.http.routers.fastapi-ws.rule: \"Host(`api.localhost`) &amp;&amp; PathPrefix(`/web`)\"\ntraefik.http.routers.fastapi-ws.entrypoints: \"web\"\ntraefik.http.routers.fastapi-ws.service: \"fastapi\"\n</code></pre>"},{"location":"architecture/docker-services/#keycloak-service","title":"Keycloak Service","text":"<pre><code>traefik.enable: \"true\"\n\ntraefik.http.routers.keycloak.rule: \"Host(`keycloak.localhost`)\"\ntraefik.http.routers.keycloak.entrypoints: \"web\"\ntraefik.http.routers.keycloak.service: \"keycloak\"\n\ntraefik.http.services.keycloak.loadbalancer.server.port: \"8080\"\n</code></pre>"},{"location":"architecture/docker-services/#prometheus-service","title":"Prometheus Service","text":"<pre><code>traefik.enable: \"true\"\n\ntraefik.http.routers.prometheus.rule: \"Host(`prometheus.localhost`)\"\ntraefik.http.routers.prometheus.entrypoints: \"web\"\ntraefik.http.routers.prometheus.service: \"prometheus\"\ntraefik.http.routers.prometheus.middlewares: \"secure-headers@file\"\n\ntraefik.http.services.prometheus.loadbalancer.server.port: \"9090\"\n</code></pre>"},{"location":"architecture/docker-services/#grafana-service","title":"Grafana Service","text":"<pre><code>traefik.enable: \"true\"\n\ntraefik.http.routers.grafana.rule: \"Host(`grafana.localhost`)\"\ntraefik.http.routers.grafana.entrypoints: \"web\"\ntraefik.http.routers.grafana.service: \"grafana\"\n\ntraefik.http.services.grafana.loadbalancer.server.port: \"3000\"\n</code></pre>"},{"location":"architecture/docker-services/#traefik-middleware","title":"Traefik Middleware","text":"<p>Defined in <code>docker/traefik/dynamic/middleware.yml</code>:</p> <p>secure-headers - Adds security headers: - <code>X-Frame-Options: DENY</code> - <code>X-Content-Type-Options: nosniff</code> - <code>Strict-Transport-Security</code> - <code>Referrer-Policy</code></p> <p>gzip-compress - Enables gzip compression for responses</p>"},{"location":"architecture/docker-services/#service-details","title":"Service Details","text":""},{"location":"architecture/docker-services/#1-traefik-reverse-proxy","title":"1. Traefik (Reverse Proxy)","text":"<p>Container: <code>traefik</code> Image: <code>traefik:v2.10</code> Networks: <code>hw-network</code> Configuration: <code>docker/traefik/traefik.yml</code>, <code>docker/traefik/dynamic/</code></p> <p>Purpose: - HTTP/HTTPS reverse proxy - Load balancing - SSL/TLS termination - Service discovery (Docker provider) - WebSocket connection upgrade - Metrics export for Prometheus</p> <p>Key Features: - Automatic service discovery via Docker labels - Health checks for backend services - Access logs in JSON format - Prometheus metrics endpoint</p>"},{"location":"architecture/docker-services/#2-fastapi-application","title":"2. FastAPI Application","text":"<p>Container: <code>hw-server</code> Image: Custom (built from <code>Dockerfile</code>) Networks: <code>hw-network</code> Depends On: <code>hw-db</code>, <code>hw-redis</code>, <code>hw-keycloak</code>, <code>prometheus</code>, <code>grafana</code>, <code>loki</code>, <code>alloy</code>, <code>traefik</code></p> <p>Environment: Configured via <code>docker/.srv_env</code></p> <p>Purpose: - Main application server - HTTP REST API - WebSocket real-time communication - Business logic processing</p> <p>Exposed Services: - <code>/api/*</code> - HTTP REST endpoints - <code>/web</code> - WebSocket endpoint - <code>/metrics</code> - Prometheus metrics - <code>/health</code> - Health check endpoint</p>"},{"location":"architecture/docker-services/#3-development-shell","title":"3. Development Shell","text":"<p>Container: <code>hw-server-shell</code> Image: Same as FastAPI Networks: <code>hw-network</code></p> <p>Purpose: - Interactive development shell - Database migrations - Management commands - Testing and debugging</p> <p>Command: <code>/bin/bash</code> (keeps container running)</p>"},{"location":"architecture/docker-services/#4-keycloak-authentication","title":"4. Keycloak (Authentication)","text":"<p>Container: <code>hw-keycloak</code> Image: <code>keycloak/keycloak:25.0</code> Networks: <code>hw-network</code> Depends On: <code>hw-db</code></p> <p>Environment: Configured via <code>docker/.kc_env</code></p> <p>Purpose: - Identity and Access Management (IAM) - JWT token issuance and validation - User management - OAuth 2.0 / OpenID Connect</p> <p>Key Features: - PostgreSQL backend - Metrics enabled (<code>KC_METRICS_ENABLED=true</code>) - Health checks enabled - Realm import on startup</p>"},{"location":"architecture/docker-services/#5-postgresql-database","title":"5. PostgreSQL Database","text":"<p>Container: <code>hw-db</code> Image: <code>postgres:13</code> Networks: <code>hw-network</code> Volumes: <code>postgres-data:/var/lib/postgresql/data</code></p> <p>Environment: - <code>POSTGRES_USER=postgres</code> - <code>POSTGRES_PASSWORD=postgres</code> - <code>POSTGRES_DB=hw_db</code></p> <p>Purpose: - Primary data store - Stores application data (authors, etc.) - Stores audit logs (user_actions table) - Keycloak backend database</p> <p>Health Check: <code>pg_isready</code> command every 10 seconds</p>"},{"location":"architecture/docker-services/#6-redis-cache","title":"6. Redis Cache","text":"<p>Container: <code>hw-redis</code> Image: <code>redis:alpine</code> Networks: <code>hw-network</code> Volumes: <code>redis-data:/data</code></p> <p>Purpose: - High-performance caching - Rate limiting counters (sliding window) - WebSocket connection tracking - User session storage - Pagination count caching</p> <p>Health Check: <code>redis-cli ping</code> every 10 seconds</p> <p>Redis Databases: - DB 0: Main cache (rate limiting, general caching) - DB 1: Authentication cache (user sessions, tokens)</p>"},{"location":"architecture/docker-services/#7-prometheus-metrics","title":"7. Prometheus (Metrics)","text":"<p>Container: <code>hw-prometheus</code> Image: <code>prom/prometheus:latest</code> Networks: <code>hw-network</code> Volumes: - <code>./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro</code> - <code>./prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro</code> - <code>prometheus-data:/prometheus</code></p> <p>Purpose: - Time-series metrics collection - Alert rule evaluation - Metrics storage and querying</p> <p>Scrape Targets: - FastAPI (<code>hw-server:8000/metrics</code>) - Every 60 seconds - Keycloak (<code>hw-keycloak:9000/metrics</code>) - Every 30 seconds - Traefik (<code>traefik:8080/metrics</code>) - Every 30 seconds</p> <p>Alert Rules: 16 alerts across 8 categories (loaded from <code>alerts.yml</code>)</p>"},{"location":"architecture/docker-services/#8-grafana-visualization","title":"8. Grafana (Visualization)","text":"<p>Container: <code>hw-grafana</code> Image: <code>grafana/grafana:latest</code> Networks: <code>hw-network</code> Volumes: - <code>./grafana/provisioning:/etc/grafana/provisioning</code> - <code>grafana-data:/var/lib/grafana</code></p> <p>Purpose: - Metrics visualization - Dashboard management - Log querying (Loki) - Alerting and notifications</p> <p>Data Sources (auto-provisioned): - Prometheus - Loki - PostgreSQL (for audit logs)</p> <p>Dashboards (auto-provisioned): - FastAPI Metrics - Keycloak Metrics - Application Logs - Audit Logs</p>"},{"location":"architecture/docker-services/#9-loki-log-aggregation","title":"9. Loki (Log Aggregation)","text":"<p>Container: <code>hw-loki</code> Image: <code>grafana/loki:latest</code> Networks: <code>hw-network</code> Volumes: - <code>./loki/loki-config.yml:/etc/loki/local-config.yaml</code> - <code>loki-data:/loki</code></p> <p>Purpose: - Centralized log storage - Log indexing and querying - LogQL query language - Integration with Grafana</p>"},{"location":"architecture/docker-services/#10-grafana-alloy-log-collector","title":"10. Grafana Alloy (Log Collector)","text":"<p>Container: <code>hw-alloy</code> Image: <code>grafana/alloy:latest</code> Networks: <code>hw-network</code> Volumes: - <code>./alloy/config.alloy:/etc/alloy/config.alloy</code> - <code>/var/run/docker.sock:/var/run/docker.sock:ro</code></p> <p>Purpose: - Modern observability collector (replaces Promtail) - Collects logs from application containers - Sends logs to Loki - Processes and enriches log data</p> <p>UI: Available at http://localhost:12345 for debugging</p>"},{"location":"architecture/docker-services/#service-dependencies","title":"Service Dependencies","text":"<pre><code>graph TB\n    TRAEFIK[Traefik]\n    FASTAPI[FastAPI]\n    SHELL[Dev Shell]\n    KEYCLOAK[Keycloak]\n    POSTGRES[PostgreSQL]\n    REDIS[Redis]\n    PROMETHEUS[Prometheus]\n    GRAFANA[Grafana]\n    LOKI[Loki]\n    ALLOY[Grafana Alloy]\n\n    FASTAPI --&gt;|depends_on| POSTGRES\n    FASTAPI --&gt;|depends_on| REDIS\n    FASTAPI --&gt;|depends_on| KEYCLOAK\n    FASTAPI --&gt;|depends_on| PROMETHEUS\n    FASTAPI --&gt;|depends_on| GRAFANA\n    FASTAPI --&gt;|depends_on| LOKI\n    FASTAPI --&gt;|depends_on| ALLOY\n    FASTAPI --&gt;|depends_on| TRAEFIK\n\n    SHELL --&gt;|depends_on| POSTGRES\n    SHELL --&gt;|depends_on| REDIS\n    SHELL --&gt;|depends_on| KEYCLOAK\n    SHELL --&gt;|depends_on| PROMETHEUS\n    SHELL --&gt;|depends_on| GRAFANA\n    SHELL --&gt;|depends_on| LOKI\n    SHELL --&gt;|depends_on| ALLOY\n\n    KEYCLOAK --&gt;|depends_on| POSTGRES\n\n    GRAFANA --&gt;|depends_on| PROMETHEUS\n    GRAFANA --&gt;|depends_on| LOKI\n\n    ALLOY --&gt;|depends_on| LOKI\n\n    style FASTAPI fill:#f9f,stroke:#333,stroke-width:4px</code></pre>"},{"location":"architecture/docker-services/#health-checks","title":"Health Checks","text":"Service Health Check Command Interval Timeout Retries Traefik <code>traefik healthcheck --ping</code> 10s 5s 3 PostgreSQL <code>pg_isready</code> 10s 5s 5 Redis <code>redis-cli ping</code> 10s 5s 5"},{"location":"architecture/docker-services/#volume-mounts","title":"Volume Mounts","text":"<p>Persistent Volumes: - <code>postgres-data</code> - PostgreSQL database files - <code>redis-data</code> - Redis persistence - <code>prometheus-data</code> - Prometheus time-series data - <code>grafana-data</code> - Grafana dashboards and settings - <code>loki-data</code> - Loki log storage</p> <p>Configuration Volumes (read-only): - <code>./prometheus/prometheus.yml</code> \u2192 <code>/etc/prometheus/prometheus.yml</code> - <code>./prometheus/alerts.yml</code> \u2192 <code>/etc/prometheus/alerts.yml</code> - <code>./grafana/provisioning</code> \u2192 <code>/etc/grafana/provisioning</code> - <code>./loki/loki-config.yml</code> \u2192 <code>/etc/loki/local-config.yaml</code> - <code>./alloy/config.alloy</code> \u2192 <code>/etc/alloy/config.alloy</code> - <code>./traefik/traefik.yml</code> \u2192 <code>/etc/traefik/traefik.yml</code> - <code>./traefik/dynamic</code> \u2192 <code>/etc/traefik/dynamic</code></p>"},{"location":"architecture/docker-services/#service-urls","title":"Service URLs","text":"Service URL Description FastAPI API http://api.localhost Main API endpoints FastAPI WebSocket ws://api.localhost/web WebSocket endpoint FastAPI Metrics http://api.localhost/metrics Prometheus metrics Keycloak Console http://keycloak.localhost Keycloak admin console Prometheus http://prometheus.localhost Prometheus UI Grafana http://grafana.localhost Grafana dashboards Traefik Dashboard http://traefik.localhost Traefik routing info Alloy UI http://localhost:12345 Alloy debugging UI"},{"location":"architecture/docker-services/#starting-services","title":"Starting Services","text":"<pre><code># Start all services\ndocker-compose -f docker/docker-compose.yml up -d\n\n# Start specific service\ndocker-compose -f docker/docker-compose.yml up -d hw-server\n\n# View logs\ndocker-compose -f docker/docker-compose.yml logs -f hw-server\n\n# Stop all services\ndocker-compose -f docker/docker-compose.yml down\n\n# Stop and remove volumes\ndocker-compose -f docker/docker-compose.yml down -v\n</code></pre>"},{"location":"architecture/docker-services/#scaling-considerations","title":"Scaling Considerations","text":"<p>Horizontal Scaling Ready: - \u2705 FastAPI (stateless, can run multiple instances behind Traefik) - \u2705 Traefik (supports multiple backend instances)</p> <p>Single Instance: - \u26a0\ufe0f PostgreSQL (requires replication for HA) - \u26a0\ufe0f Redis (requires Redis Sentinel or Cluster for HA) - \u26a0\ufe0f Keycloak (can be clustered with shared database)</p> <p>Auto-scaling Targets (Kubernetes): - FastAPI pods based on CPU/memory - Horizontal Pod Autoscaler (HPA) recommended</p>"},{"location":"architecture/docker-services/#security-notes","title":"Security Notes","text":"<p>Production Hardening:</p> <ol> <li>Change default credentials in environment files</li> <li>Enable TLS/HTTPS via Traefik Let's Encrypt</li> <li>Restrict network access (remove exposed ports for DB/Redis)</li> <li>Use secrets management (Docker secrets, Vault)</li> <li>Enable Traefik authentication for dashboard</li> <li>Restrict Prometheus/Grafana access (add authentication)</li> <li>Set <code>exposedByDefault: false</code> in Traefik (already configured)</li> </ol>"},{"location":"architecture/docker-services/#related-documentation","title":"Related Documentation","text":"<ul> <li>System Architecture Overview</li> <li>Request Flow Documentation</li> <li>Production Deployment Guide</li> <li>Docker Deployment Guide</li> <li>Monitoring &amp; Observability</li> </ul>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>Last Updated: 2025-11-25</p>"},{"location":"architecture/overview/#system-architecture","title":"System Architecture","text":"<p>This FastAPI application implements a dual-protocol API server supporting both HTTP REST and WebSocket connections with centralized authentication and authorization.</p>"},{"location":"architecture/overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    subgraph \"Client Layer\"\n        HTTP[HTTP Clients&lt;br/&gt;REST API calls]\n        WS[WebSocket Clients&lt;br/&gt;Real-time bidirectional]\n    end\n\n    subgraph \"Protocol Layer\"\n        HTTPEndpoints[HTTP Endpoints&lt;br/&gt;- /authors&lt;br/&gt;- /health&lt;br/&gt;- FastAPI routers]\n        WSEndpoint[WebSocket Endpoint&lt;br/&gt;- /web&lt;br/&gt;- Connection auth&lt;br/&gt;- Message routing&lt;br/&gt;- PackageRouter dispatch]\n    end\n\n    subgraph \"Middleware Layer\"\n        Auth[AuthenticationMiddleware&lt;br/&gt;Keycloak JWT validation]\n        RBAC[require_roles dependency&lt;br/&gt;RBAC permission checking]\n    end\n\n    subgraph \"Business Logic Layer\"\n        HTTPHandlers[HTTP Handlers&lt;br/&gt;app/api/http/]\n        WSHandlers[WebSocket Handlers&lt;br/&gt;app/api/ws/handlers/&lt;br/&gt;@pkg_router.register]\n    end\n\n    subgraph \"Managers &amp; Services\"\n        RBACMgr[RBACManager&lt;br/&gt;permission checking]\n        KCMgr[KeycloakManager&lt;br/&gt;authentication]\n        ConnMgr[ConnectionManager&lt;br/&gt;WebSocket connections]\n        PkgRouter[PackageRouter&lt;br/&gt;WebSocket routing]\n    end\n\n    subgraph \"Data Layer\"\n        DB[(PostgreSQL&lt;br/&gt;SQLModel/SQLAlchemy&lt;br/&gt;Async operations)]\n        Redis[(Redis Cache&lt;br/&gt;Session management&lt;br/&gt;Pub/Sub)]\n    end\n\n    HTTP --&gt; HTTPEndpoints\n    WS --&gt; WSEndpoint\n\n    HTTPEndpoints --&gt; Auth\n    WSEndpoint --&gt; Auth\n\n    Auth --&gt; RBAC\n    RBAC --&gt; HTTPHandlers\n    RBAC --&gt; WSHandlers\n\n    HTTPHandlers --&gt; RBACMgr\n    HTTPHandlers --&gt; KCMgr\n    WSHandlers --&gt; ConnMgr\n    WSHandlers --&gt; PkgRouter\n\n    RBACMgr --&gt; DB\n    KCMgr --&gt; Redis\n    ConnMgr --&gt; Redis\n    PkgRouter --&gt; DB\n\n    style HTTP fill:#e1f5ff\n    style WS fill:#e1f5ff\n    style HTTPEndpoints fill:#fff3cd\n    style WSEndpoint fill:#fff3cd\n    style Auth fill:#d4edda\n    style RBAC fill:#d4edda\n    style HTTPHandlers fill:#cce5ff\n    style WSHandlers fill:#cce5ff\n    style DB fill:#f8d7da\n    style Redis fill:#f8d7da</code></pre>"},{"location":"architecture/overview/#core-components","title":"Core Components","text":""},{"location":"architecture/overview/#1-request-flow","title":"1. Request Flow","text":""},{"location":"architecture/overview/#http-request-flow","title":"HTTP Request Flow","text":"<pre><code>flowchart TD\n    A[Client Request] --&gt; B[AuthenticationMiddleware&lt;br/&gt;validates JWT]\n    B --&gt; C[require_roles dependency&lt;br/&gt;checks RBAC permissions]\n    C --&gt; D[HTTP Handler&lt;br/&gt;app/api/http/]\n    D --&gt; E[Database/Redis&lt;br/&gt;operations]\n    E --&gt; F[Response to Client]\n\n    style A fill:#e1f5ff\n    style B fill:#d4edda\n    style C fill:#d4edda\n    style D fill:#cce5ff\n    style E fill:#f8d7da\n    style F fill:#e1f5ff</code></pre>"},{"location":"architecture/overview/#websocket-request-flow","title":"WebSocket Request Flow","text":"<pre><code>flowchart TD\n    A[Client Connection] --&gt; B[PackageAuthWebSocketEndpoint&lt;br/&gt;validates JWT from query params]\n    B --&gt; C[Connection Established]\n    C --&gt; D[Client sends JSON message&lt;br/&gt;pkg_id, req_id, data]\n    D --&gt; E[PackageRouter.handle_request]\n    E --&gt; F[Validation Pipeline]\n\n    F --&gt; G[1. Validate request format]\n    G --&gt; H[2. Check RBAC permissions&lt;br/&gt;RBACManager]\n    H --&gt; I[3. Validate data&lt;br/&gt;JSON schema]\n    I --&gt; J[4. Dispatch to&lt;br/&gt;registered handler]\n\n    J --&gt; K[Handler processes request]\n    K --&gt; L[Response Model&lt;br/&gt;pkg_id, req_id, status_code, data]\n    L --&gt; M[Send to client via WebSocket]\n\n    style A fill:#e1f5ff\n    style B fill:#d4edda\n    style C fill:#fff3cd\n    style D fill:#e1f5ff\n    style E fill:#cce5ff\n    style F fill:#cce5ff\n    style G fill:#cce5ff\n    style H fill:#d4edda\n    style I fill:#cce5ff\n    style J fill:#cce5ff\n    style K fill:#cce5ff\n    style L fill:#fff3cd\n    style M fill:#e1f5ff</code></pre>"},{"location":"architecture/overview/#2-authentication-system","title":"2. Authentication System","text":"<p>Provider: Keycloak (OpenID Connect / OAuth 2.0)</p> <p>Components: - <code>app/auth.py</code> - Authentication backend for Starlette - <code>app/managers/keycloak_manager.py</code> - Keycloak client wrapper - <code>app/schemas/user.py</code> - User model with roles</p> <p>Token Flow: 1. User authenticates with Keycloak (username/password or SSO) 2. Keycloak returns JWT access token 3. Client includes token in requests:    - HTTP: <code>Authorization: Bearer &lt;token&gt;</code> header    - WebSocket: <code>?Authorization=Bearer &lt;token&gt;</code> query parameter 4. <code>AuthBackend.authenticate()</code> validates and decodes JWT 5. User object with roles attached to request context</p> <p>Configuration (see <code>app/settings.py</code>): - <code>KEYCLOAK_REALM</code> - Keycloak realm name - <code>KEYCLOAK_CLIENT_ID</code> - OAuth client ID - <code>KEYCLOAK_BASE_URL</code> - Keycloak server URL - <code>EXCLUDED_PATHS</code> - Paths that bypass authentication (e.g., /health)</p>"},{"location":"architecture/overview/#3-authorization-rbac","title":"3. Authorization (RBAC)","text":"<p>Current Implementation: Decorator-based roles defined in code</p> <p>Components: - <code>app/managers/rbac_manager.py</code> - Permission checking logic - <code>app/dependencies/permissions.py</code> - FastAPI dependency for HTTP endpoints - <code>app/routing.py</code> - PackageRouter with permissions registry</p> <p>Permission Definition:</p> <p>WebSocket Handlers: <pre><code>@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    roles=[\"get-authors\"]  # Permissions defined here\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n</code></pre></p> <p>HTTP Endpoints: <pre><code>from app.dependencies.permissions import require_roles\n\n@router.get(\n    \"/authors\",\n    dependencies=[Depends(require_roles(\"get-authors\"))]\n)\nasync def get_authors():\n    ...\n</code></pre></p> <p>Permission Checking: - WebSocket: <code>RBACManager.check_ws_permission(pkg_id, user)</code> - reads from <code>pkg_router.permissions_registry</code> - HTTP: <code>require_roles(*roles)</code> FastAPI dependency - Default policy: If no roles specified = public access</p>"},{"location":"architecture/overview/#4-middleware-stack","title":"4. Middleware Stack","text":"<p>The application uses a comprehensive middleware stack for cross-cutting concerns. Middlewares process requests and responses in order:</p> <p>Middleware Execution Order (configured in <code>app/__init__.py</code>):</p> <ol> <li>TrustedHostMiddleware - Validates Host header against allowed hosts</li> <li>Prevents Host header injection attacks</li> <li> <p>Configured via <code>ALLOWED_HOSTS</code> setting</p> </li> <li> <p>AuthenticationMiddleware (Starlette) - JWT token validation</p> </li> <li>Uses <code>AuthBackend.authenticate()</code> to decode and validate Keycloak tokens</li> <li>Attaches <code>UserModel</code> with roles to request context</li> <li> <p>Respects <code>EXCLUDED_PATHS</code> for public endpoints</p> </li> <li> <p>CorrelationIDMiddleware - Adds X-Correlation-ID for distributed tracing</p> </li> <li>Generates UUID v4 if client doesn't provide correlation ID</li> <li> <p>Propagates through logs, audit logs, and metrics</p> </li> <li> <p>LoggingContextMiddleware - Enriches logs with request context</p> </li> <li>Adds request_id, user_id, endpoint, method, ip_address to all logs</li> <li>Uses contextvars for thread-safe propagation</li> <li> <p>Enables querying logs by correlation ID in Grafana Loki</p> </li> <li> <p>AuditMiddleware - Records user actions for compliance</p> </li> <li>Captures request/response metadata (method, path, status, duration)</li> <li>Extracts user info from authenticated requests</li> <li>Async queue-based processing (non-blocking)</li> <li> <p>Sends to <code>audit_logger</code> for batch database writes</p> </li> <li> <p>RequestSizeLimitMiddleware - Protects against large payload attacks</p> </li> <li>Checks Content-Length before processing</li> <li> <p>Returns 413 Payload Too Large if exceeds <code>MAX_REQUEST_BODY_SIZE</code> (1MB default)</p> </li> <li> <p>SecurityHeadersMiddleware - Adds security headers</p> </li> <li>X-Frame-Options, X-Content-Type-Options, X-XSS-Protection</li> <li>Strict-Transport-Security, Content-Security-Policy</li> <li> <p>See Security Guide for details</p> </li> <li> <p>RateLimitMiddleware - Rate limiting for HTTP endpoints</p> </li> <li>Redis-based sliding window algorithm</li> <li>Returns 429 Too Many Requests when limits exceeded</li> <li> <p>Adds X-RateLimit-* headers to responses</p> </li> <li> <p>PrometheusMiddleware - Metrics collection</p> </li> <li>Tracks http_requests_total, http_request_duration_seconds</li> <li>http_requests_in_progress gauge</li> </ol> <p>Middleware Architecture Benefits: - Separation of Concerns: Each middleware handles one responsibility - Reusability: Same middleware for all HTTP endpoints - Ordering Control: Execution order defined in application factory - Testability: Each middleware can be tested independently</p> <p>See Also: - CLAUDE.md - Detailed middleware documentation - Security Guide - Security middleware configuration</p>"},{"location":"architecture/overview/#5-websocket-package-router","title":"5. WebSocket Package Router","text":"<p>Purpose: Route WebSocket messages to appropriate handlers based on package ID (PkgID).</p> <p>Key Files: - <code>app/routing.py</code> - PackageRouter class - <code>app/api/ws/constants.py</code> - PkgID enum definitions - <code>app/api/ws/handlers/</code> - Handler implementations</p> <p>Handler Registration: <pre><code>@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    validator_callback=validator,\n    roles=[\"get-authors\"]  # Permission specification\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    # Handler implementation\n    pass\n</code></pre></p> <p>Request/Response Format: - Request: <code>{\"pkg_id\": 1, \"req_id\": \"uuid\", \"data\": {...}}</code> - Response: <code>{\"pkg_id\": 1, \"req_id\": \"uuid\", \"status_code\": 0, \"data\": {...}, \"meta\": null}</code></p> <p>Features: - Automatic JSON schema validation - RBAC permission checking - Request/response correlation via req_id - Error handling with status codes</p>"},{"location":"architecture/overview/#5-database-layer","title":"5. Database Layer","text":"<p>Technology: PostgreSQL with async SQLModel/SQLAlchemy</p> <p>Configuration (see <code>app/storage/db.py</code>): - Connection pooling (configurable pool size) - Async operations (asyncpg driver) - Automatic retry on connection failure</p> <p>Models: <code>app/models/</code> - Inherit from SQLModel with <code>table=True</code> - Support async operations - Class methods for common operations</p> <p>Pagination Helper: <pre><code>results, meta = await get_paginated_results(\n    Author,\n    page=1,\n    per_page=20,\n    filters={\"status\": \"active\"}\n)\n</code></pre></p>"},{"location":"architecture/overview/#6-connection-management","title":"6. Connection Management","text":"<p>WebSocket Connections: <code>app/managers/websocket_connection_manager.py</code> - Track active connections - Broadcast to all connected clients - Automatic cleanup on disconnect</p> <p>Redis Sessions: <code>app/storage/redis.py</code> - Session storage - Pub/sub for cross-instance communication - Connection pooling</p>"},{"location":"architecture/overview/#7-background-tasks","title":"7. Background Tasks","text":"<p>Location: <code>app/tasks/</code></p> <p>Current Tasks: - <code>kc_user_session_task</code> - Monitor Keycloak session expiration via Redis pub/sub</p> <p>Management: - Started in app startup handler - Graceful shutdown on app termination - Tracked in global tasks list</p>"},{"location":"architecture/overview/#design-patterns","title":"Design Patterns","text":""},{"location":"architecture/overview/#singleton-pattern","title":"Singleton Pattern","text":"<p>Used for managers that should have single instance: - <code>RBACManager</code> - <code>KeycloakManager</code> - Implemented via <code>SingletonMeta</code> metaclass</p>"},{"location":"architecture/overview/#decorator-pattern","title":"Decorator Pattern","text":"<p>Used for handler registration and enhancement: - <code>@pkg_router.register()</code> - WebSocket handler registration - <code>@router.get/post()</code> - HTTP endpoint registration - Proposed: <code>@require_roles()</code> for inline permission declarations</p>"},{"location":"architecture/overview/#repository-pattern","title":"Repository Pattern","text":"<p>Models encapsulate data access: - Class methods for CRUD operations - Async session management - Filter support</p>"},{"location":"architecture/overview/#configuration-management","title":"Configuration Management","text":"<p>File: <code>app/settings.py</code></p> <p>Technology: Pydantic Settings (loads from environment variables)</p> <p>Key Settings: - Database connection parameters - Keycloak configuration - Redis connection - Pool sizes and timeouts - Debug flags (development only)</p>"},{"location":"architecture/overview/#security-considerations","title":"Security Considerations","text":""},{"location":"architecture/overview/#current-security-measures","title":"Current Security Measures","text":"<ul> <li>\u2705 JWT-based authentication via Keycloak</li> <li>\u2705 RBAC for endpoint authorization</li> <li>\u2705 Comprehensive middleware stack (9 middlewares)</li> <li>\u2705 Security headers (CSP, X-Frame-Options, HSTS, etc.)</li> <li>\u2705 Rate limiting (HTTP and WebSocket)</li> <li>\u2705 Request size limits (1MB default, configurable)</li> <li>\u2705 Host header validation (prevents injection attacks)</li> <li>\u2705 IP spoofing protection (trusted proxy validation)</li> <li>\u2705 Excluded paths for public endpoints</li> <li>\u2705 WebSocket authentication on connection</li> <li>\u2705 Audit logging for compliance</li> </ul>"},{"location":"architecture/overview/#resilience-patterns","title":"Resilience Patterns","text":"<p>Circuit Breaker Pattern (see Circuit Breaker Guide):</p> <p>The application implements circuit breaker pattern for external service dependencies to prevent cascading failures:</p> <p>Protected Services: - Keycloak: Authentication service   - Fail-fast when Keycloak is unavailable   - Prevents thread exhaustion from connection timeouts   - Configurable: <code>KEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX</code> (default: 5), <code>KEYCLOAK_CIRCUIT_BREAKER_TIMEOUT</code> (default: 60s)</p> <ul> <li>Redis: Caching and rate limiting</li> <li>Graceful degradation when Redis is down</li> <li>Configurable: <code>REDIS_CIRCUIT_BREAKER_FAIL_MAX</code> (default: 3), <code>REDIS_CIRCUIT_BREAKER_TIMEOUT</code> (default: 30s)</li> </ul> <p>Circuit Breaker States: - Closed (0): Normal operation, requests pass through - Open (1): Service failing, requests fail fast (no retry) - Half-Open (2): Testing if service recovered</p> <p>Monitoring: - Prometheus metrics: <code>circuit_breaker_state</code>, <code>circuit_breaker_failures_total</code>, <code>circuit_breaker_state_changes_total</code> - Grafana dashboards: Panels 28-30 visualize circuit breaker health - Alerts: <code>CircuitBreakerOpen</code> (critical), <code>CircuitBreakerFlapping</code> (warning)</p> <p>Benefits: - Prevents resource exhaustion during outages - Allows services to recover without continued load - Provides clear visibility into service health - Reduces mean time to detection (MTTD) for outages</p>"},{"location":"architecture/overview/#known-issues","title":"Known Issues","text":"<ul> <li>All major security and resilience features implemented</li> <li>Regular security audits recommended</li> <li>Monitor Prometheus alerts for circuit breaker state</li> </ul>"},{"location":"architecture/overview/#performance-considerations","title":"Performance Considerations","text":""},{"location":"architecture/overview/#current-optimizations","title":"Current Optimizations","text":"<ul> <li>Async I/O throughout</li> <li>Database connection pooling</li> <li>Redis for caching and sessions</li> <li>Singleton managers</li> </ul>"},{"location":"architecture/overview/#potential-improvements","title":"Potential Improvements","text":"<ul> <li>Database query optimization (pagination)</li> <li>WebSocket broadcast concurrency</li> <li>Redis connection pool tuning</li> <li>Response caching</li> </ul>"},{"location":"architecture/overview/#scalability","title":"Scalability","text":""},{"location":"architecture/overview/#current-limitations","title":"Current Limitations","text":"<ul> <li>Single-instance architecture (WebSocket state)</li> <li>No load balancing strategy</li> <li>File-based RBAC configuration</li> </ul>"},{"location":"architecture/overview/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Multi-instance with Redis pub/sub</li> <li>Database-backed RBAC for runtime updates</li> <li>Distributed session management</li> <li>Horizontal scaling with load balancer</li> </ul>"},{"location":"architecture/overview/#testing-strategy","title":"Testing Strategy","text":"<p>Test Files: <code>tests/</code></p> <p>Current Coverage: ~57% (4 of 7 API files)</p> <p>Test Types: - Unit tests (handlers, managers) - Integration tests (marked with <code>@pytest.mark.integration</code>) - Mock-based authentication tests - Real Keycloak authentication tests</p> <p>See: Testing Guide</p>"},{"location":"architecture/overview/#deployment","title":"Deployment","text":""},{"location":"architecture/overview/#dependencies","title":"Dependencies","text":"<ul> <li>Python 3.13+</li> <li>PostgreSQL 12+</li> <li>Redis 6+</li> <li>Keycloak 20+</li> </ul>"},{"location":"architecture/overview/#environment","title":"Environment","text":"<ul> <li>Docker Compose for local development</li> <li>Environment variables for configuration</li> <li>Health check endpoint for monitoring</li> </ul>"},{"location":"architecture/overview/#startup-process","title":"Startup Process","text":"<ol> <li>Load settings from environment</li> <li>Initialize database connection</li> <li>Wait for database availability</li> <li>Register WebSocket handlers</li> <li>Register HTTP routers</li> <li>Start background tasks</li> <li>Start server</li> </ol>"},{"location":"architecture/overview/#related-documentation","title":"Related Documentation","text":"<ul> <li>RBAC System - Role-based access control implementation</li> <li>Design Patterns - Repository + Command + DI patterns</li> <li>Request Flow - Detailed sequence diagrams</li> <li>Testing Guide - How to test the application</li> <li>Authentication Guide - Working with Keycloak</li> </ul>"},{"location":"architecture/overview/#diagrams","title":"Diagrams","text":""},{"location":"architecture/overview/#component-interaction","title":"Component Interaction","text":"<pre><code>graph TD\n    Client[Client]\n    FastAPI[FastAPI&lt;br/&gt;Application]\n    Keycloak[Keycloak&lt;br/&gt;Auth]\n    PostgreSQL[PostgreSQL&lt;br/&gt;DB]\n    Redis[Redis&lt;br/&gt;Cache]\n    Managers[Managers&lt;br/&gt;RBAC, Keycloak]\n\n    Client --&gt; FastAPI\n    FastAPI --&gt; Keycloak\n    FastAPI --&gt; PostgreSQL\n    FastAPI --&gt; Redis\n    FastAPI --&gt; Managers\n\n    style Client fill:#e1f5ff,stroke:#333,stroke-width:2px\n    style FastAPI fill:#f9f,stroke:#333,stroke-width:3px\n    style Keycloak fill:#ffe1f5,stroke:#333,stroke-width:2px\n    style PostgreSQL fill:#e1ffe1,stroke:#333,stroke-width:2px\n    style Redis fill:#ffe1e1,stroke:#333,stroke-width:2px\n    style Managers fill:#fff4e1,stroke:#333,stroke-width:2px</code></pre>"},{"location":"architecture/overview/#maintenance","title":"Maintenance","text":"<p>Code Organization: - Follow existing package structure - Keep handlers thin (business logic in services/managers) - Use type hints throughout - Maintain 80%+ docstring coverage</p> <p>Adding New Features: 1. Define models in <code>app/models/</code> 2. Create schemas in <code>app/schemas/</code> 3. Implement handlers in <code>app/api/http/</code> or <code>app/api/ws/handlers/</code> 4. Specify required roles in handler decorators (WebSocket: <code>roles=[]</code>, HTTP: <code>require_roles()</code>) 5. Write tests in <code>tests/</code> 6. Update documentation</p>"},{"location":"architecture/rbac/","title":"RBAC System","text":"<p>Role-Based Access Control (RBAC) in this application uses a decorator-based approach where permissions are defined directly in handler code.</p>"},{"location":"architecture/rbac/#overview","title":"Overview","text":"<p>The RBAC system provides:</p> <ul> <li>Decorator-based permissions - Roles defined directly with handlers</li> <li>Type-safe - All permissions in Python code, not external files</li> <li>Co-located - Permissions live next to the code they protect</li> <li>Two protocols - Works for both HTTP and WebSocket</li> </ul>"},{"location":"architecture/rbac/#rbac-flow","title":"RBAC Flow","text":"<pre><code>flowchart TD\n    A[Request with JWT Token] --&gt; B{Protocol?}\n\n    B --&gt;|HTTP| C[require_roles dependency]\n    B --&gt;|WebSocket| D[PackageRouter.handle_request]\n\n    C --&gt; E[Extract user roles from JWT]\n    D --&gt; F[Check permissions_registry]\n    F --&gt; E\n\n    E --&gt; G{User has ALL&lt;br/&gt;required roles?}\n\n    G --&gt;|No| H[403 Forbidden&lt;br/&gt;PermissionDeniedError]\n    G --&gt;|Yes| I[Forward to Handler]\n\n    I --&gt; J[Handler Executes]\n    J --&gt; K[Response to Client]\n\n    style A fill:#e1f5ff\n    style C fill:#d4edda\n    style D fill:#d4edda\n    style E fill:#fff3cd\n    style G fill:#fff3cd\n    style H fill:#f8d7da\n    style I fill:#cce5ff\n    style J fill:#cce5ff\n    style K fill:#e1f5ff</code></pre>"},{"location":"architecture/rbac/#components","title":"Components","text":""},{"location":"architecture/rbac/#rbacmanager","title":"RBACManager","text":"<p>Singleton manager for permission checking:</p> <ul> <li><code>check_ws_permission(pkg_id, user)</code> - Validates WebSocket permissions</li> <li><code>require_roles(*roles)</code> - FastAPI dependency for HTTP endpoints</li> <li>Reads from <code>pkg_router.permissions_registry</code> for WebSocket</li> <li>No external configuration files needed</li> </ul> <p>Location: <code>app/managers/rbac_manager.py</code></p>"},{"location":"architecture/rbac/#permissions-registry","title":"Permissions Registry","text":"<p>The <code>PackageRouter</code> maintains a registry of required roles for each WebSocket handler:</p> <pre><code># Internal registry structure\npermissions_registry: dict[PkgID, list[str]] = {\n    PkgID.GET_AUTHORS: [\"get-authors\"],\n    PkgID.CREATE_AUTHOR: [\"create-author\", \"admin\"],\n    PkgID.DELETE_AUTHOR: [\"delete-author\", \"admin\"]\n}\n</code></pre>"},{"location":"architecture/rbac/#websocket-rbac","title":"WebSocket RBAC","text":""},{"location":"architecture/rbac/#defining-permissions","title":"Defining Permissions","text":"<p>Use the <code>roles</code> parameter in the <code>@pkg_router.register()</code> decorator:</p> <pre><code>from app.routing import pkg_router\nfrom app.api.ws.constants import PkgID\nfrom app.schemas.request import RequestModel\nfrom app.schemas.response import ResponseModel\n\n@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    roles=[\"get-authors\"]  # Required roles\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Get all authors - requires 'get-authors' role.\"\"\"\n    # Handler implementation\n    ...\n</code></pre>"},{"location":"architecture/rbac/#multiple-roles","title":"Multiple Roles","text":"<p>User must have ALL specified roles:</p> <pre><code>@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"delete-author\", \"admin\"]  # Requires BOTH roles\n)\nasync def delete_author_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Delete author - requires both 'delete-author' AND 'admin' roles.\"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#public-endpoints","title":"Public Endpoints","text":"<p>Omit the <code>roles</code> parameter for public access (no authentication required):</p> <pre><code>@pkg_router.register(\n    PkgID.PUBLIC_DATA,\n    json_schema=PublicDataSchema\n    # No roles parameter = public access\n)\nasync def public_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Public endpoint - no authentication required.\"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#http-rbac","title":"HTTP RBAC","text":""},{"location":"architecture/rbac/#defining-permissions_1","title":"Defining Permissions","text":"<p>Use the <code>require_roles()</code> FastAPI dependency:</p> <pre><code>from fastapi import APIRouter, Depends\nfrom app.dependencies.permissions import require_roles\nfrom app.schemas.author import Author\n\nrouter = APIRouter(prefix=\"/api\", tags=[\"authors\"])\n\n@router.get(\n    \"/authors\",\n    dependencies=[Depends(require_roles(\"get-authors\"))]\n)\nasync def get_authors() -&gt; list[Author]:\n    \"\"\"Get all authors - requires 'get-authors' role.\"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#multiple-roles_1","title":"Multiple Roles","text":"<p>User must have ALL specified roles:</p> <pre><code>@router.delete(\n    \"/authors/{author_id}\",\n    dependencies=[Depends(require_roles(\"delete-author\", \"admin\"))]\n)\nasync def delete_author(author_id: int):\n    \"\"\"Delete author - requires BOTH 'delete-author' AND 'admin' roles.\"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#public-endpoints_1","title":"Public Endpoints","text":"<p>Omit the <code>dependencies</code> parameter for public access:</p> <pre><code>@router.get(\"/health\")\nasync def health_check():\n    \"\"\"Public endpoint - no authentication required.\"\"\"\n    return {\"status\": \"healthy\"}\n</code></pre>"},{"location":"architecture/rbac/#permission-flow","title":"Permission Flow","text":""},{"location":"architecture/rbac/#http-request-flow","title":"HTTP Request Flow","text":"<pre><code>1. Client sends request with JWT token\n   \u2193\n2. AuthenticationMiddleware validates token\n   \u2193\n3. require_roles() dependency checks user roles\n   \u2193\n   \u251c\u2500 User has required roles \u2192 Continue to handler\n   \u2514\u2500 User missing roles \u2192 Return 403 Forbidden\n</code></pre>"},{"location":"architecture/rbac/#websocket-request-flow","title":"WebSocket Request Flow","text":"<pre><code>1. Client connects with JWT token in query params\n   \u2193\n2. PackageAuthWebSocketEndpoint validates token\n   \u2193\n3. Client sends message with pkg_id\n   \u2193\n4. PackageRouter.handle_request() checks permissions\n   \u2193\n5. RBACManager.check_ws_permission(pkg_id, user)\n   \u2193\n   \u251c\u2500 User has required roles \u2192 Dispatch to handler\n   \u2514\u2500 User missing roles \u2192 Return error response\n</code></pre>"},{"location":"architecture/rbac/#role-management","title":"Role Management","text":""},{"location":"architecture/rbac/#defining-roles-in-keycloak","title":"Defining Roles in Keycloak","text":"<p>Roles are managed in Keycloak:</p> <ol> <li>Log into Keycloak Admin Console</li> <li>Select your realm</li> <li>Navigate to Roles \u2192 Realm roles</li> <li>Click Create role</li> <li>Define role name (e.g., <code>get-authors</code>, <code>create-author</code>)</li> </ol>"},{"location":"architecture/rbac/#assigning-roles-to-users","title":"Assigning Roles to Users","text":"<ol> <li>Navigate to Users in Keycloak Admin</li> <li>Select the user</li> <li>Go to Role mapping tab</li> <li>Click Assign role</li> <li>Select the roles to assign</li> </ol>"},{"location":"architecture/rbac/#role-naming-convention","title":"Role Naming Convention","text":"<p>Follow these conventions for consistency:</p> <ul> <li>Use kebab-case: <code>get-authors</code>, <code>create-author</code></li> <li>Use descriptive names: <code>delete-author</code> not <code>del-auth</code></li> <li>Resource-action format: <code>{action}-{resource}</code></li> <li>Examples:</li> <li><code>get-authors</code> - View authors</li> <li><code>create-author</code> - Create new authors</li> <li><code>update-author</code> - Modify authors</li> <li><code>delete-author</code> - Remove authors</li> <li><code>admin</code> - Administrative privileges</li> </ul>"},{"location":"architecture/rbac/#common-patterns","title":"Common Patterns","text":""},{"location":"architecture/rbac/#read-only-access","title":"Read-Only Access","text":"<pre><code># WebSocket\n@pkg_router.register(PkgID.GET_AUTHORS, roles=[\"viewer\"])\n\n# HTTP\n@router.get(\"/authors\", dependencies=[Depends(require_roles(\"viewer\"))])\n</code></pre>"},{"location":"architecture/rbac/#write-access","title":"Write Access","text":"<pre><code># WebSocket\n@pkg_router.register(PkgID.CREATE_AUTHOR, roles=[\"editor\"])\n\n# HTTP\n@router.post(\"/authors\", dependencies=[Depends(require_roles(\"editor\"))])\n</code></pre>"},{"location":"architecture/rbac/#admin-only-access","title":"Admin-Only Access","text":"<pre><code># WebSocket\n@pkg_router.register(PkgID.DELETE_AUTHOR, roles=[\"admin\"])\n\n# HTTP\n@router.delete(\"/authors/{id}\", dependencies=[Depends(require_roles(\"admin\"))])\n</code></pre>"},{"location":"architecture/rbac/#combined-permissions","title":"Combined Permissions","text":"<p>Require both a specific permission AND admin role:</p> <pre><code># WebSocket\n@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"delete-author\", \"admin\"]\n)\n\n# HTTP\n@router.delete(\n    \"/authors/{id}\",\n    dependencies=[Depends(require_roles(\"delete-author\", \"admin\"))]\n)\n</code></pre>"},{"location":"architecture/rbac/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/rbac/#permission-denied-403","title":"Permission Denied (403)","text":"<p>Symptom: Users get 403 Forbidden errors</p> <p>Diagnosis: <pre><code># Check user roles in Keycloak\n# Admin Console \u2192 Users \u2192 &lt;user&gt; \u2192 Role Mappings\n\n# Check handler code for required roles\n# WebSocket: @pkg_router.register(PkgID.*, roles=[\"role-name\"])\n# HTTP: dependencies=[Depends(require_roles(\"role-name\"))]\n\n# Check application logs\ndocker logs hw-server | grep -i \"permission\\|rbac\"\n</code></pre></p> <p>Solution:</p> <ol> <li>Verify user has the required role(s) in Keycloak</li> <li>Check handler decorator to see what roles are required</li> <li>Ensure JWT token includes the roles (check token claims)</li> </ol>"},{"location":"architecture/rbac/#finding-required-roles","title":"Finding Required Roles","text":"<p>To find what roles are required for an endpoint:</p> <p>WebSocket: <pre><code># Search handler code\ngrep -r \"@pkg_router.register\" app/api/ws/handlers/ | grep \"PkgID.YOUR_HANDLER\"\n</code></pre></p> <p>HTTP: <pre><code># Search endpoint code\ngrep -r \"require_roles\" app/api/http/\n</code></pre></p>"},{"location":"architecture/rbac/#testing-rbac","title":"Testing RBAC","text":"<pre><code># tests/test_rbac.py\nimport pytest\nfrom app.managers.rbac_manager import RBACManager\nfrom app.schemas.user import UserModel\n\ndef test_user_with_correct_role():\n    \"\"\"Test user with correct role can access endpoint.\"\"\"\n    user = UserModel(\n        sub=\"user123\",\n        username=\"testuser\",\n        roles=[\"get-authors\"]\n    )\n    rbac = RBACManager()\n\n    # Should allow access\n    assert rbac.check_ws_permission(PkgID.GET_AUTHORS, user) is True\n\ndef test_user_without_role():\n    \"\"\"Test user without role is denied access.\"\"\"\n    user = UserModel(\n        sub=\"user123\",\n        username=\"testuser\",\n        roles=[\"viewer\"]  # Missing 'get-authors'\n    )\n    rbac = RBACManager()\n\n    # Should deny access\n    assert rbac.check_ws_permission(PkgID.GET_AUTHORS, user) is False\n</code></pre>"},{"location":"architecture/rbac/#best-practices","title":"Best Practices","text":""},{"location":"architecture/rbac/#1-principle-of-least-privilege","title":"1. Principle of Least Privilege","text":"<p>Only grant the minimum roles needed:</p> <pre><code># Good - specific permission\n@pkg_router.register(PkgID.GET_AUTHORS, roles=[\"get-authors\"])\n\n# Avoid - overly broad\n@pkg_router.register(PkgID.GET_AUTHORS, roles=[\"admin\"])\n</code></pre>"},{"location":"architecture/rbac/#2-descriptive-role-names","title":"2. Descriptive Role Names","text":"<p>Use clear, descriptive role names:</p> <pre><code># Good\nroles=[\"create-author\", \"update-author\"]\n\n# Avoid\nroles=[\"writer\", \"modifier\"]\n</code></pre>"},{"location":"architecture/rbac/#3-co-locate-permissions","title":"3. Co-locate Permissions","text":"<p>Define permissions next to the code they protect:</p> <pre><code># Good - roles defined with handler\n@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"delete-author\", \"admin\"]\n)\nasync def delete_author_handler(request: RequestModel):\n    ...\n\n# This makes it obvious what roles are required\n</code></pre>"},{"location":"architecture/rbac/#4-document-role-requirements","title":"4. Document Role Requirements","text":"<p>Add docstrings explaining what roles are required:</p> <pre><code>@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"delete-author\", \"admin\"]\n)\nasync def delete_author_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"\n    Delete an author.\n\n    Requires BOTH 'delete-author' AND 'admin' roles.\n    User must have all specified roles to access this endpoint.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#5-test-rbac-logic","title":"5. Test RBAC Logic","text":"<p>Always write tests for permission checks:</p> <pre><code># Test both allowed and denied scenarios\ndef test_authorized_access():\n    \"\"\"Test user with correct roles can access.\"\"\"\n    ...\n\ndef test_unauthorized_access():\n    \"\"\"Test user without roles is denied.\"\"\"\n    ...\n</code></pre>"},{"location":"architecture/rbac/#security-considerations","title":"Security Considerations","text":""},{"location":"architecture/rbac/#token-validation","title":"Token Validation","text":"<ul> <li>JWT tokens are validated on every request</li> <li>Expired tokens are automatically rejected</li> <li>Token signature is verified against Keycloak public key</li> </ul>"},{"location":"architecture/rbac/#role-extraction","title":"Role Extraction","text":"<ul> <li>Roles are extracted from <code>realm_access.roles</code> in JWT</li> <li>Only roles from the configured Keycloak realm are used</li> <li>Invalid or missing role claims result in empty role list</li> </ul>"},{"location":"architecture/rbac/#permission-checking","title":"Permission Checking","text":"<ul> <li>User must have ALL required roles (AND logic)</li> <li>No roles specified = public access (use cautiously)</li> <li>Permission denied returns 403 Forbidden (not 401)</li> </ul>"},{"location":"architecture/rbac/#related-documentation","title":"Related Documentation","text":"<ul> <li>Authentication Guide - Setting up Keycloak and users</li> <li>HTTP API Reference - HTTP endpoint documentation</li> <li>WebSocket API Reference - WebSocket handler documentation</li> <li>Testing Guide - Testing RBAC logic</li> </ul>"},{"location":"architecture/request-flow/","title":"Sequence Diagrams","text":"<p>This document provides detailed sequence diagrams for key flows in the application.</p>"},{"location":"architecture/request-flow/#authentication-flow","title":"Authentication Flow","text":""},{"location":"architecture/request-flow/#http-login-flow","title":"HTTP Login Flow","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant FastAPI\n    participant KeycloakManager\n    participant Keycloak\n    participant Redis\n\n    Client-&gt;&gt;FastAPI: POST /login {username, password}\n    FastAPI-&gt;&gt;KeycloakManager: login(username, password)\n    KeycloakManager-&gt;&gt;Keycloak: Token request (OAuth2 password grant)\n    Keycloak--&gt;&gt;KeycloakManager: {access_token, refresh_token, expires_in}\n    KeycloakManager--&gt;&gt;FastAPI: Token data\n    FastAPI-&gt;&gt;Redis: Store user session\n    Redis--&gt;&gt;FastAPI: OK\n    FastAPI--&gt;&gt;Client: {access_token, refresh_token, expires_in}</code></pre>"},{"location":"architecture/request-flow/#websocket-authentication-flow","title":"WebSocket Authentication Flow","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant WebSocket\n    participant AuthBackend\n    participant Keycloak\n    participant ConnectionLimiter\n    participant ConnectionManager\n\n    Client-&gt;&gt;WebSocket: Connect ws://host/web?token=&lt;jwt&gt;\n    WebSocket-&gt;&gt;AuthBackend: authenticate(connection)\n    AuthBackend-&gt;&gt;AuthBackend: Extract token from query params\n    AuthBackend-&gt;&gt;Keycloak: Validate JWT signature\n    Keycloak--&gt;&gt;AuthBackend: Token valid, user claims\n    AuthBackend--&gt;&gt;WebSocket: UserModel(sub, roles, ...)\n    WebSocket-&gt;&gt;ConnectionLimiter: check_limit(user_id)\n\n    alt Connection limit exceeded\n        ConnectionLimiter--&gt;&gt;WebSocket: Limit exceeded\n        WebSocket--&gt;&gt;Client: Close 1008 (Policy Violation)\n    else Limit OK\n        ConnectionLimiter--&gt;&gt;WebSocket: OK\n        WebSocket-&gt;&gt;ConnectionManager: connect(websocket)\n        ConnectionManager--&gt;&gt;WebSocket: Connection added\n        WebSocket--&gt;&gt;Client: Connection established\n    end</code></pre>"},{"location":"architecture/request-flow/#http-request-flow","title":"HTTP Request Flow","text":""},{"location":"architecture/request-flow/#get-authors-with-filtering","title":"GET /authors with Filtering","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant PrometheusMiddleware\n    participant RateLimitMiddleware\n    participant AuthMiddleware\n    participant Handler\n    participant RBACDependency as require_roles()\n    participant Database\n\n    Client-&gt;&gt;PrometheusMiddleware: GET /authors?name=John\n    PrometheusMiddleware-&gt;&gt;PrometheusMiddleware: Start metrics timer\n    PrometheusMiddleware-&gt;&gt;RateLimitMiddleware: Forward request\n\n    RateLimitMiddleware-&gt;&gt;RateLimitMiddleware: Get rate limit key\n    RateLimitMiddleware-&gt;&gt;RateLimitMiddleware: Check Redis counter\n\n    alt Rate limit exceeded\n        RateLimitMiddleware--&gt;&gt;Client: 429 Too Many Requests\n    else Rate limit OK\n        RateLimitMiddleware-&gt;&gt;AuthMiddleware: Forward request\n\n        AuthMiddleware-&gt;&gt;AuthMiddleware: Extract Authorization header\n        AuthMiddleware-&gt;&gt;AuthMiddleware: Validate JWT token\n        AuthMiddleware-&gt;&gt;AuthMiddleware: Populate request.state.user\n\n        alt Invalid token\n            AuthMiddleware--&gt;&gt;Client: 401 Unauthorized\n        else Valid token\n            AuthMiddleware-&gt;&gt;RBACDependency: Check permissions (FastAPI dependency)\n\n            RBACDependency-&gt;&gt;RBACDependency: Verify user has required roles\n\n            alt Permission denied\n                RBACDependency--&gt;&gt;Client: 403 Forbidden\n            else Permission granted\n                RBACDependency-&gt;&gt;Handler: Forward to endpoint\n\n                Handler-&gt;&gt;Handler: Validate query params\n                Handler-&gt;&gt;Database: SELECT * FROM author WHERE name ILIKE '%John%'\n                Database--&gt;&gt;Handler: [Author rows]\n                Handler--&gt;&gt;RBACDependency: [Author list]\n                RBACDependency--&gt;&gt;AuthMiddleware: Response\n                AuthMiddleware--&gt;&gt;RateLimitMiddleware: Response\n                RateLimitMiddleware-&gt;&gt;RateLimitMiddleware: Add X-RateLimit headers\n                RateLimitMiddleware--&gt;&gt;PrometheusMiddleware: Response\n                PrometheusMiddleware-&gt;&gt;PrometheusMiddleware: Record metrics\n                PrometheusMiddleware--&gt;&gt;Client: 200 OK + [Authors]\n            end\n        end\n    end</code></pre>"},{"location":"architecture/request-flow/#post-authors-create","title":"POST /authors (Create)","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Middleware\n    participant Handler\n    participant Session\n    participant Database\n\n    Client-&gt;&gt;Middleware: POST /authors {name: \"New Author\"}\n    Note over Middleware: Authentication &amp; Authorization\n    Middleware-&gt;&gt;Handler: Validated request\n\n    Handler-&gt;&gt;Handler: Validate request body (Pydantic)\n\n    alt Validation error\n        Handler--&gt;&gt;Client: 422 Validation Error\n    else Valid data\n        Handler-&gt;&gt;Repository: Inject AuthorRepository via Depends\n        Repository--&gt;&gt;Handler: Repository instance\n\n        Handler-&gt;&gt;Repository: repo.create(author)\n        Repository-&gt;&gt;Database: INSERT INTO author VALUES (...)\n        Database--&gt;&gt;Repository: Author with ID\n        Repository--&gt;&gt;Handler: Created Author\n\n        Handler-&gt;&gt;Database: COMMIT transaction\n        Database--&gt;&gt;Handler: OK\n\n        Handler--&gt;&gt;Client: 200 OK + {id: 1, name: \"New Author\"}\n    end</code></pre>"},{"location":"architecture/request-flow/#websocket-request-flow","title":"WebSocket Request Flow","text":""},{"location":"architecture/request-flow/#get_authors-request-pkgid-1","title":"GET_AUTHORS Request (PkgID: 1)","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant WebEndpoint\n    participant RateLimiter\n    participant PackageRouter\n    participant RBACManager\n    participant Handler\n    participant Database\n\n    Client-&gt;&gt;WebEndpoint: Send JSON: {pkg_id: 1, req_id: \"uuid\", data: {filters: {name: \"John\"}}}\n\n    WebEndpoint-&gt;&gt;WebEndpoint: Parse JSON message\n    WebEndpoint-&gt;&gt;WebEndpoint: Create RequestModel\n\n    WebEndpoint-&gt;&gt;RateLimiter: check_rate_limit(user_id)\n\n    alt Rate limit exceeded\n        RateLimiter--&gt;&gt;WebEndpoint: Limit exceeded\n        WebEndpoint--&gt;&gt;Client: {status_code: 1, msg: \"Rate limit exceeded\"}\n    else Rate OK\n        RateLimiter--&gt;&gt;WebEndpoint: OK\n\n        WebEndpoint-&gt;&gt;PackageRouter: handle_request(request)\n\n        PackageRouter-&gt;&gt;RBACManager: check_ws_permission(pkg_id, user)\n\n        alt Permission denied\n            RBACManager--&gt;&gt;PackageRouter: Permission denied\n            PackageRouter--&gt;&gt;WebEndpoint: {status_code: 3, msg: \"Permission denied\"}\n            WebEndpoint--&gt;&gt;Client: Error response\n        else Permission granted\n            RBACManager--&gt;&gt;PackageRouter: OK\n\n            PackageRouter-&gt;&gt;PackageRouter: Validate data against JSON schema\n\n            alt Schema validation error\n                PackageRouter--&gt;&gt;WebEndpoint: {status_code: 2, msg: \"Invalid data\"}\n                WebEndpoint--&gt;&gt;Client: Error response\n            else Valid schema\n                PackageRouter-&gt;&gt;Handler: Execute handler(request)\n\n                Handler-&gt;&gt;Database: SELECT * FROM author WHERE name ILIKE '%John%'\n                Database--&gt;&gt;Handler: [Author rows]\n\n                Handler-&gt;&gt;Handler: Build ResponseModel\n                Handler--&gt;&gt;PackageRouter: {status_code: 0, data: [...]}\n\n                PackageRouter--&gt;&gt;WebEndpoint: ResponseModel\n                WebEndpoint--&gt;&gt;Client: {pkg_id: 1, req_id: \"uuid\", status_code: 0, data: [...]}\n            end\n        end\n    end</code></pre>"},{"location":"architecture/request-flow/#get_paginated_authors-request-pkgid-2","title":"GET_PAGINATED_AUTHORS Request (PkgID: 2)","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant WebEndpoint\n    participant PackageRouter\n    participant Handler\n    participant PaginationUtil\n    participant Database\n\n    Client-&gt;&gt;WebEndpoint: {pkg_id: 2, req_id: \"uuid\", data: {page: 1, per_page: 20}}\n\n    Note over WebEndpoint: Rate limiting &amp; auth checks passed\n\n    WebEndpoint-&gt;&gt;PackageRouter: handle_request(request)\n    PackageRouter-&gt;&gt;Handler: get_paginated_authors_handler(request)\n\n    Handler-&gt;&gt;PaginationUtil: get_paginated_results(Author, page=1, per_page=20)\n\n    PaginationUtil-&gt;&gt;Database: SELECT COUNT(id) FROM author\n    Database--&gt;&gt;PaginationUtil: total=42\n\n    PaginationUtil-&gt;&gt;PaginationUtil: Calculate pages (42/20 = 3)\n\n    PaginationUtil-&gt;&gt;Database: SELECT * FROM author OFFSET 0 LIMIT 20\n    Database--&gt;&gt;PaginationUtil: [20 Author rows]\n\n    PaginationUtil--&gt;&gt;Handler: (results, MetadataModel{page: 1, per_page: 20, total: 42, pages: 3})\n\n    Handler-&gt;&gt;Handler: Build ResponseModel with meta\n    Handler--&gt;&gt;WebEndpoint: {status_code: 0, data: [...], meta: {...}}\n\n    WebEndpoint--&gt;&gt;Client: Complete response with pagination metadata</code></pre>"},{"location":"architecture/request-flow/#broadcast-flow","title":"Broadcast Flow","text":""},{"location":"architecture/request-flow/#server-initiated-broadcast","title":"Server-Initiated Broadcast","text":"<pre><code>sequenceDiagram\n    participant BackgroundTask\n    participant ConnectionManager\n    participant WebSocket1\n    participant WebSocket2\n    participant WebSocket3\n    participant Client1\n    participant Client2\n    participant Client3\n\n    BackgroundTask-&gt;&gt;BackgroundTask: Event occurs (e.g., data update)\n    BackgroundTask-&gt;&gt;BackgroundTask: Build BroadcastDataModel\n    BackgroundTask-&gt;&gt;ConnectionManager: broadcast(message)\n\n    ConnectionManager-&gt;&gt;ConnectionManager: Create connections snapshot\n    ConnectionManager-&gt;&gt;ConnectionManager: asyncio.gather(...)\n\n    par Broadcast to all clients\n        ConnectionManager-&gt;&gt;WebSocket1: send_json(message)\n        WebSocket1--&gt;&gt;Client1: {pkg_id: 1, req_id: \"00000000-...\", data: {...}}\n    and\n        ConnectionManager-&gt;&gt;WebSocket2: send_json(message)\n        WebSocket2--&gt;&gt;Client2: {pkg_id: 1, req_id: \"00000000-...\", data: {...}}\n    and\n        ConnectionManager-&gt;&gt;WebSocket3: send_json(message)\n\n        Note over WebSocket3: Connection failed\n        WebSocket3--xClient3: Exception\n        ConnectionManager-&gt;&gt;ConnectionManager: Safe error handling\n        ConnectionManager-&gt;&gt;ConnectionManager: disconnect(WebSocket3)\n    end\n\n    ConnectionManager--&gt;&gt;BackgroundTask: Broadcast complete</code></pre>"},{"location":"architecture/request-flow/#rate-limiting-flow","title":"Rate Limiting Flow","text":""},{"location":"architecture/request-flow/#sliding-window-rate-limiting","title":"Sliding Window Rate Limiting","text":"<pre><code>sequenceDiagram\n    participant Request\n    participant RateLimiter\n    participant Redis\n\n    Request-&gt;&gt;RateLimiter: check_rate_limit(key=\"user:john\", limit=60, window=60s)\n\n    RateLimiter-&gt;&gt;RateLimiter: current_time = now()\n    RateLimiter-&gt;&gt;RateLimiter: window_start = current_time - 60\n\n    RateLimiter-&gt;&gt;Redis: ZREMRANGEBYSCORE(key, -inf, window_start)\n    Note over Redis: Remove old requests outside window\n    Redis--&gt;&gt;RateLimiter: Removed count\n\n    RateLimiter-&gt;&gt;Redis: ZCARD(key)\n    Note over Redis: Count requests in current window\n    Redis--&gt;&gt;RateLimiter: current_count=45\n\n    alt current_count &gt;= limit\n        RateLimiter--&gt;&gt;Request: (False, 0) - Rate limit exceeded\n        Note over Request: Return 429 error\n    else current_count &lt; limit\n        RateLimiter-&gt;&gt;Redis: ZADD(key, current_time, request_id)\n        Note over Redis: Add current request to set\n        Redis--&gt;&gt;RateLimiter: OK\n\n        RateLimiter-&gt;&gt;Redis: EXPIRE(key, window * 2)\n        Note over Redis: Set TTL for automatic cleanup\n        Redis--&gt;&gt;RateLimiter: OK\n\n        RateLimiter-&gt;&gt;RateLimiter: remaining = limit - current_count - 1\n        RateLimiter--&gt;&gt;Request: (True, remaining) - Request allowed\n        Note over Request: Continue processing\n    end</code></pre>"},{"location":"architecture/request-flow/#websocket-connection-limiting","title":"WebSocket Connection Limiting","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant WebSocket\n    participant ConnectionLimiter\n    participant Redis\n\n    Client-&gt;&gt;WebSocket: Connect (user_id=\"user123\")\n    WebSocket-&gt;&gt;ConnectionLimiter: add_connection(user_id, connection_id)\n\n    ConnectionLimiter-&gt;&gt;Redis: SADD(\"ws:connections:user123\", connection_id)\n    Redis--&gt;&gt;ConnectionLimiter: OK\n\n    ConnectionLimiter-&gt;&gt;Redis: SCARD(\"ws:connections:user123\")\n    Note over Redis: Count connections for user\n    Redis--&gt;&gt;ConnectionLimiter: count=5\n\n    alt count &gt; max_connections (e.g., 5)\n        ConnectionLimiter-&gt;&gt;Redis: SREM(\"ws:connections:user123\", connection_id)\n        Redis--&gt;&gt;ConnectionLimiter: OK\n        ConnectionLimiter--&gt;&gt;WebSocket: False - Limit exceeded\n        WebSocket--&gt;&gt;Client: Close 1008 (Policy Violation)\n    else count &lt;= max_connections\n        ConnectionLimiter--&gt;&gt;WebSocket: True - Connection allowed\n        WebSocket--&gt;&gt;Client: Connection established\n    end</code></pre>"},{"location":"architecture/request-flow/#error-handling-flow","title":"Error Handling Flow","text":""},{"location":"architecture/request-flow/#handler-error-recovery","title":"Handler Error Recovery","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Handler\n    participant Database\n    participant Logger\n\n    Client-&gt;&gt;Handler: Request with valid data\n\n    Handler-&gt;&gt;Database: Execute query\n\n    alt Database error (SQLAlchemyError)\n        Database--xHandler: SQLAlchemyError\n        Handler-&gt;&gt;Logger: log.error(\"Database error: ...\")\n        Handler-&gt;&gt;Handler: Build error ResponseModel\n        Handler--&gt;&gt;Client: {status_code: 1, msg: \"Database error occurred\"}\n    else Validation error\n        Database--&gt;&gt;Handler: Success\n        Handler-&gt;&gt;Handler: Process results\n        Handler-&gt;&gt;Handler: Validation fails\n        Handler-&gt;&gt;Logger: log.error(\"Validation error: ...\")\n        Handler--&gt;&gt;Client: {status_code: 2, msg: \"Invalid data\"}\n    else Unexpected error\n        Database--&gt;&gt;Handler: Success\n        Handler-&gt;&gt;Handler: Processing...\n        Handler--xHandler: Unexpected exception\n        Note over Handler: Exception propagates up\n        Handler-&gt;&gt;Logger: log.exception(\"Unexpected error\")\n        Handler--&gt;&gt;Client: {status_code: 1, msg: \"Internal error\"}\n    else Success\n        Database--&gt;&gt;Handler: Results\n        Handler-&gt;&gt;Handler: Process and format\n        Handler--&gt;&gt;Client: {status_code: 0, data: [...]}\n    end</code></pre>"},{"location":"architecture/request-flow/#health-check-flow","title":"Health Check Flow","text":""},{"location":"architecture/request-flow/#health-check-with-dependency-verification","title":"Health Check with Dependency Verification","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant HealthEndpoint\n    participant Database\n    participant Redis\n\n    Client-&gt;&gt;HealthEndpoint: GET /health\n\n    par Check all dependencies\n        HealthEndpoint-&gt;&gt;Database: SELECT 1\n\n        alt Database OK\n            Database--&gt;&gt;HealthEndpoint: Success\n            HealthEndpoint-&gt;&gt;HealthEndpoint: db_status = \"healthy\"\n        else Database failed\n            Database--xHealthEndpoint: Exception\n            HealthEndpoint-&gt;&gt;HealthEndpoint: db_status = \"unhealthy\"\n        end\n    and\n        HealthEndpoint-&gt;&gt;Redis: PING\n\n        alt Redis OK\n            Redis--&gt;&gt;HealthEndpoint: PONG\n            HealthEndpoint-&gt;&gt;HealthEndpoint: redis_status = \"healthy\"\n        else Redis failed\n            Redis--xHealthEndpoint: Exception\n            HealthEndpoint-&gt;&gt;HealthEndpoint: redis_status = \"unhealthy\"\n        end\n    end\n\n    HealthEndpoint-&gt;&gt;HealthEndpoint: Aggregate statuses\n\n    alt All healthy\n        HealthEndpoint--&gt;&gt;Client: 200 OK {status: \"healthy\", database: \"healthy\", redis: \"healthy\"}\n    else Any unhealthy\n        HealthEndpoint--&gt;&gt;Client: 503 Service Unavailable {status: \"unhealthy\", ...}\n    end</code></pre>"},{"location":"architecture/request-flow/#metrics-collection-flow","title":"Metrics Collection Flow","text":""},{"location":"architecture/request-flow/#prometheus-metrics-scraping","title":"Prometheus Metrics Scraping","text":"<pre><code>sequenceDiagram\n    participant Prometheus\n    participant MetricsEndpoint\n    participant MetricsRegistry\n\n    loop Every scrape_interval (15s)\n        Prometheus-&gt;&gt;MetricsEndpoint: GET /metrics\n\n        MetricsEndpoint-&gt;&gt;MetricsRegistry: Collect all metrics\n\n        MetricsRegistry-&gt;&gt;MetricsRegistry: Gather HTTP request counters\n        MetricsRegistry-&gt;&gt;MetricsRegistry: Gather WebSocket metrics\n        MetricsRegistry-&gt;&gt;MetricsRegistry: Gather application metrics\n\n        MetricsRegistry--&gt;&gt;MetricsEndpoint: Metrics in text format\n\n        MetricsEndpoint--&gt;&gt;Prometheus: text/plain metrics\n        Note over MetricsEndpoint,Prometheus: # HELP http_requests_total...&lt;br/&gt;# TYPE http_requests_total counter&lt;br/&gt;http_requests_total{...} 1234.0\n\n        Prometheus-&gt;&gt;Prometheus: Store time series data\n        Prometheus-&gt;&gt;Prometheus: Evaluate alerting rules\n    end</code></pre>"},{"location":"architecture/request-flow/#notes","title":"Notes","text":"<p>These diagrams use Mermaid syntax and can be rendered using: - GitHub (automatic rendering) - Mermaid Live Editor: https://mermaid.live/ - VS Code with Mermaid extension - Documentation tools that support Mermaid</p> <p>For complex flows, refer to the source code in: - <code>app/middlewares/</code> - Middleware implementations - <code>app/routing.py</code> - WebSocket routing logic - <code>app/api/ws/handlers/</code> - WebSocket handlers - <code>app/api/http/</code> - HTTP handlers</p>"},{"location":"cookiecutter/","title":"Cookiecutter Template","text":"<p>This project can be used as a Cookiecutter template to generate new projects.</p>"},{"location":"cookiecutter/#contents","title":"Contents","text":"<ul> <li>Overview - Template features and structure</li> <li>Customization - Customizing the generated project</li> <li>Examples - Example projects built with this template</li> </ul>"},{"location":"cookiecutter/#quick-start","title":"Quick Start","text":"<p>```bash</p>"},{"location":"cookiecutter/#install-cookiecutter","title":"Install cookiecutter","text":"<p>pip install cookiecutter</p>"},{"location":"cookiecutter/#generate-new-project","title":"Generate new project","text":"<p>cookiecutter gh:acikabubo/fastapi-http-websocket</p>"},{"location":"cookiecutter/#follow-the-prompts-to-customize-your-project","title":"Follow the prompts to customize your project","text":"<p>```</p> <p>See Overview for more information.</p>"},{"location":"deployment/","title":"Deployment","text":"<p>Production deployment guides and operational documentation.</p>"},{"location":"deployment/#deployment-guides","title":"Deployment Guides","text":"<ul> <li>Docker Deployment - Container-based deployment</li> <li>Production Setup - Production configuration and best practices</li> <li>Security Guide - Security hardening and best practices</li> <li>Monitoring &amp; Observability - Setting up monitoring stack</li> <li>Troubleshooting - Common issues and solutions</li> <li>Backup &amp; Recovery - Data protection strategies</li> </ul>"},{"location":"deployment/#quick-deploy","title":"Quick Deploy","text":"<p>```bash</p>"},{"location":"deployment/#using-docker-compose","title":"Using Docker Compose","text":"<p>docker-compose -f docker-compose.prod.yml up -d</p>"},{"location":"deployment/#or-using-the-makefile","title":"Or using the Makefile","text":"<p>make deploy-prod ```</p> <p>See Production Setup for detailed deployment procedures.</p>"},{"location":"deployment/backup-recovery/","title":"Backup and Recovery Guide","text":"<p>This guide covers comprehensive backup strategies, disaster recovery procedures, and data protection for the FastAPI HTTP/WebSocket application.</p>"},{"location":"deployment/backup-recovery/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Backup Strategy Overview</li> <li>Database Backups</li> <li>Redis Backups</li> <li>Configuration Backups</li> <li>Volume Backups</li> <li>Automated Backup Scripts</li> <li>Backup Verification</li> <li>Disaster Recovery</li> <li>Point-in-Time Recovery</li> <li>Testing Recovery Procedures</li> </ul>"},{"location":"deployment/backup-recovery/#backup-strategy-overview","title":"Backup Strategy Overview","text":""},{"location":"deployment/backup-recovery/#backup-types","title":"Backup Types","text":"Component Backup Type Frequency Retention Priority PostgreSQL Database Full + WAL Full: DailyWAL: Continuous 30 days full7 days WAL Critical Redis Data Snapshot + AOF Snapshot: HourlyAOF: Continuous 7 days High Configuration Files Full copy On change + Daily 30 days High Docker Volumes Tarball Weekly 4 weeks Medium Keycloak Database Full dump Daily 30 days Critical Application Logs Archive Daily 90 days Medium"},{"location":"deployment/backup-recovery/#backup-locations","title":"Backup Locations","text":"<p>Primary Backup Storage: - Local: <code>/backups</code> directory (bind-mounted volume) - Network: NFS/CIFS share for immediate access</p> <p>Secondary Backup Storage: - Cloud: S3-compatible storage (AWS S3, MinIO, etc.) - Offsite: Remote backup server via rsync/restic</p>"},{"location":"deployment/backup-recovery/#rto-and-rpo-targets","title":"RTO and RPO Targets","text":"<ul> <li>RTO (Recovery Time Objective): 1 hour</li> <li>RPO (Recovery Point Objective): 15 minutes</li> <li>Database corruption detection: Within 6 hours</li> <li>Backup restoration testing: Monthly</li> </ul>"},{"location":"deployment/backup-recovery/#database-backups","title":"Database Backups","text":""},{"location":"deployment/backup-recovery/#postgresql-backup-methods","title":"PostgreSQL Backup Methods","text":""},{"location":"deployment/backup-recovery/#1-logical-backups-with-pg_dump","title":"1. Logical Backups with pg_dump","text":"<p>Full Database Backup:</p> <pre><code>#!/bin/bash\n# scripts/backup_db.sh\n\nBACKUP_DIR=\"/backups/postgres\"\nDATE=$(date +%Y%m%d_%H%M%S)\nDB_NAME=\"fastapi_prod\"\nDB_USER=\"prod_user\"\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Create backup\ndocker exec hw-db pg_dump -U \"$DB_USER\" -Fc \"$DB_NAME\" &gt; \\\n  \"$BACKUP_DIR/${DB_NAME}_${DATE}.dump\"\n\n# Compress backup\ngzip \"$BACKUP_DIR/${DB_NAME}_${DATE}.dump\"\n\n# Create metadata\ncat &gt; \"$BACKUP_DIR/${DB_NAME}_${DATE}.meta\" &lt;&lt;EOF\n{\n  \"timestamp\": \"$(date -Iseconds)\",\n  \"database\": \"$DB_NAME\",\n  \"size\": \"$(du -h \"$BACKUP_DIR/${DB_NAME}_${DATE}.dump.gz\" | cut -f1)\",\n  \"pg_version\": \"$(docker exec hw-db psql -U postgres -t -c 'SELECT version();' | head -1)\"\n}\nEOF\n\necho \"Backup completed: ${DB_NAME}_${DATE}.dump.gz\"\n\n# Remove backups older than 30 days\nfind \"$BACKUP_DIR\" -name \"*.dump.gz\" -mtime +30 -delete\nfind \"$BACKUP_DIR\" -name \"*.meta\" -mtime +30 -delete\n</code></pre> <p>Per-Table Backup:</p> <pre><code># Backup specific table (useful for large tables)\ndocker exec hw-db pg_dump -U prod_user -Fc -t author fastapi_prod &gt; \\\n  /backups/postgres/author_$(date +%Y%m%d).dump\n</code></pre> <p>Schema-Only Backup:</p> <pre><code># Backup schema without data (useful for migrations)\ndocker exec hw-db pg_dump -U prod_user -Fc --schema-only fastapi_prod &gt; \\\n  /backups/postgres/schema_$(date +%Y%m%d).dump\n</code></pre>"},{"location":"deployment/backup-recovery/#2-physical-backups-with-pg_basebackup","title":"2. Physical Backups with pg_basebackup","text":"<p>Base Backup:</p> <pre><code>#!/bin/bash\n# scripts/backup_db_physical.sh\n\nBACKUP_DIR=\"/backups/postgres/base\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Create base backup\ndocker exec hw-db pg_basebackup -U postgres -D - -Ft -z -X fetch | \\\n  tar -xzf - -C \"$BACKUP_DIR/${DATE}\"\n\necho \"Base backup completed: $BACKUP_DIR/${DATE}\"\n</code></pre> <p>Enable WAL Archiving:</p> <pre><code># docker/postgres/postgresql.conf\nwal_level = replica\narchive_mode = on\narchive_command = 'test ! -f /backups/postgres/wal/%f &amp;&amp; cp %p /backups/postgres/wal/%f'\nmax_wal_senders = 3\n</code></pre>"},{"location":"deployment/backup-recovery/#3-continuous-wal-archiving","title":"3. Continuous WAL Archiving","text":"<p>Setup:</p> <pre><code># docker-compose.yml\nservices:\n  hw-db:\n    volumes:\n      - ./backups/postgres/wal:/backups/postgres/wal\n      - ./docker/postgres/postgresql.conf:/etc/postgresql/postgresql.conf\n    command: postgres -c config_file=/etc/postgresql/postgresql.conf\n</code></pre> <p>Archive WAL Files:</p> <pre><code>#!/bin/bash\n# scripts/archive_wal.sh\n\nWAL_DIR=\"/backups/postgres/wal\"\nARCHIVE_DIR=\"/backups/postgres/wal_archive\"\nDATE=$(date +%Y%m%d)\n\n# Move old WAL files to archive\nfind \"$WAL_DIR\" -name \"*.wal\" -mtime +1 -exec mv {} \"$ARCHIVE_DIR/${DATE}/\" \\;\n\n# Compress archived WAL files\nfind \"$ARCHIVE_DIR\" -name \"*.wal\" ! -name \"*.gz\" -exec gzip {} \\;\n\n# Remove archives older than 7 days\nfind \"$ARCHIVE_DIR\" -type d -mtime +7 -exec rm -rf {} \\;\n</code></pre>"},{"location":"deployment/backup-recovery/#restore-postgresql-database","title":"Restore PostgreSQL Database","text":""},{"location":"deployment/backup-recovery/#from-pg_dump-backup","title":"From pg_dump Backup","text":"<p>Complete Restore:</p> <pre><code>#!/bin/bash\n# scripts/restore_db.sh\n\nBACKUP_FILE=\"$1\"\nDB_NAME=\"fastapi_prod\"\nDB_USER=\"prod_user\"\n\nif [ -z \"$BACKUP_FILE\" ]; then\n  echo \"Usage: $0 &lt;backup_file.dump.gz&gt;\"\n  exit 1\nfi\n\necho \"WARNING: This will DROP and recreate the database!\"\nread -p \"Continue? (yes/no): \" confirm\n\nif [ \"$confirm\" != \"yes\" ]; then\n  echo \"Restore cancelled\"\n  exit 0\nfi\n\n# Stop application\ndocker-compose stop hw-server\n\n# Uncompress if needed\nif [[ $BACKUP_FILE == *.gz ]]; then\n  gunzip -c \"$BACKUP_FILE\" &gt; \"${BACKUP_FILE%.gz}\"\n  BACKUP_FILE=\"${BACKUP_FILE%.gz}\"\nfi\n\n# Drop existing connections\ndocker exec hw-db psql -U postgres -c \\\n  \"SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname='$DB_NAME';\"\n\n# Drop and recreate database\ndocker exec hw-db psql -U postgres -c \"DROP DATABASE IF EXISTS $DB_NAME;\"\ndocker exec hw-db psql -U postgres -c \"CREATE DATABASE $DB_NAME OWNER $DB_USER;\"\n\n# Restore backup\ndocker exec -i hw-db pg_restore -U \"$DB_USER\" -d \"$DB_NAME\" -Fc &lt; \"$BACKUP_FILE\"\n\necho \"Database restored successfully\"\n\n# Restart application\ndocker-compose start hw-server\n</code></pre>"},{"location":"deployment/backup-recovery/#point-in-time-recovery-pitr-with-wal","title":"Point-in-Time Recovery (PITR) with WAL","text":"<pre><code>#!/bin/bash\n# scripts/pitr_restore.sh\n\nBASE_BACKUP=\"/backups/postgres/base/20250118_120000\"\nWAL_ARCHIVE=\"/backups/postgres/wal_archive\"\nTARGET_TIME=\"2025-01-18 14:30:00\"\n\n# Stop database\ndocker-compose stop hw-db\n\n# Remove current data\ndocker volume rm postgres-hw-data\ndocker volume create postgres-hw-data\n\n# Restore base backup\ndocker run --rm \\\n  -v postgres-hw-data:/var/lib/postgresql/data \\\n  -v \"$BASE_BACKUP:/backup\" \\\n  postgres:13 \\\n  bash -c \"cp -r /backup/* /var/lib/postgresql/data/\"\n\n# Create recovery.conf\ncat &gt; recovery.conf &lt;&lt;EOF\nrestore_command = 'cp $WAL_ARCHIVE/%f %p'\nrecovery_target_time = '$TARGET_TIME'\nrecovery_target_action = 'promote'\nEOF\n\n# Copy recovery.conf to data directory\ndocker run --rm \\\n  -v postgres-hw-data:/var/lib/postgresql/data \\\n  -v \"$(pwd)/recovery.conf:/recovery.conf\" \\\n  postgres:13 \\\n  bash -c \"cp /recovery.conf /var/lib/postgresql/data/\"\n\n# Start database\ndocker-compose start hw-db\n\necho \"Point-in-time recovery to $TARGET_TIME initiated\"\n</code></pre>"},{"location":"deployment/backup-recovery/#keycloak-database-backup","title":"Keycloak Database Backup","text":"<pre><code>#!/bin/bash\n# scripts/backup_keycloak.sh\n\nBACKUP_DIR=\"/backups/keycloak\"\nDATE=$(date +%Y%m%d_%H%M%S)\nDB_NAME=\"keycloak_prod\"\nDB_USER=\"prod_user\"\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Backup Keycloak database\ndocker exec hw-db pg_dump -U \"$DB_USER\" -Fc \"$DB_NAME\" &gt; \\\n  \"$BACKUP_DIR/${DB_NAME}_${DATE}.dump\"\n\ngzip \"$BACKUP_DIR/${DB_NAME}_${DATE}.dump\"\n\necho \"Keycloak database backed up: ${DB_NAME}_${DATE}.dump.gz\"\n\n# Export realm configuration\ndocker exec hw-keycloak /opt/keycloak/bin/kc.sh export \\\n  --dir /tmp/export \\\n  --realm production\n\ndocker cp hw-keycloak:/tmp/export \"$BACKUP_DIR/realm_export_${DATE}\"\n\necho \"Keycloak realm exported: realm_export_${DATE}\"\n</code></pre>"},{"location":"deployment/backup-recovery/#redis-backups","title":"Redis Backups","text":""},{"location":"deployment/backup-recovery/#redis-backup-methods","title":"Redis Backup Methods","text":""},{"location":"deployment/backup-recovery/#1-rdb-snapshots","title":"1. RDB Snapshots","text":"<p>Manual Snapshot:</p> <pre><code># Trigger immediate snapshot\ndocker exec hw-redis redis-cli BGSAVE\n\n# Wait for completion\ndocker exec hw-redis redis-cli LASTSAVE\n\n# Copy snapshot\ndocker cp hw-redis:/data/dump.rdb /backups/redis/dump_$(date +%Y%m%d_%H%M%S).rdb\n</code></pre> <p>Automated Snapshots:</p> <pre><code>#!/bin/bash\n# scripts/backup_redis.sh\n\nBACKUP_DIR=\"/backups/redis\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Trigger snapshot\ndocker exec hw-redis redis-cli BGSAVE\n\n# Wait for completion (check every second)\nwhile [ \"$(docker exec hw-redis redis-cli LASTSAVE)\" == \"$LAST_SAVE\" ]; do\n  sleep 1\ndone\n\n# Copy snapshot\ndocker cp hw-redis:/data/dump.rdb \"$BACKUP_DIR/dump_${DATE}.rdb\"\n\necho \"Redis snapshot created: dump_${DATE}.rdb\"\n\n# Remove snapshots older than 7 days\nfind \"$BACKUP_DIR\" -name \"dump_*.rdb\" -mtime +7 -delete\n</code></pre>"},{"location":"deployment/backup-recovery/#2-aof-append-only-file-backups","title":"2. AOF (Append-Only File) Backups","text":"<p>Enable AOF:</p> <pre><code># docker/redis/redis.conf\nappendonly yes\nappendfilename \"appendonly.aof\"\nappendfsync everysec\n</code></pre> <p>Backup AOF:</p> <pre><code># Copy AOF file\ndocker cp hw-redis:/data/appendonly.aof /backups/redis/appendonly_$(date +%Y%m%d_%H%M%S).aof\n</code></pre>"},{"location":"deployment/backup-recovery/#restore-redis-data","title":"Restore Redis Data","text":"<p>From RDB Snapshot:</p> <pre><code>#!/bin/bash\n# scripts/restore_redis.sh\n\nBACKUP_FILE=\"$1\"\n\nif [ -z \"$BACKUP_FILE\" ]; then\n  echo \"Usage: $0 &lt;backup_file.rdb&gt;\"\n  exit 1\nfi\n\n# Stop Redis\ndocker-compose stop hw-redis\n\n# Copy backup to data directory\ndocker cp \"$BACKUP_FILE\" hw-redis:/data/dump.rdb\n\n# Start Redis\ndocker-compose start hw-redis\n\necho \"Redis restored from $BACKUP_FILE\"\n</code></pre> <p>From AOF:</p> <pre><code># Stop Redis\ndocker-compose stop hw-redis\n\n# Copy AOF file\ndocker cp appendonly_backup.aof hw-redis:/data/appendonly.aof\n\n# Start Redis (will replay AOF)\ndocker-compose start hw-redis\n</code></pre>"},{"location":"deployment/backup-recovery/#configuration-backups","title":"Configuration Backups","text":""},{"location":"deployment/backup-recovery/#backup-configuration-files","title":"Backup Configuration Files","text":"<pre><code>#!/bin/bash\n# scripts/backup_config.sh\n\nBACKUP_DIR=\"/backups/config\"\nDATE=$(date +%Y%m%d_%H%M%S)\nPROJECT_DIR=\"/app\"\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Create tarball of configuration files\ntar -czf \"$BACKUP_DIR/config_${DATE}.tar.gz\" \\\n  --exclude='*.pyc' \\\n  --exclude='__pycache__' \\\n  --exclude='.git' \\\n  \"$PROJECT_DIR/.env.production\" \\\n  \"$PROJECT_DIR/docker/.srv_env\" \\\n  \"$PROJECT_DIR/docker/.pg_env.production\" \\\n  \"$PROJECT_DIR/docker/.kc_env.production\" \\\n  \"$PROJECT_DIR/docker/docker-compose.yml\" \\\n  \"$PROJECT_DIR/docker/traefik/\" \\\n  \"$PROJECT_DIR/docker/prometheus/\" \\\n  \"$PROJECT_DIR/docker/grafana/\" \\\n  \"$PROJECT_DIR/docker/loki/\" \\\n  \"$PROJECT_DIR/uvicorn_logging.json\"\n\necho \"Configuration backed up: config_${DATE}.tar.gz\"\n\n# Remove backups older than 30 days\nfind \"$BACKUP_DIR\" -name \"config_*.tar.gz\" -mtime +30 -delete\n</code></pre>"},{"location":"deployment/backup-recovery/#restore-configuration","title":"Restore Configuration","text":"<pre><code>#!/bin/bash\n# scripts/restore_config.sh\n\nBACKUP_FILE=\"$1\"\n\nif [ -z \"$BACKUP_FILE\" ]; then\n  echo \"Usage: $0 &lt;config_backup.tar.gz&gt;\"\n  exit 1\nfi\n\n# Extract configuration\ntar -xzf \"$BACKUP_FILE\" -C /\n\necho \"Configuration restored from $BACKUP_FILE\"\necho \"Review configuration files before restarting services!\"\n</code></pre>"},{"location":"deployment/backup-recovery/#volume-backups","title":"Volume Backups","text":""},{"location":"deployment/backup-recovery/#backup-docker-volumes","title":"Backup Docker Volumes","text":"<pre><code>#!/bin/bash\n# scripts/backup_volumes.sh\n\nBACKUP_DIR=\"/backups/volumes\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Backup each volume\nfor VOLUME in postgres-hw-data redis-hw-data grafana-data prometheus-data loki-data; do\n  echo \"Backing up volume: $VOLUME\"\n\n  docker run --rm \\\n    -v \"$VOLUME:/data\" \\\n    -v \"$BACKUP_DIR:/backup\" \\\n    alpine \\\n    tar czf \"/backup/${VOLUME}_${DATE}.tar.gz\" -C /data .\n\n  echo \"Volume backed up: ${VOLUME}_${DATE}.tar.gz\"\ndone\n\n# Remove backups older than 4 weeks\nfind \"$BACKUP_DIR\" -name \"*.tar.gz\" -mtime +28 -delete\n</code></pre>"},{"location":"deployment/backup-recovery/#restore-docker-volumes","title":"Restore Docker Volumes","text":"<pre><code>#!/bin/bash\n# scripts/restore_volume.sh\n\nVOLUME_NAME=\"$1\"\nBACKUP_FILE=\"$2\"\n\nif [ -z \"$VOLUME_NAME\" ] || [ -z \"$BACKUP_FILE\" ]; then\n  echo \"Usage: $0 &lt;volume_name&gt; &lt;backup_file.tar.gz&gt;\"\n  exit 1\nfi\n\necho \"WARNING: This will replace all data in volume $VOLUME_NAME!\"\nread -p \"Continue? (yes/no): \" confirm\n\nif [ \"$confirm\" != \"yes\" ]; then\n  echo \"Restore cancelled\"\n  exit 0\nfi\n\n# Stop services using the volume\ndocker-compose stop\n\n# Remove existing volume\ndocker volume rm \"$VOLUME_NAME\"\n\n# Create new volume\ndocker volume create \"$VOLUME_NAME\"\n\n# Restore data\ndocker run --rm \\\n  -v \"$VOLUME_NAME:/data\" \\\n  -v \"$(dirname \"$BACKUP_FILE\"):/backup\" \\\n  alpine \\\n  tar xzf \"/backup/$(basename \"$BACKUP_FILE\")\" -C /data\n\necho \"Volume restored: $VOLUME_NAME\"\n\n# Restart services\ndocker-compose up -d\n</code></pre>"},{"location":"deployment/backup-recovery/#automated-backup-scripts","title":"Automated Backup Scripts","text":""},{"location":"deployment/backup-recovery/#comprehensive-backup-script","title":"Comprehensive Backup Script","text":"<pre><code>#!/bin/bash\n# scripts/backup_all.sh\n\nset -e\n\nBACKUP_ROOT=\"/backups\"\nDATE=$(date +%Y%m%d_%H%M%S)\nLOG_FILE=\"$BACKUP_ROOT/backup_${DATE}.log\"\n\n# Function to log messages\nlog() {\n  echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$LOG_FILE\"\n}\n\n# Function to handle errors\nerror_exit() {\n  log \"ERROR: $1\"\n  exit 1\n}\n\nlog \"Starting comprehensive backup\"\n\n# 1. Backup PostgreSQL\nlog \"Backing up PostgreSQL database...\"\nbash /scripts/backup_db.sh || error_exit \"PostgreSQL backup failed\"\n\n# 2. Backup Keycloak\nlog \"Backing up Keycloak...\"\nbash /scripts/backup_keycloak.sh || error_exit \"Keycloak backup failed\"\n\n# 3. Backup Redis\nlog \"Backing up Redis...\"\nbash /scripts/backup_redis.sh || error_exit \"Redis backup failed\"\n\n# 4. Backup configuration\nlog \"Backing up configuration files...\"\nbash /scripts/backup_config.sh || error_exit \"Configuration backup failed\"\n\n# 5. Backup volumes (weekly only)\nif [ \"$(date +%u)\" -eq 7 ]; then\n  log \"Backing up Docker volumes (weekly)...\"\n  bash /scripts/backup_volumes.sh || error_exit \"Volume backup failed\"\nfi\n\n# 6. Upload to remote storage\nlog \"Uploading backups to remote storage...\"\nbash /scripts/upload_backups.sh \"$DATE\" || log \"WARNING: Remote upload failed\"\n\n# 7. Verify backups\nlog \"Verifying backups...\"\nbash /scripts/verify_backups.sh \"$DATE\" || log \"WARNING: Backup verification failed\"\n\n# 8. Send notification\nlog \"Sending backup notification...\"\ncurl -X POST \"https://api.slack.com/webhooks/your-webhook\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"text\\\": \\\"Backup completed successfully: $DATE\\\"}\" || log \"WARNING: Notification failed\"\n\nlog \"Comprehensive backup completed successfully\"\n</code></pre>"},{"location":"deployment/backup-recovery/#cron-schedule","title":"Cron Schedule","text":"<pre><code># /etc/cron.d/backups\n\n# Full backup daily at 2 AM\n0 2 * * * root /scripts/backup_all.sh &gt;&gt; /backups/cron.log 2&gt;&amp;1\n\n# Redis snapshots every hour\n0 * * * * root /scripts/backup_redis.sh &gt;&gt; /backups/redis_cron.log 2&gt;&amp;1\n\n# Configuration backup on changes (use inotify-tools)\n# @reboot root /scripts/watch_config_changes.sh &gt;&gt; /backups/config_watch.log 2&gt;&amp;1\n</code></pre>"},{"location":"deployment/backup-recovery/#upload-backups-to-s3","title":"Upload Backups to S3","text":"<pre><code>#!/bin/bash\n# scripts/upload_backups.sh\n\nDATE=\"$1\"\nBACKUP_DIR=\"/backups\"\nS3_BUCKET=\"s3://my-backups/fastapi-prod\"\n\n# Requires AWS CLI configured\n# apt-get install awscli\n# aws configure\n\n# Upload database backups\naws s3 sync \"$BACKUP_DIR/postgres/\" \"$S3_BUCKET/postgres/\" \\\n  --exclude \"*\" \\\n  --include \"*${DATE}*\"\n\n# Upload Redis backups\naws s3 sync \"$BACKUP_DIR/redis/\" \"$S3_BUCKET/redis/\" \\\n  --exclude \"*\" \\\n  --include \"*${DATE}*\"\n\n# Upload configuration\naws s3 sync \"$BACKUP_DIR/config/\" \"$S3_BUCKET/config/\" \\\n  --exclude \"*\" \\\n  --include \"*${DATE}*\"\n\n# Set lifecycle policy (delete after 90 days)\naws s3api put-bucket-lifecycle-configuration \\\n  --bucket my-backups \\\n  --lifecycle-configuration file://s3-lifecycle.json\n\necho \"Backups uploaded to S3\"\n</code></pre> <p>S3 Lifecycle Policy:</p> <pre><code>{\n  \"Rules\": [\n    {\n      \"Id\": \"Delete old backups\",\n      \"Status\": \"Enabled\",\n      \"Prefix\": \"fastapi-prod/\",\n      \"Expiration\": {\n        \"Days\": 90\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"deployment/backup-recovery/#backup-verification","title":"Backup Verification","text":""},{"location":"deployment/backup-recovery/#verify-database-backups","title":"Verify Database Backups","text":"<pre><code>#!/bin/bash\n# scripts/verify_backups.sh\n\nBACKUP_FILE=\"$1\"\nTEST_DB=\"fastapi_test_restore\"\n\nif [ -z \"$BACKUP_FILE\" ]; then\n  echo \"Usage: $0 &lt;backup_file.dump.gz&gt;\"\n  exit 1\nfi\n\necho \"Verifying database backup: $BACKUP_FILE\"\n\n# Uncompress if needed\nif [[ $BACKUP_FILE == *.gz ]]; then\n  gunzip -c \"$BACKUP_FILE\" &gt; \"${BACKUP_FILE%.gz}\"\n  BACKUP_FILE=\"${BACKUP_FILE%.gz}\"\nfi\n\n# Create test database\ndocker exec hw-db psql -U postgres -c \"DROP DATABASE IF EXISTS $TEST_DB;\"\ndocker exec hw-db psql -U postgres -c \"CREATE DATABASE $TEST_DB;\"\n\n# Restore to test database\ndocker exec -i hw-db pg_restore -U postgres -d \"$TEST_DB\" -Fc &lt; \"$BACKUP_FILE\"\n\nif [ $? -eq 0 ]; then\n  echo \"\u2705 Backup verification PASSED\"\n\n  # Verify data integrity\n  ROW_COUNT=$(docker exec hw-db psql -U postgres -d \"$TEST_DB\" -t -c \"SELECT COUNT(*) FROM author;\")\n  echo \"   Author table has $ROW_COUNT rows\"\n\n  # Drop test database\n  docker exec hw-db psql -U postgres -c \"DROP DATABASE $TEST_DB;\"\nelse\n  echo \"\u274c Backup verification FAILED\"\n  exit 1\nfi\n</code></pre>"},{"location":"deployment/backup-recovery/#automated-backup-testing","title":"Automated Backup Testing","text":"<pre><code>#!/bin/bash\n# scripts/test_restore_monthly.sh\n# Run this monthly to verify restore procedures\n\nBACKUP_DIR=\"/backups\"\nTEST_DATE=$(date +%Y%m%d)\n\necho \"Monthly backup restore test - $TEST_DATE\"\n\n# Find most recent backup\nLATEST_BACKUP=$(ls -t \"$BACKUP_DIR/postgres/\"*.dump.gz | head -1)\n\necho \"Testing restore from: $LATEST_BACKUP\"\n\n# Verify backup\nbash /scripts/verify_backups.sh \"$LATEST_BACKUP\"\n\nif [ $? -eq 0 ]; then\n  echo \"\u2705 Monthly restore test PASSED\"\n\n  # Send success notification\n  curl -X POST \"https://api.slack.com/webhooks/your-webhook\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\\\"text\\\": \\\"Monthly backup restore test PASSED: $TEST_DATE\\\"}\"\nelse\n  echo \"\u274c Monthly restore test FAILED\"\n\n  # Send failure alert\n  curl -X POST \"https://api.slack.com/webhooks/your-webhook\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\\\"text\\\": \\\"\ud83d\udea8 Monthly backup restore test FAILED: $TEST_DATE\\\"}\"\n\n  exit 1\nfi\n</code></pre>"},{"location":"deployment/backup-recovery/#disaster-recovery","title":"Disaster Recovery","text":""},{"location":"deployment/backup-recovery/#complete-system-recovery","title":"Complete System Recovery","text":"<p>Recovery Steps:</p> <pre><code>#!/bin/bash\n# scripts/disaster_recovery.sh\n\nset -e\n\necho \"=== DISASTER RECOVERY PROCEDURE ===\"\necho \"This will restore the entire system from backups\"\nread -p \"Enter backup date (YYYYMMDD_HHMMSS): \" BACKUP_DATE\n\nBACKUP_DIR=\"/backups\"\n\n# 1. Stop all services\necho \"1. Stopping all services...\"\ndocker-compose -f docker/docker-compose.yml down\n\n# 2. Remove all volumes\necho \"2. Removing existing volumes...\"\ndocker volume rm postgres-hw-data redis-hw-data grafana-data prometheus-data loki-data\n\n# 3. Recreate volumes\necho \"3. Recreating volumes...\"\ndocker volume create postgres-hw-data\ndocker volume create redis-hw-data\ndocker volume create grafana-data\ndocker volume create prometheus-data\ndocker volume create loki-data\n\n# 4. Restore configuration\necho \"4. Restoring configuration files...\"\ntar -xzf \"$BACKUP_DIR/config/config_${BACKUP_DATE}.tar.gz\" -C /\n\n# 5. Start database services\necho \"5. Starting database services...\"\ndocker-compose -f docker/docker-compose.yml up -d hw-db hw-redis\nsleep 30\n\n# 6. Restore PostgreSQL database\necho \"6. Restoring PostgreSQL database...\"\nLATEST_DB_BACKUP=$(ls -t \"$BACKUP_DIR/postgres/\"*${BACKUP_DATE}*.dump.gz | head -1)\nbash /scripts/restore_db.sh \"$LATEST_DB_BACKUP\"\n\n# 7. Restore Keycloak database\necho \"7. Restoring Keycloak database...\"\nLATEST_KC_BACKUP=$(ls -t \"$BACKUP_DIR/keycloak/\"*${BACKUP_DATE}*.dump.gz | head -1)\ngunzip -c \"$LATEST_KC_BACKUP\" | docker exec -i hw-db pg_restore -U prod_user -d keycloak_prod -Fc\n\n# 8. Restore Redis data\necho \"8. Restoring Redis data...\"\nLATEST_REDIS_BACKUP=$(ls -t \"$BACKUP_DIR/redis/\"*${BACKUP_DATE}*.rdb | head -1)\nbash /scripts/restore_redis.sh \"$LATEST_REDIS_BACKUP\"\n\n# 9. Start remaining services\necho \"9. Starting application services...\"\ndocker-compose -f docker/docker-compose.yml up -d\n\n# 10. Wait for services to be healthy\necho \"10. Waiting for services to be healthy...\"\nfor i in {1..30}; do\n  if curl -s http://localhost:8000/health &gt; /dev/null; then\n    echo \"\u2705 Application is healthy\"\n    break\n  fi\n  echo \"Waiting for application to be ready... ($i/30)\"\n  sleep 10\ndone\n\n# 11. Verify recovery\necho \"11. Verifying recovery...\"\ncurl -s http://localhost:8000/health | jq\n\necho \"=== DISASTER RECOVERY COMPLETED ===\"\necho \"Please verify:\"\necho \"  - Application: http://localhost:8000/health\"\necho \"  - Grafana: http://localhost:3000\"\necho \"  - Keycloak: http://localhost:8080\"\n</code></pre>"},{"location":"deployment/backup-recovery/#recovery-runbook","title":"Recovery Runbook","text":"<p>Step-by-Step Manual Recovery:</p> <ol> <li> <p>Assess Damage: <pre><code># Check what's running\ndocker ps -a\n\n# Check volumes\ndocker volume ls\n\n# Review recent logs\njournalctl -u docker --since \"1 hour ago\"\n</code></pre></p> </li> <li> <p>Identify Latest Backups: <pre><code># List available backups\nls -lh /backups/postgres/ | tail -5\nls -lh /backups/redis/ | tail -5\nls -lh /backups/config/ | tail -5\n</code></pre></p> </li> <li> <p>Stop Services: <pre><code>docker-compose -f docker/docker-compose.yml down\n</code></pre></p> </li> <li> <p>Restore Database: <pre><code># Follow database restore steps\nbash /scripts/restore_db.sh &lt;backup_file&gt;\n</code></pre></p> </li> <li> <p>Restore Configuration: <pre><code>tar -xzf /backups/config/config_latest.tar.gz -C /\n</code></pre></p> </li> <li> <p>Restart Services: <pre><code>docker-compose -f docker/docker-compose.yml up -d\n</code></pre></p> </li> <li> <p>Verify Recovery: <pre><code># Check health endpoints\ncurl http://localhost:8000/health\ncurl http://localhost:8080/health\n\n# Check logs\ndocker logs hw-server --tail 50\ndocker logs hw-keycloak --tail 50\n</code></pre></p> </li> <li> <p>Notify Stakeholders: <pre><code># Send recovery notification\necho \"System recovered from backup at $(date)\" | \\\n  mail -s \"System Recovery Complete\" ops@example.com\n</code></pre></p> </li> </ol>"},{"location":"deployment/backup-recovery/#point-in-time-recovery","title":"Point-in-Time Recovery","text":""},{"location":"deployment/backup-recovery/#postgresql-pitr","title":"PostgreSQL PITR","text":"<p>Requirements: - Base backup (pg_basebackup) - Continuous WAL archiving - Target recovery time</p> <p>Recovery Procedure:</p> <pre><code>#!/bin/bash\n# scripts/pitr.sh\n\nTARGET_TIME=\"$1\"\nBASE_BACKUP=\"/backups/postgres/base/latest\"\nWAL_ARCHIVE=\"/backups/postgres/wal_archive\"\n\nif [ -z \"$TARGET_TIME\" ]; then\n  echo \"Usage: $0 'YYYY-MM-DD HH:MM:SS'\"\n  exit 1\nfi\n\necho \"Point-in-Time Recovery to: $TARGET_TIME\"\n\n# Stop database\ndocker-compose stop hw-db\n\n# Backup current data (safety measure)\ndocker run --rm \\\n  -v postgres-hw-data:/data \\\n  -v /backups/postgres:/backup \\\n  alpine tar czf \"/backup/pre_pitr_$(date +%Y%m%d_%H%M%S).tar.gz\" -C /data .\n\n# Remove current data\ndocker volume rm postgres-hw-data\ndocker volume create postgres-hw-data\n\n# Restore base backup\ndocker run --rm \\\n  -v postgres-hw-data:/var/lib/postgresql/data \\\n  -v \"$BASE_BACKUP:/backup\" \\\n  postgres:13 bash -c \"cp -r /backup/* /var/lib/postgresql/data/\"\n\n# Create recovery configuration\ncat &gt; /tmp/recovery.signal &lt;&lt;EOF\n# Trigger recovery mode\nEOF\n\ncat &gt; /tmp/postgresql.auto.conf &lt;&lt;EOF\nrestore_command = 'cp $WAL_ARCHIVE/%f %p'\nrecovery_target_time = '$TARGET_TIME'\nrecovery_target_action = 'promote'\nEOF\n\n# Copy recovery files\ndocker run --rm \\\n  -v postgres-hw-data:/var/lib/postgresql/data \\\n  -v /tmp:/tmp \\\n  postgres:13 bash -c \"cp /tmp/recovery.signal /tmp/postgresql.auto.conf /var/lib/postgresql/data/\"\n\n# Start database (recovery will begin automatically)\ndocker-compose start hw-db\n\necho \"Point-in-Time Recovery initiated. Monitor logs:\"\necho \"  docker logs hw-db -f\"\n</code></pre>"},{"location":"deployment/backup-recovery/#testing-recovery-procedures","title":"Testing Recovery Procedures","text":""},{"location":"deployment/backup-recovery/#monthly-recovery-test-checklist","title":"Monthly Recovery Test Checklist","text":"<p>Test Schedule: First Sunday of each month</p> <p>Test Procedure:</p> <ol> <li> <p>Prepare Test Environment: <pre><code># Use separate test docker-compose file\ncp docker/docker-compose.yml docker/docker-compose.test.yml\n# Modify ports to avoid conflicts (8001, 5433, etc.)\n</code></pre></p> </li> <li> <p>Test Database Restore: <pre><code># Restore latest backup to test environment\ndocker-compose -f docker/docker-compose.test.yml up -d hw-db-test\nbash /scripts/restore_db.sh &lt;latest_backup&gt;\n</code></pre></p> </li> <li> <p>Verify Data Integrity: <pre><code># Check row counts\ndocker exec hw-db-test psql -U prod_user -d fastapi_prod \\\n  -c \"SELECT 'authors', COUNT(*) FROM author UNION ALL SELECT 'books', COUNT(*) FROM book;\"\n\n# Check recent data\ndocker exec hw-db-test psql -U prod_user -d fastapi_prod \\\n  -c \"SELECT * FROM author ORDER BY id DESC LIMIT 5;\"\n</code></pre></p> </li> <li> <p>Test Application Startup: <pre><code># Start application with test database\ndocker-compose -f docker/docker-compose.test.yml up -d hw-server-test\n\n# Test health endpoint\ncurl http://localhost:8001/health\n</code></pre></p> </li> <li> <p>Document Results: <pre><code># Create test report\ncat &gt; /backups/test_reports/recovery_test_$(date +%Y%m%d).txt &lt;&lt;EOF\nRecovery Test Report\nDate: $(date)\nBackup Used: $BACKUP_FILE\nDatabase Rows: $ROW_COUNT\nApplication Health: $(curl -s http://localhost:8001/health)\nTest Result: PASS/FAIL\nNotes: ...\nEOF\n</code></pre></p> </li> <li> <p>Cleanup: <pre><code>docker-compose -f docker/docker-compose.test.yml down\ndocker volume rm postgres-test-data\n</code></pre></p> </li> </ol>"},{"location":"deployment/backup-recovery/#automated-recovery-testing","title":"Automated Recovery Testing","text":"<pre><code>#!/bin/bash\n# scripts/automated_recovery_test.sh\n\nREPORT_DIR=\"/backups/test_reports\"\nDATE=$(date +%Y%m%d_%H%M%S)\nREPORT_FILE=\"$REPORT_DIR/recovery_test_${DATE}.txt\"\n\nmkdir -p \"$REPORT_DIR\"\n\necho \"=== AUTOMATED RECOVERY TEST ===\" | tee \"$REPORT_FILE\"\necho \"Date: $(date)\" | tee -a \"$REPORT_FILE\"\n\n# Test database restore\necho \"Testing database restore...\" | tee -a \"$REPORT_FILE\"\nLATEST_BACKUP=$(ls -t /backups/postgres/*.dump.gz | head -1)\nbash /scripts/verify_backups.sh \"$LATEST_BACKUP\" &gt;&gt; \"$REPORT_FILE\" 2&gt;&amp;1\n\nif [ $? -eq 0 ]; then\n  echo \"\u2705 Database restore test: PASSED\" | tee -a \"$REPORT_FILE\"\nelse\n  echo \"\u274c Database restore test: FAILED\" | tee -a \"$REPORT_FILE\"\n  exit 1\nfi\n\n# Test Redis restore\necho \"Testing Redis restore...\" | tee -a \"$REPORT_FILE\"\nLATEST_REDIS=$(ls -t /backups/redis/*.rdb | head -1)\n# Add Redis restore test logic here\n\necho \"=== TEST COMPLETED ===\" | tee -a \"$REPORT_FILE\"\n\n# Send report\nmail -s \"Recovery Test Report - $DATE\" ops@example.com &lt; \"$REPORT_FILE\"\n</code></pre>"},{"location":"deployment/backup-recovery/#backup-monitoring","title":"Backup Monitoring","text":""},{"location":"deployment/backup-recovery/#backup-health-checks","title":"Backup Health Checks","text":"<pre><code>#!/bin/bash\n# scripts/check_backup_health.sh\n\nBACKUP_DIR=\"/backups\"\nALERT_EMAIL=\"ops@example.com\"\n\n# Check if daily backup exists\nTODAY=$(date +%Y%m%d)\nif ! ls \"$BACKUP_DIR/postgres/\"*${TODAY}*.dump.gz &gt; /dev/null 2&gt;&amp;1; then\n  echo \"\u26a0\ufe0f WARNING: No database backup found for today\" | \\\n    mail -s \"Backup Alert: Missing Daily Backup\" \"$ALERT_EMAIL\"\nfi\n\n# Check backup age\nLATEST_BACKUP=$(ls -t \"$BACKUP_DIR/postgres/\"*.dump.gz | head -1)\nBACKUP_AGE=$(($(date +%s) - $(stat -c %Y \"$LATEST_BACKUP\")))\n\nif [ $BACKUP_AGE -gt 86400 ]; then\n  echo \"\u26a0\ufe0f WARNING: Latest backup is older than 24 hours\" | \\\n    mail -s \"Backup Alert: Backup Too Old\" \"$ALERT_EMAIL\"\nfi\n\n# Check backup size\nBACKUP_SIZE=$(du -b \"$LATEST_BACKUP\" | cut -f1)\nMIN_SIZE=$((1024 * 1024 * 10))  # 10 MB minimum\n\nif [ $BACKUP_SIZE -lt $MIN_SIZE ]; then\n  echo \"\u26a0\ufe0f WARNING: Backup size is suspiciously small\" | \\\n    mail -s \"Backup Alert: Small Backup Size\" \"$ALERT_EMAIL\"\nfi\n\necho \"Backup health check completed\"\n</code></pre>"},{"location":"deployment/backup-recovery/#additional-resources","title":"Additional Resources","text":"<ul> <li>PostgreSQL Backup Documentation</li> <li>Redis Persistence</li> <li>Docker Volume Backups</li> <li>AWS S3 Backup Best Practices</li> </ul>"},{"location":"deployment/backup-recovery/#emergency-contacts","title":"Emergency Contacts","text":"<ul> <li>On-Call Engineer: PagerDuty rotation</li> <li>Database Administrator: dba@example.com</li> <li>DevOps Team: devops@example.com</li> <li>Security Team: security@example.com</li> </ul>"},{"location":"deployment/basicauth/","title":"BasicAuth Protection for Observability Services","text":"<p>This document describes the HTTP Basic Authentication setup for protecting Prometheus, Loki, and Grafana Alloy services.</p>"},{"location":"deployment/basicauth/#overview","title":"Overview","text":"<p>BasicAuth middleware is configured in Traefik to protect observability services that don't have native authentication: - Prometheus (http://prometheus.localhost) - Loki (http://loki.localhost) - Grafana Alloy (http://alloy.localhost)</p>"},{"location":"deployment/basicauth/#credentials","title":"Credentials","text":"<p>Default credentials (DEVELOPMENT ONLY): - Username: <code>admin</code> - Password: <code>admin</code></p> <p>\u26a0\ufe0f IMPORTANT: These are development credentials. CHANGE THEM IN PRODUCTION!</p>"},{"location":"deployment/basicauth/#how-it-works","title":"How It Works","text":"<ol> <li>User accesses a protected service (e.g., http://prometheus.localhost)</li> <li>Traefik <code>observability-auth</code> middleware intercepts the request</li> <li>Browser shows HTTP Basic Authentication popup</li> <li>User enters credentials</li> <li>Traefik validates credentials against <code>.htpasswd</code> file</li> <li>If valid, request is forwarded to the service</li> </ol>"},{"location":"deployment/basicauth/#configuration-files","title":"Configuration Files","text":""},{"location":"deployment/basicauth/#1-password-file","title":"1. Password File","text":"<p>Location: <code>docker/traefik/dynamic/.htpasswd</code></p> <p>Contains MD5-hashed passwords in Apache htpasswd format: <pre><code>admin:$apr1$C47cBCz9$HDhEFmZKTYEn.aQHoYLNo1\n</code></pre></p>"},{"location":"deployment/basicauth/#2-traefik-middleware","title":"2. Traefik Middleware","text":"<p>Location: <code>docker/traefik/dynamic/middleware.yml</code></p> <p>Defines the <code>observability-auth</code> BasicAuth middleware: <pre><code>observability-auth:\n  basicAuth:\n    usersFile: \"/etc/traefik/dynamic/.htpasswd\"\n</code></pre></p>"},{"location":"deployment/basicauth/#3-service-configuration","title":"3. Service Configuration","text":"<p>Location: <code>docker/docker-compose.yml</code></p> <p>Services apply the middleware via Traefik labels: <pre><code>- \"traefik.http.routers.prometheus.middlewares=observability-auth@file,secure-headers@file\"\n- \"traefik.http.routers.loki.middlewares=observability-auth@file,secure-headers@file\"\n- \"traefik.http.routers.alloy.middlewares=observability-auth@file,secure-headers@file\"\n</code></pre></p>"},{"location":"deployment/basicauth/#protected-services","title":"Protected Services","text":"Service URL BasicAuth Notes Prometheus http://prometheus.localhost \u2705 Required Metrics &amp; monitoring Loki http://loki.localhost \u2705 Required Log aggregation (API only, no UI) Grafana Alloy http://alloy.localhost \u2705 Required Observability collector Grafana http://grafana.localhost \u274c Not protected Has its own authentication FastAPI http://api.localhost \u274c Not protected Has Keycloak authentication"},{"location":"deployment/basicauth/#testing","title":"Testing","text":""},{"location":"deployment/basicauth/#command-line-tests","title":"Command Line Tests","text":"<p>Test without credentials (should return 401 Unauthorized): <pre><code>curl -I http://prometheus.localhost/\ncurl -I http://loki.localhost/\ncurl -I http://alloy.localhost/\n</code></pre></p> <p>Test with credentials (should return 200/302 OK): <pre><code>curl -I -u admin:admin http://prometheus.localhost/\ncurl -I -u admin:admin http://loki.localhost/\ncurl -I -u admin:admin http://alloy.localhost/\n</code></pre></p>"},{"location":"deployment/basicauth/#browser-test","title":"Browser Test","text":"<ol> <li>Navigate to http://prometheus.localhost</li> <li>Browser shows authentication popup</li> <li>Enter username: <code>admin</code>, password: <code>admin</code></li> <li>Prometheus UI loads successfully</li> </ol>"},{"location":"deployment/basicauth/#changing-passwords","title":"Changing Passwords","text":""},{"location":"deployment/basicauth/#method-1-generate-new-password-hash-recommended","title":"Method 1: Generate New Password Hash (Recommended)","text":"<pre><code># Generate new password hash\ndocker run --rm httpd:2.4-alpine htpasswd -nbm admin newpassword &gt; docker/traefik/dynamic/.htpasswd\n\n# Restart Traefik to reload configuration\ndocker-compose -f docker/docker-compose.yml restart traefik\n</code></pre>"},{"location":"deployment/basicauth/#method-2-add-multiple-users","title":"Method 2: Add Multiple Users","text":"<pre><code># Add first user\ndocker run --rm httpd:2.4-alpine htpasswd -nbm admin adminpass &gt; docker/traefik/dynamic/.htpasswd\n\n# Add more users (append with &gt;&gt;)\ndocker run --rm httpd:2.4-alpine htpasswd -nbm developer devpass &gt;&gt; docker/traefik/dynamic/.htpasswd\ndocker run --rm httpd:2.4-alpine htpasswd -nbm readonly readonlypass &gt;&gt; docker/traefik/dynamic/.htpasswd\n\n# Restart Traefik\ndocker-compose -f docker/docker-compose.yml restart traefik\n</code></pre>"},{"location":"deployment/basicauth/#method-3-use-bcrypt-more-secure","title":"Method 3: Use BCrypt (More Secure)","text":"<pre><code># Generate BCrypt hash (more secure than MD5)\ndocker run --rm httpd:2.4-alpine htpasswd -nbB admin strongpassword &gt; docker/traefik/dynamic/.htpasswd\n\n# Restart Traefik\ndocker-compose -f docker/docker-compose.yml restart traefik\n</code></pre>"},{"location":"deployment/basicauth/#production-recommendations","title":"Production Recommendations","text":""},{"location":"deployment/basicauth/#security-best-practices","title":"Security Best Practices","text":"<ol> <li> <p>Change Default Credentials Immediately <pre><code>docker run --rm httpd:2.4-alpine htpasswd -nbB admin $(openssl rand -base64 16) &gt; docker/traefik/dynamic/.htpasswd\n</code></pre></p> </li> <li> <p>Use Strong Passwords</p> </li> <li>Minimum 16 characters</li> <li>Mix of uppercase, lowercase, numbers, symbols</li> <li> <p>Use a password manager</p> </li> <li> <p>Use BCrypt Instead of MD5</p> </li> <li>BCrypt is more secure than MD5</li> <li> <p>Use <code>-B</code> flag instead of <code>-m</code> when generating passwords</p> </li> <li> <p>Restrict Access by IP (Optional)    Add IP whitelist middleware for additional security:    <pre><code>observability-ip-whitelist:\n  ipWhiteList:\n    sourceRange:\n      - \"10.0.0.0/8\"      # Internal network\n      - \"192.168.0.0/16\"  # Local network\n</code></pre></p> </li> <li> <p>Enable HTTPS</p> </li> <li>BasicAuth sends credentials in Base64 encoding (not encrypted)</li> <li>Always use HTTPS in production</li> <li> <p>Configure TLS in Traefik for proper encryption</p> </li> <li> <p>Rotate Passwords Regularly</p> </li> <li>Change passwords every 90 days</li> <li> <p>Remove old/unused accounts</p> </li> <li> <p>Consider Upgrading to OAuth2</p> </li> <li>For better security, consider OAuth2 Proxy with Keycloak (see issue #124)</li> <li>BasicAuth is a simple solution but not ideal for production SSO</li> </ol>"},{"location":"deployment/basicauth/#environment-variables-for-secrets","title":"Environment Variables for Secrets","text":"<p>Instead of hardcoding passwords, consider using Docker secrets or environment variables:</p> <pre><code># docker-compose.yml\nservices:\n  traefik:\n    secrets:\n      - htpasswd\n\nsecrets:\n  htpasswd:\n    file: ./secrets/.htpasswd\n</code></pre>"},{"location":"deployment/basicauth/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/basicauth/#issue-still-getting-401-with-correct-credentials","title":"Issue: Still Getting 401 with Correct Credentials","text":"<p>Solution 1: Verify password hash format <pre><code># Check .htpasswd file\ncat docker/traefik/dynamic/.htpasswd\n\n# Regenerate if corrupted\ndocker run --rm httpd:2.4-alpine htpasswd -nbm admin admin &gt; docker/traefik/dynamic/.htpasswd\ndocker-compose -f docker/docker-compose.yml restart traefik\n</code></pre></p> <p>Solution 2: Check file is mounted correctly <pre><code># Verify file exists in container\ndocker exec hw-traefik ls -la /etc/traefik/dynamic/.htpasswd\ndocker exec hw-traefik cat /etc/traefik/dynamic/.htpasswd\n</code></pre></p>"},{"location":"deployment/basicauth/#issue-404-not-found","title":"Issue: 404 Not Found","text":"<p>Solution: Ensure <code>.htpasswd</code> is in the correct location <pre><code># File must be in docker/traefik/dynamic/.htpasswd\n# NOT in docker/traefik/.htpasswd\nmv docker/traefik/.htpasswd docker/traefik/dynamic/.htpasswd\ndocker-compose -f docker/docker-compose.yml restart traefik\n</code></pre></p>"},{"location":"deployment/basicauth/#issue-no-authentication-popup-in-browser","title":"Issue: No Authentication Popup in Browser","text":"<p>Solution: Clear browser cache and cookies <pre><code># Or test with curl\ncurl -v http://prometheus.localhost/\n# Should show: Www-Authenticate: Basic realm=\"traefik\"\n</code></pre></p>"},{"location":"deployment/basicauth/#issue-grafana-also-requires-basicauth","title":"Issue: Grafana Also Requires BasicAuth","text":"<p>Solution: Verify Grafana router does NOT have <code>observability-auth</code> middleware <pre><code># Check docker-compose.yml\ngrep \"grafana.middlewares\" docker/docker-compose.yml\n# Should NOT contain \"observability-auth@file\"\n</code></pre></p>"},{"location":"deployment/basicauth/#monitoring","title":"Monitoring","text":""},{"location":"deployment/basicauth/#check-whos-accessing-services","title":"Check Who's Accessing Services","text":"<p>Traefik logs show BasicAuth attempts: <pre><code>docker logs hw-traefik 2&gt;&amp;1 | grep -i \"basicauth\\|401\"\n</code></pre></p>"},{"location":"deployment/basicauth/#failed-login-attempts","title":"Failed Login Attempts","text":"<p>Monitor for suspicious activity: <pre><code># Watch for repeated 401s (possible brute force)\ndocker logs -f hw-traefik 2&gt;&amp;1 | grep \"401 Unauthorized\"\n</code></pre></p>"},{"location":"deployment/basicauth/#references","title":"References","text":"<ul> <li>Traefik BasicAuth Middleware Documentation</li> <li>Apache htpasswd Documentation</li> <li>Issue #123: Add BasicAuth protection for observability services</li> <li>Issue #124: Future OAuth2 Proxy investigation</li> </ul>"},{"location":"deployment/basicauth/#migration-path","title":"Migration Path","text":"<p>This BasicAuth setup is a simple, immediate solution. For production environments requiring SSO and better security:</p> <ol> <li>Short-term (current): BasicAuth with strong passwords</li> <li>Medium-term: Add IP whitelisting + HTTPS</li> <li>Long-term: Migrate to OAuth2 Proxy with Keycloak (issue #124)</li> </ol> <p>BasicAuth provides adequate protection while keeping the solution simple and maintainable.</p>"},{"location":"deployment/docker/","title":"Docker Deployment Guide","text":"<p>This guide covers Docker-specific deployment configurations, best practices, and optimization techniques for the FastAPI HTTP/WebSocket application.</p>"},{"location":"deployment/docker/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Dockerfile Best Practices</li> <li>Multi-Stage Builds</li> <li>Docker Compose Production</li> <li>Image Optimization</li> <li>Security Hardening</li> <li>Health Checks</li> <li>Resource Limits</li> <li>Networking</li> </ul>"},{"location":"deployment/docker/#dockerfile-best-practices","title":"Dockerfile Best Practices","text":""},{"location":"deployment/docker/#production-dockerfile","title":"Production Dockerfile","text":"<p>Create <code>docker/Dockerfile.production</code>:</p> <pre><code># ============================================\n# Stage 1: Builder - Install dependencies\n# ============================================\nFROM python:3.11-slim as builder\n\n# Set environment variables\nENV PYTHONUNBUFFERED=1 \\\n    PYTHONDONTWRITEBYTECODE=1 \\\n    PIP_NO_CACHE_DIR=1 \\\n    PIP_DISABLE_PIP_VERSION_CHECK=1\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    build-essential \\\n    libpq-dev \\\n    curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Create wheel directory\nWORKDIR /wheels\n\n# Copy requirements and build wheels\nCOPY requirements.txt .\nRUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements.txt\n\n# ============================================\n# Stage 2: Runtime - Minimal production image\n# ============================================\nFROM python:3.11-slim\n\n# Set environment variables\nENV PYTHONUNBUFFERED=1 \\\n    PYTHONDONTWRITEBYTECODE=1 \\\n    PATH=\"/home/appuser/.local/bin:$PATH\"\n\n# Install runtime dependencies only\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    libpq5 \\\n    curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Create non-root user\nRUN useradd -m -u 1000 -s /bin/bash appuser\n\n# Set working directory\nWORKDIR /app\n\n# Copy wheels from builder\nCOPY --from=builder /wheels /wheels\n\n# Install Python packages from wheels\nRUN pip install --no-cache --no-index --find-links=/wheels /wheels/* \\\n    &amp;&amp; rm -rf /wheels\n\n# Copy application code\nCOPY --chown=appuser:appuser . .\n\n# Switch to non-root user\nUSER appuser\n\n# Expose port\nEXPOSE 8000\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \\\n  CMD curl -f http://localhost:8000/health || exit 1\n\n# Run application\nCMD [\"uvicorn\", \"app:application\", \\\n     \"--host\", \"0.0.0.0\", \\\n     \"--port\", \"8000\", \\\n     \"--workers\", \"4\", \\\n     \"--log-config\", \"/app/uvicorn_logging.json\"]\n</code></pre>"},{"location":"deployment/docker/#key-features","title":"Key Features","text":"<ol> <li>Multi-stage build: Separates build and runtime dependencies (smaller image)</li> <li>Non-root user: Runs as <code>appuser</code> (UID 1000) for security</li> <li>Minimal base: Uses <code>slim</code> variant to reduce attack surface</li> <li>Health check: Built-in Docker health monitoring</li> <li>Optimized layers: Leverages Docker layer caching</li> </ol>"},{"location":"deployment/docker/#multi-stage-builds","title":"Multi-Stage Builds","text":""},{"location":"deployment/docker/#why-multi-stage","title":"Why Multi-Stage?","text":"<ul> <li>Smaller images: Build dependencies (gcc, build-essential) not in final image</li> <li>Faster deployment: Less data to push/pull</li> <li>Better security: Fewer packages = smaller attack surface</li> </ul>"},{"location":"deployment/docker/#build-process","title":"Build Process","text":"<pre><code># Build production image\ndocker build -f docker/Dockerfile.production -t fastapi-app:1.0.0 .\n\n# Check image size\ndocker images fastapi-app:1.0.0\n\n# Expected: ~300-400MB (vs ~800MB+ without multi-stage)\n</code></pre>"},{"location":"deployment/docker/#layer-optimization","title":"Layer Optimization","text":"<pre><code># \u274c BAD: Changes to code trigger full rebuild\nCOPY . .\nRUN pip install -r requirements.txt\n\n# \u2705 GOOD: Dependencies cached separately\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\n</code></pre>"},{"location":"deployment/docker/#docker-compose-production","title":"Docker Compose Production","text":""},{"location":"deployment/docker/#production-compose-file","title":"Production Compose File","text":"<p>Create <code>docker/docker-compose.prod.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  hw-server:\n    image: fastapi-app:${VERSION:-latest}\n    container_name: hw-server-prod\n    hostname: hw-server\n\n    networks:\n      - hw-network\n\n    # No exposed ports - only accessible via Traefik\n    expose:\n      - \"8000\"\n\n    # Production volume (code built into image)\n    volumes:\n      - /var/log/fastapi:/app/logs\n\n    # Run as non-root user\n    user: \"1000:1000\"\n\n    env_file:\n      - ../.env.production\n      - .srv_env.production\n\n    # Resource limits\n    deploy:\n      replicas: 3\n      resources:\n        limits:\n          cpus: '2'\n          memory: 2G\n        reservations:\n          cpus: '1'\n          memory: 1G\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 120s\n\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n\n    depends_on:\n      hw-db:\n        condition: service_healthy\n      hw-redis:\n        condition: service_healthy\n      hw-keycloak:\n        condition: service_healthy\n      traefik:\n        condition: service_healthy\n\n    restart: unless-stopped\n\n    # Security options\n    security_opt:\n      - no-new-privileges:true\n\n    # Read-only root filesystem (logs volume is writable)\n    read_only: true\n    tmpfs:\n      - /tmp\n\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n\n  hw-db:\n    image: postgres:13\n    container_name: hw-db-prod\n\n    networks:\n      - hw-network\n\n    # Only expose to internal network\n    expose:\n      - \"5432\"\n\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n      - ./backups:/backups\n\n    env_file:\n      - .pg_env.production\n\n    deploy:\n      resources:\n        limits:\n          cpus: '2'\n          memory: 4G\n        reservations:\n          cpus: '1'\n          memory: 2G\n\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n      start_period: 10s\n\n    restart: unless-stopped\n\n    # PostgreSQL tuning\n    command: &gt;\n      postgres\n      -c shared_buffers=2GB\n      -c effective_cache_size=6GB\n      -c maintenance_work_mem=512MB\n      -c checkpoint_completion_target=0.9\n      -c wal_buffers=16MB\n      -c default_statistics_target=100\n      -c random_page_cost=1.1\n      -c effective_io_concurrency=200\n      -c work_mem=16MB\n      -c min_wal_size=1GB\n      -c max_wal_size=4GB\n      -c max_connections=100\n\n  hw-redis:\n    image: redis:7-alpine\n    container_name: hw-redis-prod\n\n    networks:\n      - hw-network\n\n    expose:\n      - \"6379\"\n\n    volumes:\n      - redis-data:/data\n      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro\n\n    deploy:\n      resources:\n        limits:\n          cpus: '1'\n          memory: 2G\n        reservations:\n          cpus: '0.5'\n          memory: 1G\n\n    command: redis-server /usr/local/etc/redis/redis.conf\n\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n      start_period: 5s\n\n    restart: unless-stopped\n\nnetworks:\n  hw-network:\n    name: hw-network-prod\n    driver: bridge\n    ipam:\n      config:\n        - subnet: 172.25.0.0/16\n\nvolumes:\n  postgres-data:\n    name: postgres-prod-data\n  redis-data:\n    name: redis-prod-data\n  prometheus-data:\n    name: prometheus-prod-data\n  grafana-data:\n    name: grafana-prod-data\n  loki-data:\n    name: loki-prod-data\n  traefik-certificates:\n    name: traefik-prod-certs\n</code></pre>"},{"location":"deployment/docker/#image-optimization","title":"Image Optimization","text":""},{"location":"deployment/docker/#size-reduction-techniques","title":"Size Reduction Techniques","text":"<ol> <li> <p>Use Alpine base images (where possible):    <pre><code>FROM python:3.11-alpine\n# But beware: Some packages need build dependencies\n</code></pre></p> </li> <li> <p>Multi-stage builds (as shown above)</p> </li> <li> <p>Remove build artifacts:    <pre><code>RUN pip install -r requirements.txt \\\n    &amp;&amp; pip cache purge \\\n    &amp;&amp; rm -rf /root/.cache\n</code></pre></p> </li> <li> <p>Minimize layers:    <pre><code># \u274c BAD: 3 layers\nRUN apt-get update\nRUN apt-get install -y curl\nRUN rm -rf /var/lib/apt/lists/*\n\n# \u2705 GOOD: 1 layer\nRUN apt-get update &amp;&amp; apt-get install -y curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n</code></pre></p> </li> <li> <p>Use .dockerignore:    <pre><code># .dockerignore\n__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv/\nvenv/\n.git\n.gitignore\n.env\n.env.*\ndocker-compose*.yml\nDockerfile*\nREADME.md\ntests/\ndocs/\n.pytest_cache\n.coverage\nhtmlcov/\n</code></pre></p> </li> </ol>"},{"location":"deployment/docker/#build-cache-optimization","title":"Build Cache Optimization","text":"<pre><code># Use BuildKit for better caching\nDOCKER_BUILDKIT=1 docker build -t fastapi-app:latest .\n\n# Use cache from registry\ndocker build --cache-from fastapi-app:latest -t fastapi-app:1.0.1 .\n</code></pre>"},{"location":"deployment/docker/#security-hardening","title":"Security Hardening","text":""},{"location":"deployment/docker/#1-non-root-user","title":"1. Non-Root User","text":"<pre><code># Create user with specific UID\nRUN useradd -m -u 1000 -s /bin/bash appuser\n\n# Set ownership\nCOPY --chown=appuser:appuser . .\n\n# Switch to user\nUSER appuser\n</code></pre>"},{"location":"deployment/docker/#2-read-only-root-filesystem","title":"2. Read-Only Root Filesystem","text":"<pre><code># docker-compose.yml\nservices:\n  app:\n    read_only: true\n    tmpfs:\n      - /tmp\n      - /var/run\n</code></pre>"},{"location":"deployment/docker/#3-drop-capabilities","title":"3. Drop Capabilities","text":"<pre><code>services:\n  app:\n    cap_drop:\n      - ALL\n    cap_add:\n      - NET_BIND_SERVICE  # Only if binding to port &lt; 1024\n</code></pre>"},{"location":"deployment/docker/#4-security-options","title":"4. Security Options","text":"<pre><code>services:\n  app:\n    security_opt:\n      - no-new-privileges:true\n      - apparmor:docker-default\n      - seccomp:unconfined  # Only if needed\n</code></pre>"},{"location":"deployment/docker/#5-secrets-management","title":"5. Secrets Management","text":"<pre><code># Use Docker secrets (Swarm mode)\nservices:\n  app:\n    secrets:\n      - db_password\n      - api_key\n\nsecrets:\n  db_password:\n    external: true\n  api_key:\n    external: true\n</code></pre> <pre><code># Read secrets in app\nwith open('/run/secrets/db_password', 'r') as f:\n    db_password = f.read().strip()\n</code></pre>"},{"location":"deployment/docker/#health-checks","title":"Health Checks","text":""},{"location":"deployment/docker/#application-health-check","title":"Application Health Check","text":"<pre><code>HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \\\n  CMD curl -f http://localhost:8000/health || exit 1\n</code></pre>"},{"location":"deployment/docker/#fastapi-health-endpoint","title":"FastAPI Health Endpoint","text":"<pre><code># app/api/http/health.py\nfrom fastapi import APIRouter, Response, status\nfrom app.storage.db import async_session\nfrom app.storage.redis import RRedis\n\nrouter = APIRouter()\n\n@router.get(\"/health\")\nasync def health_check():\n    \"\"\"\n    Health check endpoint.\n\n    Checks:\n    - Application is running\n    - Database connection\n    - Redis connection\n    \"\"\"\n    checks = {\n        \"status\": \"healthy\",\n        \"checks\": {}\n    }\n\n    # Database check\n    try:\n        async with async_session() as session:\n            await session.execute(\"SELECT 1\")\n        checks[\"checks\"][\"database\"] = \"healthy\"\n    except Exception as e:\n        checks[\"status\"] = \"unhealthy\"\n        checks[\"checks\"][\"database\"] = f\"unhealthy: {str(e)}\"\n\n    # Redis check\n    try:\n        redis = RRedis()\n        await redis.ping()\n        checks[\"checks\"][\"redis\"] = \"healthy\"\n    except Exception as e:\n        checks[\"status\"] = \"unhealthy\"\n        checks[\"checks\"][\"redis\"] = f\"unhealthy: {str(e)}\"\n\n    status_code = status.HTTP_200_OK if checks[\"status\"] == \"healthy\" else status.HTTP_503_SERVICE_UNAVAILABLE\n\n    return Response(\n        content=json.dumps(checks),\n        status_code=status_code,\n        media_type=\"application/json\"\n    )\n</code></pre>"},{"location":"deployment/docker/#monitoring-health-status","title":"Monitoring Health Status","text":"<pre><code># Check container health\ndocker ps --filter health=healthy\ndocker ps --filter health=unhealthy\n\n# Inspect health status\ndocker inspect --format='{{json .State.Health}}' hw-server | jq\n</code></pre>"},{"location":"deployment/docker/#resource-limits","title":"Resource Limits","text":""},{"location":"deployment/docker/#memory-limits","title":"Memory Limits","text":"<pre><code>services:\n  app:\n    deploy:\n      resources:\n        limits:\n          memory: 2G  # Hard limit\n        reservations:\n          memory: 1G  # Minimum guaranteed\n</code></pre>"},{"location":"deployment/docker/#cpu-limits","title":"CPU Limits","text":"<pre><code>services:\n  app:\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'  # Max 2 CPUs\n        reservations:\n          cpus: '1.0'  # Min 1 CPU\n</code></pre>"},{"location":"deployment/docker/#monitoring-resource-usage","title":"Monitoring Resource Usage","text":"<pre><code># Real-time stats\ndocker stats\n\n# Specific container\ndocker stats hw-server\n\n# Export stats\ndocker stats --no-stream --format \"table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\" &gt; stats.txt\n</code></pre>"},{"location":"deployment/docker/#networking","title":"Networking","text":""},{"location":"deployment/docker/#bridge-network-default","title":"Bridge Network (Default)","text":"<pre><code>networks:\n  hw-network:\n    driver: bridge\n    ipam:\n      config:\n        - subnet: 172.25.0.0/16\n</code></pre>"},{"location":"deployment/docker/#custom-network-settings","title":"Custom Network Settings","text":"<pre><code>services:\n  app:\n    networks:\n      hw-network:\n        ipv4_address: 172.25.0.10\n        aliases:\n          - api\n          - fastapi-app\n</code></pre>"},{"location":"deployment/docker/#network-isolation","title":"Network Isolation","text":"<pre><code># Public network (Traefik)\nnetworks:\n  public:\n    external: true\n\n# Private network (backend services)\nnetworks:\n  private:\n    internal: true  # No external access\n\nservices:\n  traefik:\n    networks:\n      - public\n\n  app:\n    networks:\n      - public\n      - private\n\n  db:\n    networks:\n      - private  # Only accessible from app\n</code></pre>"},{"location":"deployment/docker/#logging","title":"Logging","text":""},{"location":"deployment/docker/#json-logging-driver","title":"JSON Logging Driver","text":"<pre><code>services:\n  app:\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n        labels: \"production,fastapi\"\n</code></pre>"},{"location":"deployment/docker/#centralized-logging","title":"Centralized Logging","text":"<pre><code># Use Loki driver (requires plugin)\nservices:\n  app:\n    logging:\n      driver: loki\n      options:\n        loki-url: \"http://loki:3100/loki/api/v1/push\"\n        loki-external-labels: \"job=fastapi,environment=production\"\n</code></pre>"},{"location":"deployment/docker/#build-and-deploy-workflow","title":"Build and Deploy Workflow","text":""},{"location":"deployment/docker/#automated-image-builds","title":"Automated Image Builds","text":"<p>This project includes automated Docker image builds via GitHub Actions. Every push to <code>main</code> branch triggers a build and push to GitHub Container Registry (ghcr.io).</p> <p>Workflow file: <code>.github/workflows/docker-build.yml</code></p> <p>Features: - \u2705 Multi-platform builds (linux/amd64, linux/arm64) - \u2705 Automatic tagging (latest, commit SHA, branch name) - \u2705 Layer caching for faster builds - \u2705 Push to GitHub Container Registry (ghcr.io)</p> <p>Generated image tags: <pre><code>ghcr.io/acikabubo/fastapi-http-websocket:latest\nghcr.io/acikabubo/fastapi-http-websocket:main-abc1234\nghcr.io/acikabubo/fastapi-http-websocket:main\n</code></pre></p>"},{"location":"deployment/docker/#pulling-images","title":"Pulling Images","text":"<pre><code># Pull latest image\ndocker pull ghcr.io/acikabubo/fastapi-http-websocket:latest\n\n# Pull specific commit\ndocker pull ghcr.io/acikabubo/fastapi-http-websocket:main-abc1234\n\n# Run pulled image\ndocker run -d -p 8000:8000 \\\n  --name fastapi-app \\\n  ghcr.io/acikabubo/fastapi-http-websocket:latest\n</code></pre>"},{"location":"deployment/docker/#manual-workflow-trigger","title":"Manual Workflow Trigger","text":"<p>The workflow can also be triggered manually from GitHub Actions UI:</p> <ol> <li>Go to Actions tab in GitHub</li> <li>Select Build and Push Docker Image workflow</li> <li>Click Run workflow</li> <li>Choose branch and click Run</li> </ol>"},{"location":"deployment/docker/#cicd-pipeline-example-with-deployment","title":"CI/CD Pipeline Example (with Deployment)","text":"<p>If you want to add automatic deployment after image build:</p> <pre><code># .github/workflows/deploy.yml\nname: Build and Deploy\n\non:\n  push:\n    branches: [main]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Build Docker image\n        run: |\n          docker build -f docker/Dockerfile \\\n            -t ghcr.io/user/fastapi-app:${{ github.sha }} \\\n            -t ghcr.io/user/fastapi-app:latest .\n\n      - name: Push to registry\n        run: |\n          echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin\n          docker push ghcr.io/user/fastapi-app:${{ github.sha }}\n          docker push ghcr.io/user/fastapi-app:latest\n\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    steps:\n      - name: Deploy to production\n        run: |\n          ssh user@prod-server \"cd /app &amp;&amp; \\\n            export VERSION=${{ github.sha }} &amp;&amp; \\\n            docker-compose -f docker-compose.prod.yml pull &amp;&amp; \\\n            docker-compose -f docker-compose.prod.yml up -d\"\n</code></pre>"},{"location":"deployment/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/docker/#common-issues","title":"Common Issues","text":"<p>Issue: Container exits immediately <pre><code># Check logs\ndocker logs hw-server\n\n# Check exit code\ndocker inspect hw-server --format='{{.State.ExitCode}}'\n</code></pre></p> <p>Issue: Permission denied <pre><code># Check user\ndocker exec hw-server whoami\n\n# Check file ownership\ndocker exec hw-server ls -la /app\n</code></pre></p> <p>Issue: Out of memory <pre><code># Check memory usage\ndocker stats hw-server\n\n# Increase limit in docker-compose.yml\n</code></pre></p> <p>Issue: Cannot connect to service <pre><code># Check network\ndocker network inspect hw-network\n\n# Check if service is running\ndocker-compose ps\n</code></pre></p>"},{"location":"deployment/docker/#best-practices-summary","title":"Best Practices Summary","text":"<p>\u2705 DO: - Use multi-stage builds - Run as non-root user - Set resource limits - Implement health checks - Use .dockerignore - Pin base image versions - Use BuildKit - Scan images for vulnerabilities</p> <p>\u274c DON'T: - Run as root - Store secrets in images - Use <code>latest</code> tag in production - Ignore security updates - Over-allocate resources - Skip health checks</p>"},{"location":"deployment/docker/#additional-resources","title":"Additional Resources","text":"<ul> <li>Docker Security Best Practices</li> <li>Dockerfile Best Practices</li> <li>Docker Compose Production</li> </ul>"},{"location":"deployment/monitoring/","title":"Monitoring and Observability Guide","text":"<p>Comprehensive guide to monitoring, metrics, logging, and alerting for the FastAPI HTTP/WebSocket application.</p>"},{"location":"deployment/monitoring/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Metrics Collection</li> <li>Grafana Dashboards</li> <li>Prometheus Alerts</li> <li>Log Aggregation</li> <li>Distributed Tracing</li> <li>Performance Monitoring</li> </ul>"},{"location":"deployment/monitoring/#overview","title":"Overview","text":""},{"location":"deployment/monitoring/#monitoring-stack","title":"Monitoring Stack","text":"<p>Metrics Flow:</p> <pre><code>graph TB\n    subgraph \"Application Components\"\n        FastAPI[FastAPI&lt;br/&gt;:8000]\n        Keycloak[Keycloak&lt;br/&gt;:9000]\n        Traefik[Traefik&lt;br/&gt;:8080]\n    end\n\n    FastAPI --&gt;|/metrics| Prometheus\n    Keycloak --&gt;|/metrics| Prometheus\n    Traefik --&gt;|/metrics| Prometheus\n\n    Prometheus[Prometheus&lt;br/&gt;Metrics DB&lt;br/&gt;:9090]\n    Grafana[Grafana&lt;br/&gt;Visualization&lt;br/&gt;:3000]\n\n    Prometheus --&gt;|Query| Grafana\n\n    style FastAPI fill:#f9f,stroke:#333,stroke-width:2px\n    style Keycloak fill:#fbf,stroke:#333,stroke-width:2px\n    style Traefik fill:#bbf,stroke:#333,stroke-width:2px\n    style Prometheus fill:#fbb,stroke:#333,stroke-width:2px\n    style Grafana fill:#bfb,stroke:#333,stroke-width:2px</code></pre> <p>Logs Flow:</p> <pre><code>graph TB\n    subgraph \"Application Logs\"\n        FastAPILogs[FastAPI&lt;br/&gt;JSON logs]\n        DockerLogs[Docker&lt;br/&gt;logs]\n        TraefikLogs[Traefik&lt;br/&gt;logs]\n    end\n\n    FastAPILogs --&gt;|stdout| Alloy\n    DockerLogs --&gt;|stdout| Alloy\n    TraefikLogs --&gt;|stdout| Alloy\n\n    Alloy[Grafana Alloy&lt;br/&gt;Log Collector&lt;br/&gt;:12345]\n    Loki[Loki&lt;br/&gt;Log Aggregation&lt;br/&gt;:3100]\n    GrafanaLogs[Grafana&lt;br/&gt;Log Queries&lt;br/&gt;:3000]\n\n    Alloy --&gt;|Push| Loki\n    Loki --&gt;|Query| GrafanaLogs\n\n    style FastAPILogs fill:#f9f,stroke:#333,stroke-width:2px\n    style DockerLogs fill:#ddf,stroke:#333,stroke-width:2px\n    style TraefikLogs fill:#bbf,stroke:#333,stroke-width:2px\n    style Alloy fill:#ffd,stroke:#333,stroke-width:2px\n    style Loki fill:#dff,stroke:#333,stroke-width:2px\n    style GrafanaLogs fill:#bfb,stroke:#333,stroke-width:2px</code></pre>"},{"location":"deployment/monitoring/#metrics-collection","title":"Metrics Collection","text":""},{"location":"deployment/monitoring/#application-metrics","title":"Application Metrics","text":"<p>The application exposes Prometheus metrics at <code>/metrics</code> endpoint.</p> <p>Key Metric Types:</p> <ol> <li>Counters: Cumulative values (requests, errors)</li> <li>Gauges: Point-in-time values (connections, queue size)</li> <li>Histograms: Distributions (latency, request size)</li> <li>Summaries: Quantiles (percentiles)</li> </ol>"},{"location":"deployment/monitoring/#available-metrics","title":"Available Metrics","text":""},{"location":"deployment/monitoring/#http-metrics","title":"HTTP Metrics","text":"<pre><code># Total HTTP requests by method, endpoint, status\nhttp_requests_total{method=\"GET\",endpoint=\"/authors\",status_code=\"200\"}\n\n# Request duration histogram (seconds)\nhttp_request_duration_seconds{method=\"POST\",endpoint=\"/authors\"}\n\n# Percentiles\nhttp_request_duration_seconds{method=\"GET\",endpoint=\"/authors\",quantile=\"0.99\"}\n\n# In-progress requests\nhttp_requests_in_progress{method=\"GET\",endpoint=\"/authors\"}\n</code></pre>"},{"location":"deployment/monitoring/#websocket-metrics","title":"WebSocket Metrics","text":"<pre><code># Active WebSocket connections\nws_connections_active\n\n# Total connections by status\nws_connections_total{status=\"accepted\"}\nws_connections_total{status=\"rejected_auth\"}\nws_connections_total{status=\"rejected_limit\"}\n\n# Messages received/sent\nws_messages_received_total\nws_messages_sent_total\n\n# Message processing duration by handler\nws_message_processing_duration_seconds{pkg_id=\"1\"}\n</code></pre>"},{"location":"deployment/monitoring/#database-metrics","title":"Database Metrics","text":"<pre><code># Query duration by operation\ndb_query_duration_seconds{operation=\"select\"}\n\n# Active database connections\ndb_connections_active\n\n# Database errors\ndb_errors_total{operation=\"insert\",error_type=\"integrity_error\"}\n</code></pre>"},{"location":"deployment/monitoring/#rate-limiting-metrics","title":"Rate Limiting Metrics","text":"<pre><code># Rate limit hits by type\nrate_limit_hits_total{limit_type=\"http\"}\nrate_limit_hits_total{limit_type=\"websocket_connection\"}\nrate_limit_hits_total{limit_type=\"websocket_message\"}\n</code></pre>"},{"location":"deployment/monitoring/#authentication-metrics","title":"Authentication Metrics","text":"<pre><code># Auth attempts by status\nauth_attempts_total{status=\"success\"}\nauth_attempts_total{status=\"failed\"}\nauth_attempts_total{status=\"token_expired\"}\n\n# Token validation\ntoken_validation_total{status=\"valid\"}\ntoken_validation_total{status=\"invalid\"}\n</code></pre>"},{"location":"deployment/monitoring/#application-info","title":"Application Info","text":"<pre><code># Application version and environment\napp_info{version=\"1.0.0\",python_version=\"3.11.0\",environment=\"production\"}\n</code></pre>"},{"location":"deployment/monitoring/#traefik-metrics","title":"Traefik Metrics","text":"<pre><code># Requests per service\ntraefik_service_requests_total{service=\"fastapi@docker\"}\n\n# Request duration\ntraefik_service_request_duration_seconds{service=\"fastapi@docker\"}\n\n# Backend server status\ntraefik_service_server_up{service=\"fastapi@docker\"}\n\n# Open connections\ntraefik_service_open_connections{service=\"fastapi@docker\"}\n</code></pre>"},{"location":"deployment/monitoring/#keycloak-metrics","title":"Keycloak Metrics","text":"<pre><code># JVM heap memory\njvm_memory_used_bytes{area=\"heap\"}\njvm_memory_max_bytes{area=\"heap\"}\n\n# Garbage collection\njvm_gc_pause_seconds_sum\njvm_gc_pause_seconds_count\n\n# Thread count\njvm_threads_current\njvm_threads_peak\n</code></pre>"},{"location":"deployment/monitoring/#postgresql-metrics","title":"PostgreSQL Metrics","text":"<p>If using PostgreSQL exporter:</p> <pre><code># Database size\npg_database_size_bytes{datname=\"fastapi_prod\"}\n\n# Active connections\npg_stat_database_numbackends{datname=\"fastapi_prod\"}\n\n# Transactions per second\nrate(pg_stat_database_xact_commit{datname=\"fastapi_prod\"}[5m])\n\n# Cache hit ratio\npg_stat_database_blks_hit / (pg_stat_database_blks_hit + pg_stat_database_blks_read)\n</code></pre>"},{"location":"deployment/monitoring/#redis-metrics","title":"Redis Metrics","text":"<p>If using Redis exporter:</p> <pre><code># Connected clients\nredis_connected_clients\n\n# Memory usage\nredis_memory_used_bytes\nredis_memory_max_bytes\n\n# Commands per second\nrate(redis_commands_processed_total[5m])\n\n# Keyspace hits/misses\nredis_keyspace_hits_total\nredis_keyspace_misses_total\n\n# Hit ratio\nredis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total)\n</code></pre>"},{"location":"deployment/monitoring/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"deployment/monitoring/#existing-dashboards","title":"Existing Dashboards","text":"<p>The application includes pre-configured Grafana dashboards:</p> <ol> <li>FastAPI Metrics (<code>fastapi-metrics.json</code>)</li> <li>Request rates and latency</li> <li>WebSocket connections</li> <li>Error rates</li> <li> <p>Rate limiting</p> </li> <li> <p>Traefik Metrics (<code>traefik-metrics.json</code>)</p> </li> <li>Request distribution</li> <li>Backend health</li> <li>Response times</li> <li> <p>Status codes</p> </li> <li> <p>Keycloak Metrics (<code>keycloak-metrics.json</code>)</p> </li> <li>JVM metrics</li> <li>Memory usage</li> <li>GC activity</li> <li> <p>Thread count</p> </li> <li> <p>Application Logs (<code>application-logs.json</code>)</p> </li> <li>Log volume</li> <li>Error logs</li> <li>HTTP requests</li> <li>Rate limits</li> </ol>"},{"location":"deployment/monitoring/#accessing-dashboards","title":"Accessing Dashboards","text":"<pre><code># Access Grafana\nhttps://grafana.example.com\n\n# Login via Keycloak (auto-redirect)\n\n# Dashboards location\nHome \u2192 Dashboards \u2192 Browse\n\n# Or direct URLs\nhttps://grafana.example.com/d/fastapi-metrics\nhttps://grafana.example.com/d/traefik-metrics\nhttps://grafana.example.com/d/keycloak-metrics\nhttps://grafana.example.com/d/application-logs\n</code></pre>"},{"location":"deployment/monitoring/#creating-custom-dashboards","title":"Creating Custom Dashboards","text":"<p>Via UI: 1. Grafana \u2192 Dashboards \u2192 New Dashboard 2. Add Panel 3. Select Prometheus data source 4. Enter PromQL query 5. Configure visualization 6. Save dashboard</p> <p>Via JSON (recommended for version control):</p> <pre><code>{\n  \"dashboard\": {\n    \"title\": \"Custom Dashboard\",\n    \"panels\": [\n      {\n        \"title\": \"Request Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(http_requests_total[5m])\",\n            \"legendFormat\": \"{{method}} {{endpoint}}\"\n          }\n        ],\n        \"type\": \"graph\"\n      }\n    ]\n  }\n}\n</code></pre> <p>Save to <code>docker/grafana/provisioning/dashboards/custom.json</code> and set permissions to 644.</p>"},{"location":"deployment/monitoring/#prometheus-alerts","title":"Prometheus Alerts","text":""},{"location":"deployment/monitoring/#alert-rules-configuration","title":"Alert Rules Configuration","text":"<p>Create <code>docker/prometheus/alerts/application.yml</code>:</p> <pre><code>groups:\n  - name: application\n    interval: 30s\n    rules:\n      # High Error Rate\n      - alert: HighErrorRate\n        expr: |\n          rate(http_requests_total{status_code=~\"5..\"}[5m])\n          / rate(http_requests_total[5m]) &gt; 0.05\n        for: 5m\n        labels:\n          severity: critical\n          component: fastapi\n        annotations:\n          summary: \"High error rate detected\"\n          description: \"Error rate is {{ $value | humanizePercentage }} (threshold: 5%)\"\n\n      # Slow Response Time\n      - alert: SlowResponseTime\n        expr: |\n          histogram_quantile(0.99,\n            rate(http_request_duration_seconds_bucket[5m])\n          ) &gt; 1.0\n        for: 5m\n        labels:\n          severity: warning\n          component: fastapi\n        annotations:\n          summary: \"Slow response time (p99 &gt; 1s)\"\n          description: \"99th percentile latency is {{ $value }}s\"\n\n      # WebSocket Connection Limit\n      - alert: HighWebSocketConnections\n        expr: ws_connections_active &gt; 1000\n        for: 5m\n        labels:\n          severity: warning\n          component: fastapi\n        annotations:\n          summary: \"High number of WebSocket connections\"\n          description: \"{{ $value }} active connections (threshold: 1000)\"\n\n      # Rate Limit Abuse\n      - alert: RateLimitAbuse\n        expr: rate(rate_limit_hits_total[5m]) &gt; 100\n        for: 5m\n        labels:\n          severity: warning\n          component: fastapi\n        annotations:\n          summary: \"High rate of rate limit hits\"\n          description: \"{{ $value }} rate limit hits per second\"\n\n      # Database Connection Pool Exhaustion\n      - alert: DatabaseConnectionPoolExhausted\n        expr: db_connections_active / db_connections_max &gt; 0.9\n        for: 5m\n        labels:\n          severity: critical\n          component: database\n        annotations:\n          summary: \"Database connection pool nearly exhausted\"\n          description: \"{{ $value | humanizePercentage }} of connections in use\"\n\n  - name: infrastructure\n    interval: 30s\n    rules:\n      # Service Down\n      - alert: ServiceDown\n        expr: up{job=~\"fastapi|keycloak|traefik\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Service {{ $labels.job }} is down\"\n          description: \"Service has been down for 1 minute\"\n\n      # Database Down\n      - alert: DatabaseDown\n        expr: up{job=\"postgres\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n          component: database\n        annotations:\n          summary: \"PostgreSQL is down\"\n          description: \"Database has been unreachable for 1 minute\"\n\n      # Redis Down\n      - alert: RedisDown\n        expr: up{job=\"redis\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n          component: redis\n        annotations:\n          summary: \"Redis is down\"\n          description: \"Redis has been unreachable for 1 minute\"\n\n      # High Memory Usage\n      - alert: HighMemoryUsage\n        expr: |\n          container_memory_usage_bytes{name=\"hw-server\"}\n          / container_spec_memory_limit_bytes{name=\"hw-server\"} &gt; 0.9\n        for: 5m\n        labels:\n          severity: warning\n          component: fastapi\n        annotations:\n          summary: \"High memory usage\"\n          description: \"Memory usage is {{ $value | humanizePercentage }}\"\n\n      # High CPU Usage\n      - alert: HighCPUUsage\n        expr: |\n          rate(container_cpu_usage_seconds_total{name=\"hw-server\"}[5m]) &gt; 0.8\n        for: 5m\n        labels:\n          severity: warning\n          component: fastapi\n        annotations:\n          summary: \"High CPU usage\"\n          description: \"CPU usage is {{ $value | humanizePercentage }}\"\n\n  - name: security\n    interval: 30s\n    rules:\n      # High Failed Login Rate\n      - alert: HighFailedLoginRate\n        expr: rate(auth_attempts_total{status=\"failed\"}[5m]) &gt; 10\n        for: 5m\n        labels:\n          severity: warning\n          component: security\n        annotations:\n          summary: \"High rate of failed login attempts\"\n          description: \"{{ $value }} failed logins per second\"\n\n      # Unauthorized Access Attempts\n      - alert: UnauthorizedAccessAttempts\n        expr: rate(http_requests_total{status_code=\"403\"}[5m]) &gt; 5\n        for: 5m\n        labels:\n          severity: warning\n          component: security\n        annotations:\n          summary: \"High rate of unauthorized access attempts\"\n          description: \"{{ $value }} 403 responses per second\"\n</code></pre>"},{"location":"deployment/monitoring/#alert-manager-configuration","title":"Alert Manager Configuration","text":"<p>Create <code>docker/prometheus/alertmanager.yml</code>:</p> <pre><code>global:\n  resolve_timeout: 5m\n\nroute:\n  group_by: ['alertname', 'severity']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 12h\n  receiver: 'default'\n  routes:\n    - match:\n        severity: critical\n      receiver: 'pagerduty'\n      continue: true\n\n    - match:\n        severity: warning\n      receiver: 'slack'\n\nreceivers:\n  - name: 'default'\n    email_configs:\n      - to: 'ops@example.com'\n        from: 'alertmanager@example.com'\n        smarthost: 'smtp.example.com:587'\n        auth_username: 'alertmanager@example.com'\n        auth_password: 'password'\n\n  - name: 'slack'\n    slack_configs:\n      - api_url: 'https://hooks.slack.com/services/XXX/YYY/ZZZ'\n        channel: '#alerts'\n        title: '{{ range .Alerts }}{{ .Annotations.summary }}\\n{{ end }}'\n        text: '{{ range .Alerts }}{{ .Annotations.description }}\\n{{ end }}'\n\n  - name: 'pagerduty'\n    pagerduty_configs:\n      - service_key: 'YOUR_PAGERDUTY_KEY'\n        description: '{{ .GroupLabels.alertname }}'\n</code></pre>"},{"location":"deployment/monitoring/#testing-alerts","title":"Testing Alerts","text":"<pre><code># Trigger high error rate alert\nfor i in {1..1000}; do\n  curl -X POST https://api.example.com/nonexistent\ndone\n\n# Trigger slow response alert\n# (Requires endpoint that sleeps)\n\n# Check alert status\nhttps://prometheus.example.com/alerts\n\n# Check AlertManager\nhttps://alertmanager.example.com\n</code></pre>"},{"location":"deployment/monitoring/#log-aggregation","title":"Log Aggregation","text":""},{"location":"deployment/monitoring/#structured-logging","title":"Structured Logging","text":"<p>The application uses structured JSON logging (see <code>app/logging.py</code>).</p> <p>Log Format: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"level\": \"INFO\",\n  \"logger\": \"app.api.http.author\",\n  \"message\": \"Author created successfully\",\n  \"request_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"user_id\": \"user123\",\n  \"endpoint\": \"/authors\",\n  \"method\": \"POST\",\n  \"status_code\": 201,\n  \"duration_ms\": 45.2,\n  \"environment\": \"production\"\n}\n</code></pre></p>"},{"location":"deployment/monitoring/#logql-queries","title":"LogQL Queries","text":"<p>Common Queries:</p> <pre><code># Recent error logs\n{service=\"shell\"} | json | level=\"ERROR\"\n\n# Logs for specific user\n{service=\"shell\"} | json | user_id=\"user123\"\n\n# HTTP requests to specific endpoint\n{service=\"shell\"} | json | endpoint=~\"/api/authors.*\"\n\n# Failed authentication attempts\n{service=\"shell\"} | json | logger=~\"app.auth.*\" |~ \"(?i)(error|failed|invalid)\"\n\n# Rate limit violations\n{service=\"shell\"} | json |~ \"(?i)(rate limit|too many requests)\"\n\n# WebSocket logs\n{service=\"shell\"} | json | logger=~\"app.api.ws.*\"\n\n# Slow operations (&gt; 100ms)\n{service=\"shell\"} | json | duration_ms &gt; 100\n\n# Correlate by request ID\n{service=\"shell\"} | json | request_id=\"550e8400-e29b-41d4-a716-446655440000\"\n\n# Error rate over time\nrate({service=\"shell\"} | json | level=\"ERROR\"[5m])\n\n# Top 10 error messages\ntopk(10, sum by (message) (count_over_time({service=\"shell\"} | json | level=\"ERROR\"[1h])))\n</code></pre>"},{"location":"deployment/monitoring/#log-retention","title":"Log Retention","text":"<p>Configure in <code>docker/loki/loki-config.yml</code>:</p> <pre><code>limits_config:\n  retention_period: 744h  # 31 days\n\ntable_manager:\n  retention_deletes_enabled: true\n  retention_period: 744h\n</code></pre>"},{"location":"deployment/monitoring/#distributed-tracing","title":"Distributed Tracing","text":""},{"location":"deployment/monitoring/#correlation-id-tracing-built-in","title":"Correlation ID Tracing (Built-in)","text":"<p>The application uses correlation IDs for distributed tracing without requiring OpenTelemetry. This provides equivalent functionality for monolithic services and simple microservices architectures.</p> <p>How It Works:</p> <ol> <li>X-Correlation-ID Header: Automatically added to all requests (8-char UUID)</li> <li>Request Propagation: Correlation ID flows through entire request lifecycle</li> <li>Structured Logging: All logs include <code>request_id</code> field</li> <li>Audit Logs: Database records include <code>request_id</code> column</li> <li>Grafana Queries: Filter logs by correlation ID for request tracing</li> </ol> <p>Architecture:</p> <pre><code>Client Request\n    \u2502\n    \u251c\u2500&gt; X-Correlation-ID: abc12345\n    \u2502\n    v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  CorrelationIDMiddleware        \u2502\n\u2502  - Extract/generate correlation \u2502\n\u2502  - Store in request.state       \u2502\n\u2502  - Set context variable         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n              \u251c\u2500&gt; HTTP Handler\n              \u2502   \u2514\u2500&gt; logger.info(\"...\", extra={\"request_id\": \"abc12345\"})\n              \u2502\n              \u251c\u2500&gt; WebSocket Handler\n              \u2502   \u2514\u2500&gt; RequestModel(req_id=\"abc12345\")\n              \u2502\n              \u251c\u2500&gt; Database Query\n              \u2502   \u2514\u2500&gt; audit_log(request_id=\"abc12345\")\n              \u2502\n              \u2514\u2500&gt; Response\n                  \u2514\u2500&gt; X-Correlation-ID: abc12345\n</code></pre> <p>Accessing Correlation ID:</p> <pre><code>from app.middlewares.correlation_id import get_correlation_id\n\n# In any handler or middleware\ncorrelation_id = get_correlation_id()\nlogger.info(f\"Processing request {correlation_id}\")\n\n# Automatically included in structured logs\nlogger.info(\"User action\", extra={\n    \"user_id\": \"123\",\n    \"action\": \"create_author\"\n})\n# Output: {\"request_id\": \"abc12345\", \"user_id\": \"123\", \"action\": \"create_author\", ...}\n</code></pre> <p>Tracing Request Flow in Grafana:</p> <pre><code># 1. Find request by correlation ID\n{service=\"shell\"} | json | request_id=\"abc12345\"\n\n# 2. Trace complete request lifecycle\n{service=\"shell\"} | json | request_id=\"abc12345\"\n  | line_format \"{{.timestamp}} [{{.level}}] {{.logger}}: {{.message}}\"\n\n# 3. Filter by specific component\n{service=\"shell\"} | json | request_id=\"abc12345\" | logger=~\"app.api.*\"\n\n# 4. Show error logs only\n{service=\"shell\"} | json | request_id=\"abc12345\" | level=\"ERROR\"\n\n# 5. Correlate with audit logs (PostgreSQL dashboard)\nSELECT * FROM user_actions WHERE request_id = 'abc12345' ORDER BY timestamp;\n</code></pre> <p>Example: Tracing Failed Request</p> <p>1. Find error in logs: <pre><code>{service=\"shell\"} | json | level=\"ERROR\" |~ \"Author not found\"\n</code></pre></p> <p>2. Extract correlation ID from error log: <pre><code>{\n  \"timestamp\": \"2025-01-29T10:15:30Z\",\n  \"level\": \"ERROR\",\n  \"request_id\": \"abc12345\",\n  \"message\": \"Author not found: id=999\"\n}\n</code></pre></p> <p>3. Trace complete request flow: <pre><code>{service=\"shell\"} | json | request_id=\"abc12345\"\n</code></pre></p> <p>Output: <pre><code>10:15:29 [INFO] app.middlewares.correlation_id: Request received\n10:15:29 [INFO] app.auth: User authenticated: user_id=u123\n10:15:29 [INFO] app.api.http.author: GET /authors/999\n10:15:29 [DEBUG] app.repositories.author: Query: SELECT * FROM authors WHERE id=999\n10:15:30 [ERROR] app.api.http.author: Author not found: id=999\n10:15:30 [INFO] app.middlewares.audit: Audit log created: outcome=error\n</code></pre></p> <p>4. Check audit log in PostgreSQL: <pre><code>SELECT timestamp, username, action_type, resource, outcome, error_message\nFROM user_actions\nWHERE request_id = 'abc12345';\n</code></pre></p> <p>Cross-Service Tracing:</p> <p>For microservices, propagate correlation ID via HTTP headers:</p> <pre><code># Service A: Extract correlation ID\nfrom app.middlewares.correlation_id import get_correlation_id\n\nasync def call_service_b():\n    correlation_id = get_correlation_id()\n\n    # Pass to downstream service\n    response = await httpx.get(\n        \"http://service-b/api/resource\",\n        headers={\"X-Correlation-ID\": correlation_id}\n    )\n\n    return response\n\n# Service B: Receives same correlation ID\n# CorrelationIDMiddleware extracts it automatically\n# All logs in Service B will have same request_id\n</code></pre> <p>Correlation ID vs OpenTelemetry:</p> Feature Correlation ID OpenTelemetry Request tracing \u2705 Via logs \u2705 Via spans Cross-service tracking \u2705 Via headers \u2705 Via context propagation Timeline visualization \u274c Logs only \u2705 Jaeger UI Span-level timing \u274c \u2705 Implementation complexity Low High Dependencies None Jaeger, OTLP exporter Best for Monolithic services Microservices <p>When to Use OpenTelemetry:</p> <p>Consider OpenTelemetry if: - Running complex microservices architecture (5+ services) - Need span-level timing within handlers - Want visualized trace graphs (Jaeger UI) - Require standard instrumentation across polyglot services</p> <p>OpenTelemetry Integration (Optional):</p> <p>If you need OpenTelemetry for advanced tracing:</p> <pre><code># app/tracing.py\nfrom opentelemetry import trace\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\ndef setup_tracing():\n    \"\"\"Configure OpenTelemetry tracing.\"\"\"\n    trace.set_tracer_provider(TracerProvider())\n    tracer = trace.get_tracer(__name__)\n\n    jaeger_exporter = JaegerExporter(\n        agent_host_name=\"jaeger\",\n        agent_port=6831,\n    )\n\n    span_processor = BatchSpanProcessor(jaeger_exporter)\n    trace.get_tracer_provider().add_span_processor(span_processor)\n\n    return tracer\n\n# Usage in request handler\nfrom app.tracing import tracer\n\n@router.post(\"/authors\")\nasync def create_author(data: CreateAuthorInput):\n    with tracer.start_as_current_span(\"create_author\"):\n        # Your code here\n        pass\n</code></pre> <p>Best Practice: Start with correlation IDs. Add OpenTelemetry only when scaling to complex microservices.</p>"},{"location":"deployment/monitoring/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"deployment/monitoring/#key-performance-indicators-kpis","title":"Key Performance Indicators (KPIs)","text":"Metric Target Critical Response Time (p99) &lt; 500ms &gt; 1s Error Rate &lt; 1% &gt; 5% Availability &gt; 99.9% &lt; 99% WebSocket Connections &lt; 5000 &gt; 10000 Database Connections &lt; 80% &gt; 95% CPU Usage &lt; 70% &gt; 90% Memory Usage &lt; 80% &gt; 95%"},{"location":"deployment/monitoring/#performance-queries","title":"Performance Queries","text":"<pre><code># Average response time by endpoint\navg(rate(http_request_duration_seconds_sum[5m]))\nby (endpoint)\n/\navg(rate(http_request_duration_seconds_count[5m]))\nby (endpoint)\n\n# Request throughput (req/s)\nrate(http_requests_total[5m])\n\n# Error rate percentage\nrate(http_requests_total{status_code=~\"5..\"}[5m])\n/\nrate(http_requests_total[5m]) * 100\n\n# Apdex score (Application Performance Index)\n# Target: 100ms, Tolerating: 400ms\n(\n  sum(rate(http_request_duration_seconds_bucket{le=\"0.1\"}[5m]))\n  + sum(rate(http_request_duration_seconds_bucket{le=\"0.4\"}[5m])) / 2\n)\n/\nsum(rate(http_request_duration_seconds_count[5m]))\n</code></pre>"},{"location":"deployment/monitoring/#load-testing","title":"Load Testing","text":"<p>Use tools like Locust or k6:</p> <pre><code># locustfile.py\nfrom locust import HttpUser, task, between\n\nclass WebsiteUser(HttpUser):\n    wait_time = between(1, 3)\n\n    @task(3)\n    def get_authors(self):\n        self.client.get(\"/authors\")\n\n    @task(1)\n    def create_author(self):\n        self.client.post(\"/authors\", json={\n            \"name\": \"Test Author\",\n            \"bio\": \"Test bio\"\n        })\n\n# Run load test\nlocust -f locustfile.py --host=https://api.example.com\n</code></pre>"},{"location":"deployment/monitoring/#best-practices","title":"Best Practices","text":""},{"location":"deployment/monitoring/#monitoring-checklist","title":"Monitoring Checklist","text":"<ul> <li> All services expose /metrics endpoint</li> <li> Prometheus scraping all targets</li> <li> Grafana dashboards configured</li> <li> Alert rules defined</li> <li> AlertManager configured with receivers</li> <li> Log aggregation working (Loki)</li> <li> Structured JSON logging enabled</li> <li> Retention policies configured</li> <li> Performance baselines established</li> <li> On-call rotation defined</li> </ul>"},{"location":"deployment/monitoring/#alert-best-practices","title":"Alert Best Practices","text":"<ol> <li>Actionable: Every alert should require action</li> <li>Clear: Descriptions should explain what's wrong</li> <li>Prioritized: Use severity levels (critical, warning, info)</li> <li>Tested: Test alerts before deploying</li> <li>Documented: Runbooks for each alert</li> </ol>"},{"location":"deployment/monitoring/#dashboard-best-practices","title":"Dashboard Best Practices","text":"<ol> <li>Overview first: Start with high-level metrics</li> <li>Drill-down: Link to detailed views</li> <li>Time range: Include time range selector</li> <li>Variables: Use template variables for filtering</li> <li>Auto-refresh: Enable for real-time monitoring</li> </ol>"},{"location":"deployment/monitoring/#additional-resources","title":"Additional Resources","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Documentation</li> <li>Loki Documentation</li> <li>PromQL Tutorial</li> <li>LogQL Tutorial</li> </ul>"},{"location":"deployment/production/","title":"Production Deployment Guide","text":"<p>This guide covers deploying the FastAPI HTTP/WebSocket application to production with Traefik reverse proxy, Keycloak authentication, and full observability stack.</p>"},{"location":"deployment/production/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Prerequisites</li> <li>Architecture Overview</li> <li>Environment Configuration</li> <li>Deployment Steps</li> <li>Post-Deployment Verification</li> <li>Scaling</li> <li>Backup and Recovery</li> </ul>"},{"location":"deployment/production/#prerequisites","title":"Prerequisites","text":""},{"location":"deployment/production/#required-services","title":"Required Services","text":"<ul> <li>Docker 24.0+ with Docker Compose v2</li> <li>PostgreSQL 13+ (for application and Keycloak)</li> <li>Redis 7+ (for rate limiting and sessions)</li> <li>Domain Names:</li> <li>API endpoint (e.g., <code>api.example.com</code>)</li> <li>Authentication (e.g., <code>auth.example.com</code>)</li> <li>Monitoring dashboards (e.g., <code>grafana.example.com</code>, <code>prometheus.example.com</code>)</li> <li>Traefik dashboard (e.g., <code>traefik.example.com</code>)</li> </ul>"},{"location":"deployment/production/#ssltls-certificates","title":"SSL/TLS Certificates","text":"<ul> <li>Valid SSL certificates for all domains</li> <li>Let's Encrypt integration configured in Traefik</li> <li>Or provide your own certificates</li> </ul>"},{"location":"deployment/production/#resource-requirements","title":"Resource Requirements","text":"<p>Minimum (Single Instance): - CPU: 2 cores - RAM: 4GB - Disk: 20GB SSD</p> <p>Recommended (Production): - CPU: 4+ cores - RAM: 8GB+ - Disk: 50GB+ SSD - Load balancer for multiple instances</p>"},{"location":"deployment/production/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TB\n    Internet[Internet]\n\n    Traefik[Traefik v3.0&lt;br/&gt;Reverse Proxy + SSL&lt;br/&gt;Port 80/443]\n\n    FastAPI[FastAPI App&lt;br/&gt;:8000]\n    Keycloak[Keycloak Auth&lt;br/&gt;:8080]\n    Grafana[Grafana Dashboard&lt;br/&gt;:3000]\n\n    Postgres[Postgres&lt;br/&gt;:5432]\n    Redis[Redis&lt;br/&gt;:6379]\n    Prometheus[Prometheus&lt;br/&gt;:9090]\n    Loki[Loki&lt;br/&gt;:3100]\n\n    Internet --&gt; Traefik\n\n    Traefik --&gt; FastAPI\n    Traefik --&gt; Keycloak\n    Traefik --&gt; Grafana\n\n    FastAPI --&gt; Postgres\n    FastAPI --&gt; Redis\n    FastAPI --&gt; Prometheus\n    FastAPI --&gt; Loki\n\n    Keycloak --&gt; Postgres\n    Keycloak --&gt; Prometheus\n\n    Grafana --&gt; Prometheus\n    Grafana --&gt; Loki\n\n    style Internet fill:#e1f5ff\n    style Traefik fill:#fff4e6\n    style FastAPI fill:#e8f5e9\n    style Keycloak fill:#e8f5e9\n    style Grafana fill:#e8f5e9\n    style Postgres fill:#f3e5f5\n    style Redis fill:#f3e5f5\n    style Prometheus fill:#f3e5f5\n    style Loki fill:#f3e5f5</code></pre>"},{"location":"deployment/production/#environment-configuration","title":"Environment Configuration","text":""},{"location":"deployment/production/#1-create-production-environment-files","title":"1. Create Production Environment Files","text":"<p><code>.env.production</code> (Application environment):</p> <pre><code># ========================================\n# Application Settings\n# ========================================\nENVIRONMENT=production\nDEBUG=false\nLOG_LEVEL=INFO\n\n# ========================================\n# Database Configuration\n# ========================================\nDATABASE_URL=postgresql+asyncpg://prod_user:CHANGE_ME@postgres:5432/fastapi_prod\nDB_POOL_SIZE=20\nDB_MAX_OVERFLOW=10\n\n# ========================================\n# Redis Configuration\n# ========================================\nREDIS_IP=redis\nREDIS_PORT=6379\nREDIS_PASSWORD=CHANGE_ME  # Enable Redis auth\nMAIN_REDIS_DB=0\nAUTH_REDIS_DB=1\nREDIS_MAX_CONNECTIONS=50\n\n# ========================================\n# Keycloak Configuration\n# ========================================\nKEYCLOAK_BASE_URL=https://auth.example.com\nKEYCLOAK_REALM=production\nKEYCLOAK_CLIENT_ID=fastapi-app\nKEYCLOAK_CLIENT_SECRET=CHANGE_ME  # Get from Keycloak admin\n\nKEYCLOAK_ADMIN_USERNAME=admin\nKEYCLOAK_ADMIN_PASSWORD=CHANGE_ME\n\n# ========================================\n# Security\n# ========================================\nSECRET_KEY=CHANGE_ME  # Generate with: openssl rand -hex 32\nALLOWED_HOSTS=[\"api.example.com\"]\nCORS_ORIGINS=[\"https://app.example.com\",\"https://grafana.example.com\"]\n\n# ========================================\n# Rate Limiting\n# ========================================\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_PER_MINUTE=60\nRATE_LIMIT_BURST=10\nWS_MAX_CONNECTIONS_PER_USER=5\nWS_MESSAGE_RATE_LIMIT=100\n\n# ========================================\n# Monitoring\n# ========================================\nPROMETHEUS_ENABLED=true\nLOKI_URL=http://loki:3100\n\n# ========================================\n# Logging\n# ========================================\nLOG_CONSOLE_FORMAT=json  # CRITICAL for production\nAUDIT_QUEUE_MAX_SIZE=10000\n</code></pre> <p><code>docker/.pg_env.production</code> (PostgreSQL):</p> <pre><code>POSTGRES_USER=prod_user\nPOSTGRES_PASSWORD=CHANGE_ME\nPOSTGRES_DB=fastapi_prod\n</code></pre> <p><code>docker/.kc_env.production</code> (Keycloak):</p> <pre><code>KEYCLOAK_ADMIN=admin\nKEYCLOAK_ADMIN_PASSWORD=CHANGE_ME\n\nKC_DB=postgres\nKC_DB_URL_HOST=hw-db\nKC_DB_URL_DATABASE=keycloak_prod\nKC_DB_URL_PORT=5432\nKC_DB_USERNAME=prod_user\nKC_DB_PASSWORD=CHANGE_ME\n\n# Enable production mode\nKC_HOSTNAME=auth.example.com\nKC_HOSTNAME_STRICT=true\nKC_HTTP_ENABLED=false  # Force HTTPS\nKC_PROXY=edge  # Behind Traefik\n\n# Metrics and health\nKC_METRICS_ENABLED=true\nKC_HEALTH_ENABLED=true\n</code></pre>"},{"location":"deployment/production/#2-configure-traefik-for-production","title":"2. Configure Traefik for Production","text":"<p><code>docker/traefik/traefik.yml</code>:</p> <p>Update for production domains:</p> <pre><code>entryPoints:\n  web:\n    address: \":80\"\n    http:\n      redirections:\n        entryPoint:\n          to: websecure\n          scheme: https\n          permanent: true\n\n  websecure:\n    address: \":443\"\n    http:\n      tls:\n        certResolver: letsencrypt\n\ncertificatesResolvers:\n  letsencrypt:\n    acme:\n      email: ops@example.com  # CHANGE THIS\n      storage: /letsencrypt/acme.json\n      httpChallenge:\n        entryPoint: web\n</code></pre> <p><code>docker/docker-compose.prod.yml</code>:</p> <p>Update service labels with production domains:</p> <pre><code>services:\n  hw-server:\n    labels:\n      - \"traefik.http.routers.fastapi.rule=Host(`api.example.com`)\"\n      - \"traefik.http.routers.fastapi.entrypoints=websecure\"\n      - \"traefik.http.routers.fastapi.tls.certresolver=letsencrypt\"\n\n  hw-keycloak:\n    labels:\n      - \"traefik.http.routers.keycloak.rule=Host(`auth.example.com`)\"\n      - \"traefik.http.routers.keycloak.entrypoints=websecure\"\n      - \"traefik.http.routers.keycloak.tls.certresolver=letsencrypt\"\n\n  grafana:\n    labels:\n      - \"traefik.http.routers.grafana.rule=Host(`grafana.example.com`)\"\n      - \"traefik.http.routers.grafana.entrypoints=websecure\"\n      - \"traefik.http.routers.grafana.tls.certresolver=letsencrypt\"\n</code></pre>"},{"location":"deployment/production/#deployment-steps","title":"Deployment Steps","text":""},{"location":"deployment/production/#1-initial-setup","title":"1. Initial Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/acikabubo/fastapi-http-websocket.git\ncd fastapi-http-websocket\n\n# Checkout production branch\ngit checkout main\n\n# Create production environment files\ncp .env.example .env.production\ncp docker/.pg_env docker/.pg_env.production\ncp docker/.kc_env docker/.kc_env.production\n\n# IMPORTANT: Update all passwords and secrets in these files\n</code></pre>"},{"location":"deployment/production/#2-generate-secrets","title":"2. Generate Secrets","text":"<pre><code># Generate SECRET_KEY\nopenssl rand -hex 32\n\n# Generate database passwords\nopenssl rand -base64 32\n\n# Generate Keycloak admin password\nopenssl rand -base64 24\n</code></pre>"},{"location":"deployment/production/#3-configure-dns","title":"3. Configure DNS","text":"<p>Point your domains to the server:</p> <pre><code>api.example.com        \u2192 A     \u2192 SERVER_IP\nauth.example.com       \u2192 A     \u2192 SERVER_IP\ngrafana.example.com    \u2192 A     \u2192 SERVER_IP\nprometheus.example.com \u2192 A     \u2192 SERVER_IP\ntraefik.example.com    \u2192 A     \u2192 SERVER_IP\n</code></pre>"},{"location":"deployment/production/#4-deploy-services","title":"4. Deploy Services","text":"<pre><code># Set UID/GID for file permissions\nexport UID=$(id -u)\nexport GID=$(id -g)\n\n# Create volumes\ndocker volume create postgres-hw-data\ndocker volume create prometheus-data\ndocker volume create grafana-data\ndocker volume create loki-data\ndocker volume create traefik-certificates\n\n# Start services\ndocker-compose -f docker/docker-compose.yml \\\n  --env-file .env.production \\\n  up -d\n\n# Wait for services to be healthy\ndocker-compose -f docker/docker-compose.yml ps\n</code></pre>"},{"location":"deployment/production/#5-database-initialization","title":"5. Database Initialization","text":"<pre><code># Run migrations\ndocker exec hw-server alembic upgrade head\n\n# Verify migrations\ndocker exec hw-server alembic current\ndocker exec hw-server alembic history\n</code></pre>"},{"location":"deployment/production/#6-configure-keycloak","title":"6. Configure Keycloak","text":"<pre><code># Access Keycloak admin console\nhttps://auth.example.com\n\n# Login with admin credentials from .kc_env.production\n\n# Create production realm:\n1. Realm \u2192 Create Realm \u2192 Name: \"production\"\n2. Import realm-export.json (update redirect URIs for production domains)\n\n# Create client for FastAPI:\n1. Clients \u2192 Create Client\n2. Client ID: fastapi-app\n3. Client Authentication: ON\n4. Valid redirect URIs:\n   - https://api.example.com/*\n5. Web Origins: https://api.example.com\n6. Copy client secret to .env.production\n\n# Create users and assign roles\n</code></pre>"},{"location":"deployment/production/#7-configure-grafana","title":"7. Configure Grafana","text":"<pre><code># Access Grafana\nhttps://grafana.example.com\n\n# Login via Keycloak (auto-redirects)\n\n# Import dashboards (already provisioned):\n- FastAPI Metrics\n- Traefik Metrics\n- Keycloak Metrics\n- Application Logs\n\n# Configure alerts:\nAlerting \u2192 Contact points \u2192 Add Slack/Email/PagerDuty\n</code></pre>"},{"location":"deployment/production/#8-verify-ssl-certificates","title":"8. Verify SSL Certificates","text":"<pre><code># Check Traefik dashboard\nhttps://traefik.example.com\n\n# Verify ACME certificates\ndocker exec hw-traefik ls -la /letsencrypt/\n\n# Test HTTPS\ncurl -v https://api.example.com/health\n</code></pre>"},{"location":"deployment/production/#post-deployment-verification","title":"Post-Deployment Verification","text":""},{"location":"deployment/production/#health-checks","title":"Health Checks","text":"<pre><code># Application health\ncurl https://api.example.com/health\n# Expected: {\"status\":\"ok\"}\n\n# Keycloak health\ncurl https://auth.example.com/health\n# Expected: {\"status\":\"UP\"}\n\n# Prometheus\ncurl https://prometheus.example.com/-/healthy\n# Expected: Healthy\n\n# Traefik\ncurl https://traefik.example.com/ping\n# Expected: OK\n</code></pre>"},{"location":"deployment/production/#metrics-verification","title":"Metrics Verification","text":"<pre><code># Check Prometheus targets\nhttps://prometheus.example.com/targets\n\n# All targets should be UP:\n- fastapi (hw-server:8000/metrics)\n- keycloak (hw-keycloak:9000/metrics)\n- traefik (traefik:8080/metrics)\n</code></pre>"},{"location":"deployment/production/#log-verification","title":"Log Verification","text":"<pre><code># Check application logs\ndocker logs hw-server | tail -20\n\n# Expected: Structured JSON logs with no errors\n# Verify LOG_CONSOLE_FORMAT=json is working\n\n# Check Loki ingestion\n# Grafana \u2192 Explore \u2192 Loki \u2192 Query: {service=\"shell\"}\n</code></pre>"},{"location":"deployment/production/#websocket-testing","title":"WebSocket Testing","text":"<pre><code># Test WebSocket connection\nwscat -c wss://api.example.com/web?access_token=YOUR_TOKEN\n\n# Send test message\n{\"pkg_id\": 1, \"req_id\": \"test-123\", \"data\": {}}\n\n# Expected: Response with same req_id\n</code></pre>"},{"location":"deployment/production/#rate-limiting-testing","title":"Rate Limiting Testing","text":"<pre><code># Test HTTP rate limit\nfor i in {1..100}; do curl -s -o /dev/null -w \"%{http_code}\\n\" https://api.example.com/health; done\n\n# Expected: 200 responses, then 429 (Too Many Requests) after limit\n\n# Check rate limit headers\ncurl -I https://api.example.com/health\n# X-RateLimit-Limit: 60\n# X-RateLimit-Remaining: 59\n# X-RateLimit-Reset: 1234567890\n</code></pre>"},{"location":"deployment/production/#scaling","title":"Scaling","text":""},{"location":"deployment/production/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>Update docker-compose.yml:</p> <pre><code>services:\n  hw-server:\n    deploy:\n      replicas: 3  # Run 3 instances\n      resources:\n        limits:\n          cpus: '2'\n          memory: 2G\n        reservations:\n          cpus: '1'\n          memory: 1G\n</code></pre> <p>Adjust Database Connection Pool:</p> <pre><code># If running 3 instances\n# Total connections = 3 \u00d7 DB_POOL_SIZE\n# Keep total &lt; Postgres max_connections\n\nDB_POOL_SIZE=10  # 3 \u00d7 10 = 30 total connections\nDB_MAX_OVERFLOW=5\n</code></pre> <p>Load Balancer Configuration:</p> <p>Traefik automatically load balances across replicas. Monitor distribution:</p> <pre><code># Prometheus query\nrate(http_requests_total[5m]) by (instance)\n</code></pre>"},{"location":"deployment/production/#vertical-scaling","title":"Vertical Scaling","text":"<p>Database:</p> <pre><code># PostgreSQL tuning\nshared_buffers = 2GB  # 25% of RAM\neffective_cache_size = 6GB  # 75% of RAM\nwork_mem = 16MB\nmaintenance_work_mem = 512MB\nmax_connections = 100\n</code></pre> <p>Redis:</p> <pre><code># redis.conf\nmaxmemory 2gb\nmaxmemory-policy allkeys-lru\n</code></pre>"},{"location":"deployment/production/#auto-scaling-kubernetes","title":"Auto-Scaling (Kubernetes)","text":"<p>For Kubernetes deployments, use HPA (Horizontal Pod Autoscaler):</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: fastapi-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: fastapi-app\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n</code></pre>"},{"location":"deployment/production/#backup-and-recovery","title":"Backup and Recovery","text":"<p>See BACKUP_RECOVERY.md for detailed procedures.</p> <p>Quick Backup:</p> <pre><code># Database backup\ndocker exec hw-db pg_dump -U prod_user fastapi_prod &gt; backup-$(date +%Y%m%d).sql\n\n# Volume backup\ndocker run --rm -v postgres-hw-data:/data -v $(pwd):/backup \\\n  alpine tar czf /backup/postgres-data-$(date +%Y%m%d).tar.gz /data\n</code></pre>"},{"location":"deployment/production/#monitoring-and-alerts","title":"Monitoring and Alerts","text":""},{"location":"deployment/production/#key-metrics-to-monitor","title":"Key Metrics to Monitor","text":"Metric Alert Threshold Action <code>http_requests_total{status_code=~\"5..\"}</code> &gt; 5% error rate for 5min Investigate errors <code>http_request_duration_seconds{quantile=\"0.99\"}</code> &gt; 1s for 5min Check slow endpoints <code>ws_connections_active</code> &gt; 1000 Scale horizontally <code>rate_limit_hits_total</code> Sudden spike Check for abuse <code>up{job=\"postgres\"}</code> == 0 Database down! <code>redis_connected_clients</code> &gt; 90% of maxclients Scale Redis"},{"location":"deployment/production/#alert-configuration","title":"Alert Configuration","text":"<p>See MONITORING.md for Prometheus alert rules.</p>"},{"location":"deployment/production/#troubleshooting","title":"Troubleshooting","text":"<p>See TROUBLESHOOTING.md for common issues and solutions.</p> <p>Quick Checks:</p> <pre><code># Check service health\ndocker-compose -f docker/docker-compose.yml ps\n\n# Check logs\ndocker logs hw-server --tail 100\ndocker logs hw-traefik --tail 100\n\n# Check resource usage\ndocker stats\n\n# Check Traefik routing\ncurl https://traefik.example.com/api/http/routers\n</code></pre>"},{"location":"deployment/production/#security-checklist","title":"Security Checklist","text":"<p>Before going live, verify:</p> <ul> <li> All default passwords changed</li> <li> SSL/TLS certificates valid</li> <li> Firewall configured (only 80/443 open)</li> <li> Database accessible only from app containers</li> <li> Redis password enabled</li> <li> Keycloak production mode enabled</li> <li> CORS origins restricted</li> <li> Rate limiting enabled</li> <li> Audit logging enabled</li> <li> Monitoring and alerts configured</li> <li> Backup procedures tested</li> <li> Secrets not committed to git</li> </ul>"},{"location":"deployment/production/#rollback-procedure","title":"Rollback Procedure","text":"<p>If deployment fails:</p> <pre><code># 1. Stop new version\ndocker-compose -f docker/docker-compose.yml down\n\n# 2. Restore database backup\ndocker exec -i hw-db psql -U prod_user fastapi_prod &lt; backup-YYYYMMDD.sql\n\n# 3. Revert to previous git tag\ngit checkout v1.0.0  # Previous stable version\n\n# 4. Redeploy\ndocker-compose -f docker/docker-compose.yml up -d\n\n# 5. Verify\ncurl https://api.example.com/health\n</code></pre>"},{"location":"deployment/production/#additional-resources","title":"Additional Resources","text":"<ul> <li>Docker Deployment Guide</li> <li>Security Guide</li> <li>Monitoring Guide</li> <li>Troubleshooting Guide</li> <li>Backup and Recovery</li> </ul>"},{"location":"deployment/production/#support","title":"Support","text":"<ul> <li>GitHub Issues: https://github.com/acikabubo/fastapi-http-websocket/issues</li> <li>Internal Docs: Confluence/Wiki</li> <li>On-call: PagerDuty rotation</li> </ul>"},{"location":"deployment/security/","title":"Security Guide","text":"<p>Comprehensive security best practices and hardening guidelines for production deployment of the FastAPI HTTP/WebSocket application.</p>"},{"location":"deployment/security/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Security Principles</li> <li>Authentication &amp; Authorization</li> <li>Network Security</li> <li>Data Security</li> <li>Application Security</li> <li>Infrastructure Security</li> <li>Monitoring &amp; Auditing</li> <li>Incident Response</li> <li>Compliance</li> </ul>"},{"location":"deployment/security/#security-principles","title":"Security Principles","text":""},{"location":"deployment/security/#defense-in-depth","title":"Defense in Depth","text":"<p>Implement multiple layers of security:</p> <ol> <li>Network Layer: Firewall, VPC, network segmentation</li> <li>Transport Layer: TLS/SSL encryption</li> <li>Application Layer: Authentication, authorization, input validation</li> <li>Data Layer: Encryption at rest, secure backups</li> <li>Monitoring Layer: Intrusion detection, audit logging</li> </ol>"},{"location":"deployment/security/#least-privilege","title":"Least Privilege","text":"<ul> <li>Users/services should have minimum permissions needed</li> <li>Database users with specific grants only</li> <li>Container capabilities dropped to minimum</li> <li>File system mounted read-only where possible</li> </ul>"},{"location":"deployment/security/#security-by-default","title":"Security by Default","text":"<ul> <li>Authentication required by default</li> <li>Rate limiting enabled</li> <li>Secure headers enforced</li> <li>Debug mode disabled in production</li> </ul>"},{"location":"deployment/security/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"deployment/security/#key-cloak-configuration","title":"Key cloak Configuration","text":""},{"location":"deployment/security/#production-realm-setup","title":"Production Realm Setup","text":"<pre><code># 1. Create production realm\nRealm Name: production\nDisplay Name: Production Environment\nEnabled: ON\n\n# 2. Security Settings\nRealm Settings \u2192 Security Defenses:\n- Brute Force Detection: ON\n- Permanent Lockout: ON\n- Max Login Failures: 5\n- Wait Increment: 60 seconds\n- Quick Login Check: 1000ms\n- Minimum Quick Login Wait: 60 seconds\n\n# 3. Token Settings\nRealm Settings \u2192 Tokens:\n- Access Token Lifespan: 5 minutes\n- Access Token Lifespan For Implicit Flow: 15 minutes\n- Client Login Timeout: 5 minutes\n- Login Action Timeout: 5 minutes\n- Refresh Token Max Reuse: 0\n- SSO Session Idle: 30 minutes\n- SSO Session Max: 10 hours\n</code></pre>"},{"location":"deployment/security/#client-configuration","title":"Client Configuration","text":"<pre><code># FastAPI Client\nClient ID: fastapi-app\nClient Protocol: openid-connect\nAccess Type: confidential\nStandard Flow Enabled: ON\nDirect Access Grants Enabled: OFF  # Disable for production\nService Accounts Enabled: OFF\nAuthorization Enabled: ON\n\n# Valid Redirect URIs (strict)\nhttps://api.example.com/*\n# DO NOT use wildcards like https://* in production\n\n# Web Origins\nhttps://api.example.com\n\n# Advanced Settings\nProof Key for Code Exchange Code Challenge Method: S256  # Enable PKCE\n</code></pre>"},{"location":"deployment/security/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<p>Decorator-Based RBAC Configuration:</p> <p>Roles are defined directly in handler code using decorators:</p> <p>WebSocket Handlers: <pre><code>@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    roles=[\"viewer\"]  # Read-only access\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n\n@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"admin\"]  # Admin only\n)\nasync def delete_author_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n</code></pre></p> <p>HTTP Endpoints: <pre><code>from app.dependencies.permissions import require_roles\n\n@router.get(\"/authors\", dependencies=[Depends(require_roles(\"viewer\"))])\nasync def get_authors():\n    ...\n\n@router.delete(\"/authors/{id}\", dependencies=[Depends(require_roles(\"admin\"))])\nasync def delete_author(id: int):\n    ...\n\n@router.get(\"/health\")  # No require_roles = public endpoint\nasync def health_check():\n    ...\n</code></pre></p> <p>Best Practices:</p> <ol> <li>Principle of Least Privilege: Assign minimum role needed</li> <li>Regular Audits: Review role assignments quarterly</li> <li>Service Accounts: Create dedicated roles for service-to-service auth</li> <li>Temporary Elevation: Use time-limited admin access</li> </ol>"},{"location":"deployment/security/#token-security","title":"Token Security","text":""},{"location":"deployment/security/#jwt-validation","title":"JWT Validation","text":"<pre><code># app/auth.py - Already implemented\nclass AuthBackend(AuthenticationBackend):\n    async def authenticate(self, conn):\n        # 1. Extract token from header/query\n        # 2. Decode and verify signature\n        # 3. Check expiration\n        # 4. Verify audience\n        # 5. Validate issuer\n        # 6. Check not-before (nbf) claim\n        # 7. Verify token wasn't revoked\n</code></pre>"},{"location":"deployment/security/#token-storage","title":"Token Storage","text":"<p>\u274c DON'T: - Store tokens in localStorage (vulnerable to XSS) - Log tokens - Send tokens in URL parameters (except WebSocket initial connection) - Store tokens in cookies without HttpOnly flag</p> <p>\u2705 DO: - Use HttpOnly, Secure cookies for web apps - Store tokens in memory for SPAs - Implement token refresh flow - Use short-lived access tokens (5-15 min) - Use long-lived refresh tokens with rotation</p>"},{"location":"deployment/security/#token-revocation","title":"Token Revocation","text":"<pre><code># Implement token blacklist in Redis\nfrom app.storage.redis import RRedis\n\nasync def revoke_token(token_jti: str, exp: int):\n    \"\"\"Revoke a token by adding to blacklist.\"\"\"\n    redis = RRedis()\n    ttl = exp - int(time.time())\n    await redis.setex(f\"revoked_token:{token_jti}\", ttl, \"1\")\n\nasync def is_token_revoked(token_jti: str) -&gt; bool:\n    \"\"\"Check if token is revoked.\"\"\"\n    redis = RRedis()\n    return await redis.exists(f\"revoked_token:{token_jti}\")\n</code></pre>"},{"location":"deployment/security/#network-security","title":"Network Security","text":""},{"location":"deployment/security/#firewall-rules","title":"Firewall Rules","text":"<pre><code># Allow only necessary ports\nufw default deny incoming\nufw default allow outgoing\n\n# HTTP/HTTPS (Traefik)\nufw allow 80/tcp\nufw allow 443/tcp\n\n# SSH (restrict to specific IPs)\nufw allow from 1.2.3.4 to any port 22\n\n# Enable firewall\nufw enable\n</code></pre>"},{"location":"deployment/security/#tlsssl-configuration","title":"TLS/SSL Configuration","text":""},{"location":"deployment/security/#traefik-tls-settings","title":"Traefik TLS Settings","text":"<pre><code># docker/traefik/traefik.yml\nentryPoints:\n  websecure:\n    address: \":443\"\n    http:\n      tls:\n        options: default\n        certResolver: letsencrypt\n        domains:\n          - main: example.com\n            sans:\n              - \"*.example.com\"\n\n# TLS Options\ntls:\n  options:\n    default:\n      minVersion: VersionTLS12\n      maxVersion: VersionTLS13\n      cipherSuites:\n        - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\n        - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305\n        - TLS_AES_256_GCM_SHA384\n        - TLS_CHACHA20_POLY1305_SHA256\n      sniStrict: true\n</code></pre>"},{"location":"deployment/security/#certificate-management","title":"Certificate Management","text":"<pre><code># Let's Encrypt auto-renewal\n# Traefik handles this automatically\n\n# Check certificate expiration\necho | openssl s_client -servername api.example.com -connect api.example.com:443 2&gt;/dev/null | openssl x509 -noout -dates\n\n# Monitor expiration in Prometheus\nssl_certificate_expiry{domain=\"api.example.com\"} &lt; 604800  # 7 days\n</code></pre>"},{"location":"deployment/security/#network-segmentation","title":"Network Segmentation","text":"<pre><code># docker-compose.yml\nnetworks:\n  # Public network - accessible from internet\n  public:\n    driver: bridge\n\n  # Private network - internal services only\n  private:\n    driver: bridge\n    internal: true  # No external access\n\nservices:\n  traefik:\n    networks:\n      - public  # Internet-facing\n\n  hw-server:\n    networks:\n      - public   # Accessible via Traefik\n      - private  # Can access backend services\n\n  hw-db:\n    networks:\n      - private  # Not accessible from internet\n\n  hw-redis:\n    networks:\n      - private  # Not accessible from internet\n</code></pre>"},{"location":"deployment/security/#data-security","title":"Data Security","text":""},{"location":"deployment/security/#database-security","title":"Database Security","text":""},{"location":"deployment/security/#postgresql-hardening","title":"PostgreSQL Hardening","text":"<p><code>docker/.pg_env.production</code>: <pre><code># Strong password (32+ characters)\nPOSTGRES_PASSWORD=CHANGE_ME_LONG_RANDOM_STRING\n\n# SSL Mode\nPGSSLMODE=require\nPGSSLCERT=/path/to/client-cert.pem\nPGSSLKEY=/path/to/client-key.pem\nPGSSLROOTCERT=/path/to/ca-cert.pem\n</code></pre></p> <p>Connection String: <pre><code>DATABASE_URL=postgresql+asyncpg://user:pass@host:5432/db?ssl=require\n</code></pre></p> <p>PostgreSQL Configuration (<code>postgresql.conf</code>): <pre><code># Authentication\nssl = on\nssl_cert_file = '/var/lib/postgresql/server.crt'\nssl_key_file = '/var/lib/postgresql/server.key'\nssl_ca_file = '/var/lib/postgresql/root.crt'\n\n# Network\nlisten_addresses = '127.0.0.1,172.25.0.0/16'  # Only internal network\n\n# Logging\nlog_connections = on\nlog_disconnections = on\nlog_statement = 'ddl'  # Log DDL statements\nlog_line_prefix = '%t [%p]: user=%u,db=%d,app=%a,client=%h '\n\n# Security\npassword_encryption = scram-sha-256\n</code></pre></p> <p>Database User Permissions: <pre><code>-- Create application user with minimal permissions\nCREATE USER app_user WITH PASSWORD 'STRONG_PASSWORD';\n\n-- Grant only necessary permissions\nGRANT CONNECT ON DATABASE production TO app_user;\nGRANT USAGE ON SCHEMA public TO app_user;\nGRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO app_user;\nGRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO app_user;\n\n-- Revoke dangerous permissions\nREVOKE CREATE ON SCHEMA public FROM PUBLIC;\nREVOKE ALL ON DATABASE postgres FROM PUBLIC;\n</code></pre></p>"},{"location":"deployment/security/#sql-injection-prevention","title":"SQL Injection Prevention","text":"<p>\u2705 Always Use Parameterized Queries (SQLAlchemy/SQLModel does this automatically):</p> <pre><code># \u2705 SAFE: Parameterized query\nstmt = select(Author).where(Author.name == user_input)\nresult = await session.execute(stmt)\n\n# \u274c NEVER DO THIS: String concatenation\nquery = f\"SELECT * FROM authors WHERE name = '{user_input}'\"\n</code></pre> <p>Input Validation with Pydantic: <pre><code>from pydantic import BaseModel, validator\n\nclass AuthorCreate(BaseModel):\n    name: str\n    bio: str | None = None\n\n    @validator('name')\n    def validate_name(cls, v):\n        if not v or len(v) &gt; 100:\n            raise ValueError('Name must be 1-100 characters')\n        if not v.replace(' ', '').isalnum():\n            raise ValueError('Name must be alphanumeric')\n        return v\n</code></pre></p>"},{"location":"deployment/security/#redis-security","title":"Redis Security","text":"<p><code>docker/redis/redis.conf</code>: <pre><code># Bind to internal network only\nbind 127.0.0.1 172.25.0.1\n\n# Require password\nrequirepass STRONG_REDIS_PASSWORD\n\n# Disable dangerous commands\nrename-command FLUSHDB \"\"\nrename-command FLUSHALL \"\"\nrename-command CONFIG \"CONFIG_SECRET_NAME\"\nrename-command SHUTDOWN \"\"\nrename-command DEBUG \"\"\n\n# Enable SSL/TLS\nport 0  # Disable unencrypted port\ntls-port 6379\ntls-cert-file /path/to/redis.crt\ntls-key-file /path/to/redis.key\ntls-ca-cert-file /path/to/ca.crt\n\n# Memory limits\nmaxmemory 2gb\nmaxmemory-policy allkeys-lru\n\n# Persistence (if needed)\nsave 900 1\nsave 300 10\nsave 60 10000\n</code></pre></p> <p>Application Configuration: <pre><code># app/storage/redis.py\nredis_client = Redis(\n    host=settings.REDIS_IP,\n    port=settings.REDIS_PORT,\n    password=settings.REDIS_PASSWORD,\n    ssl=True,  # Enable SSL in production\n    ssl_cert_reqs='required',\n    ssl_ca_certs='/path/to/ca.crt',\n    socket_connect_timeout=5,\n    socket_timeout=5,\n    decode_responses=True,\n)\n</code></pre></p>"},{"location":"deployment/security/#encryption-at-rest","title":"Encryption at Rest","text":""},{"location":"deployment/security/#database-encryption","title":"Database Encryption","text":"<pre><code># PostgreSQL transparent data encryption (TDE)\n# Requires PostgreSQL with encryption support\n\n# File-level encryption with dm-crypt/LUKS\ncryptsetup luksFormat /dev/sdb\ncryptsetup open /dev/sdb postgres_encrypted\nmkfs.ext4 /dev/mapper/postgres_encrypted\nmount /dev/mapper/postgres_encrypted /var/lib/postgresql/data\n</code></pre>"},{"location":"deployment/security/#secrets-management","title":"Secrets Management","text":"<p>AWS Secrets Manager: <pre><code>import boto3\nfrom botocore.exceptions import ClientError\n\ndef get_secret(secret_name):\n    \"\"\"Retrieve secret from AWS Secrets Manager.\"\"\"\n    client = boto3.client('secretsmanager', region_name='us-east-1')\n\n    try:\n        response = client.get_secret_value(SecretId=secret_name)\n        return response['SecretString']\n    except ClientError as e:\n        raise Exception(f\"Error retrieving secret: {e}\")\n\n# Usage\ndb_password = get_secret('prod/db/password')\n</code></pre></p> <p>HashiCorp Vault: <pre><code>import hvac\n\nclient = hvac.Client(url='https://vault.example.com:8200')\nclient.auth.approle.login(\n    role_id='app-role-id',\n    secret_id='app-secret-id',\n)\n\n# Read secret\nsecret = client.secrets.kv.v2.read_secret_version(\n    path='production/database',\n)\ndb_password = secret['data']['data']['password']\n</code></pre></p>"},{"location":"deployment/security/#application-security","title":"Application Security","text":""},{"location":"deployment/security/#input-validation","title":"Input Validation","text":"<p>Pydantic Models (already implemented): <pre><code>from pydantic import BaseModel, Field, validator\nfrom typing import Literal\n\nclass CreateAuthorInput(BaseModel):\n    name: str = Field(..., min_length=1, max_length=100)\n    bio: str | None = Field(None, max_length=1000)\n    status: Literal['active', 'inactive'] = 'active'\n\n    @validator('name')\n    def sanitize_name(cls, v):\n        # Remove potentially dangerous characters\n        import re\n        v = re.sub(r'[&lt;&gt;\\\"\\'&amp;]', '', v)\n        return v.strip()\n</code></pre></p>"},{"location":"deployment/security/#output-encoding","title":"Output Encoding","text":"<p>XSS Prevention: <pre><code>from html import escape\n\n# Escape user-generated content before rendering\nsafe_bio = escape(author.bio)\n</code></pre></p> <p>Response Headers: <pre><code># app/middlewares/security_headers.py\nfrom starlette.middleware.base import BaseHTTPMiddleware\n\nclass SecurityHeadersMiddleware(BaseHTTPMiddleware):\n    async def dispatch(self, request, call_next):\n        response = await call_next(request)\n\n        # XSS Protection\n        response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n        response.headers[\"X-Frame-Options\"] = \"DENY\"\n        response.headers[\"X-XSS-Protection\"] = \"1; mode=block\"\n\n        # HTTPS Enforcement\n        response.headers[\"Strict-Transport-Security\"] = \"max-age=31536000; includeSubDomains\"\n\n        # CSP\n        response.headers[\"Content-Security-Policy\"] = (\n            \"default-src 'self'; \"\n            \"script-src 'self' 'unsafe-inline' https://cdn.example.com; \"\n            \"style-src 'self' 'unsafe-inline'; \"\n            \"img-src 'self' data: https:; \"\n            \"font-src 'self' data:; \"\n            \"connect-src 'self' wss://api.example.com; \"\n            \"frame-ancestors 'none'\"\n        )\n\n        # Permissions Policy\n        response.headers[\"Permissions-Policy\"] = (\n            \"geolocation=(), \"\n            \"microphone=(), \"\n            \"camera=()\"\n        )\n\n        return response\n</code></pre></p>"},{"location":"deployment/security/#rate-limiting","title":"Rate Limiting","text":"<p>Already implemented in <code>app/middlewares/rate_limit.py</code> and <code>app/utils/rate_limiter.py</code>.</p> <p>Production Configuration: <pre><code># .env.production\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_PER_MINUTE=60  # 1 request per second\nRATE_LIMIT_BURST=10\nWS_MAX_CONNECTIONS_PER_USER=5\nWS_MESSAGE_RATE_LIMIT=100\n</code></pre></p> <p>DDoS Protection: - Use Cloudflare or AWS WAF - Enable Traefik rate limiting as additional layer - Monitor <code>rate_limit_hits_total</code> metric for abuse</p>"},{"location":"deployment/security/#cors-configuration","title":"CORS Configuration","text":"<pre><code># app/__init__.py\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\n        \"https://app.example.com\",\n        \"https://admin.example.com\"\n    ],  # Specific origins only\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\"],\n    allow_headers=[\"*\"],\n    max_age=600,  # Cache preflight requests for 10 minutes\n)\n</code></pre>"},{"location":"deployment/security/#websocket-security","title":"WebSocket Security","text":"<p>Authentication: <pre><code># Already implemented in app/api/ws/websocket.py\nclass PackageAuthWebSocketEndpoint(WebSocketEndpoint):\n    async def on_connect(self, websocket: WebSocket):\n        # 1. Extract token from query params\n        # 2. Validate token with Keycloak\n        # 3. Check rate limits\n        # 4. Accept or reject connection\n</code></pre></p> <p>Message Validation: <pre><code># Already implemented in app/routing.py\nclass PackageRouter:\n    async def handle_request(self, request: RequestModel, user: UserModel):\n        # 1. Validate JSON schema\n        # 2. Check RBAC permissions\n        # 3. Rate limit messages\n        # 4. Sanitize input\n</code></pre></p>"},{"location":"deployment/security/#infrastructure-security","title":"Infrastructure Security","text":""},{"location":"deployment/security/#docker-security","title":"Docker Security","text":"<p>See DOCKER.md for detailed Docker security practices.</p> <p>Key Points: - Run as non-root user - Read-only root filesystem - Drop all capabilities - Use security options (no-new-privileges) - Scan images for vulnerabilities</p>"},{"location":"deployment/security/#secrets-in-docker","title":"Secrets in Docker","text":"<p>Never in Dockerfile or docker-compose.yml: <pre><code># \u274c NEVER DO THIS\nenvironment:\n  - DB_PASSWORD=plaintext_password\n\n# \u2705 Use env_file\nenv_file:\n  - .env.production  # Not committed to git\n\n# \u2705 Or Docker secrets (Swarm)\nsecrets:\n  - db_password\n</code></pre></p>"},{"location":"deployment/security/#vulnerability-scanning","title":"Vulnerability Scanning","text":"<pre><code># Scan Docker images\ndocker scan fastapi-app:latest\n\n# Scan Python dependencies\nmake skjold-scan\n\n# SAST scanning\nmake bandit-scan\n\n# Check for outdated packages\nmake outdated-pkgs-scan\n</code></pre>"},{"location":"deployment/security/#monitoring-auditing","title":"Monitoring &amp; Auditing","text":""},{"location":"deployment/security/#audit-logging","title":"Audit Logging","text":"<p>Already implemented in <code>app/models/user_action.py</code>.</p> <p>What to Log: - Authentication attempts (success/failure) - Authorization failures - Database modifications (CREATE, UPDATE, DELETE) - Admin actions - Configuration changes - API access patterns - Rate limit violations</p> <p>Log Retention: <pre><code>-- Automated cleanup (run daily)\nDELETE FROM user_action_logs\nWHERE timestamp &lt; NOW() - INTERVAL '90 days';\n</code></pre></p> <p>Log Analysis: <pre><code># Grafana Loki queries\n{service=\"shell\"} | json | action=\"login\" | status=\"failed\"\n{service=\"shell\"} | json | action=\"delete\" | user_role=\"admin\"\n{service=\"shell\"} | json |~ \"(?i)(permission denied|unauthorized)\"\n</code></pre></p>"},{"location":"deployment/security/#security-monitoring","title":"Security Monitoring","text":"<p>Prometheus Alerts: <pre><code># prometheus/alerts/security.yml\ngroups:\n  - name: security\n    rules:\n      - alert: HighFailedLoginRate\n        expr: rate(auth_attempts_total{status=\"failed\"}[5m]) &gt; 10\n        for: 5m\n        annotations:\n          summary: \"High rate of failed login attempts\"\n          description: \"{{ $value }} failed logins per second\"\n\n      - alert: RateLimitAbuse\n        expr: rate(rate_limit_hits_total[5m]) &gt; 100\n        for: 5m\n        annotations:\n          summary: \"Potential DDoS attack or abuse\"\n\n      - alert: UnauthorizedAccess\n        expr: increase(http_requests_total{status_code=\"403\"}[5m]) &gt; 50\n        annotations:\n          summary: \"High rate of unauthorized access attempts\"\n</code></pre></p>"},{"location":"deployment/security/#incident-response","title":"Incident Response","text":""},{"location":"deployment/security/#security-incident-playbook","title":"Security Incident Playbook","text":"<p>1. Detection &amp; Analysis (0-30 minutes): - [ ] Alert received (failed logins, data breach, etc.) - [ ] Verify incident is real (not false positive) - [ ] Assess scope and severity - [ ] Activate incident response team</p> <p>2. Containment (30-60 minutes): - [ ] Isolate affected systems - [ ] Block malicious IPs at firewall - [ ] Revoke compromised credentials - [ ] Disable compromised accounts - [ ] Take snapshots/backups of affected systems</p> <p>3. Eradication (1-4 hours): - [ ] Identify root cause - [ ] Remove malware/backdoors - [ ] Patch vulnerabilities - [ ] Update firewall rules - [ ] Force password resets if needed</p> <p>4. Recovery (4-24 hours): - [ ] Restore from clean backups if needed - [ ] Verify system integrity - [ ] Gradual service restoration - [ ] Enhanced monitoring</p> <p>5. Post-Incident (1-7 days): - [ ] Document timeline - [ ] Root cause analysis - [ ] Update security procedures - [ ] Notify affected users (if required) - [ ] Improve detection/prevention</p>"},{"location":"deployment/security/#emergency-contacts","title":"Emergency Contacts","text":"<pre><code># incident_contacts.yml\nprimary:\n  - name: Security Lead\n    phone: +1-xxx-xxx-xxxx\n    email: security@example.com\n\nescalation:\n  - name: CTO\n    phone: +1-xxx-xxx-xxxx\n    email: cto@example.com\n\nexternal:\n  - name: Incident Response Firm\n    phone: +1-xxx-xxx-xxxx\n    email: ir@firm.com\n</code></pre>"},{"location":"deployment/security/#evidence-preservation","title":"Evidence Preservation","text":"<pre><code># Preserve logs\ndocker logs hw-server &gt; incident-logs-$(date +%Y%m%d-%H%M%S).log\n\n# Preserve memory dump\ndocker exec hw-server gcore $(docker exec hw-server pidof python)\n\n# Preserve disk image\ndocker commit hw-server incident-snapshot-$(date +%Y%m%d)\n\n# Preserve network traffic\ntcpdump -i any -w incident-traffic-$(date +%Y%m%d).pcap\n</code></pre>"},{"location":"deployment/security/#compliance","title":"Compliance","text":""},{"location":"deployment/security/#gdpr-compliance","title":"GDPR Compliance","text":"<p>Data Minimization: - Only collect necessary data - Delete data when no longer needed - Implement data retention policies</p> <p>Right to Access: <pre><code>@router.get(\"/users/{user_id}/data\")\nasync def get_user_data(user_id: str):\n    \"\"\"Export all user data (GDPR compliance).\"\"\"\n    # Return all data associated with user\n</code></pre></p> <p>Right to be Forgotten: <pre><code>@router.delete(\"/users/{user_id}/gdpr-delete\")\nasync def gdpr_delete_user(user_id: str):\n    \"\"\"Permanently delete all user data.\"\"\"\n    # Delete from all tables\n    # Anonymize audit logs\n</code></pre></p>"},{"location":"deployment/security/#soc-2-compliance","title":"SOC 2 Compliance","text":"<p>Access Controls: - [ ] MFA for admin accounts - [ ] Principle of least privilege - [ ] Regular access reviews</p> <p>Change Management: - [ ] Code review required - [ ] Deployment approval process - [ ] Rollback procedures documented</p> <p>Monitoring: - [ ] Centralized logging - [ ] Audit trail of all changes - [ ] Security alerts configured</p>"},{"location":"deployment/security/#security-checklist","title":"Security Checklist","text":""},{"location":"deployment/security/#pre-deployment","title":"Pre-Deployment","text":"<ul> <li> All default passwords changed</li> <li> Secrets stored in vault (not in code)</li> <li> SSL/TLS certificates valid</li> <li> Firewall rules configured</li> <li> Database encryption enabled</li> <li> Redis authentication enabled</li> <li> Rate limiting enabled</li> <li> CORS properly configured</li> <li> Security headers configured</li> <li> Audit logging enabled</li> <li> Vulnerability scan passed</li> <li> Penetration testing completed</li> </ul>"},{"location":"deployment/security/#post-deployment","title":"Post-Deployment","text":"<ul> <li> Monitor security alerts</li> <li> Review audit logs daily</li> <li> Apply security patches weekly</li> <li> Rotate credentials monthly</li> <li> Review access controls quarterly</li> <li> Penetration testing annually</li> </ul>"},{"location":"deployment/security/#additional-resources","title":"Additional Resources","text":"<ul> <li>OWASP Top 10</li> <li>CIS Docker Benchmark</li> <li>NIST Cybersecurity Framework</li> <li>Keycloak Security Guide</li> </ul>"},{"location":"deployment/troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide provides solutions to common issues encountered when deploying and operating the FastAPI HTTP/WebSocket application.</p>"},{"location":"deployment/troubleshooting/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Deployment Issues</li> <li>Service Connectivity</li> <li>Authentication &amp; Authorization</li> <li>Performance Issues</li> <li>Database Problems</li> <li>Redis Issues</li> <li>Traefik Routing</li> <li>Docker Container Issues</li> <li>WebSocket Connection Problems</li> <li>Rate Limiting Issues</li> <li>Log Analysis</li> <li>Emergency Procedures</li> </ul>"},{"location":"deployment/troubleshooting/#deployment-issues","title":"Deployment Issues","text":""},{"location":"deployment/troubleshooting/#container-fails-to-start","title":"Container Fails to Start","text":"<p>Symptoms: - Container exits immediately after starting - <code>docker ps</code> shows container not running - Exit code non-zero</p> <p>Diagnosis: <pre><code># Check container logs\ndocker logs hw-server\n\n# Check exit code\ndocker inspect hw-server --format='{{.State.ExitCode}}'\n\n# Check recent events\ndocker events --since 10m\n</code></pre></p> <p>Common Causes &amp; Solutions:</p> <ol> <li>Missing Environment Variables: <pre><code># Check if .env files exist\nls -la .env.production docker/.srv_env docker/.pg_env docker/.kc_env\n\n# Verify required variables are set\ndocker exec hw-server printenv | grep -E \"DATABASE_URL|KEYCLOAK_BASE_URL|REDIS_IP\"\n</code></pre></li> </ol> <p>Fix: Ensure all required variables are set in environment files.</p> <ol> <li>Port Already in Use: <pre><code># Check what's using the port\nsudo netstat -tulpn | grep :8000\n</code></pre></li> </ol> <p>Fix: Stop conflicting service or change port mapping.</p> <ol> <li>Volume Permission Issues: <pre><code># Check volume permissions\ndocker exec hw-server ls -la /app\n\n# Fix ownership\nsudo chown -R 1000:1000 /path/to/volumes\n</code></pre></li> </ol>"},{"location":"deployment/troubleshooting/#database-migration-failures","title":"Database Migration Failures","text":"<p>Symptoms: - Migration command fails - \"Target database is not up to date\" error - Duplicate column/table errors</p> <p>Diagnosis: <pre><code># Check current migration version\ndocker exec hw-server alembic current\n\n# View migration history\ndocker exec hw-server alembic history\n\n# Check for pending migrations\ndocker exec hw-server alembic heads\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Database Out of Sync: <pre><code># Check which migrations are applied\ndocker exec hw-db psql -U prod_user -d fastapi_prod \\\n  -c \"SELECT * FROM alembic_version;\"\n\n# Stamp database at current code version\ndocker exec hw-server alembic stamp head\n\n# Or downgrade and re-apply\ndocker exec hw-server alembic downgrade -1\ndocker exec hw-server alembic upgrade head\n</code></pre></p> </li> <li> <p>Migration Conflicts: <pre><code># Check for multiple heads\ndocker exec hw-server alembic heads\n\n# Merge branches if needed\ndocker exec hw-server alembic merge &lt;revision1&gt; &lt;revision2&gt;\n</code></pre></p> </li> <li> <p>Failed Partial Migration: <pre><code># Manual rollback\ndocker exec hw-db psql -U prod_user -d fastapi_prod \\\n  -c \"BEGIN; -- manually undo changes; COMMIT;\"\n\n# Update alembic_version table\ndocker exec hw-db psql -U prod_user -d fastapi_prod \\\n  -c \"UPDATE alembic_version SET version_num='&lt;previous_revision&gt;';\"\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#ssl-certificate-issues","title":"SSL Certificate Issues","text":"<p>Symptoms: - \"Certificate verify failed\" errors - HTTPS connections rejected - Let's Encrypt challenge fails</p> <p>Diagnosis: <pre><code># Check Traefik logs\ndocker logs hw-traefik | grep -i certificate\n\n# Check certificate status\ndocker exec hw-traefik ls -la /letsencrypt/\n\n# Test certificate\ncurl -vI https://api.example.com 2&gt;&amp;1 | grep -A 10 \"SSL certificate\"\n</code></pre></p> <p>Solutions:</p> <ol> <li>Let's Encrypt Rate Limiting:</li> <li>Wait for rate limit reset (weekly limit: 50 certs per domain)</li> <li> <p>Use staging environment for testing:      <pre><code># traefik.yml\ncertificatesResolvers:\n  letsencrypt:\n    acme:\n      caServer: https://acme-staging-v02.api.letsencrypt.org/directory\n</code></pre></p> </li> <li> <p>DNS Not Propagated: <pre><code># Check DNS resolution\nnslookup api.example.com\ndig api.example.com\n\n# Wait for DNS propagation (up to 48 hours)\n</code></pre></p> </li> <li> <p>Port 80 Not Accessible: <pre><code># Check firewall\nsudo ufw status\nsudo iptables -L -n | grep 80\n\n# Test port 80 access\ncurl -I http://api.example.com/.well-known/acme-challenge/test\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#service-connectivity","title":"Service Connectivity","text":""},{"location":"deployment/troubleshooting/#cannot-connect-to-application","title":"Cannot Connect to Application","text":"<p>Symptoms: - \"Connection refused\" errors - \"No route to host\" - Timeout errors</p> <p>Diagnosis: <pre><code># Check if service is running\ndocker ps | grep hw-server\n\n# Check if port is listening\ndocker exec hw-server netstat -tulpn | grep 8000\n\n# Check health status\ncurl http://localhost:8000/health\n\n# Check Traefik routing\ncurl http://localhost:8080/api/http/routers\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Service Not Running: <pre><code># Restart service\ndocker-compose -f docker/docker-compose.yml restart hw-server\n\n# Check startup logs\ndocker logs hw-server --tail 50\n</code></pre></p> </li> <li> <p>Network Issues: <pre><code># Check network configuration\ndocker network inspect hw-network\n\n# Test connectivity between containers\ndocker exec hw-server ping hw-db\ndocker exec hw-server nc -zv hw-redis 6379\n</code></pre></p> </li> <li> <p>Firewall Blocking: <pre><code># Check firewall rules\nsudo ufw status\n\n# Allow necessary ports\nsudo ufw allow 80/tcp\nsudo ufw allow 443/tcp\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#inter-service-communication-fails","title":"Inter-Service Communication Fails","text":"<p>Symptoms: - Application cannot reach database - Redis connection errors - Keycloak unreachable</p> <p>Diagnosis: <pre><code># Check all services are on same network\ndocker network inspect hw-network | jq '.[0].Containers'\n\n# Test DNS resolution\ndocker exec hw-server nslookup hw-db\ndocker exec hw-server nslookup hw-redis\n\n# Test port connectivity\ndocker exec hw-server nc -zv hw-db 5432\ndocker exec hw-server nc -zv hw-redis 6379\ndocker exec hw-server nc -zv hw-keycloak 8080\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Services Not on Same Network: <pre><code># Ensure all services have same network in docker-compose.yml\nservices:\n  hw-server:\n    networks:\n      - hw-network\n  hw-db:\n    networks:\n      - hw-network\n</code></pre></p> </li> <li> <p>Wrong Service Names: <pre><code># Use container names, not localhost\n# \u274c Wrong: DATABASE_URL=postgresql://localhost:5432/db\n# \u2705 Correct: DATABASE_URL=postgresql://hw-db:5432/db\n</code></pre></p> </li> <li> <p>Restart All Services: <pre><code>docker-compose -f docker/docker-compose.yml down\ndocker-compose -f docker/docker-compose.yml up -d\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"deployment/troubleshooting/#keycloak-authentication-fails","title":"Keycloak Authentication Fails","text":"<p>Symptoms: - \"Invalid token\" errors - \"Unauthorized\" (401) responses - \"Token signature verification failed\"</p> <p>Diagnosis: <pre><code># Check Keycloak is running\ndocker logs hw-keycloak | tail -50\n\n# Test Keycloak health\ncurl http://localhost:8080/health\n\n# Verify token endpoint\ncurl http://localhost:8080/realms/production/.well-known/openid-configuration\n\n# Check application logs for auth errors\ndocker logs hw-server | grep -i \"auth\\|token\\|keycloak\"\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Token Expired: <pre><code># Check token expiration settings in Keycloak\n# Admin Console \u2192 Realm Settings \u2192 Tokens\n# Access Token Lifespan: 5 minutes (default)\n# Refresh Token Lifespan: 30 minutes (default)\n\n# Get new token\ncurl -X POST http://localhost:8080/realms/production/protocol/openid-connect/token \\\n  -d \"client_id=fastapi-app\" \\\n  -d \"client_secret=YOUR_SECRET\" \\\n  -d \"grant_type=password\" \\\n  -d \"username=user@example.com\" \\\n  -d \"password=password\"\n</code></pre></p> </li> <li> <p>Wrong Keycloak Configuration: <pre><code># Verify environment variables\ndocker exec hw-server printenv | grep KEYCLOAK\n\n# Should match:\n# KEYCLOAK_BASE_URL=http://hw-keycloak:8080\n# KEYCLOAK_REALM=production\n# KEYCLOAK_CLIENT_ID=fastapi-app\n</code></pre></p> </li> <li> <p>Client Secret Mismatch: <pre><code># Get client secret from Keycloak\n# Admin Console \u2192 Clients \u2192 fastapi-app \u2192 Credentials\n\n# Update in .env.production\nKEYCLOAK_CLIENT_SECRET=&lt;secret-from-keycloak&gt;\n\n# Restart application\ndocker-compose restart hw-server\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#permission-denied-errors","title":"Permission Denied Errors","text":"<p>Symptoms: - \"Permission denied\" (403) responses - \"Insufficient permissions\" errors - User cannot access expected endpoints</p> <p>Diagnosis: <pre><code># Check user roles in Keycloak\n# Admin Console \u2192 Users \u2192 &lt;user&gt; \u2192 Role Mappings\n\n# Check handler code for required roles\n# WebSocket: @pkg_router.register(PkgID.*, roles=[\"role-name\"])\n# HTTP: dependencies=[Depends(require_roles(\"role-name\"))]\n\n# Check application logs\ndocker logs hw-server | grep -i \"permission\\|rbac\"\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>User Missing Required Role: <pre><code># Add role to user in Keycloak\n# Admin Console \u2192 Users \u2192 &lt;user&gt; \u2192 Role Mappings \u2192 Assign role\n\n# Or via kcadm.sh\ndocker exec hw-keycloak /opt/keycloak/bin/kcadm.sh \\\n  add-roles -r production --uusername user@example.com --rolename admin\n</code></pre></p> </li> <li> <p>Check Handler Role Requirements: <pre><code># Example WebSocket handler\n@pkg_router.register(\n    PkgID.CREATE_AUTHOR,\n    roles=[\"create-author\", \"admin\"]  # Requires BOTH roles\n)\n\n# Example HTTP endpoint\n@router.post(\n    \"/authors\",\n    dependencies=[Depends(require_roles(\"create-author\", \"admin\"))]\n)\n\n# User must have ALL specified roles to access the endpoint\n</code></pre></p> </li> <li> <p>Token Not Decoded Properly: <pre><code># Check token contents\necho \"eyJhbGc...\" | cut -d'.' -f2 | base64 -d | jq\n\n# Verify 'realm_access.roles' field exists\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"deployment/troubleshooting/#slow-response-times","title":"Slow Response Times","text":"<p>Symptoms: - API requests take &gt; 1 second - WebSocket messages delayed - Timeout errors</p> <p>Diagnosis: <pre><code># Check application metrics\ncurl http://localhost:8000/metrics | grep http_request_duration\n\n# Check database query performance\ndocker exec hw-db psql -U prod_user -d fastapi_prod \\\n  -c \"SELECT query, calls, total_time, mean_time FROM pg_stat_statements ORDER BY mean_time DESC LIMIT 10;\"\n\n# Check CPU/memory usage\ndocker stats hw-server hw-db hw-redis\n\n# Check network latency\ndocker exec hw-server ping hw-db\ndocker exec hw-server time nc -zv hw-db 5432\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Database Query Optimization: <pre><code>-- Enable pg_stat_statements\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n\n-- Find slow queries\nSELECT query, calls, total_time, mean_time\nFROM pg_stat_statements\nORDER BY mean_time DESC\nLIMIT 10;\n\n-- Add indexes\nCREATE INDEX idx_author_name ON author(name);\nCREATE INDEX idx_book_author_id ON book(author_id);\n</code></pre></p> </li> <li> <p>Increase Connection Pool: <pre><code># In .env.production\nDB_POOL_SIZE=30  # Increase from 20\nDB_MAX_OVERFLOW=20  # Increase from 10\n\n# Restart application\ndocker-compose restart hw-server\n</code></pre></p> </li> <li> <p>Scale Horizontally: <pre><code># docker-compose.yml\nservices:\n  hw-server:\n    deploy:\n      replicas: 3  # Run 3 instances\n</code></pre></p> </li> <li> <p>Enable Caching: <pre><code># Add Redis caching for expensive queries\nfrom app.storage.redis import RRedis\n\nasync def get_popular_authors():\n    cache_key = \"popular_authors\"\n    cached = await redis.get(cache_key)\n    if cached:\n        return json.loads(cached)\n\n    authors = await fetch_from_db()\n    await redis.setex(cache_key, 300, json.dumps(authors))\n    return authors\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptoms: - OOM (Out of Memory) errors - Container restarts - Memory usage &gt; 90%</p> <p>Diagnosis: <pre><code># Check memory usage\ndocker stats hw-server --no-stream\n\n# Check container memory limit\ndocker inspect hw-server | jq '.[0].HostConfig.Memory'\n\n# Check Python memory usage\ndocker exec hw-server python -c \"import psutil; print(psutil.virtual_memory())\"\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Increase Memory Limit: <pre><code># docker-compose.yml\nservices:\n  hw-server:\n    deploy:\n      resources:\n        limits:\n          memory: 4G  # Increase from 2G\n</code></pre></p> </li> <li> <p>Check for Memory Leaks: <pre><code># Use memory profiler\nfrom memory_profiler import profile\n\n@profile\ndef problematic_function():\n    ...\n\n# Run and check output\ndocker exec hw-server python -m memory_profiler app.py\n</code></pre></p> </li> <li> <p>Reduce Workers: <pre><code># CMD in Dockerfile or docker-compose command\nCMD [\"uvicorn\", \"app:application\", \"--workers\", \"2\"]  # Reduce from 4\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#database-problems","title":"Database Problems","text":""},{"location":"deployment/troubleshooting/#cannot-connect-to-database","title":"Cannot Connect to Database","text":"<p>Symptoms: - \"could not connect to server\" errors - \"FATAL: password authentication failed\" - \"database does not exist\"</p> <p>Diagnosis: <pre><code># Check PostgreSQL is running\ndocker ps | grep hw-db\n\n# Check PostgreSQL logs\ndocker logs hw-db | tail -50\n\n# Test connection from application container\ndocker exec hw-server psql -h hw-db -U prod_user -d fastapi_prod -c \"SELECT 1;\"\n\n# Check connection string\ndocker exec hw-server printenv DATABASE_URL\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Database Not Ready: <pre><code># Wait for database to be healthy\ndocker-compose -f docker/docker-compose.yml up -d hw-db\n\n# Check health status\ndocker inspect hw-db --format='{{.State.Health.Status}}'\n\n# Wait and retry\nsleep 10\ndocker-compose restart hw-server\n</code></pre></p> </li> <li> <p>Wrong Credentials: <pre><code># Verify credentials match\n# .env.production: DATABASE_URL=postgresql://prod_user:PASSWORD@hw-db:5432/fastapi_prod\n# docker/.pg_env: POSTGRES_USER=prod_user, POSTGRES_PASSWORD=PASSWORD\n\n# Reset password if needed\ndocker exec hw-db psql -U postgres \\\n  -c \"ALTER USER prod_user WITH PASSWORD 'new_password';\"\n</code></pre></p> </li> <li> <p>Database Does Not Exist: <pre><code># Create database\ndocker exec hw-db psql -U postgres -c \"CREATE DATABASE fastapi_prod;\"\n\n# Or recreate database container\ndocker-compose down hw-db\ndocker volume rm postgres-hw-data\ndocker-compose up -d hw-db\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#database-locksdeadlocks","title":"Database Locks/Deadlocks","text":"<p>Symptoms: - \"deadlock detected\" errors - Queries hanging indefinitely - \"could not obtain lock\" errors</p> <p>Diagnosis: <pre><code>-- Check active locks\nSELECT locktype, relation::regclass, mode, granted, pid\nFROM pg_locks\nWHERE NOT granted;\n\n-- Check blocking queries\nSELECT blocked_locks.pid AS blocked_pid,\n       blocked_activity.usename AS blocked_user,\n       blocking_locks.pid AS blocking_pid,\n       blocking_activity.usename AS blocking_user,\n       blocked_activity.query AS blocked_statement,\n       blocking_activity.query AS blocking_statement\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Kill Blocking Query: <pre><code>-- Terminate blocking process\nSELECT pg_terminate_backend(&lt;blocking_pid&gt;);\n</code></pre></p> </li> <li> <p>Prevent Long Transactions: <pre><code># Use short-lived transactions\nasync with async_session() as session:\n    async with session.begin():\n        # Keep transaction scope small\n        await session.execute(stmt)\n        # Don't do expensive operations here\n</code></pre></p> </li> <li> <p>Set Statement Timeout: <pre><code>-- Set timeout for long-running queries\nALTER DATABASE fastapi_prod SET statement_timeout = '30s';\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#redis-issues","title":"Redis Issues","text":""},{"location":"deployment/troubleshooting/#cannot-connect-to-redis","title":"Cannot Connect to Redis","text":"<p>Symptoms: - \"Connection refused\" errors - \"NOAUTH Authentication required\" - Rate limiting not working</p> <p>Diagnosis: <pre><code># Check Redis is running\ndocker ps | grep hw-redis\n\n# Test connection\ndocker exec hw-redis redis-cli ping\n\n# Test from application container\ndocker exec hw-server redis-cli -h hw-redis ping\n\n# Check Redis logs\ndocker logs hw-redis | tail -50\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Redis Not Running: <pre><code># Restart Redis\ndocker-compose restart hw-redis\n\n# Check health\ndocker exec hw-redis redis-cli ping\n</code></pre></p> </li> <li> <p>Authentication Required: <pre><code># Check if Redis requires password\ndocker exec hw-redis redis-cli CONFIG GET requirepass\n\n# If yes, ensure REDIS_PASSWORD is set in .env.production\nREDIS_PASSWORD=your_redis_password\n\n# Test with password\ndocker exec hw-redis redis-cli -a your_redis_password ping\n</code></pre></p> </li> <li> <p>Wrong Redis DB: <pre><code># Check which DB application is using\ndocker exec hw-server printenv | grep REDIS\n\n# Should be:\n# MAIN_REDIS_DB=0\n# AUTH_REDIS_DB=1\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#redis-memory-issues","title":"Redis Memory Issues","text":"<p>Symptoms: - \"OOM command not allowed\" errors - Redis crashes - High memory usage</p> <p>Diagnosis: <pre><code># Check Redis memory usage\ndocker exec hw-redis redis-cli INFO memory\n\n# Check max memory setting\ndocker exec hw-redis redis-cli CONFIG GET maxmemory\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Increase Max Memory: <pre><code># docker/redis/redis.conf\nmaxmemory 2gb\n\n# Or set at runtime\ndocker exec hw-redis redis-cli CONFIG SET maxmemory 2gb\n\n# Restart Redis\ndocker-compose restart hw-redis\n</code></pre></p> </li> <li> <p>Configure Eviction Policy: <pre><code># docker/redis/redis.conf\nmaxmemory-policy allkeys-lru  # Evict least recently used keys\n\n# Or set at runtime\ndocker exec hw-redis redis-cli CONFIG SET maxmemory-policy allkeys-lru\n</code></pre></p> </li> <li> <p>Clear Unused Keys: <pre><code># Find keys by pattern\ndocker exec hw-redis redis-cli KEYS \"rate_limit:*\"\n\n# Clear old keys (be careful!)\ndocker exec hw-redis redis-cli FLUSHDB\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#traefik-routing","title":"Traefik Routing","text":""},{"location":"deployment/troubleshooting/#404-not-found-errors","title":"404 Not Found Errors","text":"<p>Symptoms: - Traefik returns 404 for valid endpoints - \"Service not found\" errors</p> <p>Diagnosis: <pre><code># Check Traefik dashboard\ncurl http://localhost:8080/api/http/routers | jq\n\n# Check container labels\ndocker inspect hw-server | jq '.[0].Config.Labels'\n\n# Check Traefik logs\ndocker logs hw-traefik | grep -i error\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Missing Labels: <pre><code># docker-compose.yml\nservices:\n  hw-server:\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.fastapi.rule=Host(`api.example.com`)\"\n      - \"traefik.http.routers.fastapi.entrypoints=websecure\"\n      - \"traefik.http.services.fastapi.loadbalancer.server.port=8000\"\n</code></pre></p> </li> <li> <p>Restart Traefik: <pre><code>docker-compose restart hw-traefik\n\n# Verify routing rules\ncurl http://localhost:8080/api/http/routers\n</code></pre></p> </li> <li> <p>Check Service Discovery: <pre><code># Ensure service is on same network as Traefik\ndocker network inspect hw-network | jq '.[0].Containers'\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#ssltls-redirect-loop","title":"SSL/TLS Redirect Loop","text":"<p>Symptoms: - Browser shows \"too many redirects\" - Infinite redirect between HTTP and HTTPS</p> <p>Solutions:</p> <pre><code># docker-compose.yml - Ensure Traefik knows it's behind a proxy\nservices:\n  hw-server:\n    labels:\n      - \"traefik.http.middlewares.secure-headers.headers.sslproxyheaders.X-Forwarded-Proto=https\"\n      - \"traefik.http.routers.fastapi.middlewares=secure-headers\"\n</code></pre>"},{"location":"deployment/troubleshooting/#docker-container-issues","title":"Docker Container Issues","text":""},{"location":"deployment/troubleshooting/#container-keeps-restarting","title":"Container Keeps Restarting","text":"<p>Symptoms: - Container in restart loop - <code>docker ps</code> shows \"Restarting\" status</p> <p>Diagnosis: <pre><code># Check restart count\ndocker inspect hw-server | jq '.[0].RestartCount'\n\n# Check last exit code\ndocker inspect hw-server | jq '.[0].State.ExitCode'\n\n# View all logs (before restart)\ndocker logs hw-server --timestamps\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Application Crash: <pre><code># Check for Python exceptions\ndocker logs hw-server | grep -i \"exception\\|error\\|traceback\"\n\n# Run container interactively to debug\ndocker run -it --rm --entrypoint /bin/bash hw-server\n</code></pre></p> </li> <li> <p>Health Check Failing: <pre><code># Test health check manually\ndocker exec hw-server curl -f http://localhost:8000/health\n\n# Adjust health check parameters\n# In Dockerfile:\nHEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=5 \\\n  CMD curl -f http://localhost:8000/health || exit 1\n</code></pre></p> </li> <li> <p>Resource Limits: <pre><code># Check if hitting resource limits\ndocker stats hw-server --no-stream\n\n# Increase limits in docker-compose.yml\ndeploy:\n  resources:\n    limits:\n      cpus: '4'\n      memory: 4G\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#volume-permission-issues","title":"Volume Permission Issues","text":"<p>Symptoms: - \"Permission denied\" errors when writing files - Cannot create directories</p> <p>Solutions:</p> <pre><code># Fix volume ownership\ndocker exec --user root hw-server chown -R appuser:appuser /app\n\n# Or set ownership on host\nsudo chown -R 1000:1000 /path/to/volume\n\n# Ensure user ID matches\ndocker exec hw-server id\n# uid=1000(appuser) gid=1000(appuser)\n</code></pre>"},{"location":"deployment/troubleshooting/#websocket-connection-problems","title":"WebSocket Connection Problems","text":""},{"location":"deployment/troubleshooting/#websocket-connection-rejected","title":"WebSocket Connection Rejected","text":"<p>Symptoms: - \"Connection closed: 1006\" - \"Connection closed: 1008 (policy violation)\" - Cannot establish WebSocket connection</p> <p>Diagnosis: <pre><code># Check application logs\ndocker logs hw-server | grep -i websocket\n\n# Test WebSocket connection\nwscat -c ws://localhost:8000/web?access_token=TOKEN\n\n# Check Traefik WebSocket configuration\ncurl http://localhost:8080/api/http/routers | jq '.[] | select(.name==\"fastapi\")'\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Missing Access Token: <pre><code># WebSocket requires token in query string\nwscat -c \"ws://localhost:8000/web?access_token=YOUR_JWT_TOKEN\"\n</code></pre></p> </li> <li> <p>Connection Limit Reached: <pre><code># Check active connections in Redis\ndocker exec hw-redis redis-cli SCARD \"ws_connections:user123\"\n\n# Increase limit in .env.production\nWS_MAX_CONNECTIONS_PER_USER=10  # Increase from 5\n\n# Restart application\ndocker-compose restart hw-server\n</code></pre></p> </li> <li> <p>Traefik Not Forwarding WebSocket: <pre><code># docker-compose.yml\nservices:\n  hw-server:\n    labels:\n      # Ensure WebSocket headers are preserved\n      - \"traefik.http.routers.fastapi.rule=Host(`api.example.com`)\"\n      # Traefik v3 handles WebSocket automatically, but verify:\n      - \"traefik.http.services.fastapi.loadbalancer.passhostheader=true\"\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#websocket-messages-not-received","title":"WebSocket Messages Not Received","text":"<p>Symptoms: - Messages sent but no response - Connection stays open but silent</p> <p>Diagnosis: <pre><code># Check application logs for message processing\ndocker logs hw-server | grep \"pkg_id\\|req_id\"\n\n# Check rate limiting\ndocker logs hw-server | grep \"rate limit\"\n\n# Test with wscat\nwscat -c \"ws://localhost:8000/web?access_token=TOKEN\"\n&gt; {\"pkg_id\": 1, \"req_id\": \"test-123\", \"data\": {}}\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Invalid Message Format: <pre><code>// Correct format\n{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"data\": {}\n}\n</code></pre></p> </li> <li> <p>Handler Not Registered: <pre><code># Check registered handlers\nmake ws-handlers\n\n# Or check logs at startup\ndocker logs hw-server | grep \"Registered handler\"\n</code></pre></p> </li> <li> <p>Rate Limit Hit: <pre><code># Check rate limit settings\ndocker exec hw-server printenv WS_MESSAGE_RATE_LIMIT\n\n# Increase if needed\nWS_MESSAGE_RATE_LIMIT=200  # In .env.production\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#rate-limiting-issues","title":"Rate Limiting Issues","text":""},{"location":"deployment/troubleshooting/#false-positive-rate-limits","title":"False Positive Rate Limits","text":"<p>Symptoms: - Users getting 429 errors incorrectly - Rate limit triggers too quickly</p> <p>Diagnosis: <pre><code># Check rate limit settings\ndocker exec hw-server printenv | grep RATE_LIMIT\n\n# Check Redis rate limit keys\ndocker exec hw-redis redis-cli KEYS \"rate_limit:*\"\n\n# Check specific user's rate limit\ndocker exec hw-redis redis-cli GET \"rate_limit:user:user123\"\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Increase Rate Limits: <pre><code># .env.production\nRATE_LIMIT_PER_MINUTE=120  # Increase from 60\nRATE_LIMIT_BURST=20  # Increase from 10\nWS_MESSAGE_RATE_LIMIT=200  # Increase from 100\n\n# Restart application\ndocker-compose restart hw-server\n</code></pre></p> </li> <li> <p>Clear Rate Limit Keys: <pre><code># Clear specific user\ndocker exec hw-redis redis-cli DEL \"rate_limit:user:user123\"\n\n# Clear all rate limit keys (careful!)\ndocker exec hw-redis redis-cli KEYS \"rate_limit:*\" | \\\n  xargs docker exec hw-redis redis-cli DEL\n</code></pre></p> </li> <li> <p>Exclude Specific Endpoints: <pre><code># app/middlewares/rate_limit.py\nEXCLUDED_PATHS = [\n    r\"^/health$\",\n    r\"^/metrics$\",\n    r\"^/docs$\",\n    r\"^/internal/.*\",  # Add internal endpoints\n]\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#log-analysis","title":"Log Analysis","text":""},{"location":"deployment/troubleshooting/#finding-errors-in-logs","title":"Finding Errors in Logs","text":"<p>Common LogQL Queries:</p> <pre><code># Recent errors\n{service=\"shell\"} | json | level=\"ERROR\"\n\n# Authentication failures\n{service=\"shell\"} | json | logger=~\"app.auth.*\" |~ \"(?i)(failed|invalid|denied)\"\n\n# Database errors\n{service=\"shell\"} | json |~ \"(?i)(database|postgres|sqlalchemy)\" | level=\"ERROR\"\n\n# Slow queries (requires duration_ms field)\n{service=\"shell\"} | json | duration_ms &gt; 1000\n\n# WebSocket errors\n{service=\"shell\"} | json | logger=~\"app.api.ws.*\" | level=\"ERROR\"\n\n# Rate limit violations\n{service=\"shell\"} | json |~ \"(?i)(rate limit|429|too many requests)\"\n\n# Specific user activity\n{service=\"shell\"} | json | user_id=\"user123\"\n\n# Specific endpoint\n{service=\"shell\"} | json | endpoint=~\"/api/authors.*\"\n</code></pre>"},{"location":"deployment/troubleshooting/#analyzing-performance-issues","title":"Analyzing Performance Issues","text":"<pre><code># HTTP request duration\n{service=\"shell\"} | json | logfmt | line_format \"{{.method}} {{.endpoint}} {{.duration_ms}}ms\"\n\n# Database query performance\n{service=\"shell\"} | json |~ \"(?i)query\" | line_format \"{{.message}} {{.duration_ms}}ms\"\n\n# Top error messages\n{service=\"shell\"} | json | level=\"ERROR\" | line_format \"{{.message}}\" | count by message\n</code></pre>"},{"location":"deployment/troubleshooting/#emergency-procedures","title":"Emergency Procedures","text":""},{"location":"deployment/troubleshooting/#application-down","title":"Application Down","text":"<p>Immediate Actions:</p> <ol> <li> <p>Check service health: <pre><code>docker ps | grep hw-\ncurl http://localhost:8000/health\n</code></pre></p> </li> <li> <p>Restart failed services: <pre><code>docker-compose -f docker/docker-compose.yml restart hw-server\n</code></pre></p> </li> <li> <p>Check recent logs: <pre><code>docker logs hw-server --tail 100\ndocker logs hw-traefik --tail 100\n</code></pre></p> </li> <li> <p>If restart fails, rollback: <pre><code>git log --oneline -5\ngit checkout &lt;previous-working-commit&gt;\ndocker-compose down\ndocker-compose up -d\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#database-corruption","title":"Database Corruption","text":"<p>Immediate Actions:</p> <ol> <li> <p>Stop application: <pre><code>docker-compose stop hw-server\n</code></pre></p> </li> <li> <p>Check database integrity: <pre><code>docker exec hw-db pg_dump -U prod_user fastapi_prod &gt; emergency_backup.sql\n</code></pre></p> </li> <li> <p>Restore from backup: <pre><code>docker exec hw-db psql -U postgres -c \"DROP DATABASE fastapi_prod;\"\ndocker exec hw-db psql -U postgres -c \"CREATE DATABASE fastapi_prod;\"\ndocker exec -i hw-db psql -U prod_user fastapi_prod &lt; latest_backup.sql\n</code></pre></p> </li> <li> <p>Restart application: <pre><code>docker-compose start hw-server\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#security-incident","title":"Security Incident","text":"<p>Immediate Actions:</p> <ol> <li> <p>Isolate affected services: <pre><code># Disconnect from network\ndocker network disconnect hw-network hw-server\n</code></pre></p> </li> <li> <p>Review audit logs: <pre><code>docker logs hw-server | grep -i \"suspicious\\|attack\\|unauthorized\"\n</code></pre></p> </li> <li> <p>Block malicious IPs (if applicable): <pre><code>sudo ufw deny from &lt;malicious-ip&gt;\n</code></pre></p> </li> <li> <p>Rotate credentials: <pre><code># Generate new secrets\nopenssl rand -hex 32\n\n# Update .env.production\n# Restart services\ndocker-compose restart\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#complete-system-failure","title":"Complete System Failure","text":"<p>Recovery Steps:</p> <ol> <li> <p>Document current state: <pre><code>docker ps -a &gt; system_state.txt\ndocker logs hw-server &gt; logs_server.txt\ndocker logs hw-db &gt; logs_db.txt\n</code></pre></p> </li> <li> <p>Stop all services: <pre><code>docker-compose -f docker/docker-compose.yml down\n</code></pre></p> </li> <li> <p>Restore from backups: <pre><code># Restore database\ndocker volume rm postgres-hw-data\ndocker volume create postgres-hw-data\ndocker-compose up -d hw-db\ndocker exec -i hw-db psql -U prod_user fastapi_prod &lt; backup.sql\n\n# Restore Redis data if needed\ndocker volume rm redis-hw-data\ndocker volume create redis-hw-data\n</code></pre></p> </li> <li> <p>Start services gradually: <pre><code>docker-compose up -d hw-db hw-redis\nsleep 10\ndocker-compose up -d hw-keycloak\nsleep 10\ndocker-compose up -d hw-server\ndocker-compose up -d hw-traefik\n</code></pre></p> </li> <li> <p>Verify system health: <pre><code>curl http://localhost:8000/health\ndocker ps\ndocker-compose logs --tail 50\n</code></pre></p> </li> </ol>"},{"location":"deployment/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If issues persist after trying these solutions:</p> <ol> <li>Check application logs in Grafana:</li> <li>http://localhost:3000/d/application-logs</li> <li> <p>Filter by service, level, endpoint</p> </li> <li> <p>Review metrics in Prometheus:</p> </li> <li>http://localhost:9090</li> <li> <p>Check for anomalies</p> </li> <li> <p>Consult documentation:</p> </li> <li>Monitoring Guide</li> <li>Backup/Recovery Guide</li> <li> <p>Security Guide</p> </li> <li> <p>Contact support:</p> </li> <li>GitHub Issues: https://github.com/acikabubo/fastapi-http-websocket/issues</li> <li>Internal documentation: Confluence/Wiki</li> <li>On-call rotation: PagerDuty</li> </ol>"},{"location":"deployment/troubleshooting/#additional-resources","title":"Additional Resources","text":"<ul> <li>Docker Documentation</li> <li>PostgreSQL Troubleshooting</li> <li>Redis Troubleshooting</li> <li>Traefik Documentation</li> <li>FastAPI Documentation</li> </ul>"},{"location":"development/","title":"Development","text":"<p>Resources for developers contributing to the project.</p>"},{"location":"development/#development-guides","title":"Development Guides","text":"<ul> <li>Setup - Development environment setup</li> <li>Testing - Writing and running tests</li> <li>Database Migrations - Managing database schema</li> <li>Code Quality - Linting, formatting, and best practices</li> <li>Contributing - Contribution guidelines</li> </ul>"},{"location":"development/#quick-commands","title":"Quick Commands","text":"<p>```bash</p>"},{"location":"development/#run-tests","title":"Run tests","text":"<p>make test</p>"},{"location":"development/#start-development-server","title":"Start development server","text":"<p>make serve</p>"},{"location":"development/#run-linter","title":"Run linter","text":"<p>make ruff-check</p>"},{"location":"development/#create-migration","title":"Create migration","text":"<p>make migration msg=\"add new field\" ```</p>"},{"location":"development/code-quality/","title":"Code Quality","text":""},{"location":"development/code-quality/#overview","title":"Overview","text":"<p>The project maintains high code quality standards through automated tools and pre-commit hooks.</p>"},{"location":"development/code-quality/#code-style","title":"Code Style","text":""},{"location":"development/code-quality/#line-length","title":"Line Length","text":"<p>79 characters maximum (enforced by Ruff)</p>"},{"location":"development/code-quality/#formatting","title":"Formatting","text":"<pre><code># Format code\nuvx ruff format\n\n# Check formatting\nuvx ruff check --config=pyproject.toml\n</code></pre>"},{"location":"development/code-quality/#type-hints","title":"Type Hints","text":"<p>Required on all functions (enforced by mypy --strict):</p> <pre><code>def get_author(author_id: int) -&gt; Author | None:\n    \"\"\"Get author by ID.\"\"\"\n    pass\n</code></pre>"},{"location":"development/code-quality/#docstrings","title":"Docstrings","text":"<p>Required on all public functions, classes, and methods (80% coverage minimum):</p> <pre><code>def create_author(name: str) -&gt; Author:\n    \"\"\"\n    Create a new author.\n\n    Args:\n        name: Author's full name\n\n    Returns:\n        Created author instance\n\n    Raises:\n        ValueError: If name is empty\n    \"\"\"\n    pass\n</code></pre>"},{"location":"development/code-quality/#linting","title":"Linting","text":""},{"location":"development/code-quality/#ruff","title":"Ruff","text":"<pre><code># Check all files\nmake ruff-check\n\n# Auto-fix issues\nuvx ruff check --fix\n</code></pre>"},{"location":"development/code-quality/#mypy","title":"Mypy","text":"<pre><code># Type check\nuvx mypy app/\n</code></pre>"},{"location":"development/code-quality/#interrogate","title":"Interrogate","text":"<pre><code># Check docstring coverage\nuvx interrogate app/\n</code></pre>"},{"location":"development/code-quality/#security","title":"Security","text":""},{"location":"development/code-quality/#bandit","title":"Bandit","text":"<pre><code># SAST scanning\nmake bandit-scan\n</code></pre>"},{"location":"development/code-quality/#skjold","title":"Skjold","text":"<pre><code># Dependency vulnerability scanning\nmake skjold-scan\n</code></pre>"},{"location":"development/code-quality/#dead-code-detection","title":"Dead Code Detection","text":"<pre><code># Find unused code\nmake dead-code-scan\n</code></pre>"},{"location":"development/code-quality/#spell-checking","title":"Spell Checking","text":"<pre><code># Check typos\nuvx typos\n</code></pre>"},{"location":"development/code-quality/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>All checks run automatically on commit:</p> <pre><code># Install hooks\npre-commit install\n\n# Run manually\npre-commit run --all-files\n</code></pre>"},{"location":"development/code-quality/#related","title":"Related","text":"<ul> <li>Testing Guide</li> <li>Contributing Guide</li> </ul>"},{"location":"development/contributing/","title":"Contributing Guide","text":""},{"location":"development/contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository</li> <li>Clone your fork</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Run tests and linting</li> <li>Submit a pull request</li> </ol>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#1-create-feature-branch","title":"1. Create Feature Branch","text":"<pre><code>git checkout -b feature/my-new-feature develop\n</code></pre>"},{"location":"development/contributing/#2-make-changes","title":"2. Make Changes","text":"<p>Follow Code Quality guidelines.</p>"},{"location":"development/contributing/#3-run-tests","title":"3. Run Tests","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=app --cov-report=html\n</code></pre>"},{"location":"development/contributing/#4-commit-changes","title":"4. Commit Changes","text":"<pre><code>git add .\ngit commit -m \"feat: Add new feature\"\n</code></pre> <p>Use conventional commit format: - <code>feat:</code> - New feature - <code>fix:</code> - Bug fix - <code>docs:</code> - Documentation changes - <code>refactor:</code> - Code refactoring - <code>test:</code> - Test changes</p>"},{"location":"development/contributing/#5-push-and-create-pr","title":"5. Push and Create PR","text":"<pre><code>git push origin feature/my-new-feature\n</code></pre> <p>Then create a pull request on GitHub.</p>"},{"location":"development/contributing/#code-review","title":"Code Review","text":"<p>Pull requests require: - \u2705 All tests passing - \u2705 Code coverage maintained - \u2705 Linting checks passing - \u2705 Documentation updated - \u2705 Reviewer approval</p>"},{"location":"development/contributing/#related","title":"Related","text":"<ul> <li>Testing Guide</li> <li>Code Quality</li> </ul>"},{"location":"development/migrations/","title":"Database Migrations with Alembic","text":"<p>This project uses Alembic for database schema migrations. Alembic provides version control for your database schema, allowing safe evolution of the database structure over time.</p>"},{"location":"development/migrations/#overview","title":"Overview","text":"<p>Previous approach: The project previously used <code>SQLModel.metadata.create_all()</code> which had limitations: - \u274c No migration history or rollback capability - \u274c Cannot safely modify existing tables - \u274c Risk of data loss when changing schemas - \u274c No team synchronization for schema changes</p> <p>Current approach: Alembic migrations provide: - \u2705 Version-controlled migration history - \u2705 Safe schema evolution without data loss - \u2705 Rollback support for failed migrations - \u2705 Automatic migration generation from model changes - \u2705 Team synchronization (everyone applies same migrations) - \u2705 Production-safe deployment workflow</p>"},{"location":"development/migrations/#quick-start","title":"Quick Start","text":""},{"location":"development/migrations/#applying-migrations","title":"Applying Migrations","text":"<p>Apply all pending migrations to bring your database up to date:</p> <pre><code>make migrate\n</code></pre> <p>This runs <code>alembic upgrade head</code> and applies all migrations that haven't been applied yet.</p>"},{"location":"development/migrations/#creating-new-migrations","title":"Creating New Migrations","text":"<p>When you modify a SQLModel (add/remove/modify fields), generate a new migration:</p> <pre><code>make migration msg=\"Add email field to Author\"\n</code></pre> <p>This will: 1. Auto-detect changes between your models and current database schema 2. Generate a new migration file in <code>app/storage/migrations/versions/</code> 3. Create both <code>upgrade()</code> and <code>downgrade()</code> functions</p> <p>Important: Always review the generated migration before applying it!</p>"},{"location":"development/migrations/#viewing-migration-status","title":"Viewing Migration Status","text":"<p>Check which migration is currently applied:</p> <pre><code>make migration-current\n</code></pre> <p>View full migration history:</p> <pre><code>make migration-history\n</code></pre>"},{"location":"development/migrations/#rolling-back-migrations","title":"Rolling Back Migrations","text":"<p>Roll back the most recent migration:</p> <pre><code>make rollback\n</code></pre> <p>This runs <code>alembic downgrade -1</code> to revert the last migration.</p>"},{"location":"development/migrations/#migration-workflow","title":"Migration Workflow","text":""},{"location":"development/migrations/#1-modify-your-model","title":"1. Modify Your Model","text":"<p>Edit a model file (e.g., <code>app/models/author.py</code>):</p> <pre><code>class Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    email: str | None = None  # NEW FIELD\n</code></pre>"},{"location":"development/migrations/#2-generate-migration","title":"2. Generate Migration","text":"<pre><code>make migration msg=\"Add email field to Author\"\n</code></pre>"},{"location":"development/migrations/#3-review-generated-migration","title":"3. Review Generated Migration","text":"<p>Check the generated file in <code>app/storage/migrations/versions/</code>:</p> <pre><code>def upgrade() -&gt; None:\n    # ### commands auto generated by Alembic ###\n    op.add_column('author', sa.Column('email', sa.String(), nullable=True))\n    # ### end Alembic commands ###\n\n\ndef downgrade() -&gt; None:\n    # ### commands auto generated by Alembic ###\n    op.drop_column('author', 'email')\n    # ### end Alembic commands ###\n</code></pre> <p>Important checks: - Verify the operations match your intent - Check for data loss risks (e.g., dropping columns) - Ensure nullable constraints are correct - Review default values for new required fields</p>"},{"location":"development/migrations/#4-apply-migration","title":"4. Apply Migration","text":"<pre><code>make migrate\n</code></pre>"},{"location":"development/migrations/#5-if-issues-occur-rollback","title":"5. If Issues Occur, Rollback","text":"<pre><code>make rollback\n</code></pre>"},{"location":"development/migrations/#advanced-usage","title":"Advanced Usage","text":""},{"location":"development/migrations/#manual-migration-creation","title":"Manual Migration Creation","text":"<p>For complex migrations that can't be auto-generated:</p> <pre><code>uv run alembic revision -m \"Custom migration description\"\n</code></pre> <p>Then manually edit the generated file to add your custom operations.</p>"},{"location":"development/migrations/#downgrade-to-specific-version","title":"Downgrade to Specific Version","text":"<pre><code>uv run alembic downgrade &lt;revision_id&gt;\n</code></pre>"},{"location":"development/migrations/#upgrade-to-specific-version","title":"Upgrade to Specific Version","text":"<pre><code>uv run alembic upgrade &lt;revision_id&gt;\n</code></pre>"},{"location":"development/migrations/#stamp-database-without-running-migrations","title":"Stamp Database Without Running Migrations","text":"<p>If you have an existing database that matches a specific migration:</p> <pre><code>make migration-stamp rev=\"&lt;revision_id&gt;\"\n</code></pre> <p>Or stamp to the latest:</p> <pre><code>make migration-stamp rev=\"head\"\n</code></pre> <p>This is useful when: - Migrating from the old <code>create_all()</code> approach to Alembic - Setting up a database that was manually created - Recovering from migration issues</p>"},{"location":"development/migrations/#initial-setup-for-new-developers","title":"Initial Setup (For New Developers)","text":"<ol> <li>Clone the repository</li> <li>Start services: <pre><code>make start  # Starts PostgreSQL, Redis, Keycloak, etc.\n</code></pre></li> <li>Apply migrations: <pre><code>make migrate\n</code></pre></li> </ol> <p>That's it! Your database schema is now up to date.</p>"},{"location":"development/migrations/#production-deployment","title":"Production Deployment","text":""},{"location":"development/migrations/#safe-deployment-process","title":"Safe Deployment Process","text":"<ol> <li> <p>Test migrations locally: <pre><code>make migrate\n</code></pre></p> </li> <li> <p>Review migration on staging environment</p> </li> <li> <p>Backup production database before applying migrations</p> </li> <li> <p>Apply migrations during maintenance window: <pre><code>make migrate\n</code></pre></p> </li> <li> <p>Verify application functionality</p> </li> <li> <p>If issues occur: <pre><code>make rollback\n</code></pre></p> </li> </ol>"},{"location":"development/migrations/#zero-downtime-migrations","title":"Zero-Downtime Migrations","text":"<p>For zero-downtime deployments, follow this pattern:</p> <p>Phase 1: Add new column (nullable) <pre><code># Migration 1: Add nullable column\nemail: str | None = None\n</code></pre></p> <p>Phase 2: Backfill data <pre><code># Migration 2: Populate email field\ndef upgrade():\n    # Custom data migration\n    op.execute(\"UPDATE author SET email = name || '@example.com'\")\n</code></pre></p> <p>Phase 3: Make non-nullable (if needed) <pre><code># Migration 3: Add NOT NULL constraint\ndef upgrade():\n    op.alter_column('author', 'email', nullable=False)\n</code></pre></p>"},{"location":"development/migrations/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/migrations/#target-database-is-not-up-to-date","title":"\"Target database is not up to date\"","text":"<pre><code># Check current version\nmake migration-current\n\n# Apply pending migrations\nmake migrate\n</code></pre>"},{"location":"development/migrations/#cant-locate-revision-identified-by-xyz","title":"\"Can't locate revision identified by 'xyz'\"","text":"<p>The migration file might have been deleted. Check <code>app/storage/migrations/versions/</code> directory.</p>"},{"location":"development/migrations/#failed-multiple-head-revisions-are-present","title":"\"FAILED: Multiple head revisions are present\"","text":"<p>This happens when multiple branches exist in migration history. Merge them:</p> <pre><code>uv run alembic merge heads -m \"Merge migration branches\"\n</code></pre>"},{"location":"development/migrations/#migration-conflicts","title":"Migration Conflicts","text":"<p>If you get conflicts because someone else created a migration:</p> <ol> <li>Pull latest code</li> <li>Regenerate your migration:    <pre><code>rm app/storage/migrations/versions/your_migration.py\nmake migration msg=\"Your description\"\n</code></pre></li> </ol>"},{"location":"development/migrations/#reset-migration-history-development-only","title":"Reset Migration History (Development Only!)","text":"<p>WARNING: This will delete all migration history. Never do this in production!</p> <pre><code># Drop all tables\n# Recreate database\n# Regenerate initial migration\nmake migration msg=\"Initial migration\"\nmake migrate\n</code></pre>"},{"location":"development/migrations/#configuration","title":"Configuration","text":""},{"location":"development/migrations/#database-connection","title":"Database Connection","text":"<p>Alembic automatically uses the database URL from <code>app/settings.py</code>:</p> <pre><code>DATABASE_URL = f\"postgresql+asyncpg://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n</code></pre> <p>This is configured in <code>app/storage/migrations/env.py</code>:</p> <pre><code>config.set_main_option(\"sqlalchemy.url\", app_settings.DATABASE_URL)\n</code></pre>"},{"location":"development/migrations/#adding-new-models","title":"Adding New Models","text":"<p>When you create a new model, import it in <code>app/storage/migrations/env.py</code>:</p> <pre><code>from app.models.author import Author  # noqa: F401\nfrom app.models.book import Book  # noqa: F401  # ADD NEW IMPORTS\n</code></pre> <p>This ensures Alembic can detect the model and generate migrations for it.</p>"},{"location":"development/migrations/#best-practices","title":"Best Practices","text":""},{"location":"development/migrations/#do","title":"\u2705 Do","text":"<ul> <li>Always review generated migrations before applying</li> <li>Test migrations on development/staging before production</li> <li>Backup production database before running migrations</li> <li>Use descriptive migration messages: <code>make migration msg=\"Add user email verification\"</code></li> <li>Keep migrations small and focused on one logical change</li> <li>Commit migration files to version control</li> <li>Add custom data migrations when needed (e.g., backfilling data)</li> </ul>"},{"location":"development/migrations/#dont","title":"\u274c Don't","text":"<ul> <li>Never edit applied migrations - create a new migration instead</li> <li>Never delete migration files that have been applied to production</li> <li>Don't skip reviewing auto-generated migrations</li> <li>Don't make breaking changes without a rollout plan</li> <li>Don't drop columns without checking for data</li> <li>Never use <code>make rollback</code> in production without careful consideration</li> </ul>"},{"location":"development/migrations/#common-operations","title":"Common Operations","text":""},{"location":"development/migrations/#add-a-column","title":"Add a Column","text":"<pre><code># Model change\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    bio: str | None = None  # NEW\n</code></pre> <pre><code>make migration msg=\"Add bio to Author\"\nmake migrate\n</code></pre>"},{"location":"development/migrations/#remove-a-column","title":"Remove a Column","text":"<pre><code># Model change - remove field\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    # bio removed\n</code></pre> <pre><code>make migration msg=\"Remove bio from Author\"\n# Review the migration - it will drop the column!\nmake migrate\n</code></pre>"},{"location":"development/migrations/#rename-a-column","title":"Rename a Column","text":"<p>Alembic can't auto-detect renames (it sees drop + add). Do it manually:</p> <pre><code>def upgrade() -&gt; None:\n    op.alter_column('author', 'name', new_column_name='full_name')\n\ndef downgrade() -&gt; None:\n    op.alter_column('author', 'full_name', new_column_name='name')\n</code></pre>"},{"location":"development/migrations/#change-column-type","title":"Change Column Type","text":"<pre><code># Model change\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str = Field(max_length=200)  # Changed from default\n</code></pre> <pre><code>make migration msg=\"Increase author name length\"\nmake migrate\n</code></pre>"},{"location":"development/migrations/#add-index","title":"Add Index","text":"<pre><code># Model change\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str = Field(index=True)  # Add index\n</code></pre> <pre><code>make migration msg=\"Add index on author name\"\nmake migrate\n</code></pre>"},{"location":"development/migrations/#additional-resources","title":"Additional Resources","text":"<ul> <li>Alembic Documentation</li> <li>SQLModel Documentation</li> <li>Alembic Tutorial</li> <li>Alembic Auto Generate</li> <li>SQLAlchemy Migration Operations</li> </ul>"},{"location":"development/migrations/#support","title":"Support","text":"<p>If you encounter issues with migrations:</p> <ol> <li>Check this documentation</li> <li>Review the Alembic documentation</li> <li>Check migration history: <code>make migration-history</code></li> <li>Verify current version: <code>make migration-current</code></li> <li>Ask the team for help if stuck</li> </ol>"},{"location":"development/mypy-type-ignores/","title":"MyPy Type Ignore Comments - Reference Document","text":"<p>This document tracks all <code># type: ignore</code> comments added during the mypy strict mode migration. These represent cases where mypy's type checker has limitations or where proper typing would require significant refactoring.</p>"},{"location":"development/mypy-type-ignores/#summary-statistics","title":"Summary Statistics","text":"<ul> <li>Starting errors: 211 errors across 84+ files</li> <li>Final non-import errors: 0</li> <li>Total type: ignore comments: 47</li> </ul>"},{"location":"development/mypy-type-ignores/#categories-of-type-ignores","title":"Categories of Type Ignores","text":""},{"location":"development/mypy-type-ignores/#1-third-party-library-subclassing-misc-20-occurrences","title":"1. Third-Party Library Subclassing (misc) - 20 occurrences","text":"<p>These are cases where we subclass from third-party libraries (Pydantic, SQLModel, Starlette) that mypy doesn't fully understand in strict mode.</p> <p>Files affected: - <code>app/models/base.py:13</code> - BaseModel (SQLModel + AsyncAttrs) - <code>app/models/author.py:6</code> - Author model (table=True argument) - <code>app/models/user_action.py:11</code> - UserAction model (SQLModel with table=True) - <code>app/schemas/*.py</code> - All Pydantic BaseModel subclasses (7 files) - <code>app/middlewares/*.py</code> - All BaseHTTPMiddleware subclasses (7 files) - <code>app/api/ws/websocket.py</code> - WebSocket-related classes (2 occurrences) - <code>app/auth.py:45</code> - AuthBackend - <code>app/fields/unix_timestamp.py:22</code> - TypeDecorator</p> <p>Reason: These libraries use metaclasses and dynamic behavior that mypy's type system cannot fully represent.</p> <p>Future fix: These may resolve with updated type stubs from the libraries or when mypy improves metaclass handling.</p>"},{"location":"development/mypy-type-ignores/#2-sqlalchemy-column-attributes-attr-defined-1-occurrence","title":"2. SQLAlchemy Column Attributes (attr-defined) - 1 occurrence","text":"<p>File: <code>app/repositories/author_repository.py:75</code> <pre><code>stmt = select(Author).where(Author.name.ilike(f\"%{name_pattern}%\"))  # type: ignore[attr-defined]\n</code></pre></p> <p>Reason: SQLModel fields appear as <code>str</code> in the class definition but become SQLAlchemy Column objects at runtime with methods like <code>ilike()</code>.</p> <p>Future fix: This is a known limitation of SQLModel's typing. May improve with future SQLModel versions.</p>"},{"location":"development/mypy-type-ignores/#3-untyped-decorators-untyped-decorator-2-occurrences","title":"3. Untyped Decorators (untyped-decorator) - 2 occurrences","text":"<p>Files: - <code>app/settings.py:79</code> - Pydantic's <code>@field_validator</code> - <code>app/api/http/metrics.py:9</code> - FastAPI's <code>@router.get</code></p> <p>Reason: Some decorators from third-party libraries don't have complete type annotations.</p> <p>Future fix: Will resolve when FastAPI and Pydantic provide fully typed decorators.</p>"},{"location":"development/mypy-type-ignores/#4-union-type-narrowing-union-attr-3-occurrences","title":"4. Union Type Narrowing (union-attr) - 3 occurrences","text":"<p>Files: - <code>app/tasks/kc_user_session.py:31</code> - Redis pubsub (returns Any | None) - <code>app/api/http/health.py:76</code> - Redis ping (returns Any | None)</p> <p>Reason: Functions like <code>get_redis_connection()</code> return <code>Redis | None</code>, but we check for None before calling methods. Mypy doesn't track these runtime checks perfectly.</p> <p>Future fix: Could add explicit None checks or use TypeGuard functions for better type narrowing.</p>"},{"location":"development/mypy-type-ignores/#5-assignment-type-mismatches-assignment-5-occurrences","title":"5. Assignment Type Mismatches (assignment) - 5 occurrences","text":"<p>Files: - <code>app/middlewares/rate_limit.py:108</code> - getattr returns Any - <code>app/utils/audit_logger.py:198,201</code> - Recursive dict sanitization - <code>app/routing.py:152</code> - JsonSchemaType union handling</p> <p>Reason: Complex type unions or dynamic attribute access that mypy cannot fully infer.</p> <p>Future fix: Could use more specific type guards or restructure code to avoid dynamic typing.</p>"},{"location":"development/mypy-type-ignores/#6-function-return-values-func-returns-value-1-occurrence","title":"6. Function Return Values (func-returns-value) - 1 occurrence","text":"<p>File: <code>app/auth.py:152</code> <pre><code>token = kc_manager.login(credentials.username, credentials.password)  # type: ignore[func-returns-value]\n</code></pre></p> <p>Reason: KeycloakManager.login() has incorrect type hints in the keycloak library.</p> <p>Future fix: Report to python-keycloak library or override with more specific type stub.</p>"},{"location":"development/mypy-type-ignores/#7-callable-argument-types-arg-type-4-occurrences","title":"7. Callable Argument Types (arg-type) - 4 occurrences","text":"<p>Files: - <code>app/api/http/profiling.py:89</code> - Lambda key function for sort - <code>app/api/http/audit_logs.py:97,178</code> - apply_filters callable signature</p> <p>Reason: Complex callable signatures that mypy cannot fully infer from generic types.</p> <p>Future fix: Could define more specific Protocol types for these callables.</p>"},{"location":"development/mypy-type-ignores/#8-union-attribute-access-call-arg-no-untyped-def-6-occurrences","title":"8. Union Attribute Access (call-arg, no-untyped-def) - 6 occurrences","text":"<p>Files: - <code>app/routing.py:149</code> - Pydantic model_json_schema classmethod - <code>app/schemas/user.py:14</code> - Dynamic **kwargs in init - <code>app/dependencies/permissions.py:15</code> - Variable args in require_roles - <code>app/api/ws/handlers/__init__.py:5</code> - Dynamic handler loading - <code>app/fields/unix_timestamp.py:87</code> - SQLAlchemy column defaults</p> <p>Reason: Dynamic behavior with **kwargs, classmethods, or variable arguments.</p> <p>Future fix: Could add overload signatures or more specific type hints.</p>"},{"location":"development/mypy-type-ignores/#9-dict-key-type-mismatches-misc-2-occurrences","title":"9. Dict Key Type Mismatches (misc) - 2 occurrences","text":"<p>Files: - <code>app/storage/redis.py:146</code> - Dict comprehension with int keys expected to be str - <code>app/schemas/response.py</code> - Generic type parameters</p> <p>Reason: Type system expects str keys in dict but runtime uses int.</p> <p>Future fix: Could use explicit type cast or restructure data to use str keys.</p>"},{"location":"development/mypy-type-ignores/#recommendations-for-future-cleanup","title":"Recommendations for Future Cleanup","text":""},{"location":"development/mypy-type-ignores/#high-priority-easy-to-fix","title":"High Priority (Easy to Fix)","text":"<ol> <li>Union narrowing - Add explicit <code>if x is None: return</code> checks before using optional values</li> <li>Dict key types - Convert int keys to str or use explicit type casts</li> <li>getattr usage - Use hasattr checks or default values with specific types</li> </ol>"},{"location":"development/mypy-type-ignores/#medium-priority-moderate-effort","title":"Medium Priority (Moderate Effort)","text":"<ol> <li>Callable signatures - Define Protocol types for complex callables</li> <li>Dynamic **kwargs - Use TypedDict for structured kwargs</li> <li>KeycloakManager types - Create local type stub file</li> </ol>"},{"location":"development/mypy-type-ignores/#low-priority-library-dependent","title":"Low Priority (Library-Dependent)","text":"<ol> <li>Third-party subclassing - Wait for library type stub improvements</li> <li>Untyped decorators - Will resolve with FastAPI/Pydantic updates</li> <li>SQLAlchemy column attributes - SQLModel typing limitation</li> </ol>"},{"location":"development/mypy-type-ignores/#best-practices-going-forward","title":"Best Practices Going Forward","text":"<ol> <li>Avoid adding new type: ignore comments without documenting the reason</li> <li>Prefer explicit type narrowing over type: ignore when possible</li> <li>Review this file periodically as libraries improve their type hints</li> <li>Test that ignored code paths work correctly since mypy won't catch errors there</li> </ol>"},{"location":"development/mypy-type-ignores/#monitoring","title":"Monitoring","text":"<p>To check for unused type: ignore comments: <pre><code>uvx mypy app/ --warn-unused-ignores\n</code></pre></p> <p>To find all type: ignore comments: <pre><code>grep -rn \"# type: ignore\" app/ | grep -v \".pyc\" | wc -l\n</code></pre></p> <p>Last updated: 2025-12-28 MyPy version: 1.19.1 Python version: 3.13</p>"},{"location":"development/protobuf-testing/","title":"Protocol Buffers WebSocket Testing Guide","text":"<p>This document provides step-by-step instructions for testing the protobuf WebSocket implementation.</p>"},{"location":"development/protobuf-testing/#prerequisites","title":"Prerequisites","text":"<ol> <li>Docker services running: <code>make start</code></li> <li>Valid Keycloak access token</li> <li>Postman or similar WebSocket client</li> </ol>"},{"location":"development/protobuf-testing/#getting-a-valid-access-token","title":"Getting a Valid Access Token","text":""},{"location":"development/protobuf-testing/#option-1-using-keycloak-direct-grant-password-flow","title":"Option 1: Using Keycloak Direct Grant (Password Flow)","text":"<pre><code># Login and get access token\ncurl -X POST \"http://localhost:8080/realms/HW-App/protocol/openid-connect/token\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"client_id=auth-hw-frontend\" \\\n  -d \"username=acika\" \\\n  -d \"password=YOUR_PASSWORD\" \\\n  -d \"grant_type=password\" | jq -r '.access_token'\n</code></pre>"},{"location":"development/protobuf-testing/#option-2-using-python-script","title":"Option 2: Using Python Script","text":"<pre><code>from app.managers.keycloak_manager import KeycloakManager\n\nkc = KeycloakManager()\ntoken_response = kc.login(\"acika\", \"YOUR_PASSWORD\")\naccess_token = token_response[\"access_token\"]\nprint(f\"Token: {access_token}\")\n</code></pre>"},{"location":"development/protobuf-testing/#test-scenarios","title":"Test Scenarios","text":""},{"location":"development/protobuf-testing/#test-1-json-format-default-backwards-compatibility","title":"Test 1: JSON Format (Default - Backwards Compatibility)","text":"<p>WebSocket URL: <pre><code>ws://localhost:8000/web?Authorization=Bearer YOUR_ACCESS_TOKEN\n</code></pre></p> <p>Request Message (JSON): <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"method\": null,\n  \"data\": {\n    \"page\": 1,\n    \"per_page\": 10\n  }\n}\n</code></pre></p> <p>Expected Response (JSON): <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 0,\n  \"data\": [\n    {\n      \"id\": 1,\n      \"name\": \"Author Name\",\n      \"bio\": \"Author bio...\"\n    }\n  ],\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 10,\n    \"total\": 25,\n    \"pages\": 3\n  }\n}\n</code></pre></p>"},{"location":"development/protobuf-testing/#test-2-protobuf-format-new-feature","title":"Test 2: Protobuf Format (New Feature)","text":"<p>WebSocket URL: <pre><code>ws://localhost:8000/web?Authorization=Bearer YOUR_ACCESS_TOKEN&amp;format=protobuf\n</code></pre></p> <p>Python Client Example:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nProtobuf WebSocket client test script.\n\"\"\"\nimport asyncio\nimport json\nimport uuid\nimport websockets\nfrom app.schemas.proto import Request, Response\n\nasync def test_protobuf_websocket():\n    # Replace with your actual token\n    token = \"YOUR_ACCESS_TOKEN\"\n    url = f\"ws://localhost:8000/web?Authorization=Bearer {token}&amp;format=protobuf\"\n\n    async with websockets.connect(url) as websocket:\n        # Create protobuf Request message\n        request = Request()\n        request.pkg_id = 1  # PkgID.GET_AUTHORS\n        request.req_id = str(uuid.uuid4())\n        request.data_json = json.dumps({\n            \"page\": 1,\n            \"per_page\": 10\n        })\n\n        # Serialize and send\n        request_bytes = request.SerializeToString()\n        print(f\"Sending protobuf request ({len(request_bytes)} bytes)\")\n        await websocket.send(request_bytes)\n\n        # Receive and parse response\n        response_bytes = await websocket.recv()\n        print(f\"Received protobuf response ({len(response_bytes)} bytes)\")\n\n        response = Response()\n        response.ParseFromString(response_bytes)\n\n        print(f\"Status Code: {response.status_code}\")\n        print(f\"Package ID: {response.pkg_id}\")\n        print(f\"Request ID: {response.req_id}\")\n\n        if response.data_json:\n            data = json.loads(response.data_json)\n            print(f\"Data: {json.dumps(data, indent=2)}\")\n\n        if response.HasField(\"meta\"):\n            print(f\"Pagination: Page {response.meta.page}/{response.meta.pages}, Total: {response.meta.total}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(test_protobuf_websocket())\n</code></pre> <p>Running the test: <pre><code># From project root\npython examples/clients/websocket_protobuf_client.py\n</code></pre></p>"},{"location":"development/protobuf-testing/#test-3-invalid-format-should-fallback-to-json","title":"Test 3: Invalid Format (Should Fallback to JSON)","text":"<p>WebSocket URL: <pre><code>ws://localhost:8000/web?Authorization=Bearer YOUR_ACCESS_TOKEN&amp;format=invalid\n</code></pre></p> <p>Expected Behavior: - Server logs warning: \"Invalid format 'invalid' specified, defaulting to json\" - Connection uses JSON format - Works exactly like Test 1</p>"},{"location":"development/protobuf-testing/#test-4-protobuf-with-different-pkg_id-values","title":"Test 4: Protobuf with Different pkg_id Values","text":"<p>Test CREATE operation (if available):</p> <pre><code>async def test_create_author():\n    token = \"YOUR_ACCESS_TOKEN\"\n    url = f\"ws://localhost:8000/web?Authorization=Bearer {token}&amp;format=protobuf\"\n\n    async with websockets.connect(url) as websocket:\n        request = Request()\n        request.pkg_id = 2  # PkgID.CREATE_AUTHOR (check actual value)\n        request.req_id = str(uuid.uuid4())\n        request.data_json = json.dumps({\n            \"name\": \"New Author\",\n            \"bio\": \"Test author created via protobuf\"\n        })\n\n        await websocket.send(request.SerializeToString())\n\n        response_bytes = await websocket.recv()\n        response = Response()\n        response.ParseFromString(response_bytes)\n\n        print(f\"Create Result: {response.status_code}\")\n        if response.data_json:\n            print(f\"Created: {response.data_json}\")\n</code></pre>"},{"location":"development/protobuf-testing/#test-5-size-comparison-json-vs-protobuf","title":"Test 5: Size Comparison (JSON vs Protobuf)","text":"<p>Comparative test script:</p> <pre><code>import json\nfrom app.schemas.proto import Request\nfrom app.schemas.request import RequestModel\nfrom uuid import uuid4\nfrom app.api.ws.constants import PkgID\n\n# Create same request in both formats\nreq_id = uuid4()\ndata = {\"page\": 1, \"per_page\": 20}\n\n# JSON format\njson_request = RequestModel(\n    pkg_id=PkgID.GET_AUTHORS,\n    req_id=req_id,\n    data=data\n)\njson_size = len(json.dumps(json_request.model_dump()).encode())\n\n# Protobuf format\nproto_request = Request()\nproto_request.pkg_id = PkgID.GET_AUTHORS.value\nproto_request.req_id = str(req_id)\nproto_request.data_json = json.dumps(data)\nprotobuf_size = len(proto_request.SerializeToString())\n\nprint(f\"JSON size: {json_size} bytes\")\nprint(f\"Protobuf size: {protobuf_size} bytes\")\nprint(f\"Size reduction: {((json_size - protobuf_size) / json_size * 100):.1f}%\")\n</code></pre>"},{"location":"development/protobuf-testing/#testing-with-postman","title":"Testing with Postman","text":""},{"location":"development/protobuf-testing/#setup-for-json-format","title":"Setup for JSON Format","text":"<ol> <li>Create New WebSocket Request</li> <li>Set URL: <code>ws://localhost:8000/web?Authorization=Bearer YOUR_TOKEN</code></li> <li>Connect</li> <li>Send Message: <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"data\": {\"page\": 1, \"per_page\": 10}\n}\n</code></pre></li> </ol>"},{"location":"development/protobuf-testing/#setup-for-protobuf-format","title":"Setup for Protobuf Format","text":"<p>Note: Postman doesn't natively support sending binary protobuf messages. Use Python client or tools like <code>websocat</code> for protobuf testing.</p> <p>Alternative: Use Postman's pre-request script to encode protobuf (requires additional setup).</p>"},{"location":"development/protobuf-testing/#testing-with-websocat-command-line","title":"Testing with websocat (Command Line)","text":""},{"location":"development/protobuf-testing/#json-format","title":"JSON Format:","text":"<pre><code># Install websocat: cargo install websocat or download binary\n\necho '{\"pkg_id\": 1, \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\", \"data\": {\"page\": 1}}' | \\\n  websocat \"ws://localhost:8000/web?Authorization=Bearer YOUR_TOKEN\"\n</code></pre>"},{"location":"development/protobuf-testing/#protobuf-format","title":"Protobuf Format:","text":"<pre><code># Requires pre-encoded protobuf message in a file\nwebsocat --binary \"ws://localhost:8000/web?Authorization=Bearer YOUR_TOKEN&amp;format=protobuf\" &lt; request.pb\n</code></pre>"},{"location":"development/protobuf-testing/#verification-checklist","title":"Verification Checklist","text":"<ul> <li> JSON format works (backwards compatibility)</li> <li> Protobuf format works with <code>?format=protobuf</code></li> <li> Invalid format falls back to JSON with warning in logs</li> <li> Server logs show correct format detection</li> <li> Response format matches request format</li> <li> Protobuf messages are smaller than JSON</li> <li> Both formats produce identical data results</li> <li> Rate limiting works for both formats</li> <li> Authentication works for both formats</li> <li> Audit logs record correct message format</li> </ul>"},{"location":"development/protobuf-testing/#expected-server-logs","title":"Expected Server Logs","text":""},{"location":"development/protobuf-testing/#for-json-request","title":"For JSON Request:","text":"<pre><code>DEBUG - Received JSON request: {'pkg_id': 1, 'req_id': '...', 'data': {...}}\nDEBUG - Successfully sent json response for PkgID.GET_AUTHORS\n</code></pre>"},{"location":"development/protobuf-testing/#for-protobuf-request","title":"For Protobuf Request:","text":"<pre><code>DEBUG - WebSocket connection using format: protobuf\nDEBUG - Received protobuf request: pkg_id=PkgID.GET_AUTHORS\nDEBUG - Successfully sent protobuf response for PkgID.GET_AUTHORS\n</code></pre>"},{"location":"development/protobuf-testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/protobuf-testing/#error-modulenotfounderror-no-module-named-google","title":"Error: \"ModuleNotFoundError: No module named 'google'\"","text":"<p>Solution: Rebuild Docker container with protobuf dependencies: <pre><code>make build\nmake stop &amp;&amp; make start\n</code></pre></p>"},{"location":"development/protobuf-testing/#error-connection-rejected","title":"Error: \"Connection rejected\"","text":"<p>Solution: Check if token is valid and not expired. Get new token.</p>"},{"location":"development/protobuf-testing/#error-permission-denied","title":"Error: \"Permission denied\"","text":"<p>Solution: Ensure user has required roles for the pkg_id being accessed.</p>"},{"location":"development/protobuf-testing/#protobuf-parsing-fails","title":"Protobuf parsing fails","text":"<p>Solution: - Verify <code>format=protobuf</code> query parameter is set - Ensure message is properly serialized binary data - Check protobuf schema matches (run <code>make protobuf-generate</code> if needed)</p>"},{"location":"development/protobuf-testing/#performance-testing","title":"Performance Testing","text":""},{"location":"development/protobuf-testing/#recommended-load-testing-tools","title":"Recommended Load Testing Tools:","text":"<ul> <li>k6 for WebSocket load testing</li> <li>Artillery for continuous load</li> <li>locust for distributed testing</li> </ul>"},{"location":"development/protobuf-testing/#sample-k6-script","title":"Sample k6 Script:","text":"<pre><code>import ws from 'k6/ws';\nimport { check } from 'k6';\n\nexport default function () {\n  const url = 'ws://localhost:8000/web?Authorization=Bearer YOUR_TOKEN&amp;format=protobuf';\n\n  const res = ws.connect(url, function (socket) {\n    socket.on('open', () =&gt; {\n      // Send protobuf binary message\n      socket.sendBinary(protobufMessage);\n    });\n\n    socket.on('message', (data) =&gt; {\n      console.log('Received response:', data);\n      socket.close();\n    });\n  });\n\n  check(res, { 'status is 101': (r) =&gt; r &amp;&amp; r.status === 101 });\n}\n</code></pre>"},{"location":"development/protobuf-testing/#next-steps","title":"Next Steps","text":"<p>After successful testing: 1. Monitor Prometheus metrics for protobuf message processing 2. Compare performance (throughput, latency) between JSON and Protobuf 3. Update client applications to use protobuf for high-frequency messaging 4. Document migration path for existing clients 5. Consider adding compression for even smaller messages</p>"},{"location":"development/protobuf-testing/#related-files","title":"Related Files","text":"<ul> <li>Protobuf schema: <code>proto/websocket.proto</code></li> <li>Converter utilities: <code>app/utils/protobuf_converter.py</code></li> <li>WebSocket consumer: <code>app/api/ws/consumers/web.py</code></li> <li>Format negotiation: <code>app/api/ws/websocket.py</code></li> <li>Python client example: <code>examples/clients/websocket_protobuf_client.py</code></li> <li>Unit tests: <code>tests/test_protobuf_converter.py</code></li> </ul>"},{"location":"development/setup/","title":"Development Setup","text":""},{"location":"development/setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.13+</li> <li>Docker &amp; Docker Compose</li> <li>Git</li> <li>uv (Python package manager)</li> </ul>"},{"location":"development/setup/#quick-start","title":"Quick Start","text":"<pre><code># Clone repository\ngit clone https://github.com/your-org/fastapi-http-websocket.git\ncd fastapi-http-websocket\n\n# Install dependencies\nuv sync\n\n# Start services (PostgreSQL, Redis, Keycloak)\nmake start\n\n# Run migrations\nmake migrate\n\n# Start development server\nmake serve\n</code></pre>"},{"location":"development/setup/#detailed-setup","title":"Detailed Setup","text":"<p>See Installation Guide for complete instructions.</p>"},{"location":"development/setup/#development-tools","title":"Development Tools","text":"<pre><code># Code quality\nmake ruff-check      # Linting\nmake dead-code-scan  # Find unused code\nuvx mypy app/        # Type checking\n\n# Testing\nuv run pytest                    # Run all tests\nuv run pytest tests/test_foo.py  # Run specific test\n\n# Database\nmake migration msg=\"Add field\"  # Create migration\nmake migrate                     # Apply migrations\nmake rollback                   # Rollback last migration\n</code></pre>"},{"location":"development/setup/#ide-setup","title":"IDE Setup","text":""},{"location":"development/setup/#vscode","title":"VSCode","text":"<p>Install recommended extensions: - Python - Pylance - Ruff - SQLTools</p>"},{"location":"development/setup/#pycharm","title":"PyCharm","text":"<p>Configure interpreter to use uv virtual environment.</p>"},{"location":"development/setup/#related","title":"Related","text":"<ul> <li>Installation Guide</li> <li>Testing Guide</li> <li>Code Quality</li> </ul>"},{"location":"development/swagger-testing/","title":"Testing with Swagger UI (OpenAPI)","text":"<p>This guide explains how to test HTTP API endpoints using FastAPI's built-in Swagger UI.</p>"},{"location":"development/swagger-testing/#quick-start","title":"Quick Start","text":""},{"location":"development/swagger-testing/#1-start-the-application","title":"1. Start the Application","text":"<pre><code>make serve\n# Or: uvicorn app:application --reload\n</code></pre>"},{"location":"development/swagger-testing/#2-get-an-access-token","title":"2. Get an Access Token","text":"<pre><code>python scripts/get_token.py acika 12345\n</code></pre> <p>Output: <pre><code>=== Access Token ===\neyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJxxx...\n\n=== Token Info ===\nExpires in: 300 seconds\nUser: acika\nRoles: ['admin', 'get-authors', 'create-author', ...]\n</code></pre></p> <p>Copy the access token (the long string starting with <code>eyJhbGc...</code>).</p>"},{"location":"development/swagger-testing/#3-open-swagger-ui","title":"3. Open Swagger UI","text":"<p>Navigate to: http://localhost:8000/docs</p>"},{"location":"development/swagger-testing/#4-authorize-in-swagger-ui","title":"4. Authorize in Swagger UI","text":"<ol> <li>Click the \"Authorize\" button (green lock icon in the top-right corner)</li> <li>In the \"Available authorizations\" popup:</li> <li>Find the \"HTTPBearer (http, Bearer)\" section</li> <li>In the \"Value\" field, paste your token:      <pre><code>Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJxxx...\n</code></pre> Important: Include the word <code>Bearer</code> followed by a space before the token.</li> <li>Click \"Authorize\"</li> <li>The popup will show \"Authorized\" with a checkmark</li> <li>Click \"Close\"</li> </ol>"},{"location":"development/swagger-testing/#5-test-any-endpoint","title":"5. Test Any Endpoint","text":"<p>Now all HTTP requests will include your access token automatically:</p> <ol> <li>Find an endpoint (e.g., GET /api/authors)</li> <li>Click to expand it</li> <li>Click \"Try it out\"</li> <li>Fill in any required parameters</li> <li>Click \"Execute\"</li> </ol> <p>You'll see: - Request URL - The actual URL called - Request headers - Including your <code>Authorization: Bearer ...</code> header - Response body - The JSON response - Response code - HTTP status code (200, 401, etc.)</p>"},{"location":"development/swagger-testing/#token-expiration","title":"Token Expiration","text":"<p>Tokens expire after 5 minutes (300 seconds).</p> <p>When your token expires, you'll get 401 Unauthorized errors:</p> <pre><code>{\n  \"detail\": \"Could not validate credentials\"\n}\n</code></pre> <p>Solution: 1. Get a new token: <code>python scripts/get_token.py acika 12345</code> 2. Click \"Authorize\" again 3. Paste the new token 4. Continue testing</p>"},{"location":"development/swagger-testing/#using-different-users","title":"Using Different Users","text":"<p>Test with different user accounts to verify RBAC (role-based access control):</p> <pre><code># Admin user with all permissions\npython scripts/get_token.py acika 12345\n\n# Limited user (if you have one configured)\npython scripts/get_token.py testuser password\n</code></pre> <p>Each user has different roles, so some endpoints may return 403 Forbidden for users without proper permissions.</p>"},{"location":"development/swagger-testing/#testing-protected-endpoints","title":"Testing Protected Endpoints","text":""},{"location":"development/swagger-testing/#example-testing-get-apiauthors","title":"Example: Testing GET /api/authors","text":"<p>This endpoint requires the <code>get-authors</code> role.</p> <ol> <li> <p>Get token for user with <code>get-authors</code> role:    <pre><code>python scripts/get_token.py acika 12345\n</code></pre></p> </li> <li> <p>Authorize in Swagger UI (paste <code>Bearer &lt;token&gt;</code>)</p> </li> <li> <p>Execute the request:</p> </li> <li>Expand GET /api/authors</li> <li>Click \"Try it out\"</li> <li> <p>Click \"Execute\"</p> </li> <li> <p>Expected response (200 OK):    <pre><code>[\n  {\n    \"id\": 1,\n    \"name\": \"John Doe\",\n    \"created_at\": \"2024-01-15T10:30:00\"\n  }\n]\n</code></pre></p> </li> </ol>"},{"location":"development/swagger-testing/#example-testing-post-apiauthors","title":"Example: Testing POST /api/authors","text":"<p>This endpoint requires both <code>create-author</code> AND <code>admin</code> roles.</p> <ol> <li> <p>Get token for admin user:    <pre><code>python scripts/get_token.py acika 12345\n</code></pre></p> </li> <li> <p>Authorize in Swagger UI</p> </li> <li> <p>Execute the request:</p> </li> <li>Expand POST /api/authors</li> <li>Click \"Try it out\"</li> <li>Enter request body:      <pre><code>{\n  \"name\": \"Jane Smith\"\n}\n</code></pre></li> <li> <p>Click \"Execute\"</p> </li> <li> <p>Expected response (201 Created):    <pre><code>{\n  \"id\": 2,\n  \"name\": \"Jane Smith\",\n  \"created_at\": \"2024-01-15T11:00:00\"\n}\n</code></pre></p> </li> </ol>"},{"location":"development/swagger-testing/#testing-error-cases","title":"Testing Error Cases","text":""},{"location":"development/swagger-testing/#401-unauthorized-no-token","title":"401 Unauthorized (No Token)","text":"<ol> <li>Click \"Authorize\" and then \"Logout\" to clear your token</li> <li>Try to execute a protected endpoint</li> <li>You'll get:    <pre><code>{\n  \"detail\": \"Not authenticated\"\n}\n</code></pre></li> </ol>"},{"location":"development/swagger-testing/#401-unauthorized-expired-token","title":"401 Unauthorized (Expired Token)","text":"<ol> <li>Wait more than 5 minutes after getting a token</li> <li>Try to execute an endpoint</li> <li>You'll get:    <pre><code>{\n  \"detail\": \"Could not validate credentials\"\n}\n</code></pre></li> </ol>"},{"location":"development/swagger-testing/#403-forbidden-missing-role","title":"403 Forbidden (Missing Role)","text":"<ol> <li>Use a token from a user without required roles</li> <li>Try to execute a protected endpoint</li> <li>You'll get:    <pre><code>{\n  \"error\": \"permission_denied\",\n  \"message\": \"User does not have required roles: ['admin', 'create-author']\"\n}\n</code></pre></li> </ol>"},{"location":"development/swagger-testing/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"development/swagger-testing/#1-keep-a-token-ready","title":"1. Keep a Token Ready","text":"<p>Open a terminal and keep this command ready:</p> <pre><code>python scripts/get_token.py acika 12345\n</code></pre> <p>When your token expires (every 5 minutes), just run it again and copy the new token.</p>"},{"location":"development/swagger-testing/#2-use-json-output-for-scripting","title":"2. Use JSON Output for Scripting","text":"<p>Get just the token for easy copying:</p> <pre><code>python scripts/get_token.py acika 12345 --json | jq -r '.access_token'\n</code></pre> <p>Or get the full token with Bearer prefix:</p> <pre><code>TOKEN=$(python scripts/get_token.py acika 12345 --json | jq -r '.access_token')\necho \"Bearer $TOKEN\"\n</code></pre>"},{"location":"development/swagger-testing/#3-check-token-roles","title":"3. Check Token Roles","text":"<p>See what roles your user has:</p> <pre><code>python scripts/get_token.py acika 12345\n</code></pre> <p>Look at the Roles line in the output: <pre><code>Roles: ['admin', 'get-authors', 'create-author', ...]\n</code></pre></p>"},{"location":"development/swagger-testing/#4-test-multiple-users","title":"4. Test Multiple Users","text":"<p>Create multiple terminal tabs with tokens for different users:</p> <p>Tab 1 - Admin: <pre><code>python scripts/get_token.py acika 12345\n</code></pre></p> <p>Tab 2 - Regular User: <pre><code>python scripts/get_token.py testuser password\n</code></pre></p> <p>Switch between tokens in Swagger UI to test different permission levels.</p>"},{"location":"development/swagger-testing/#5-copy-token-faster","title":"5. Copy Token Faster","text":"<p>Use your terminal's selection to copy:</p> <pre><code>python scripts/get_token.py acika 12345 | grep -A1 \"Access Token\" | tail -1\n</code></pre> <p>This outputs just the token (no \"=== Access Token ===\" header).</p>"},{"location":"development/swagger-testing/#6-monitor-token-expiry","title":"6. Monitor Token Expiry","text":"<p>Set a 4-minute timer after getting a token to remind you to refresh:</p> <pre><code>python scripts/get_token.py acika 12345 &amp;&amp; sleep 240 &amp;&amp; echo \"\u23f0 Token expires in 1 minute!\"\n</code></pre>"},{"location":"development/swagger-testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/swagger-testing/#problem-not-authenticated-error","title":"Problem: \"Not authenticated\" error","text":"<p>Cause: No token provided or token not in correct format.</p> <p>Solution: 1. Check you clicked \"Authorize\" in Swagger UI 2. Ensure token starts with <code>Bearer</code> (with space) 3. Check token was copied completely (very long string)</p>"},{"location":"development/swagger-testing/#problem-could-not-validate-credentials","title":"Problem: \"Could not validate credentials\"","text":"<p>Cause: Token expired (older than 5 minutes).</p> <p>Solution: 1. Get a new token: <code>python scripts/get_token.py acika 12345</code> 2. Click \"Authorize\" again 3. Paste new token</p>"},{"location":"development/swagger-testing/#problem-permission-denied-error","title":"Problem: \"Permission denied\" error","text":"<p>Cause: User doesn't have required roles for this endpoint.</p> <p>Solution: 1. Check required roles in error message 2. Verify your user has these roles:    <pre><code>python scripts/get_token.py acika 12345\n# Look at Roles: line\n</code></pre> 3. Use an admin user or add roles to your user in Keycloak</p>"},{"location":"development/swagger-testing/#problem-keycloak-connection-error","title":"Problem: Keycloak connection error","text":"<p>Cause: Keycloak is not running.</p> <p>Solution: <pre><code># Start all services including Keycloak\nmake start\n\n# Check Keycloak is running\ndocker ps | grep keycloak\n\n# Access Keycloak admin console\nopen http://localhost:8080\n# Login: admin/admin\n</code></pre></p>"},{"location":"development/swagger-testing/#problem-invalid-credentials-when-getting-token","title":"Problem: \"Invalid credentials\" when getting token","text":"<p>Cause: Wrong username or password for Keycloak user.</p> <p>Solution: 1. Verify user exists in Keycloak admin console 2. Check username and password are correct 3. Create test user if needed (see Keycloak admin console)</p>"},{"location":"development/swagger-testing/#alternative-redoc-ui","title":"Alternative: ReDoc UI","text":"<p>FastAPI also provides ReDoc at http://localhost:8000/redoc.</p> <p>ReDoc is read-only (no \"Try it out\" button) but provides: - Better documentation layout - Easier to browse API structure - Printable API reference</p> <p>Use Swagger UI for testing, ReDoc for documentation.</p>"},{"location":"development/swagger-testing/#next-steps","title":"Next Steps","text":"<ul> <li>See testing.md for automated testing with pytest</li> <li>See websocket-testing.md for WebSocket testing with tokens</li> <li>See ../deployment/troubleshooting.md for common issues</li> </ul>"},{"location":"development/testing/","title":"Testing Guide","text":"<p>This guide explains how to test the application with proper authentication.</p>"},{"location":"development/testing/#quick-links","title":"Quick Links","text":"<ul> <li>Testing HTTP API with Swagger UI: See swagger-testing.md - Complete guide for testing with FastAPI's OpenAPI interface</li> <li>Automated Testing: See sections below for pytest and mock usage</li> <li>WebSocket Testing: See Testing WebSocket Endpoints section</li> </ul>"},{"location":"development/testing/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Test Organization</li> <li>Getting Valid Tokens</li> <li>Debug Mode (Development Only)</li> <li>Manual Testing</li> <li>Automated Testing with Pytest</li> <li>Using Centralized Test Mocks</li> <li>Testing WebSocket Endpoints</li> </ol>"},{"location":"development/testing/#test-organization","title":"Test Organization","text":"<p>Tests are organized into subdirectories by test type for better maintainability and scalability.</p>"},{"location":"development/testing/#directory-structure","title":"Directory Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/              # Fast unit tests (no external dependencies)\n\u2502   \u251c\u2500\u2500 commands/      # Command pattern tests\n\u2502   \u2502   \u2514\u2500\u2500 test_author_commands.py\n\u2502   \u251c\u2500\u2500 repositories/  # Repository pattern tests\n\u2502   \u2502   \u2514\u2500\u2500 test_author_repository.py\n\u2502   \u251c\u2500\u2500 pagination/    # Pagination logic tests (4 files)\n\u2502   \u251c\u2500\u2500 schemas/       # Schema validation tests (3 files)\n\u2502   \u251c\u2500\u2500 middleware/    # Middleware tests (3 files)\n\u2502   \u251c\u2500\u2500 rbac/          # RBAC tests (3 files)\n\u2502   \u251c\u2500\u2500 websocket/     # WebSocket utility tests (2 files)\n\u2502   \u251c\u2500\u2500 utils/         # Utility tests (8 files)\n\u2502   \u251c\u2500\u2500 edge_cases/    # Edge case tests (2 files)\n\u2502   \u2514\u2500\u2500 test_check.py  # Smoke test\n\u251c\u2500\u2500 integration/       # Integration tests (require external services)\n\u2502   \u251c\u2500\u2500 test_database.py\n\u2502   \u251c\u2500\u2500 test_redis.py\n\u2502   \u2514\u2500\u2500 test_keycloak.py\n\u251c\u2500\u2500 load/              # Performance and load tests\n\u2502   \u2514\u2500\u2500 test_websocket_load.py\n\u251c\u2500\u2500 chaos/             # Chaos engineering tests (failure scenarios)\n\u2502   \u251c\u2500\u2500 test_redis_failures.py\n\u2502   \u251c\u2500\u2500 test_database_failures.py\n\u2502   \u2514\u2500\u2500 test_keycloak_failures.py\n\u251c\u2500\u2500 mocks/             # Centralized mock factories\n\u2502   \u251c\u2500\u2500 redis_mocks.py\n\u2502   \u251c\u2500\u2500 websocket_mocks.py\n\u2502   \u2514\u2500\u2500 auth_mocks.py\n\u2514\u2500\u2500 conftest.py        # Shared fixtures and configuration\n</code></pre>"},{"location":"development/testing/#test-categories","title":"Test Categories","text":"<p>Unit Tests (<code>tests/unit/</code>): - Test individual functions/classes in isolation - Use mocks for all external dependencies - Fast execution (&lt; 1 second per test) - No database, Redis, or Keycloak required - Examples: pagination logic, data validation, encoding/decoding</p> <p>Integration Tests (<code>tests/integration/</code>): - Test interaction between components - Use real external services (Docker containers) - Slower execution (1-10 seconds per test) - Marked with <code>@pytest.mark.integration</code> - Examples: database queries, Redis operations, Keycloak authentication</p> <p>Load Tests (<code>tests/load/</code>): - Test performance under high load - Measure throughput, latency, resource usage - Very slow execution (10+ seconds) - Marked with <code>@pytest.mark.load</code> - Examples: 1000 concurrent WebSocket connections, broadcast performance</p> <p>Chaos Tests (<code>tests/chaos/</code>): - Test resilience when dependencies fail - Simulate failures, timeouts, network partitions - Marked with <code>@pytest.mark.chaos</code> - Examples: Redis down, database connection loss, Keycloak unavailable</p>"},{"location":"development/testing/#running-tests-by-category","title":"Running Tests by Category","text":"<pre><code># Run unit tests only (fast)\npytest tests/unit/ -v\n\n# Run integration tests (requires Docker)\npytest tests/integration/ -v -m integration\n\n# Run all tests except slow ones\npytest -m \"not load and not chaos\"\n\n# Run load tests\npytest tests/load/ -v -m load\n\n# Run chaos tests\npytest tests/chaos/ -v -m chaos\n\n# Run all tests in parallel\npytest -n auto\n</code></pre>"},{"location":"development/testing/#naming-conventions","title":"Naming Conventions","text":"<p>Test Files: - <code>test_&lt;component&gt;_&lt;scenario&gt;.py</code> - Examples: <code>test_pagination_edge_cases.py</code>, <code>test_websocket_load.py</code></p> <p>Test Functions: - <code>test_&lt;what&gt;_&lt;condition&gt;_&lt;expected_result&gt;()</code> - Examples: <code>test_pagination_with_invalid_page_raises_error()</code></p> <p>Test Classes: - <code>Test&lt;ComponentName&gt;&lt;Category&gt;</code> - Examples: <code>TestPaginationProperties</code>, <code>TestAuthenticationFailures</code></p>"},{"location":"development/testing/#when-creating-new-tests","title":"When Creating New Tests","text":"<ol> <li>Determine test type: Unit, integration, load, or chaos?</li> <li>Place in correct directory: Use structure above</li> <li>Add appropriate markers: <code>@pytest.mark.integration</code>, <code>@pytest.mark.load</code>, etc.</li> <li>Use centralized mocks: Import from <code>tests/mocks/</code> directory</li> <li>Follow naming conventions: Clear, descriptive names</li> </ol> <p>Example:</p> <pre><code># tests/unit/test_pagination_properties.py\nimport pytest\nfrom hypothesis import given, strategies as st\n\nclass TestPaginationProperties:\n    \"\"\"Property-based tests for pagination logic.\"\"\"\n\n    @given(\n        page=st.integers(min_value=1, max_value=100),\n        per_page=st.integers(min_value=1, max_value=100),\n    )\n    def test_offset_calculation_always_valid(self, page: int, per_page: int):\n        \"\"\"Test that offset calculation is always correct.\"\"\"\n        offset = (page - 1) * per_page\n        assert offset &gt;= 0\n        assert offset == (page - 1) * per_page\n</code></pre>"},{"location":"development/testing/#getting-valid-tokens","title":"Getting Valid Tokens","text":""},{"location":"development/testing/#method-1-using-the-token-helper-script-recommended","title":"Method 1: Using the Token Helper Script (Recommended)","text":"<p>The easiest way to get a valid access token:</p> <pre><code># Get token for user 'acika'\npython scripts/get_token.py acika 12345\n\n# Output will show:\n# === Access Token ===\n# eyJhbGci...\n#\n# === Token Info ===\n# Expires in: 300 seconds\n# User: acika\n# Roles: ['admin', 'get-authors', ...]\n</code></pre> <p>For JSON output: <pre><code>python scripts/get_token.py acika 12345 --json\n</code></pre></p> <p>Include refresh token: <pre><code>python scripts/get_token.py acika 12345 --refresh\n</code></pre></p>"},{"location":"development/testing/#method-2-direct-api-call-to-keycloak","title":"Method 2: Direct API Call to Keycloak","text":"<pre><code>curl -X POST \"http://localhost:8080/realms/HW-App/protocol/openid-connect/token\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"username=acika\" \\\n  -d \"password=12345\" \\\n  -d \"grant_type=password\" \\\n  -d \"client_id=auth-hw-frontend\"\n</code></pre>"},{"location":"development/testing/#method-3-use-keycloak-admin-console","title":"Method 3: Use Keycloak Admin Console","text":"<ol> <li>Navigate to http://localhost:8080</li> <li>Login with admin credentials (admin/admin)</li> <li>Go to your realm \u2192 Users</li> <li>Select a user \u2192 Credentials \u2192 Generate token</li> </ol>"},{"location":"development/testing/#manual-testing","title":"Manual Testing","text":""},{"location":"development/testing/#http-endpoints","title":"HTTP Endpoints","text":"<p>Using cURL: <pre><code># 1. Get token\nTOKEN=$(python scripts/get_token.py acika 12345 | grep -A1 \"Access Token\" | tail -1 | xargs)\n\n# 2. Make authenticated request\ncurl -X GET \"http://localhost:8000/authors\" \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\"\n</code></pre></p> <p>Using VS Code REST Client (api-testing/api.http): <pre><code>@baseUrl = localhost:8000\n\n### GET Request Example\nGET http://{{baseUrl}}/authors\nContent-Type: application/json\nAuthorization: Bearer eyJhbGci...YOUR_TOKEN_HERE...\n</code></pre></p> <p>Using HTTPie: <pre><code>TOKEN=$(python scripts/get_token.py acika 12345 | grep -A1 \"Access Token\" | tail -1 | xargs)\nhttp GET localhost:8000/authors \"Authorization: Bearer $TOKEN\"\n</code></pre></p>"},{"location":"development/testing/#websocket-endpoints","title":"WebSocket Endpoints","text":"<p>Using wscat: <pre><code># Install wscat\nnpm install -g wscat\n\n# Get token\nTOKEN=$(python scripts/get_token.py acika 12345 | grep -A1 \"Access Token\" | tail -1 | xargs)\n\n# Connect\nwscat -c \"ws://localhost:8000/web?Authorization=Bearer $TOKEN\"\n\n# Send message\n{\"pkg_id\": 1, \"req_id\": \"test-123\", \"data\": {}}\n</code></pre></p> <p>Using VS Code REST Client (api-testing/ws.http): <pre><code>WS ws://localhost:8000/web?Authorization=Bearer YOUR_TOKEN_HERE\n\n{\"pkg_id\": 1, \"req_id\": \"123qweasd\"}\n</code></pre></p>"},{"location":"development/testing/#automated-testing-with-pytest","title":"Automated Testing with Pytest","text":""},{"location":"development/testing/#using-mock-authentication-unit-tests","title":"Using Mock Authentication (Unit Tests)","text":"<p>The <code>tests/conftest.py</code> provides fixtures that mock Keycloak:</p> <pre><code>import pytest\nfrom app.schemas.request import RequestModel\nfrom app.api.ws.handlers.author_handler import get_authors_handler\n\n\n@pytest.mark.asyncio\nasync def test_get_authors_with_mock_auth(\n    mock_keycloak_manager, mock_user\n):\n    \"\"\"Test handler with mocked authentication.\"\"\"\n    request = RequestModel(\n        pkg_id=1,\n        req_id=\"test-123\",\n        data={\"filters\": {\"name\": \"Test\"}}\n    )\n\n    response = await get_authors_handler(request)\n\n    assert response.status_code == 0\n    assert isinstance(response.data, list)\n</code></pre>"},{"location":"development/testing/#available-fixtures","title":"Available Fixtures","text":"<ul> <li><code>mock_keycloak_token</code>: Mock token response</li> <li><code>mock_user_data</code>: Mock decoded user data</li> <li><code>mock_user</code>: UserModel instance</li> <li><code>mock_keycloak_manager</code>: Mocked KeycloakManager</li> <li><code>auth_headers</code>: Headers with Bearer token</li> <li><code>admin_user_data</code>: Admin user with full permissions</li> <li><code>limited_user_data</code>: User with limited permissions</li> </ul>"},{"location":"development/testing/#testing-rbac-permissions","title":"Testing RBAC Permissions","text":"<pre><code>@pytest.mark.asyncio\nasync def test_permission_denied_for_limited_user(limited_user_data):\n    \"\"\"Test that users without proper roles are denied.\"\"\"\n    user = UserModel(**limited_user_data)\n    request = RequestModel(pkg_id=1, req_id=\"test-123\", data={})\n\n    response = await pkg_router.handle_request(user, request)\n\n    assert response.status_code == RSPCode.PERMISSION_DENIED\n</code></pre>"},{"location":"development/testing/#integration-tests-with-real-keycloak","title":"Integration Tests with Real Keycloak","text":"<p>For integration tests that actually connect to Keycloak:</p> <pre><code>@pytest.mark.integration\n@pytest.mark.asyncio\nasync def test_real_keycloak_auth():\n    \"\"\"Integration test with real Keycloak instance.\"\"\"\n    from app.managers.keycloak_manager import KeycloakManager\n\n    kc = KeycloakManager()\n    token = kc.login(\"acika\", \"12345\")\n\n    assert \"access_token\" in token\n\n    user_data = kc.openid.decode_token(token[\"access_token\"])\n    assert user_data[\"preferred_username\"] == \"acika\"\n</code></pre> <p>Run integration tests only: <pre><code>uv run pytest -m integration\n</code></pre></p>"},{"location":"development/testing/#using-centralized-test-mocks","title":"Using Centralized Test Mocks","text":""},{"location":"development/testing/#why-centralized-mocks","title":"Why Centralized Mocks?","text":"<p>The project uses centralized mock factories located in <code>tests/mocks/</code> to promote consistency and reduce code duplication.</p> <p>Benefits: - \u2705 Consistency: Same mock behavior across all tests - \u2705 Maintainability: Update once in <code>tests/mocks/</code>, benefits all tests - \u2705 Less Code: ~80 lines eliminated per test file - \u2705 Discoverability: Easy to find and reuse existing mocks - \u2705 Type Safety: Mocks use <code>spec</code> parameter for better IDE support</p>"},{"location":"development/testing/#available-mock-factories","title":"Available Mock Factories","text":""},{"location":"development/testing/#redis-mocks-testsmocksredis_mockspy","title":"Redis Mocks (<code>tests/mocks/redis_mocks.py</code>)","text":"<pre><code>from tests.mocks.redis_mocks import (\n    create_mock_redis_connection,     # Full Redis connection with all operations\n    create_mock_rate_limiter,          # RateLimiter instance\n    create_mock_connection_limiter,    # ConnectionLimiter instance\n)\n\n# Example usage\n@pytest.fixture\ndef mock_redis():\n    return create_mock_redis_connection()\n\nasync def test_with_redis(mock_redis):\n    # Mock already has all methods configured\n    result = await mock_redis.get(\"key\")\n</code></pre>"},{"location":"development/testing/#websocket-mocks-testsmockswebsocket_mockspy","title":"WebSocket Mocks (<code>tests/mocks/websocket_mocks.py</code>)","text":"<pre><code>from tests.mocks.websocket_mocks import (\n    create_mock_websocket,             # WebSocket connection with send/receive\n    create_mock_connection_manager,    # ConnectionManager with broadcast\n    create_mock_package_router,        # PackageRouter with handle_request\n    create_mock_broadcast_message,     # BroadcastDataModel factory\n)\n\n# Example usage\nasync def test_websocket_handler():\n    mock_ws = create_mock_websocket()\n    # Already has send_json, send_response, accept, close, client.host, etc.\n    await handler.on_connect(mock_ws)\n</code></pre>"},{"location":"development/testing/#auth-mocks-testsmocksauth_mockspy","title":"Auth Mocks (<code>tests/mocks/auth_mocks.py</code>)","text":"<pre><code>from tests.mocks.auth_mocks import (\n    create_mock_keycloak_manager,      # KeycloakManager with login/decode_token\n    create_mock_user_model,             # UserModel factory\n    create_mock_auth_backend,           # AuthBackend for middleware tests\n    create_mock_rbac_manager,           # RBACManager for permission tests\n)\n\n# Example usage\nasync def test_authentication():\n    mock_kc = create_mock_keycloak_manager()\n    # Already configured with login and decode_token methods\n    with patch(\"app.auth.keycloak_manager\", mock_kc):\n        result = await auth_backend.authenticate(request)\n</code></pre>"},{"location":"development/testing/#repository-mocks-testsmocksrepository_mockspy","title":"Repository Mocks (<code>tests/mocks/repository_mocks.py</code>)","text":"<pre><code>from tests.mocks.repository_mocks import (\n    create_mock_author_repository,     # AuthorRepository with CRUD ops\n    create_mock_crud_repository,        # Generic BaseRepository\n)\n\n# Example usage\nasync def test_with_repo():\n    mock_repo = create_mock_author_repository()\n    # Configure mock behavior as needed\n    mock_repo.get_by_id.return_value = create_author_fixture(id=1)\n\n    author = await mock_repo.get_by_id(1)\n    assert author.id == 1\n</code></pre>"},{"location":"development/testing/#inline-vs-centralized-comparison","title":"Inline vs Centralized: Comparison","text":"<p>\u274c BAD - Inline mock (hard to maintain)</p> <pre><code>@pytest.fixture\ndef mock_redis():\n    redis_mock = AsyncMock()\n    redis_mock.zadd = AsyncMock()\n    redis_mock.zcard = AsyncMock(return_value=0)\n    redis_mock.zremrangebyscore = AsyncMock()\n    redis_mock.expire = AsyncMock()\n    redis_mock.pipeline = MagicMock()\n    redis_mock.pipeline.return_value.__aenter__ = AsyncMock()\n    redis_mock.pipeline.return_value.__aexit__ = AsyncMock()\n    # ... 10 more lines of setup\n    return redis_mock\n</code></pre> <p>\u2705 GOOD - Use centralized mock</p> <pre><code>from tests.mocks.redis_mocks import create_mock_redis_connection\n\n@pytest.fixture\ndef mock_redis():\n    return create_mock_redis_connection()\n</code></pre>"},{"location":"development/testing/#when-to-use-centralized-vs-custom-mocks","title":"When to Use Centralized vs Custom Mocks","text":"<p>Use Centralized Mocks When: - \u2705 Testing standard components (Redis, WebSocket, Auth, Repositories) - \u2705 Mock needs common default behavior - \u2705 Multiple tests need the same mock - \u2705 Mock is reusable across test files</p> <p>Create Custom Inline Mocks When: - \u26a0\ufe0f Testing very specific edge case behavior - \u26a0\ufe0f Mock is used in only one test - \u26a0\ufe0f Centralized mock doesn't exist yet (consider adding it!)</p>"},{"location":"development/testing/#adding-new-centralized-mocks","title":"Adding New Centralized Mocks","text":"<p>If you create a mock that could be reused, add it to <code>tests/mocks/</code>:</p> <ol> <li>Choose the right file: <code>redis_mocks.py</code>, <code>auth_mocks.py</code>, <code>websocket_mocks.py</code>, <code>repository_mocks.py</code></li> <li>Create factory function: Use <code>create_mock_*</code> naming convention</li> <li>Use <code>spec</code> parameter: For better type safety</li> <li>Add docstring: Explain what the mock provides</li> <li>Update conftest.py: If it's a common fixture</li> </ol> <p>Example:</p> <pre><code># tests/mocks/redis_mocks.py\ndef create_mock_redis_connection() -&gt; AsyncMock:\n    \"\"\"\n    Create a mock Redis connection with common operations configured.\n\n    Returns:\n        AsyncMock: Configured Redis connection mock\n    \"\"\"\n    redis_mock = AsyncMock(spec=Redis)\n    redis_mock.get = AsyncMock(return_value=None)\n    redis_mock.set = AsyncMock(return_value=True)\n    redis_mock.zadd = AsyncMock(return_value=1)\n    # ... configure other methods\n    return redis_mock\n</code></pre>"},{"location":"development/testing/#examples-in-action","title":"Examples in Action","text":"<p>See these refactored test files for proper usage: - <code>tests/test_rate_limiting.py</code> - Redis mock usage - <code>tests/test_websocket.py</code> - WebSocket mock usage - <code>tests/test_auth_basic.py</code> - Keycloak mock usage - <code>tests/test_auth_backend.py</code> - Comprehensive auth testing</p> <p>Reference: See <code>CLAUDE.md</code> lines 1539-1650 for comprehensive mock documentation.</p>"},{"location":"development/testing/#testing-websocket-endpoints","title":"Testing WebSocket Endpoints","text":""},{"location":"development/testing/#example-websocket-test","title":"Example WebSocket Test","text":"<pre><code>import pytest\nfrom fastapi.testclient import TestClient\nfrom app import application\n\n\n@pytest.mark.asyncio\nasync def test_websocket_connection(mock_keycloak_manager):\n    \"\"\"Test WebSocket connection with authentication.\"\"\"\n    client = TestClient(application())\n\n    with client.websocket_connect(\n        \"/web?Authorization=Bearer mock_token\"\n    ) as websocket:\n        # Send request\n        websocket.send_json({\n            \"pkg_id\": 1,\n            \"req_id\": \"ws-test-123\",\n            \"data\": {}\n        })\n\n        # Receive response\n        response = websocket.receive_json()\n\n        assert response[\"pkg_id\"] == 1\n        assert response[\"req_id\"] == \"ws-test-123\"\n</code></pre>"},{"location":"development/testing/#makefile-integration","title":"Makefile Integration","text":"<p>Add these helpful commands to your workflow:</p> <pre><code># Get token quickly\nmake get-token USER=acika PASS=12345\n\n# Run tests with coverage\nmake test-with-coverage\n</code></pre> <p>Add to Makefile: <pre><code>get-token:\n    @python scripts/get_token.py $(USER) $(PASS)\n\ntest-with-coverage:\n    @uv run pytest --cov=app --cov-report=html\n</code></pre></p>"},{"location":"development/testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/testing/#token-expired","title":"Token Expired","text":"<p>Error: <code>JWT token expired</code></p> <p>Solution: Tokens expire after 5 minutes. Get a fresh token: <pre><code>python scripts/get_token.py acika 12345\n</code></pre></p>"},{"location":"development/testing/#keycloak-not-running","title":"Keycloak Not Running","text":"<p>Error: Connection refused to hw-keycloak:8080</p> <p>Solution: <pre><code>make start  # Start all services including Keycloak\ndocker ps   # Verify hw-keycloak is running\n</code></pre></p>"},{"location":"development/testing/#invalid-credentials","title":"Invalid Credentials","text":"<p>Error: <code>Invalid credentials</code></p> <p>Solution: Verify user exists in Keycloak and credentials are correct: <pre><code># Access Keycloak admin console\nopen http://localhost:8080\n# Login: admin/admin\n# Check Users in HW-App realm\n</code></pre></p>"},{"location":"development/testing/#permission-denied","title":"Permission Denied","text":"<p>Error: <code>No permission for pkg_id X</code></p> <p>Solution: Check handler's <code>roles</code> parameter in <code>@pkg_router.register()</code> decorator and ensure user has required role: <pre><code># See your roles\npython scripts/get_token.py acika 12345\n# Output shows: Roles: ['admin', 'get-authors', ...]\n\n# Check handler code for required roles\n# Example: @pkg_router.register(PkgID.GET_AUTHORS, roles=[\"get-authors\"])\n</code></pre></p>"},{"location":"development/testing/#best-practices","title":"Best Practices","text":"<ol> <li>Use Mock Authentication for Unit Tests: Fast and reliable</li> <li>Use Real Tokens for Integration Tests: Catch real-world issues</li> <li>Never commit tokens: Tokens in git history are security risks</li> <li>Rotate tokens regularly: Even in development</li> <li>Test with different user roles: Verify RBAC properly</li> <li>Use Property-Based Testing: Catch edge cases automatically with Hypothesis</li> </ol>"},{"location":"development/testing/#property-based-testing-with-hypothesis","title":"Property-Based Testing with Hypothesis","text":""},{"location":"development/testing/#what-is-property-based-testing","title":"What is Property-Based Testing?","text":"<p>Property-based testing automatically generates test cases to verify that code properties hold for a wide range of inputs. Instead of writing specific examples, you define properties that should always be true.</p> <p>Benefits: - Catches edge cases you wouldn't think to test manually - One property test replaces dozens of example tests - Automatically finds minimal failing cases - Tests thousands of input combinations</p>"},{"location":"development/testing/#installation","title":"Installation","text":"<p>Hypothesis is included in dev dependencies:</p> <pre><code>uv sync --group dev\n</code></pre>"},{"location":"development/testing/#example-testing-pagination-properties","title":"Example: Testing Pagination Properties","text":"<pre><code>from hypothesis import given, strategies as st\nimport pytest\n\nclass TestPaginationProperties:\n    @given(\n        page=st.integers(min_value=1, max_value=100),\n        per_page=st.integers(min_value=1, max_value=100),\n    )\n    def test_page_calculation_properties(self, page: int, per_page: int) -&gt; None:\n        \"\"\"\n        Test mathematical properties of pagination calculations.\n\n        Properties:\n        1. offset = (page - 1) * per_page\n        2. offset is always &gt;= 0\n        \"\"\"\n        offset = (page - 1) * per_page\n\n        assert offset == (page - 1) * per_page\n        assert offset &gt;= 0\n        assert offset + per_page == page * per_page\n</code></pre>"},{"location":"development/testing/#running-property-based-tests","title":"Running Property-Based Tests","text":"<pre><code># Run property-based tests\npytest tests/test_pagination_property_based.py -v\n\n# Hypothesis runs 100 examples by default\n# Example output:\n# test_page_calculation_properties PASSED (ran 100 examples)\n</code></pre>"},{"location":"development/testing/#common-use-cases","title":"Common Use Cases","text":"<p>1. Reversible Operations: <pre><code>@given(st.text())\ndef test_encoding_roundtrip(self, value: str) -&gt; None:\n    \"\"\"Test that decode(encode(x)) == x\"\"\"\n    encoded = encode_cursor(value)\n    decoded = decode_cursor(encoded)\n    assert decoded == value\n</code></pre></p> <p>2. Boundary Conditions: <pre><code>@given(st.integers(min_value=-100, max_value=0))\ndef test_invalid_pages_rejected(self, invalid_page: int) -&gt; None:\n    \"\"\"Test that page &lt;= 0 raises ValueError\"\"\"\n    with pytest.raises(ValueError):\n        get_paginated_results(Model, page=invalid_page, per_page=10)\n</code></pre></p> <p>3. Data Validation: <pre><code>@given(st.dictionaries(keys=st.text(), values=st.integers()))\ndef test_filters_json_serializable(self, filters: dict) -&gt; None:\n    \"\"\"Test that filters are always JSON-serializable\"\"\"\n    import json\n    serialized = json.dumps(filters)\n    assert json.loads(serialized) == filters\n</code></pre></p>"},{"location":"development/testing/#best-practices_1","title":"Best Practices","text":"<ul> <li>Start with simple mathematical properties</li> <li>Use realistic input bounds</li> <li>Combine with example-based tests</li> <li>Document what property is being tested</li> <li>Let Hypothesis automatically shrink failing cases</li> </ul>"},{"location":"development/testing/#see-also","title":"See Also","text":"<ul> <li>Example file: <code>tests/test_pagination_property_based.py</code></li> <li>Hypothesis Documentation</li> <li>CLAUDE.md section on Property-Based Testing</li> </ul>"},{"location":"development/testing/#example-test-file","title":"Example Test File","text":"<p>See <code>tests/test_auth_example.py</code> for a complete example of testing with authentication.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to the FastAPI HTTP/WebSocket Template! This guide will help you get up and running quickly.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.13+ - Download Python</li> <li>Docker &amp; Docker Compose - Install Docker</li> <li>uv - Python package manager: <code>pip install uv</code></li> <li>Git - Version control</li> </ul>"},{"location":"getting-started/#quick-setup","title":"Quick Setup","text":"<p>Follow these three steps to get started:</p> <ol> <li>Installation - Set up your development environment</li> <li>Quick Start - Create your first endpoints</li> <li>Configuration - Configure services and environment</li> </ol>"},{"location":"getting-started/#what-youll-build","title":"What You'll Build","text":"<p>By the end of this guide, you'll have:</p> <ul> <li>\u2705 A running FastAPI application with HTTP and WebSocket support</li> <li>\u2705 Keycloak authentication with JWT tokens</li> <li>\u2705 PostgreSQL database with migrations</li> <li>\u2705 Redis for caching and rate limiting</li> <li>\u2705 Prometheus metrics and Grafana dashboards</li> <li>\u2705 Full observability stack (logs, metrics, traces)</li> </ul>"},{"location":"getting-started/#learning-path","title":"Learning Path","text":"BeginnersExperienced Developers <ol> <li>Start with Installation</li> <li>Follow the Quick Start guide</li> <li>Learn about Authentication</li> <li>Explore HTTP Endpoints</li> </ol> <ol> <li>Review Architecture Overview</li> <li>Check Design Patterns</li> <li>Jump to API Reference</li> <li>Deploy with Production Guide</li> </ol>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li> <p> Install</p> <p>Set up your development environment</p> <p> Installation Guide</p> </li> <li> <p> Quick Start</p> <p>Build your first endpoints in 10 minutes</p> <p> Quick Start</p> </li> <li> <p> Configure</p> <p>Configure services and environment</p> <p> Configuration</p> </li> </ul>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Learn how to configure the application and its services for different environments.</p>"},{"location":"getting-started/configuration/#environment-files","title":"Environment Files","text":"<p>The project uses multiple environment files:</p> File Purpose Location <code>.env</code> Application configuration Project root <code>docker/.srv_env</code> Service environment Docker directory <code>docker/.pg_env</code> PostgreSQL credentials Docker directory <code>docker/.kc_env</code> Keycloak configuration Docker directory"},{"location":"getting-started/configuration/#application-configuration","title":"Application Configuration","text":""},{"location":"getting-started/configuration/#env-file","title":".env File","text":"<p>Create <code>.env</code> in the project root:</p> <pre><code># ========================================\n# Environment &amp; Security\n# ========================================\nENV=dev  # dev, staging, production\nALLOWED_HOSTS=[\"*\"]  # Use specific domains in production: [\"example.com\", \"*.example.com\"]\nTRUSTED_PROXIES=[\"10.0.0.0/8\", \"172.16.0.0/12\", \"192.168.0.0/16\"]  # Docker networks\nMAX_REQUEST_BODY_SIZE=1048576  # 1MB\nEXCLUDED_PATHS=/health|/metrics|/docs.*  # Regex for paths excluded from auth\n\n# ========================================\n# Database Configuration\n# ========================================\nDB_HOST=localhost\nDB_PORT=5432\nDB_NAME=fastapi\nDB_USER=fastapi\nDB_PASSWORD=fastapi\nDB_POOL_SIZE=20\nDB_MAX_OVERFLOW=10\nDB_POOL_RECYCLE=3600\nDB_POOL_PRE_PING=true\nDB_INIT_MAX_RETRIES=5\nDB_INIT_RETRY_INTERVAL=5\nDEFAULT_PAGE_SIZE=20\n\n# ========================================\n# Redis Configuration\n# ========================================\nREDIS_IP=localhost\nREDIS_PORT=6379\nMAIN_REDIS_DB=1\nAUTH_REDIS_DB=10\nREDIS_MAX_CONNECTIONS=50\nREDIS_SOCKET_TIMEOUT=5\nREDIS_CONNECT_TIMEOUT=5\nREDIS_HEALTH_CHECK_INTERVAL=30\nREDIS_RETRY_ON_TIMEOUT=true\n\n# ========================================\n# Keycloak Configuration\n# ========================================\nKEYCLOAK_BASE_URL=http://localhost:8080\nKEYCLOAK_REALM=development\nKEYCLOAK_CLIENT_ID=fastapi-app\nKEYCLOAK_ADMIN_USERNAME=admin\nKEYCLOAK_ADMIN_PASSWORD=admin\nUSER_SESSION_REDIS_KEY_PREFIX=user_session:\n\n# ========================================\n# Rate Limiting\n# ========================================\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_PER_MINUTE=60\nRATE_LIMIT_BURST=10\nRATE_LIMIT_FAIL_MODE=open  # open or closed\nWS_MAX_CONNECTIONS_PER_USER=5\nWS_MESSAGE_RATE_LIMIT=100\n\n# ========================================\n# Audit Logging\n# ========================================\nAUDIT_LOG_ENABLED=true\nAUDIT_LOG_RETENTION_DAYS=90\nAUDIT_QUEUE_MAX_SIZE=10000\nAUDIT_BATCH_SIZE=100\nAUDIT_BATCH_TIMEOUT=5\n\n# ========================================\n# Logging\n# ========================================\nLOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR, CRITICAL\nLOG_CONSOLE_FORMAT=human  # human or json (use json in production for Grafana Alloy)\nLOG_FILE_PATH=logs/logging_errors.log\nLOG_EXCLUDED_PATHS=/health|/metrics\n\n# ========================================\n# Circuit Breaker\n# ========================================\nCIRCUIT_BREAKER_ENABLED=true\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX=5\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT=60\nREDIS_CIRCUIT_BREAKER_FAIL_MAX=3\nREDIS_CIRCUIT_BREAKER_TIMEOUT=30\n\n# ========================================\n# Profiling\n# ========================================\nPROFILING_ENABLED=true\nPROFILING_OUTPUT_DIR=profiling_reports\nPROFILING_INTERVAL_SECONDS=30\n</code></pre>"},{"location":"getting-started/configuration/#docker-services-configuration","title":"Docker Services Configuration","text":""},{"location":"getting-started/configuration/#postgresql-dockerpg_env","title":"PostgreSQL (docker/.pg_env)","text":"<pre><code>POSTGRES_USER=fastapi\nPOSTGRES_PASSWORD=fastapi\nPOSTGRES_DB=fastapi\n</code></pre>"},{"location":"getting-started/configuration/#keycloak-dockerkc_env","title":"Keycloak (docker/.kc_env)","text":"<pre><code>KEYCLOAK_ADMIN=admin\nKEYCLOAK_ADMIN_PASSWORD=admin\n\nKC_DB=postgres\nKC_DB_URL_HOST=hw-db\nKC_DB_URL_DATABASE=keycloak\nKC_DB_URL_PORT=5432\nKC_DB_USERNAME=fastapi\nKC_DB_PASSWORD=fastapi\n\nKC_HOSTNAME=localhost\nKC_HTTP_ENABLED=true\nKC_HOSTNAME_STRICT=false\nKC_PROXY=edge\n\nKC_METRICS_ENABLED=true\nKC_HEALTH_ENABLED=true\n</code></pre>"},{"location":"getting-started/configuration/#application-service-dockersrv_env","title":"Application Service (docker/.srv_env)","text":"<pre><code>LOG_CONSOLE_FORMAT=human  # human for development, json for production\n</code></pre>"},{"location":"getting-started/configuration/#configuration-options","title":"Configuration Options","text":""},{"location":"getting-started/configuration/#environment-security-settings","title":"Environment &amp; Security Settings","text":"Variable Default Description <code>ENV</code> <code>dev</code> Environment type (<code>dev</code>, <code>staging</code>, <code>production</code>). Controls default log levels and security settings. <code>ALLOWED_HOSTS</code> <code>[\"*\"]</code> List of allowed Host header values to prevent Host header injection attacks. Use <code>[\"example.com\", \"*.example.com\"]</code> in production. <code>TRUSTED_PROXIES</code> Docker networks List of trusted proxy IP addresses/networks (CIDR notation) for X-Forwarded-For validation. Prevents IP spoofing. <code>MAX_REQUEST_BODY_SIZE</code> <code>1048576</code> (1MB) Maximum request body size in bytes. Protects against large payload attacks. <code>EXCLUDED_PATHS</code> Docs, metrics Regex patterns for paths excluded from authentication (e.g., <code>/health</code>, <code>/metrics</code>, <code>/docs</code>). <p>Production Security: - Always set specific <code>ALLOWED_HOSTS</code> in production (never use <code>[\"*\"]</code>) - Configure <code>TRUSTED_PROXIES</code> to match your load balancer/proxy IPs - Keep <code>MAX_REQUEST_BODY_SIZE</code> as low as practical for your use case - Minimize <code>EXCLUDED_PATHS</code> to only public endpoints</p>"},{"location":"getting-started/configuration/#database-settings","title":"Database Settings","text":"Variable Default Description <code>DB_HOST</code> <code>localhost</code> PostgreSQL host address <code>DB_PORT</code> <code>5432</code> PostgreSQL port <code>DB_NAME</code> <code>fastapi</code> Database name <code>DB_USER</code> <code>fastapi</code> Database username <code>DB_PASSWORD</code> - Database password (required) <code>DB_POOL_SIZE</code> <code>20</code> Base connection pool size <code>DB_MAX_OVERFLOW</code> <code>10</code> Max overflow connections beyond pool size <code>DB_POOL_RECYCLE</code> <code>3600</code> Connection recycle time in seconds (prevents stale connections) <code>DB_POOL_PRE_PING</code> <code>true</code> Test connections before use (prevents using dead connections) <code>DB_INIT_MAX_RETRIES</code> <code>5</code> Max retries for database initialization on startup <code>DB_INIT_RETRY_INTERVAL</code> <code>5</code> Seconds between database init retries <code>DEFAULT_PAGE_SIZE</code> <code>20</code> Default items per page for paginated endpoints <p>Tuning Guidelines: - Low traffic (&lt;100 req/s): <code>DB_POOL_SIZE=10</code>, <code>DB_MAX_OVERFLOW=5</code> - Medium traffic (100-500 req/s): <code>DB_POOL_SIZE=20</code>, <code>DB_MAX_OVERFLOW=10</code> (default) - High traffic (&gt;500 req/s): <code>DB_POOL_SIZE=50</code>, <code>DB_MAX_OVERFLOW=20</code> - Monitor <code>db_connections_active</code> Prometheus metric to optimize pool size</p>"},{"location":"getting-started/configuration/#redis-settings","title":"Redis Settings","text":"Variable Default Description <code>REDIS_IP</code> <code>localhost</code> Redis host address <code>REDIS_PORT</code> <code>6379</code> Redis port <code>MAIN_REDIS_DB</code> <code>1</code> Main Redis database number (rate limiting, caching) <code>AUTH_REDIS_DB</code> <code>10</code> Auth Redis database number (token cache, sessions) <code>REDIS_MAX_CONNECTIONS</code> <code>50</code> Max connections per Redis pool <code>REDIS_SOCKET_TIMEOUT</code> <code>5</code> Socket operation timeout in seconds <code>REDIS_CONNECT_TIMEOUT</code> <code>5</code> Connection establishment timeout in seconds <code>REDIS_HEALTH_CHECK_INTERVAL</code> <code>30</code> Health check frequency in seconds <code>REDIS_RETRY_ON_TIMEOUT</code> <code>true</code> Retry operations on timeout <p>Redis Pool Monitoring: - Monitor <code>redis_pool_connections_in_use</code> and <code>redis_pool_connections_available</code> metrics - If pool exhaustion occurs frequently, increase <code>REDIS_MAX_CONNECTIONS</code> - Configure Prometheus alerts for pool usage &gt; 80%</p>"},{"location":"getting-started/configuration/#rate-limiting","title":"Rate Limiting","text":"Variable Default Description <code>RATE_LIMIT_ENABLED</code> <code>true</code> Enable rate limiting middleware <code>RATE_LIMIT_PER_MINUTE</code> <code>60</code> HTTP requests per minute per user/IP <code>RATE_LIMIT_BURST</code> <code>10</code> Burst allowance for short-term traffic spikes <code>RATE_LIMIT_FAIL_MODE</code> <code>open</code> Fail mode when Redis unavailable (<code>open</code> = allow requests, <code>closed</code> = deny requests) <code>WS_MAX_CONNECTIONS_PER_USER</code> <code>5</code> Max concurrent WebSocket connections per user <code>WS_MESSAGE_RATE_LIMIT</code> <code>100</code> WebSocket messages per minute per user <p>Environment-Specific Defaults: - Development: <code>RATE_LIMIT_FAIL_MODE=open</code> (permissive) - Staging: <code>RATE_LIMIT_FAIL_MODE=open</code> (forgiving for testing) - Production: <code>RATE_LIMIT_FAIL_MODE=closed</code> (strict security)</p> <p>Tuning Guidelines: - Public APIs: Use lower limits (60/min) with monitoring - Internal APIs: Higher limits (300/min) acceptable - WebSocket: <code>WS_MESSAGE_RATE_LIMIT</code> depends on real-time requirements</p>"},{"location":"getting-started/configuration/#audit-logging","title":"Audit Logging","text":"Variable Default Description <code>AUDIT_LOG_ENABLED</code> <code>true</code> Enable audit logging middleware <code>AUDIT_LOG_RETENTION_DAYS</code> <code>90</code> Audit log retention period (PostgreSQL cleanup) <code>AUDIT_QUEUE_MAX_SIZE</code> <code>10000</code> Max audit log queue size (prevents memory overflow) <code>AUDIT_BATCH_SIZE</code> <code>100</code> Number of logs written per database batch <code>AUDIT_BATCH_TIMEOUT</code> <code>5</code> Seconds to wait before flushing partial batch <p>Queue Overflow Monitoring: - Monitor <code>audit_logs_dropped_total</code> metric - If logs are dropping, increase <code>AUDIT_QUEUE_MAX_SIZE</code> or <code>AUDIT_BATCH_SIZE</code> - Configure alert: <code>rate(audit_logs_dropped_total[5m]) &gt; 1</code> (see Prometheus alerts)</p> <p>Compliance Settings: - Financial services: <code>AUDIT_LOG_RETENTION_DAYS=2555</code> (7 years) - Healthcare (HIPAA): <code>AUDIT_LOG_RETENTION_DAYS=2555</code> (7 years) - GDPR: <code>AUDIT_LOG_RETENTION_DAYS=365</code> (1 year minimum)</p>"},{"location":"getting-started/configuration/#logging","title":"Logging","text":"Variable Default Description <code>LOG_LEVEL</code> Env-dependent Logging level (<code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code>) <code>LOG_FILE_PATH</code> <code>logs/logging_errors.log</code> Error log file path (JSON format) <code>LOG_CONSOLE_FORMAT</code> Env-dependent Console log format (<code>human</code> for development, <code>json</code> for production) <code>LOG_EXCLUDED_PATHS</code> <code>/health</code>, <code>/metrics</code> Paths excluded from access logs (reduces log noise) <p>Environment-Specific Defaults: - Development: <code>LOG_LEVEL=DEBUG</code>, <code>LOG_CONSOLE_FORMAT=human</code> - Staging: <code>LOG_LEVEL=INFO</code>, <code>LOG_CONSOLE_FORMAT=json</code> - Production: <code>LOG_LEVEL=WARNING</code>, <code>LOG_CONSOLE_FORMAT=json</code></p> <p>Important: - Always use <code>LOG_CONSOLE_FORMAT=json</code> in production for Grafana Alloy/Loki integration - Use <code>LOG_CONSOLE_FORMAT=human</code> for local development (easier to read) - Grafana Alloy requires JSON format to parse structured logs correctly</p>"},{"location":"getting-started/configuration/#circuit-breaker","title":"Circuit Breaker","text":"Variable Default Description <code>CIRCUIT_BREAKER_ENABLED</code> <code>true</code> Enable circuit breaker pattern for external services <code>KEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX</code> <code>5</code> Max failures before opening Keycloak circuit breaker <code>KEYCLOAK_CIRCUIT_BREAKER_TIMEOUT</code> <code>60</code> Seconds to wait before half-open (retry) state <code>REDIS_CIRCUIT_BREAKER_FAIL_MAX</code> <code>3</code> Max failures before opening Redis circuit breaker <code>REDIS_CIRCUIT_BREAKER_TIMEOUT</code> <code>30</code> Seconds to wait before half-open (retry) state <p>Tuning Guidelines: - Critical services (Keycloak): Higher <code>FAIL_MAX</code> (5) + longer <code>TIMEOUT</code> (60s) = more retries before failing fast - Non-critical services (Redis cache): Lower <code>FAIL_MAX</code> (3) + shorter <code>TIMEOUT</code> (30s) = fail fast to protect system - Monitor <code>circuit_breaker_state</code> metric (0=closed, 1=open, 2=half_open) - Configure alerts for open circuit breakers (critical incidents)</p> <p>See: Circuit Breaker Guide for comprehensive documentation</p>"},{"location":"getting-started/configuration/#profiling","title":"Profiling","text":"Variable Default Description <code>PROFILING_ENABLED</code> Env-dependent Enable Scalene profiling integration <code>PROFILING_OUTPUT_DIR</code> <code>profiling_reports</code> Directory for profiling report output <code>PROFILING_INTERVAL_SECONDS</code> <code>30</code> Profiling sample interval <p>Environment-Specific Defaults: - Development: <code>PROFILING_ENABLED=true</code> (enabled for local testing) - Staging: <code>PROFILING_ENABLED=true</code> (performance testing) - Production: <code>PROFILING_ENABLED=false</code> (disabled to reduce overhead)</p> <p>Usage: - Run application with Scalene: <code>scalene run -- uvicorn app:application</code> - Access reports via <code>/api/profiling/reports</code> endpoint - See Performance Profiling section</p>"},{"location":"getting-started/configuration/#keycloak","title":"Keycloak","text":"Variable Default Description <code>KEYCLOAK_BASE_URL</code> <code>http://localhost:8080</code> Keycloak server URL <code>KEYCLOAK_REALM</code> - Keycloak realm name (required) <code>KEYCLOAK_CLIENT_ID</code> - OAuth2 client ID (required) <code>KEYCLOAK_ADMIN_USERNAME</code> - Keycloak admin username (required) <code>KEYCLOAK_ADMIN_PASSWORD</code> - Keycloak admin password (required) <code>USER_SESSION_REDIS_KEY_PREFIX</code> <code>user_session:</code> Redis key prefix for user session tracking"},{"location":"getting-started/configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"getting-started/configuration/#development","title":"Development","text":"<pre><code>ENVIRONMENT=development\nDEBUG=true\nLOG_LEVEL=DEBUG\nLOG_CONSOLE_FORMAT=human\nRATE_LIMIT_PER_MINUTE=1000  # Higher limits for testing\n</code></pre>"},{"location":"getting-started/configuration/#staging","title":"Staging","text":"<pre><code>ENVIRONMENT=staging\nDEBUG=false\nLOG_LEVEL=INFO\nLOG_CONSOLE_FORMAT=json\nRATE_LIMIT_PER_MINUTE=120\n</code></pre>"},{"location":"getting-started/configuration/#production","title":"Production","text":"<pre><code>ENVIRONMENT=production\nDEBUG=false\nLOG_LEVEL=WARNING\nLOG_CONSOLE_FORMAT=json\nRATE_LIMIT_PER_MINUTE=60\n\n# Use strong secrets\nSECRET_KEY=&lt;generated-with-openssl-rand&gt;\nKEYCLOAK_CLIENT_SECRET=&lt;from-keycloak-admin&gt;\n\n# Use production domains\nKEYCLOAK_BASE_URL=https://auth.example.com\nALLOWED_HOSTS=[\"api.example.com\"]\nCORS_ORIGINS=[\"https://app.example.com\"]\n</code></pre>"},{"location":"getting-started/configuration/#keycloak-configuration","title":"Keycloak Configuration","text":""},{"location":"getting-started/configuration/#creating-a-realm","title":"Creating a Realm","text":"<ol> <li>Access Keycloak admin console: http://localhost:8080</li> <li>Login with admin credentials</li> <li>Create a new realm (e.g., \"development\")</li> <li>Configure realm settings</li> </ol>"},{"location":"getting-started/configuration/#creating-a-client","title":"Creating a Client","text":"<ol> <li>Go to Clients \u2192 Create</li> <li>Set Client ID: <code>fastapi-app</code></li> <li>Enable \"Client authentication\"</li> <li>Set Valid redirect URIs: <code>http://localhost:8000/*</code></li> <li>Set Web origins: <code>http://localhost:8000</code></li> <li>Save and copy the client secret</li> </ol>"},{"location":"getting-started/configuration/#creating-roles","title":"Creating Roles","text":"<ol> <li>Go to Realm roles \u2192 Create role</li> <li>Create roles: <code>admin</code>, <code>user</code>, <code>viewer</code></li> <li>Assign roles to users</li> </ol>"},{"location":"getting-started/configuration/#creating-users","title":"Creating Users","text":"<ol> <li>Go to Users \u2192 Add user</li> <li>Set username and email</li> <li>Go to Credentials tab \u2192 Set password</li> <li>Go to Role mapping \u2192 Assign roles</li> </ol>"},{"location":"getting-started/configuration/#rbac-configuration","title":"RBAC Configuration","text":"<p>Role-based access control is configured directly in handler code using decorators:</p> <p>WebSocket Handlers (<code>app/api/ws/handlers/</code>): <pre><code>@pkg_router.register(\n    PkgID.GET_AUTHORS,\n    json_schema=GetAuthorsModel,\n    roles=[\"get-authors\"]  # Define required roles here\n)\nasync def get_authors_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n</code></pre></p> <p>HTTP Endpoints (<code>app/api/http/</code>): <pre><code>from app.dependencies.permissions import require_roles\n\n@router.get(\n    \"/authors\",\n    dependencies=[Depends(require_roles(\"get-authors\"))]\n)\nasync def get_authors():\n    ...\n</code></pre></p> <p>No external configuration file needed - permissions are co-located with handler code.</p>"},{"location":"getting-started/configuration/#docker-compose-configuration","title":"Docker Compose Configuration","text":"<p>The <code>docker-compose.yml</code> file can be customized for different environments:</p>"},{"location":"getting-started/configuration/#development_1","title":"Development","text":"<pre><code>services:\n  hw-server:\n    volumes:\n      - .:/app  # Mount code for hot reload\n    command: uvicorn app:application --reload\n    environment:\n      - DEBUG=true\n</code></pre>"},{"location":"getting-started/configuration/#production_1","title":"Production","text":"<pre><code>services:\n  hw-server:\n    image: fastapi-app:latest  # Use built image\n    deploy:\n      replicas: 3\n      resources:\n        limits:\n          cpus: '2'\n          memory: 2G\n    environment:\n      - DEBUG=false\n</code></pre>"},{"location":"getting-started/configuration/#monitoring-configuration","title":"Monitoring Configuration","text":""},{"location":"getting-started/configuration/#prometheus-dockerprometheusprometheusyml","title":"Prometheus (docker/prometheus/prometheus.yml)","text":"<pre><code>global:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: 'fastapi'\n    static_configs:\n      - targets: ['hw-server:8000']\n</code></pre>"},{"location":"getting-started/configuration/#grafana-dockergrafanaprovisioning","title":"Grafana (docker/grafana/provisioning/)","text":"<p>Grafana is pre-configured with: - Data sources (Prometheus, Loki) - Dashboards (FastAPI Metrics, Application Logs, Keycloak Metrics) - Default admin credentials: admin/admin</p>"},{"location":"getting-started/configuration/#troubleshooting-configuration","title":"Troubleshooting Configuration","text":""},{"location":"getting-started/configuration/#check-current-configuration","title":"Check Current Configuration","text":"<pre><code># Inside the application\nuv run python -c \"from app.settings import settings; print(settings.model_dump())\"\n\n# Or use IPython\nmake ipython\n&gt;&gt;&gt; from app.settings import settings\n&gt;&gt;&gt; settings.DATABASE_URL\n</code></pre>"},{"location":"getting-started/configuration/#validate-environment-files","title":"Validate Environment Files","text":"<pre><code># Check if all required variables are set\ngrep -v '^#' .env | grep -v '^$' | sort\n\n# Validate docker environment files\nls -la docker/.*.env\n</code></pre>"},{"location":"getting-started/configuration/#common-issues","title":"Common Issues","text":"<p>Issue: <code>DATABASE_URL</code> not found <pre><code># Solution: Ensure .env file exists\ncp .env.example .env\n</code></pre></p> <p>Issue: Keycloak connection refused <pre><code># Solution: Ensure Keycloak is running\ndocker ps | grep keycloak\ndocker logs hw-keycloak\n</code></pre></p> <p>Issue: Redis connection error <pre><code># Solution: Check Redis is accessible\ndocker exec hw-redis redis-cli ping\n</code></pre></p>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Build your first endpoints</li> <li>Authentication Guide - Configure authentication</li> <li>Security Guide - Production security</li> <li>Deployment Guide - Deploy to production</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will walk you through setting up the FastAPI HTTP/WebSocket template for local development.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the following installed:</p> Requirement Version Purpose Python 3.13+ Application runtime Docker 24.0+ Containerization Docker Compose v2+ Service orchestration uv latest Python package manager Git latest Version control"},{"location":"getting-started/installation/#install-uv-python-package-manager","title":"Install uv (Python Package Manager)","text":"<pre><code># Install uv\npip install uv\n\n# Verify installation\nuv --version\n</code></pre>"},{"location":"getting-started/installation/#clone-the-repository","title":"Clone the Repository","text":"<pre><code># Clone the repository\ngit clone https://github.com/acikabubo/fastapi-http-websocket.git\ncd fastapi-http-websocket\n\n# Or if using as a template\ncookiecutter gh:acikabubo/fastapi-http-websocket\n</code></pre>"},{"location":"getting-started/installation/#install-python-dependencies","title":"Install Python Dependencies","text":"<pre><code># Sync all dependencies\nuv sync\n\n# Sync with dev dependencies\nuv sync --all-groups\n\n# Activate virtual environment\nsource .venv/bin/activate  # Linux/macOS\n# OR\n.venv\\Scripts\\activate  # Windows\n</code></pre>"},{"location":"getting-started/installation/#start-infrastructure-services","title":"Start Infrastructure Services","text":"<p>The application requires several infrastructure services. Start them with Docker Compose:</p> <pre><code># Start all services in background\nmake start\n\n# Or using docker-compose directly\ndocker compose -f docker/docker-compose.yml up -d\n</code></pre> <p>This will start:</p> <ul> <li>PostgreSQL (port 5432) - Main database</li> <li>Redis (port 6379) - Cache and rate limiting</li> <li>Keycloak (port 8080) - Authentication server</li> <li>Prometheus (port 9090) - Metrics collection</li> <li>Grafana (port 3000) - Dashboards and visualization</li> <li>Loki (port 3100) - Log aggregation</li> <li>Grafana Alloy - Log collection agent</li> <li>Traefik (ports 80/443/8080) - Reverse proxy</li> </ul>"},{"location":"getting-started/installation/#verify-services","title":"Verify Services","text":"<pre><code># Check all services are running\ndocker ps\n\n# Check service health\ncurl http://localhost:8000/health  # Application (after starting)\ncurl http://localhost:8080/health  # Keycloak\ncurl http://localhost:9090/-/healthy  # Prometheus\n</code></pre>"},{"location":"getting-started/installation/#initialize-the-database","title":"Initialize the Database","text":"<p>Run database migrations to set up the schema:</p> <pre><code># Run migrations\nmake migrate\n\n# Or using alembic directly\nuv run alembic upgrade head\n\n# Verify current migration\nmake migration-current\n</code></pre>"},{"location":"getting-started/installation/#configure-keycloak","title":"Configure Keycloak","text":"<p>Keycloak is pre-configured with a realm export, but you need to verify the configuration:</p> <ol> <li>Access Keycloak Admin Console: http://localhost:8080</li> <li>Login with credentials from <code>docker/.kc_env</code>:</li> <li>Username: <code>admin</code></li> <li>Password: <code>admin</code> (change in production!)</li> <li>Verify Realm: Check that the <code>development</code> realm exists</li> <li>Verify Client: Check that the <code>fastapi-app</code> client is configured</li> </ol>"},{"location":"getting-started/installation/#environment-configuration","title":"Environment Configuration","text":"<p>Create your environment file from the example:</p> <pre><code># Copy example environment file\ncp .env.example .env\n\n# Edit configuration\nnano .env  # or your preferred editor\n</code></pre>"},{"location":"getting-started/installation/#key-environment-variables","title":"Key Environment Variables","text":"<pre><code># Application\nENVIRONMENT=development\nDEBUG=true\nLOG_LEVEL=DEBUG\n\n# Database\nDATABASE_URL=postgresql+asyncpg://fastapi:fastapi@localhost:5432/fastapi\n\n# Redis\nREDIS_IP=localhost\nREDIS_PORT=6379\nMAIN_REDIS_DB=0\nAUTH_REDIS_DB=1\n\n# Keycloak\nKEYCLOAK_BASE_URL=http://localhost:8080\nKEYCLOAK_REALM=development\nKEYCLOAK_CLIENT_ID=fastapi-app\nKEYCLOAK_CLIENT_SECRET=your-client-secret\n\n# Rate Limiting\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_PER_MINUTE=60\nWS_MAX_CONNECTIONS_PER_USER=5\n</code></pre>"},{"location":"getting-started/installation/#start-the-application","title":"Start the Application","text":""},{"location":"getting-started/installation/#option-1-using-make-recommended","title":"Option 1: Using Make (Recommended)","text":"<pre><code># Start with auto-reload\nmake serve\n</code></pre>"},{"location":"getting-started/installation/#option-2-using-uvicorn-directly","title":"Option 2: Using Uvicorn Directly","text":"<pre><code># Start application\nuv run uvicorn app:application --host 0.0.0.0 --port 8000 --reload\n</code></pre>"},{"location":"getting-started/installation/#option-3-using-docker-shell","title":"Option 3: Using Docker Shell","text":"<pre><code># Enter development container\nmake shell\n\n# Inside container\nuvicorn app:application --host 0.0.0.0 --reload\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":""},{"location":"getting-started/installation/#check-application-health","title":"Check Application Health","text":"<pre><code>curl http://localhost:8000/health\n</code></pre> <p>Expected response: <pre><code>{\n  \"status\": \"ok\",\n  \"version\": \"0.1.0\",\n  \"environment\": \"development\"\n}\n</code></pre></p>"},{"location":"getting-started/installation/#access-api-documentation","title":"Access API Documentation","text":"<p>Open in your browser:</p> <ul> <li>OpenAPI/Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> </ul>"},{"location":"getting-started/installation/#access-monitoring-dashboards","title":"Access Monitoring Dashboards","text":"<ul> <li>Grafana: http://localhost:3000 (admin/admin)</li> <li>FastAPI Metrics dashboard</li> <li>Application Logs dashboard</li> <li>Keycloak Metrics dashboard</li> <li>Prometheus: http://localhost:9090</li> <li>Traefik Dashboard: http://localhost:8080</li> </ul>"},{"location":"getting-started/installation/#development-tools","title":"Development Tools","text":""},{"location":"getting-started/installation/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Install pre-commit hooks for code quality:</p> <pre><code># Install pre-commit\nuv run pre-commit install\n\n# Run hooks manually\nuv run pre-commit run --all-files\n</code></pre>"},{"location":"getting-started/installation/#code-quality-checks","title":"Code Quality Checks","text":"<pre><code># Run linter\nmake ruff-check\n\n# Run security scan\nmake bandit-scan\n\n# Check for dead code\nmake dead-code-scan\n\n# Run tests\nmake test\n\n# Run tests with coverage\nmake test-coverage\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#services-not-starting","title":"Services Not Starting","text":"<pre><code># Check logs\ndocker compose -f docker/docker-compose.yml logs\n\n# Restart services\nmake stop\nmake start\n</code></pre>"},{"location":"getting-started/installation/#database-connection-issues","title":"Database Connection Issues","text":"<pre><code># Check PostgreSQL is running\ndocker ps | grep postgres\n\n# Check database logs\ndocker logs hw-db\n\n# Recreate database\ndocker compose -f docker/docker-compose.yml down -v\ndocker compose -f docker/docker-compose.yml up -d hw-db\nmake migrate\n</code></pre>"},{"location":"getting-started/installation/#port-already-in-use","title":"Port Already in Use","text":"<pre><code># Check what's using the port\nsudo lsof -i :8000  # Linux/macOS\nnetstat -ano | findstr :8000  # Windows\n\n# Stop conflicting process or change port\nuvicorn app:application --port 8001\n</code></pre>"},{"location":"getting-started/installation/#redis-connection-issues","title":"Redis Connection Issues","text":"<pre><code># Test Redis connection\ndocker exec hw-redis redis-cli ping\n\n# Check Redis logs\ndocker logs hw-redis\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that you have everything installed:</p> <ol> <li>Quick Start Guide - Create your first endpoints</li> <li>Configuration Guide - Customize your setup</li> <li>Authentication Guide - Set up auth</li> </ol>"},{"location":"getting-started/installation/#clean-up","title":"Clean Up","text":"<p>When you're done developing:</p> <pre><code># Stop all services\nmake stop\n\n# Remove all containers and volumes\ndocker compose -f docker/docker-compose.yml down -v\n\n# Clean up Docker resources\ndocker system prune -f\n</code></pre>"},{"location":"getting-started/installation/#additional-resources","title":"Additional Resources","text":"<ul> <li>Development Guide</li> <li>Testing Guide</li> <li>Docker Deployment</li> <li>Troubleshooting Guide</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get your first HTTP and WebSocket endpoints running in 10 minutes.</p> <p>Prerequisites</p> <p>Make sure you've completed the Installation guide before proceeding.</p>"},{"location":"getting-started/quickstart/#start-the-application","title":"Start the Application","text":"<pre><code># Start infrastructure services\nmake start\n\n# Start the application with auto-reload\nmake serve\n</code></pre> <p>The application should now be running at http://localhost:8000</p>"},{"location":"getting-started/quickstart/#your-first-http-endpoint","title":"Your First HTTP Endpoint","text":"<p>Let's create a simple HTTP endpoint to manage books.</p>"},{"location":"getting-started/quickstart/#1-create-the-model","title":"1. Create the Model","text":"<p>Create <code>app/models/book.py</code>:</p> <pre><code>from sqlmodel import Field, SQLModel\n\nclass Book(SQLModel, table=True):\n    \"\"\"Book model.\"\"\"\n\n    id: int | None = Field(default=None, primary_key=True)\n    title: str = Field(index=True)\n    author: str\n    isbn: str = Field(unique=True)\n    published_year: int\n</code></pre>"},{"location":"getting-started/quickstart/#2-create-a-migration","title":"2. Create a Migration","text":"<pre><code>make migration msg=\"add book model\"\nmake migrate\n</code></pre>"},{"location":"getting-started/quickstart/#3-create-the-repository","title":"3. Create the Repository","text":"<p>Create <code>app/repositories/book_repository.py</code>:</p> <pre><code>from app.models.book import Book\nfrom app.repositories.base_repository import BaseRepository\n\nclass BookRepository(BaseRepository[Book]):\n    \"\"\"Repository for Book operations.\"\"\"\n    pass\n</code></pre>"},{"location":"getting-started/quickstart/#4-create-http-endpoints","title":"4. Create HTTP Endpoints","text":"<p>Create <code>app/api/http/book.py</code>:</p> <pre><code>from fastapi import APIRouter, Depends, HTTPException, status\nfrom app.models.book import Book\nfrom app.repositories.book_repository import BookRepository\nfrom app.storage.db import async_session\n\nrouter = APIRouter(prefix=\"/books\", tags=[\"books\"])\n\n@router.post(\"/\", response_model=Book, status_code=status.HTTP_201_CREATED)\nasync def create_book(book: Book):\n    \"\"\"Create a new book.\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        return await repo.create(book)\n\n@router.get(\"/\", response_model=list[Book])\nasync def get_books():\n    \"\"\"Get all books.\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        return await repo.get_all()\n\n@router.get(\"/{book_id}\", response_model=Book)\nasync def get_book(book_id: int):\n    \"\"\"Get book by ID.\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        book = await repo.get_by_id(book_id)\n        if not book:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"Book not found\"\n            )\n        return book\n</code></pre>"},{"location":"getting-started/quickstart/#5-test-the-endpoint","title":"5. Test the Endpoint","text":"<pre><code># Create a book\ncurl -X POST http://localhost:8000/books/ \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"title\": \"Clean Code\",\n    \"author\": \"Robert C. Martin\",\n    \"isbn\": \"978-0132350884\",\n    \"published_year\": 2008\n  }'\n\n# Get all books\ncurl http://localhost:8000/books/\n\n# Get specific book\ncurl http://localhost:8000/books/1\n</code></pre> <p>Or visit the interactive API docs: http://localhost:8000/docs</p>"},{"location":"getting-started/quickstart/#your-first-websocket-handler","title":"Your First WebSocket Handler","text":"<p>Let's create a WebSocket handler to get books.</p>"},{"location":"getting-started/quickstart/#1-add-package-id","title":"1. Add Package ID","text":"<p>Edit <code>app/api/ws/constants.py</code>:</p> <pre><code>class PkgID(IntEnum):\n    \"\"\"WebSocket package IDs.\"\"\"\n    # ... existing handlers ...\n    GET_BOOKS = 100\n    CREATE_BOOK = 101\n</code></pre>"},{"location":"getting-started/quickstart/#2-create-websocket-handler","title":"2. Create WebSocket Handler","text":"<p>Create <code>app/api/ws/handlers/book.py</code>:</p> <pre><code>from app.routing import pkg_router\nfrom app.api.ws.constants import PkgID\nfrom app.schemas.models import RequestModel, ResponseModel\nfrom app.repositories.book_repository import BookRepository\nfrom app.storage.db import async_session\n\n@pkg_router.register(PkgID.GET_BOOKS)\nasync def get_books_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Get all books via WebSocket.\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        books = await repo.get_all()\n\n        return ResponseModel.success(\n            request.pkg_id,\n            request.req_id,\n            data=[book.model_dump() for book in books]\n        )\n\n@pkg_router.register(PkgID.CREATE_BOOK)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Create a book via WebSocket.\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        book_data = request.data\n        book = Book(**book_data)\n        created_book = await repo.create(book)\n\n        return ResponseModel.success(\n            request.pkg_id,\n            request.req_id,\n            data=created_book.model_dump()\n        )\n</code></pre>"},{"location":"getting-started/quickstart/#3-test-websocket-handler","title":"3. Test WebSocket Handler","text":"<p>Using <code>wscat</code> or any WebSocket client:</p> <pre><code># Install wscat (if needed)\nnpm install -g wscat\n\n# Connect (replace TOKEN with actual JWT token from Keycloak)\nwscat -c \"ws://localhost:8000/web?access_token=YOUR_TOKEN\"\n\n# Send message\n{\"pkg_id\": 100, \"req_id\": \"test-001\", \"data\": {}}\n\n# Expected response\n{\n  \"pkg_id\": 100,\n  \"req_id\": \"test-001\",\n  \"status_code\": 0,\n  \"data\": [...]\n}\n</code></pre>"},{"location":"getting-started/quickstart/#add-rbac-permissions","title":"Add RBAC Permissions","text":"<p>Add role requirements directly to your handler decorators:</p> <p>WebSocket Handler (<code>app/api/ws/handlers/book_handler.py</code>): <pre><code>@pkg_router.register(\n    PkgID.GET_BOOKS,\n    json_schema=GetBooksModel,\n    roles=[\"get-books\"]  # Define required roles\n)\nasync def get_books_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n\n@pkg_router.register(\n    PkgID.CREATE_BOOK,\n    json_schema=CreateBookModel,\n    roles=[\"create-book\", \"admin\"]  # Multiple roles = user must have ALL\n)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    ...\n</code></pre></p> <p>HTTP Endpoint (<code>app/api/http/book.py</code>): <pre><code>from app.dependencies.permissions import require_roles\n\n@router.get(\n    \"/books\",\n    dependencies=[Depends(require_roles(\"get-books\"))]\n)\nasync def get_books():\n    ...\n\n@router.post(\n    \"/books\",\n    dependencies=[Depends(require_roles(\"create-book\", \"admin\"))]\n)\nasync def create_book(book: Book):\n    ...\n</code></pre></p> <p>Now only users with appropriate roles can access these endpoints!</p>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Congratulations! You've created your first HTTP and WebSocket endpoints. Next, learn about:</p> <ul> <li>Authentication - Secure your endpoints</li> <li>Rate Limiting - Protect against abuse</li> <li>Database Operations - Advanced database patterns</li> <li>Testing - Write tests for your endpoints</li> </ul>"},{"location":"getting-started/quickstart/#see-also","title":"See Also","text":"<ul> <li>HTTP API Guide</li> <li>WebSocket API Guide</li> <li>Design Patterns</li> </ul>"},{"location":"guides/","title":"User Guides","text":"<p>Step-by-step guides for common tasks and features.</p>"},{"location":"guides/#available-guides","title":"Available Guides","text":"<ul> <li>Authentication - Keycloak integration and JWT tokens</li> <li>HTTP Endpoints - Creating REST API endpoints</li> <li>WebSocket Handlers - Building WebSocket handlers</li> <li>Rate Limiting - Implementing rate limits</li> <li>Circuit Breaker - Resilience pattern for external services</li> <li>Audit Logging - Tracking user actions</li> <li>Database Operations - Working with PostgreSQL</li> <li>Monitoring - Observability and metrics</li> </ul>"},{"location":"guides/audit-logging/","title":"User Action Logging and Audit Trail","text":"<p>This guide explains how to use and maintain the user action logging (audit logging) system in this FastAPI application.</p>"},{"location":"guides/audit-logging/#overview","title":"Overview","text":"<p>The audit logging system tracks user activities for security, compliance, debugging, and analytics purposes. It captures comprehensive information about user actions across both HTTP and WebSocket endpoints.</p>"},{"location":"guides/audit-logging/#architecture","title":"Architecture","text":"<p>The system uses a database-first approach with the following components:</p> <ul> <li>UserAction Model (<code>app/models/user_action.py</code>): SQLModel storing audit records</li> <li>AuditLogger (<code>app/utils/audit_logger.py</code>): Utility functions for logging actions</li> <li>AuditMiddleware (<code>app/middlewares/audit_middleware.py</code>): HTTP request logging</li> <li>WebSocket Integration: Manual logging in WebSocket handlers</li> </ul>"},{"location":"guides/audit-logging/#what-gets-logged","title":"What Gets Logged","text":""},{"location":"guides/audit-logging/#essential-information","title":"Essential Information","text":"<p>Every action log captures:</p> Field Description Example <code>timestamp</code> When the action occurred (UTC) <code>2025-11-27T14:32:15.123456Z</code> <code>user_id</code> Keycloak user ID <code>sub</code> field from JWT <code>username</code> Human-readable username <code>preferred_username</code> <code>user_roles</code> Roles at time of action <code>[\"admin\", \"user\"]</code> <code>action_type</code> HTTP method or WebSocket PkgID <code>POST</code>, <code>GET</code>, <code>PkgID.GET_AUTHORS</code> <code>resource</code> Resource accessed/modified <code>/api/authors/123</code>, <code>Author:123</code> <code>outcome</code> Result of the action <code>success</code>, <code>error</code>, <code>permission_denied</code> <code>ip_address</code> Client IP (proxy-aware) <code>192.168.1.100</code> <code>user_agent</code> Browser/client info <code>Mozilla/5.0 ...</code>"},{"location":"guides/audit-logging/#optional-contextual-data","title":"Optional Contextual Data","text":"<ul> <li><code>request_id</code>: Correlation ID for distributed tracing</li> <li><code>request_data</code>: Sanitized request payload</li> <li><code>response_status</code>: HTTP status code</li> <li><code>error_message</code>: Error details for failures</li> <li><code>duration_ms</code>: Request processing time</li> </ul>"},{"location":"guides/audit-logging/#using-the-audit-logger","title":"Using the Audit Logger","text":""},{"location":"guides/audit-logging/#in-http-endpoints","title":"In HTTP Endpoints","text":"<p>HTTP requests are automatically logged by <code>AuditMiddleware</code>. No manual logging required for standard endpoints.</p> <pre><code>from fastapi import APIRouter\nfrom app.dependencies import AuthorRepoDep\n\nrouter = APIRouter()\n\n@router.post(\"/authors\")\nasync def create_author(author: AuthorCreate, repo: AuthorRepoDep):\n    # Middleware automatically logs this action\n    return await repo.create(author)\n</code></pre>"},{"location":"guides/audit-logging/#in-websocket-handlers","title":"In WebSocket Handlers","text":"<p>WebSocket actions require manual logging:</p> <pre><code>from app.utils.audit_logger import log_user_action\nfrom app.api.ws.models import RequestModel, ResponseModel\nfrom app.storage.db import async_session\nfrom app.repositories.author_repository import AuthorRepository\n\n@pkg_router.register(PkgID.CREATE_AUTHOR, json_schema=CreateAuthorSchema)\nasync def create_author_handler(request: RequestModel) -&gt; ResponseModel:\n    try:\n        # Perform action using Repository pattern\n        async with async_session() as session:\n            repo = AuthorRepository(session)\n            author = await repo.create(Author(**request.data))\n\n        # Log successful action\n        await log_user_action(\n            user_id=request.user.id,\n            username=request.user.username,\n            user_roles=request.user.roles,\n            action_type=f\"WS:{request.pkg_id.name}\",\n            resource=f\"Author:{author.id}\",\n            outcome=\"success\",\n            ip_address=request.ip_address,\n            request_id=request.req_id,\n            request_data=request.data,\n            duration_ms=request.duration_ms\n        )\n\n        return ResponseModel.success(...)\n    except Exception as e:\n        # Log failed action\n        await log_user_action(\n            user_id=request.user.id,\n            username=request.user.username,\n            user_roles=request.user.roles,\n            action_type=f\"WS:{request.pkg_id.name}\",\n            resource=\"Author\",\n            outcome=\"error\",\n            error_message=str(e),\n            ip_address=request.ip_address,\n            request_id=request.req_id\n        )\n        raise\n</code></pre>"},{"location":"guides/audit-logging/#logging-permission-denials","title":"Logging Permission Denials","text":"<p>RBAC permission denials are automatically logged by the middleware and WebSocket permission checks.</p>"},{"location":"guides/audit-logging/#sensitive-data-handling","title":"Sensitive Data Handling","text":""},{"location":"guides/audit-logging/#never-log","title":"Never Log","text":"<p>\u26a0\ufe0f DO NOT log these fields: - Passwords or password hashes - Full credit card numbers - Personal health information (PHI) - Full access tokens or API keys - Social security numbers or national IDs - Private encryption keys</p>"},{"location":"guides/audit-logging/#data-sanitization","title":"Data Sanitization","text":"<p>The <code>sanitize_data()</code> function automatically redacts sensitive fields:</p> <pre><code>from app.utils.audit_logger import sanitize_data\n\ndata = {\n    \"username\": \"john\",\n    \"password\": \"secret123\",\n    \"email\": \"john@example.com\",\n    \"token\": \"Bearer xyz...\"\n}\n\nsanitized = sanitize_data(data)\n# Result: {\n#     \"username\": \"john\",\n#     \"password\": \"[REDACTED]\",\n#     \"email\": \"john@example.com\",\n#     \"token\": \"[REDACTED]\"\n# }\n</code></pre> <p>Default redacted fields: - <code>password</code>, <code>passwd</code>, <code>pwd</code> - <code>token</code>, <code>access_token</code>, <code>refresh_token</code> - <code>secret</code>, <code>api_key</code>, <code>private_key</code> - <code>ssn</code>, <code>social_security_number</code> - <code>credit_card</code>, <code>card_number</code>, <code>cvv</code></p>"},{"location":"guides/audit-logging/#querying-audit-logs","title":"Querying Audit Logs","text":""},{"location":"guides/audit-logging/#using-the-api-admin-only","title":"Using the API (Admin Only)","text":"<pre><code># Get audit logs with filters\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/api/audit-logs?page=1&amp;per_page=20&amp;user_id=abc123&amp;outcome=error\"\n\n# Filter by date range\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/api/audit-logs?start_date=2025-01-01&amp;end_date=2025-01-31\"\n\n# Filter by action type\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  \"http://localhost:8000/api/audit-logs?action_type=POST\"\n</code></pre>"},{"location":"guides/audit-logging/#direct-database-queries","title":"Direct Database Queries","text":"<pre><code>from sqlmodel import select\nfrom app.models.user_action import UserAction\nfrom app.storage.db import async_session\n\n# Get all actions by a user in date range\nasync with async_session() as session:\n    stmt = (\n        select(UserAction)\n        .where(UserAction.user_id == \"user123\")\n        .where(UserAction.timestamp &gt;= start_date)\n        .where(UserAction.timestamp &lt;= end_date)\n        .order_by(UserAction.timestamp.desc())\n    )\n    actions = (await session.exec(stmt)).all()\n\n# Get failed login attempts\nasync with async_session() as session:\n    stmt = (\n        select(UserAction)\n        .where(UserAction.action_type == \"POST\")\n        .where(UserAction.resource.like(\"%/auth/login%\"))\n        .where(UserAction.outcome == \"error\")\n        .order_by(UserAction.timestamp.desc())\n        .limit(100)\n    )\n    failed_logins = (await session.exec(stmt)).all()\n\n# Get permission denied events\nasync with async_session() as session:\n    stmt = (\n        select(UserAction)\n        .where(UserAction.outcome == \"permission_denied\")\n        .order_by(UserAction.timestamp.desc())\n    )\n    denied = (await session.exec(stmt)).all()\n\n# Get actions on a specific resource\nasync with async_session() as session:\n    stmt = (\n        select(UserAction)\n        .where(UserAction.resource == \"Author:123\")\n        .order_by(UserAction.timestamp.desc())\n    )\n    author_actions = (await session.exec(stmt)).all()\n</code></pre>"},{"location":"guides/audit-logging/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guides/audit-logging/#1-security-incident-investigation","title":"1. Security Incident Investigation","text":"<p>Track what a compromised user did:</p> <pre><code>actions = await session.exec(\n    select(UserAction)\n    .where(UserAction.user_id == compromised_user_id)\n    .where(UserAction.timestamp &gt;= incident_start)\n    .where(UserAction.timestamp &lt;= incident_end)\n    .order_by(UserAction.timestamp.asc())\n)\n</code></pre>"},{"location":"guides/audit-logging/#2-failed-authentication-monitoring","title":"2. Failed Authentication Monitoring","text":"<p>Detect brute force attempts:</p> <pre><code>failed_logins = await session.exec(\n    select(UserAction)\n    .where(UserAction.resource.like(\"%/auth/login%\"))\n    .where(UserAction.outcome == \"error\")\n    .where(UserAction.timestamp &gt;= datetime.utcnow() - timedelta(hours=1))\n    .order_by(UserAction.timestamp.desc())\n)\n</code></pre>"},{"location":"guides/audit-logging/#3-user-activity-timeline","title":"3. User Activity Timeline","text":"<p>Generate activity report for a user:</p> <pre><code>timeline = await session.exec(\n    select(UserAction)\n    .where(UserAction.user_id == user_id)\n    .order_by(UserAction.timestamp.desc())\n    .limit(100)\n)\n</code></pre>"},{"location":"guides/audit-logging/#4-resource-access-audit","title":"4. Resource Access Audit","text":"<p>See who accessed a sensitive resource:</p> <pre><code>access_log = await session.exec(\n    select(UserAction)\n    .where(UserAction.resource.like(\"Author:sensitive_id%\"))\n    .order_by(UserAction.timestamp.desc())\n)\n</code></pre>"},{"location":"guides/audit-logging/#performance-considerations","title":"Performance Considerations","text":""},{"location":"guides/audit-logging/#database-indexes","title":"Database Indexes","text":"<p>The following indexes are created automatically:</p> <ul> <li><code>user_id</code> - Fast user-specific queries</li> <li><code>timestamp</code> - Date range filtering</li> <li><code>action_type</code> - Action type filtering</li> <li><code>outcome</code> - Error/success filtering</li> <li><code>request_id</code> - Request correlation</li> <li>Composite index on <code>(user_id, timestamp)</code> - Optimized user timeline queries</li> </ul>"},{"location":"guides/audit-logging/#best-practices","title":"Best Practices","text":"<ol> <li>Asynchronous logging: All logging is async to avoid blocking requests</li> <li>Pagination: Always use pagination when querying large result sets</li> <li>Date range limits: Limit queries to reasonable time windows (e.g., 30 days)</li> <li>Archival: Implement log archival for records older than retention period</li> <li>Partitioning: Consider table partitioning by date for very large deployments</li> </ol>"},{"location":"guides/audit-logging/#compliance-features","title":"Compliance Features","text":""},{"location":"guides/audit-logging/#gdpr","title":"GDPR","text":"<p>Right to be Forgotten: <pre><code># Delete all logs for a user\nawait session.exec(delete(UserAction).where(UserAction.user_id == user_id))\n</code></pre></p> <p>Data Export: <pre><code># Export user's activity history\nactions = await session.exec(\n    select(UserAction).where(UserAction.user_id == user_id)\n)\nexport_data = [action.model_dump() for action in actions]\n</code></pre></p>"},{"location":"guides/audit-logging/#hipaa","title":"HIPAA","text":"<ul> <li>All logs containing PHI are encrypted at rest (PostgreSQL encryption)</li> <li>6-year retention requirement enforced by archival policy</li> <li>Access to audit logs restricted to admin role</li> </ul>"},{"location":"guides/audit-logging/#sox","title":"SOX","text":"<ul> <li>Immutable logs (no UPDATE capability in the model)</li> <li>Financial transaction logs retained indefinitely</li> <li>Audit trail for all data modifications</li> </ul>"},{"location":"guides/audit-logging/#pci-dss","title":"PCI-DSS","text":"<ul> <li>Cardholder data access logged (if applicable)</li> <li>1-year minimum retention enforced</li> </ul>"},{"location":"guides/audit-logging/#configuration","title":"Configuration","text":"<p>Environment variables in <code>app/settings.py</code>:</p> <pre><code># Audit logging settings\nAUDIT_LOG_ENABLED: bool = True  # Enable/disable audit logging\nAUDIT_LOG_RETENTION_DAYS: int = 365  # Log retention period\nAUDIT_LOG_EXCLUDED_PATHS: list[str] = [\n    \"/health\",\n    \"/metrics\",\n    \"/docs\",\n    \"/openapi.json\"\n]\n</code></pre>"},{"location":"guides/audit-logging/#excluded-paths","title":"Excluded Paths","text":"<p>The following paths are not logged to reduce noise:</p> <ul> <li><code>/health</code> - Health check endpoint</li> <li><code>/metrics</code> - Prometheus metrics</li> <li><code>/docs</code> - API documentation</li> <li><code>/openapi.json</code> - OpenAPI schema</li> <li><code>/static/*</code> - Static files</li> </ul>"},{"location":"guides/audit-logging/#monitoring","title":"Monitoring","text":"<p>Prometheus metrics track audit logging performance:</p> <pre><code># Total audit logs created\naudit_logs_total{outcome}\n\n# Audit log creation duration\naudit_log_duration_seconds\n\n# Audit log errors\naudit_log_errors_total{error_type}\n</code></pre>"},{"location":"guides/audit-logging/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/audit-logging/#logs-not-appearing","title":"Logs not appearing","text":"<ol> <li>Check <code>AUDIT_LOG_ENABLED</code> setting</li> <li>Verify user is authenticated (unauthenticated requests not logged)</li> <li>Check if path is in <code>AUDIT_LOG_EXCLUDED_PATHS</code></li> <li>Review application logs for errors</li> </ol>"},{"location":"guides/audit-logging/#performance-issues","title":"Performance issues","text":"<ol> <li>Verify database indexes exist</li> <li>Check query date ranges (avoid unbounded queries)</li> <li>Use pagination for large result sets</li> <li>Consider archiving old logs</li> </ol>"},{"location":"guides/audit-logging/#storage-growth","title":"Storage growth","text":"<ol> <li>Implement log archival (move old logs to cold storage)</li> <li>Adjust retention policy</li> <li>Enable log compression</li> <li>Consider external logging service for high-volume scenarios</li> </ol>"},{"location":"guides/audit-logging/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements to consider:</p> <ul> <li>Log streaming: Real-time log streaming to SIEM tools</li> <li>Anomaly detection: ML-based detection of unusual patterns</li> <li>Log encryption: Per-record encryption for sensitive actions</li> <li>Export formats: CSV/JSON export functionality</li> <li>Compliance reports: Automated compliance report generation</li> <li>Log integrity: Cryptographic checksums to detect tampering</li> </ul>"},{"location":"guides/audit-logging/#related-documentation","title":"Related Documentation","text":"<ul> <li>Authentication Guide</li> <li>Testing Guide</li> <li>Database Migrations</li> </ul>"},{"location":"guides/authentication/","title":"Authentication Guide","text":"<p>Complete guide to authentication including HTTP and WebSocket flows, RBAC, token caching, circuit breakers, and security best practices.</p>"},{"location":"guides/authentication/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Quick Start</li> <li>Configuration</li> <li>HTTP Authentication</li> <li>WebSocket Authentication</li> <li>Role-Based Access Control (RBAC)</li> <li>Token Caching</li> <li>Debug Mode</li> <li>Prometheus Metrics</li> <li>Circuit Breaker</li> <li>Security Best Practices</li> <li>Troubleshooting</li> <li>API Reference</li> </ol>"},{"location":"guides/authentication/#overview","title":"Overview","text":"<p>The application uses Keycloak for authentication with JWT tokens. Authentication is handled by the <code>AuthBackend</code> class which integrates with FastAPI's authentication middleware.</p>"},{"location":"guides/authentication/#architecture","title":"Architecture","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant FastAPI\n    participant AuthBackend\n    participant TokenCache\n    participant Keycloak\n\n    Client-&gt;&gt;FastAPI: Request + JWT Token\n    FastAPI-&gt;&gt;AuthBackend: Authenticate\n    AuthBackend-&gt;&gt;TokenCache: Check cache\n    alt Cache Hit\n        TokenCache--&gt;&gt;AuthBackend: Cached claims\n    else Cache Miss\n        AuthBackend-&gt;&gt;Keycloak: Validate token\n        Keycloak--&gt;&gt;AuthBackend: Token claims\n        AuthBackend-&gt;&gt;TokenCache: Cache claims\n    end\n    AuthBackend--&gt;&gt;FastAPI: UserModel\n    FastAPI--&gt;&gt;Client: Response</code></pre>"},{"location":"guides/authentication/#key-components","title":"Key Components","text":"<ul> <li>AuthBackend (<code>app/auth.py</code>): Validates JWT tokens from Authorization header or query parameters</li> <li>KeycloakManager (<code>app/managers/keycloak_manager.py</code>): Singleton managing Keycloak client instances</li> <li>RBACManager (<code>app/managers/rbac_manager.py</code>): Role-based access control enforcement</li> <li>Token Cache (<code>app/utils/token_cache.py</code>): Redis-based caching of decoded JWT claims</li> <li>UserModel (<code>app/schemas/user.py</code>): User data extracted from JWT claims</li> </ul>"},{"location":"guides/authentication/#supported-auth-flows","title":"Supported Auth Flows","text":"<ol> <li>HTTP Authentication: JWT token in <code>Authorization: Bearer &lt;token&gt;</code> header</li> <li>WebSocket Authentication: JWT token in query parameter <code>?Authorization=Bearer%20&lt;token&gt;</code></li> </ol>"},{"location":"guides/authentication/#quick-start","title":"Quick Start","text":""},{"location":"guides/authentication/#1-get-a-token-from-keycloak","title":"1. Get a Token from Keycloak","text":"<pre><code># Using curl\nTOKEN=$(curl -X POST \"http://localhost:8080/realms/myrealm/protocol/openid-connect/token\" \\\n  -d \"client_id=myclient\" \\\n  -d \"client_secret=your-client-secret\" \\\n  -d \"username=testuser\" \\\n  -d \"password=password\" \\\n  -d \"grant_type=password\" | jq -r '.access_token')\n</code></pre>"},{"location":"guides/authentication/#2-test-http-endpoint","title":"2. Test HTTP Endpoint","text":"<pre><code>curl -H \"Authorization: Bearer $TOKEN\" http://localhost:8000/api/authors\n</code></pre>"},{"location":"guides/authentication/#3-test-websocket-connection","title":"3. Test WebSocket Connection","text":"<pre><code>const token = 'Bearer eyJhbGc...';\nconst wsUrl = `ws://localhost:8000/web?Authorization=${encodeURIComponent(token)}`;\nconst ws = new WebSocket(wsUrl);\n\nws.onopen = () =&gt; console.log('Authenticated!');\n</code></pre>"},{"location":"guides/authentication/#configuration","title":"Configuration","text":""},{"location":"guides/authentication/#environment-variables","title":"Environment Variables","text":"Variable Description Required Default <code>KEYCLOAK_BASE_URL</code> Keycloak server URL Yes - <code>KEYCLOAK_REALM</code> Keycloak realm name Yes - <code>KEYCLOAK_CLIENT_ID</code> OAuth client ID Yes - <code>KEYCLOAK_CLIENT_SECRET</code> OAuth client secret Yes - <code>KEYCLOAK_ADMIN_USERNAME</code> Keycloak admin username Yes - <code>KEYCLOAK_ADMIN_PASSWORD</code> Keycloak admin password Yes - <code>CIRCUIT_BREAKER_ENABLED</code> Enable circuit breaker for Keycloak No <code>true</code> <code>KEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX</code> Open circuit after N failures No <code>5</code> <code>KEYCLOAK_CIRCUIT_BREAKER_TIMEOUT</code> Circuit open duration (seconds) No <code>60</code>"},{"location":"guides/authentication/#example-env-file","title":"Example .env File","text":"<pre><code># Production\nKEYCLOAK_BASE_URL=https://keycloak.example.com\nKEYCLOAK_REALM=production\nKEYCLOAK_CLIENT_ID=prod-client\nKEYCLOAK_CLIENT_SECRET=&lt;strong-secret&gt;\n</code></pre>"},{"location":"guides/authentication/#http-authentication","title":"HTTP Authentication","text":""},{"location":"guides/authentication/#token-validation-flow","title":"Token Validation Flow","text":"<pre><code>flowchart TD\n    A[HTTP Request] --&gt; B{Authorization header?}\n    B --&gt;|No| C{Path excluded?}\n    C --&gt;|Yes| D[Allow request]\n    C --&gt;|No| E[401 Unauthorized]\n    B --&gt;|Yes| F[Extract token]\n    F --&gt; G[Check token cache]\n    G --&gt;|Cache hit| H[Return cached claims]\n    G --&gt;|Cache miss| I[Validate with Keycloak]\n    I --&gt;|Valid| J[Cache claims + Return]\n    I --&gt;|Invalid| K[401 Unauthorized]\n    J --&gt; L[Create UserModel]\n    H --&gt; L\n    L --&gt; M{Has required roles?}\n    M --&gt;|No| N[403 Forbidden]\n    M --&gt;|Yes| O[Process request]</code></pre>"},{"location":"guides/authentication/#protected-endpoints","title":"Protected Endpoints","text":"<pre><code>from fastapi import APIRouter, Depends\nfrom app.dependencies.permissions import require_roles\n\nrouter = APIRouter()\n\n# Any authenticated user\n@router.get(\"/authenticated\")\nasync def authenticated_endpoint(request: Request):\n    user: UserModel = request.user\n    return {\"username\": user.username}\n\n# Specific roles required (user must have ALL)\n@router.get(\"/admin\", dependencies=[Depends(require_roles(\"admin\"))])\nasync def admin_endpoint():\n    return {\"message\": \"Admin access\"}\n</code></pre>"},{"location":"guides/authentication/#excluded-paths","title":"Excluded Paths","text":"<p>Configured via <code>EXCLUDED_PATHS</code> regex in <code>app/settings.py</code>:</p> <pre><code>EXCLUDED_PATHS: list[str] = [\n    r\"^/docs.*\",      # API documentation\n    r\"^/metrics$\",    # Prometheus metrics\n    r\"^/health$\",     # Health check\n]\n</code></pre>"},{"location":"guides/authentication/#websocket-authentication","title":"WebSocket Authentication","text":""},{"location":"guides/authentication/#token-in-query-parameters","title":"Token in Query Parameters","text":"<p>\u26a0\ufe0f IMPORTANT: WebSocket connections use tokens in query parameters due to browser limitations (cannot send custom headers during handshake).</p> <pre><code>// \u274c Not supported by WebSocket API\nconst ws = new WebSocket('wss://api.example.com/web', {\n  headers: { 'Authorization': 'Bearer token' }\n});\n\n// \u2705 Must use query parameters\nconst token = await getAccessToken();\nconst wsUrl = `wss://api.example.com/web?Authorization=${encodeURIComponent(token)}`;\nconst ws = new WebSocket(wsUrl);\n</code></pre>"},{"location":"guides/authentication/#security-implications","title":"Security Implications","text":"<p>Risks: - Tokens appear in server access logs - Tokens stored in browser history - Potential proxy caching</p> <p>Mitigations (already implemented): - \u2705 Always use WSS (WebSocket over TLS) - \u2705 Short-lived tokens (5 minutes default) - \u2705 Origin validation for CSRF protection - \u2705 Referrer-Policy header prevents leakage</p>"},{"location":"guides/authentication/#client-best-practices","title":"Client Best Practices","text":"<pre><code>// 1. Get fresh token before connecting\nconst token = await getAccessToken();\n\n// 2. Encode properly\nconst wsUrl = `wss://api.example.com/web?Authorization=${encodeURIComponent('Bearer ' + token)}`;\n\n// 3. Connect\nconst ws = new WebSocket(wsUrl);\n\n// 4. Refresh for long connections\nsetInterval(async () =&gt; {\n    ws.close();\n    const newToken = await refreshAccessToken();\n    ws = new WebSocket(`wss://api.example.com/web?Authorization=${encodeURIComponent('Bearer ' + newToken)}`);\n}, 4 * 60 * 1000); // Every 4 minutes\n</code></pre>"},{"location":"guides/authentication/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":""},{"location":"guides/authentication/#rbac-decision-flow","title":"RBAC Decision Flow","text":"<pre><code>flowchart TD\n    A[Request] --&gt; B{Authenticated?}\n    B --&gt;|No| C[401 Unauthorized]\n    B --&gt;|Yes| D{Has ALL required roles?}\n    D --&gt;|No| E[403 Forbidden]\n    D --&gt;|Yes| F[Process request]</code></pre>"},{"location":"guides/authentication/#http-endpoints","title":"HTTP Endpoints","text":"<pre><code>from app.dependencies.permissions import require_roles\n\n# Single role\n@router.get(\"/users\", dependencies=[Depends(require_roles(\"view-users\"))])\nasync def list_users():\n    pass\n\n# Multiple roles (user must have ALL - AND logic)\n@router.delete(\n    \"/users/{id}\",\n    dependencies=[Depends(require_roles(\"admin\", \"delete-users\"))]\n)\nasync def delete_user(id: int):\n    pass\n</code></pre>"},{"location":"guides/authentication/#websocket-handlers","title":"WebSocket Handlers","text":"<pre><code>from app.routing import pkg_router\nfrom app.api.ws.constants import PkgID\n\n# With roles\n@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"admin\", \"delete-author\"]  # Must have ALL\n)\nasync def delete_author_handler(request: RequestModel):\n    pass\n\n# Public (no authentication)\n@pkg_router.register(PkgID.PUBLIC_DATA)\nasync def public_handler(request: RequestModel):\n    pass\n</code></pre>"},{"location":"guides/authentication/#role-extraction","title":"Role Extraction","text":"<p>Roles are extracted from JWT <code>resource_access</code> claim:</p> <pre><code>{\n  \"resource_access\": {\n    \"myclient\": {\n      \"roles\": [\"user\", \"admin\", \"view-authors\"]\n    }\n  }\n}\n</code></pre>"},{"location":"guides/authentication/#token-caching","title":"Token Caching","text":""},{"location":"guides/authentication/#how-it-works","title":"How It Works","text":"<p>JWT claims are cached in Redis to reduce CPU overhead:</p> <pre><code># Cache lookup (SHA-256 hash of token as key)\ncached_claims = await get_cached_token_claims(access_token)\nif cached_claims:\n    return cached_claims  # Cache hit\n\n# Validate with Keycloak\nclaims = await keycloak_manager.openid.a_decode_token(access_token)\n\n# Cache for future requests (TTL = token expiry - 30s)\nawait cache_token_claims(access_token, claims)\n</code></pre>"},{"location":"guides/authentication/#performance-impact","title":"Performance Impact","text":"<ul> <li>90% reduction in token decode CPU time</li> <li>85-95% cache hit rate for repeated requests</li> <li>85-95% reduction in Keycloak API load</li> </ul>"},{"location":"guides/authentication/#metrics","title":"Metrics","text":"<pre><code># Cache hit rate\nrate(token_cache_hits_total[5m]) /\n(rate(token_cache_hits_total[5m]) + rate(token_cache_misses_total[5m]))\n</code></pre>"},{"location":"guides/authentication/#prometheus-metrics","title":"Prometheus Metrics","text":""},{"location":"guides/authentication/#available-metrics","title":"Available Metrics","text":"<pre><code># Authentication attempts\nkeycloak_auth_attempts_total{status, method}\n\n# Token validation\nkeycloak_token_validation_total{status, reason}\n\n# Operation duration\nkeycloak_operation_duration_seconds{operation}\n\n# Token cache\ntoken_cache_hits_total\ntoken_cache_misses_total\n</code></pre>"},{"location":"guides/authentication/#alerts","title":"Alerts","text":"<pre><code># High auth failure rate\n- alert: HighAuthFailureRate\n  expr: |\n    rate(auth_backend_requests_total{outcome=\"denied\"}[5m]) /\n    rate(auth_backend_requests_total[5m]) &gt; 0.20\n  for: 3m\n</code></pre>"},{"location":"guides/authentication/#dashboard","title":"Dashboard","text":"<p>Grafana <code>fastapi-metrics</code> dashboard includes authentication panels for success rate, failures, cache hit rate, and latency.</p>"},{"location":"guides/authentication/#circuit-breaker","title":"Circuit Breaker","text":""},{"location":"guides/authentication/#states","title":"States","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Closed\n    Closed --&gt; Open: Failures &gt;= 5\n    Open --&gt; HalfOpen: After 60s\n    HalfOpen --&gt; Closed: Success\n    HalfOpen --&gt; Open: Failure</code></pre>"},{"location":"guides/authentication/#configuration_1","title":"Configuration","text":"<pre><code>CIRCUIT_BREAKER_ENABLED = True\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX = 5   # Open after 5 failures\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT = 60   # Keep open 60 seconds\n</code></pre>"},{"location":"guides/authentication/#protected-operations","title":"Protected Operations","text":"<ul> <li><code>KeycloakManager.login_async()</code> - User authentication</li> <li>Token validation calls to Keycloak</li> </ul> <p>Raises <code>CircuitBreakerError</code> when circuit is open (Keycloak down).</p>"},{"location":"guides/authentication/#security-best-practices","title":"Security Best Practices","text":""},{"location":"guides/authentication/#token-handling","title":"Token Handling","text":"<p>DO: - \u2705 Use HTTPS/WSS in production - \u2705 Keep tokens short-lived (5-15 minutes) - \u2705 Clear tokens from memory after use</p> <p>DON'T: - \u274c Log tokens in application logs - \u274c Store in localStorage (XSS risk) - \u274c Use long-lived access tokens</p>"},{"location":"guides/authentication/#rate-limiting-integration","title":"Rate Limiting Integration","text":"<pre><code>from app.utils.rate_limiter import RateLimiter\n\nrate_limiter = RateLimiter()\n\nasync def rate_limit_check(request: Request):\n    is_allowed, _ = await rate_limiter.check_rate_limit(\n        key=f\"user:{request.user.id}\",\n        limit=60,\n        window_seconds=60\n    )\n    if not is_allowed:\n        raise HTTPException(429, \"Rate limit exceeded\")\n</code></pre>"},{"location":"guides/authentication/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/authentication/#common-errors","title":"Common Errors","text":"<p>401 Unauthorized: \"token_expired\"</p> <p>Solution: Get fresh token from Keycloak.</p> <p>403 Forbidden: \"User does not have required roles\"</p> <p>Solution: Check user's roles in Keycloak, assign missing roles.</p> <p>WebSocket Connection Rejected</p> <p>Solution: Ensure token is URL-encoded and not expired.</p> <p>Circuit Breaker Open</p> <p>Solution: Check Keycloak connectivity, wait for circuit to close.</p>"},{"location":"guides/authentication/#debug-logging","title":"Debug Logging","text":"<pre><code>LOG_LEVEL=DEBUG\n</code></pre> <p>Shows token validation, cache hits/misses, RBAC checks.</p>"},{"location":"guides/authentication/#api-reference","title":"API Reference","text":""},{"location":"guides/authentication/#authbackend","title":"AuthBackend","text":"<pre><code>class AuthBackend:\n    async def authenticate(self, conn: HTTPConnection):\n        \"\"\"\n        Validate JWT token from Authorization header or query params.\n\n        Returns: (AuthCredentials, UserModel) or None\n        Raises: AuthenticationError for invalid/expired tokens\n        \"\"\"\n</code></pre>"},{"location":"guides/authentication/#keycloakmanager","title":"KeycloakManager","text":"<pre><code>class KeycloakManager:\n    async def login_async(self, username: str, password: str):\n        \"\"\"\n        Authenticate user with Keycloak.\n\n        Returns: {\"access_token\": \"...\", \"expires_in\": 300, ...}\n        Raises: KeycloakAuthenticationError, CircuitBreakerError\n        \"\"\"\n</code></pre>"},{"location":"guides/authentication/#rbacmanager","title":"RBACManager","text":"<pre><code>class RBACManager:\n    def check_ws_permission(self, pkg_id: int, user: UserModel):\n        \"\"\"\n        Check if user has required roles for WebSocket handler.\n\n        Raises: PermissionDeniedError if lacking roles\n        \"\"\"\n</code></pre>"},{"location":"guides/authentication/#require_roles","title":"require_roles()","text":"<pre><code>def require_roles(*roles: str):\n    \"\"\"\n    FastAPI dependency enforcing role requirements.\n\n    User must have ALL specified roles (AND logic).\n\n    Raises: HTTPException 401/403\n    \"\"\"\n</code></pre>"},{"location":"guides/authentication/#usermodel","title":"UserModel","text":"<pre><code>class UserModel:\n    id: str              # Keycloak user ID (sub claim)\n    username: str        # preferred_username claim\n    email: str | None\n    roles: list[str]     # Client roles from resource_access\n    expired_in: int      # Token expiration (exp claim)\n</code></pre>"},{"location":"guides/authentication/#related-documentation","title":"Related Documentation","text":"<ul> <li>HTTP API Reference</li> <li>WebSocket API Reference</li> <li>Monitoring Guide</li> <li>Rate Limiting Guide</li> <li>Architecture Overview</li> </ul>"},{"location":"guides/circuit-breaker/","title":"Circuit Breaker Pattern","text":"<p>The application implements the Circuit Breaker pattern to prevent cascading failures when external services (Keycloak and Redis) become unavailable or slow. This resilience pattern protects your application from repeatedly attempting operations that are likely to fail.</p>"},{"location":"guides/circuit-breaker/#overview","title":"Overview","text":"<p>The circuit breaker acts as a proxy between your application and external services. It monitors failures and can temporarily \"open\" (block requests) when failure thresholds are exceeded, giving the failing service time to recover.</p>"},{"location":"guides/circuit-breaker/#circuit-breaker-states","title":"Circuit Breaker States","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; CLOSED\n\n    CLOSED --&gt; OPEN: Failures \u2265 threshold\n    OPEN --&gt; HALF_OPEN: Timeout expires\n    HALF_OPEN --&gt; CLOSED: Request succeeds\n    HALF_OPEN --&gt; OPEN: Request fails\n\n    CLOSED: CLOSED\\n(Normal operation)\n    OPEN: OPEN\\n(Failing fast)\n    HALF_OPEN: HALF-OPEN\\n(Testing recovery)\n\n    note right of CLOSED\n        Requests pass through\n        Monitor failures\n        Increment counter on error\n    end note\n\n    note right of OPEN\n        Requests fail immediately\n        No service calls\n        Wait for timeout\n    end note\n\n    note right of HALF_OPEN\n        Allow single test request\n        Success \u2192 CLOSED\n        Failure \u2192 OPEN\n    end note</code></pre> <p>States:</p> <ul> <li>CLOSED (0): Normal operation - requests pass through</li> <li>Circuit breaker monitors failures</li> <li>Increments failure counter on each error</li> <li> <p>Opens when failure threshold (<code>fail_max</code>) is reached</p> </li> <li> <p>OPEN (1): Circuit is open - requests fail fast</p> </li> <li>All requests immediately return error (no attempt to call service)</li> <li>Prevents cascading failures and resource exhaustion</li> <li> <p>Automatic transition to HALF-OPEN after timeout period</p> </li> <li> <p>HALF-OPEN (2): Testing recovery - limited requests allowed</p> </li> <li>Allows a single test request through</li> <li>If successful \u2192 transition to CLOSED (service recovered)</li> <li>If failure \u2192 transition back to OPEN (service still unhealthy)</li> </ul>"},{"location":"guides/circuit-breaker/#protected-services","title":"Protected Services","text":""},{"location":"guides/circuit-breaker/#keycloak-authentication","title":"Keycloak (Authentication)","text":"<p>Protected Operations: - <code>keycloak_manager.login_async(username, password)</code> - User authentication - Token validation and decoding</p> <p>Configuration: <pre><code>KEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX = 5  # Open after 5 consecutive failures\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT = 60  # Stay open for 60 seconds\n</code></pre></p> <p>Behavior on Failure: - Circuit breaker opens after 5 failed login attempts - Returns <code>None</code> or raises <code>CircuitBreakerError</code> - Authentication fails gracefully (HTTP 401 or WebSocket permission denied) - Application remains available for unauthenticated endpoints</p>"},{"location":"guides/circuit-breaker/#redis-caching-rate-limiting","title":"Redis (Caching &amp; Rate Limiting)","text":"<p>Protected Operations: - <code>get_redis_connection(db)</code> - Get Redis connection - All rate limiting operations - Token cache operations - Session storage</p> <p>Configuration: <pre><code>REDIS_CIRCUIT_BREAKER_FAIL_MAX = 3   # Open after 3 consecutive failures\nREDIS_CIRCUIT_BREAKER_TIMEOUT = 30   # Stay open for 30 seconds\n</code></pre></p> <p>Behavior on Failure: - Circuit breaker opens after 3 failed connection attempts - Returns <code>None</code> from <code>get_redis_connection()</code> - Rate limiting operates in fail-open mode (allows requests) - Token caching falls back to direct token decode - Application degrades gracefully without Redis</p>"},{"location":"guides/circuit-breaker/#configuration","title":"Configuration","text":""},{"location":"guides/circuit-breaker/#environment-variables","title":"Environment Variables","text":"<p>Add to your <code>.env</code> file:</p> <pre><code># Enable/disable circuit breaker pattern (default: true)\nCIRCUIT_BREAKER_ENABLED=true\n\n# Keycloak circuit breaker settings\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX=5   # Failures before opening\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT=60   # Seconds to stay open\n\n# Redis circuit breaker settings\nREDIS_CIRCUIT_BREAKER_FAIL_MAX=3      # Failures before opening\nREDIS_CIRCUIT_BREAKER_TIMEOUT=30      # Seconds to stay open\n</code></pre>"},{"location":"guides/circuit-breaker/#tuning-guidelines","title":"Tuning Guidelines","text":"<p><code>FAIL_MAX</code> (Failure Threshold): - Lower values (2-3): Faster failure detection, more aggressive protection   - Use for: Non-critical services, high-availability requirements   - Risk: May open prematurely on transient errors</p> <ul> <li>Higher values (5-10): More tolerance for transient failures</li> <li>Use for: Critical services, unreliable networks</li> <li>Risk: Longer cascading failure window</li> </ul> <p><code>TIMEOUT</code> (Recovery Window): - Shorter timeouts (10-30s): Faster recovery attempts   - Use for: Services that recover quickly, low-traffic systems   - Risk: May reopen circuit before service is fully recovered</p> <ul> <li>Longer timeouts (60-120s): More time for service recovery</li> <li>Use for: Services with slow recovery, high-traffic systems</li> <li>Risk: Longer downtime if service recovers quickly</li> </ul> <p>Recommended Starting Values: <pre><code># Development\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX=10  # More tolerance\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT=30   # Faster recovery\n\n# Production\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX=5   # Balanced\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT=60   # Conservative\n\nREDIS_CIRCUIT_BREAKER_FAIL_MAX=3      # Fast detection\nREDIS_CIRCUIT_BREAKER_TIMEOUT=30      # Standard window\n</code></pre></p>"},{"location":"guides/circuit-breaker/#monitoring","title":"Monitoring","text":""},{"location":"guides/circuit-breaker/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>The circuit breaker exposes three key metrics:</p> <pre><code># Current circuit breaker state (0=closed, 1=open, 2=half_open)\ncircuit_breaker_state{service=\"keycloak\"}\ncircuit_breaker_state{service=\"redis\"}\n\n# Total state changes (track flapping)\ncircuit_breaker_state_changes_total{service=\"keycloak\",from_state=\"closed\",to_state=\"open\"}\n\n# Total failures detected by circuit breaker\ncircuit_breaker_failures_total{service=\"keycloak\"}\n</code></pre>"},{"location":"guides/circuit-breaker/#example-queries","title":"Example Queries","text":"<p>Check if any circuit breakers are open: <pre><code>circuit_breaker_state &gt; 0\n</code></pre></p> <p>Circuit breaker state changes in last hour: <pre><code>increase(circuit_breaker_state_changes_total[1h])\n</code></pre></p> <p>Failure rate per minute: <pre><code>rate(circuit_breaker_failures_total[1m])\n</code></pre></p> <p>Circuit breaker open duration: <pre><code>time() - (circuit_breaker_state == 1) * time()\n</code></pre></p>"},{"location":"guides/circuit-breaker/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Circuit breaker metrics are visualized in the FastAPI Metrics dashboard:</p> <ul> <li>Panel 28: Circuit Breaker State (Timeseries)</li> <li>Shows state transitions over time</li> <li> <p>Color-coded: Green (closed), Red (open), Yellow (half-open)</p> </li> <li> <p>Panel 29: Circuit Breaker Failures (Timeseries)</p> </li> <li>Tracks failure rates per service</li> <li> <p>Helps identify when services are unhealthy</p> </li> <li> <p>Panel 30: State Changes (Counter)</p> </li> <li>Total state transitions</li> <li>High values indicate flapping (service instability)</li> </ul> <p>Access: http://localhost:3000/d/fastapi-metrics</p>"},{"location":"guides/circuit-breaker/#alerts","title":"Alerts","text":"<p>Prometheus alerts are configured in <code>docker/prometheus/alerts.yml</code>:</p> <p><code>CircuitBreakerOpen</code> (Critical): - Triggers when circuit breaker stays open &gt; 2 minutes - Indicates prolonged service unavailability - Action: Check service health, review logs</p> <p><code>CircuitBreakerFlapping</code> (Warning): - Triggers when &gt; 10 state changes in 5 minutes - Indicates unstable service or misconfigured thresholds - Action: Tune circuit breaker settings or investigate service</p> <p><code>HighCircuitBreakerFailureRate</code> (Warning): - Triggers when failure rate &gt; 5/minute for 3 minutes - Indicates service degradation - Action: Monitor service, prepare for circuit opening</p>"},{"location":"guides/circuit-breaker/#error-handling","title":"Error Handling","text":""},{"location":"guides/circuit-breaker/#http-endpoints","title":"HTTP Endpoints","text":"<p>When a circuit breaker is open, HTTP endpoints return appropriate errors:</p> <pre><code>from app.managers.keycloak_manager import keycloak_manager\nfrom pybreaker import CircuitBreakerError\n\n@router.post(\"/login\")\nasync def login(credentials: Credentials):\n    try:\n        token = await keycloak_manager.login_async(\n            credentials.username,\n            credentials.password\n        )\n        return {\"access_token\": token[\"access_token\"]}\n    except CircuitBreakerError:\n        # Circuit breaker is open - Keycloak unavailable\n        raise HTTPException(\n            status_code=503,\n            detail=\"Authentication service temporarily unavailable\"\n        )\n    except KeycloakAuthenticationError:\n        # Invalid credentials\n        raise HTTPException(\n            status_code=401,\n            detail=\"Invalid credentials\"\n        )\n</code></pre>"},{"location":"guides/circuit-breaker/#websocket-handlers","title":"WebSocket Handlers","text":"<p>Circuit breaker failures in WebSocket handlers return error responses:</p> <pre><code>@pkg_router.register(PkgID.GET_AUTHORS)\nasync def get_authors(request: RequestModel) -&gt; ResponseModel:\n    redis = await get_redis_connection()\n\n    if redis is None:\n        # Circuit breaker open or Redis unavailable\n        # Fallback: Continue without cache\n        logger.warning(\"Redis unavailable, operating without cache\")\n\n    # Your logic here (graceful degradation)\n    ...\n</code></pre>"},{"location":"guides/circuit-breaker/#client-side-handling","title":"Client-Side Handling","text":"<p>HTTP Clients: <pre><code>async function login(username, password) {\n    try {\n        const response = await fetch('/api/login', {\n            method: 'POST',\n            body: JSON.stringify({ username, password })\n        });\n\n        if (response.status === 503) {\n            // Circuit breaker open\n            showError('Authentication service is temporarily unavailable. Please try again in a minute.');\n            return null;\n        }\n\n        return await response.json();\n    } catch (error) {\n        showError('Network error. Please check your connection.');\n        return null;\n    }\n}\n</code></pre></p> <p>WebSocket Clients: <pre><code>ws.onmessage = (event) =&gt; {\n    const response = JSON.parse(event.data);\n\n    if (response.status_code === 3) {  // PERMISSION_DENIED\n        // May be due to circuit breaker on auth\n        showError('Authentication failed. Service may be temporarily unavailable.');\n        scheduleReconnect(60000);  // Retry in 60 seconds\n    }\n};\n</code></pre></p>"},{"location":"guides/circuit-breaker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/circuit-breaker/#circuit-breaker-is-frequently-opening","title":"Circuit Breaker is Frequently Opening","text":"<p>Symptoms: - Circuit breaker opens and closes repeatedly (flapping) - Intermittent service unavailability - High <code>circuit_breaker_state_changes_total</code> metric</p> <p>Possible Causes: 1. Service is actually unstable - Investigate service logs and health 2. Threshold too low - Increase <code>FAIL_MAX</code> to tolerate transient errors 3. Timeout too short - Increase <code>TIMEOUT</code> to allow more recovery time 4. Network issues - Check network connectivity between services</p> <p>Resolution: <pre><code># Increase tolerance for transient failures\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX=10  # Was: 5\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT=90   # Was: 60\n\n# Monitor and iterate\nwatch -n 5 'curl -s http://localhost:8000/metrics | grep circuit_breaker_state'\n</code></pre></p>"},{"location":"guides/circuit-breaker/#circuit-breaker-stays-open","title":"Circuit Breaker Stays Open","text":"<p>Symptoms: - Circuit breaker remains in OPEN state - Service appears healthy but circuit won't close - Continuous 503 errors</p> <p>Possible Causes: 1. Service is still unhealthy - Service returning errors during recovery tests 2. Timeout not expired - Circuit hasn't attempted recovery yet 3. Health check failing - Service responds but returns errors</p> <p>Resolution: <pre><code># Check service health directly\ncurl -I http://hw-keycloak:8080/health  # Keycloak\nredis-cli -h hw-redis PING              # Redis\n\n# Check circuit breaker state\ncurl -s http://localhost:8000/metrics | grep 'circuit_breaker_state{service=\"keycloak\"}'\n\n# Wait for timeout period to elapse\n# Circuit will auto-transition to HALF-OPEN and test recovery\n\n# If persistent, restart application to reset circuit breaker state\ndocker restart hw-server-shell\n</code></pre></p>"},{"location":"guides/circuit-breaker/#circuit-breaker-never-opens-should-open","title":"Circuit Breaker Never Opens (Should Open)","text":"<p>Symptoms: - Service is clearly failing but circuit breaker stays CLOSED - Application continues attempting failed operations - High error rates without circuit breaker opening</p> <p>Possible Causes: 1. Circuit breaker disabled - <code>CIRCUIT_BREAKER_ENABLED=false</code> 2. Threshold too high - <code>FAIL_MAX</code> set too high 3. Success responses - Service returning 200 but with errors in payload 4. Exceptions not raised - Errors handled before reaching circuit breaker</p> <p>Resolution: <pre><code># Verify circuit breaker is enabled\necho $CIRCUIT_BREAKER_ENABLED  # Should be \"true\"\n\n# Lower threshold for testing\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX=2  # Very sensitive\n\n# Check error propagation in code\n# Ensure exceptions reach circuit breaker layer\n</code></pre></p>"},{"location":"guides/circuit-breaker/#monitoring-circuit-breaker-health","title":"Monitoring Circuit Breaker Health","text":"<p>Real-time monitoring: <pre><code># Watch circuit breaker state\nwatch -n 1 'curl -s http://localhost:8000/metrics | grep circuit_breaker'\n\n# Check failure counts\ncurl -s http://localhost:8000/metrics | grep circuit_breaker_failures_total\n\n# Check state changes\ncurl -s http://localhost:8000/metrics | grep circuit_breaker_state_changes_total\n</code></pre></p> <p>Log monitoring: <pre><code># Watch for circuit breaker events\ndocker logs -f hw-server-shell | grep -i \"circuit breaker\"\n\n# Expected log messages:\n# - \"Keycloak circuit breaker initialized (fail_max=5, timeout=60s)\"\n# - \"Redis circuit breaker initialized (fail_max=3, timeout=30s)\"\n# - \"Keycloak circuit breaker failure: [error details]\"\n# - \"Keycloak circuit breaker state changed: closed \u2192 open\"\n</code></pre></p>"},{"location":"guides/circuit-breaker/#best-practices","title":"Best Practices","text":""},{"location":"guides/circuit-breaker/#1-monitor-circuit-breaker-metrics","title":"1. Monitor Circuit Breaker Metrics","text":"<p>Set up alerts for circuit breaker events: - Alert when circuit stays open &gt; 2 minutes (service down) - Alert on excessive state changes (service flapping) - Track failure rates to predict circuit openings</p>"},{"location":"guides/circuit-breaker/#2-implement-graceful-degradation","title":"2. Implement Graceful Degradation","text":"<p>Design your application to continue functioning when circuits are open:</p> <pre><code># Good: Graceful degradation\nredis = await get_redis_connection()\nif redis is None:\n    # Continue without cache\n    results = await db.query(...)\nelse:\n    # Try cache first\n    cached = await redis.get(cache_key)\n    if cached:\n        return cached\n    results = await db.query(...)\n    await redis.set(cache_key, results)\n\nreturn results\n</code></pre> <pre><code># Bad: Hard failure\nredis = await get_redis_connection()\ncached = await redis.get(cache_key)  # Fails if redis is None\n</code></pre>"},{"location":"guides/circuit-breaker/#3-tune-for-your-traffic-patterns","title":"3. Tune for Your Traffic Patterns","text":"<ul> <li>Low traffic: Use higher <code>FAIL_MAX</code> (avoid premature opens on single failures)</li> <li>High traffic: Use lower <code>FAIL_MAX</code> (detect failures faster)</li> <li>Stable services: Use longer <code>TIMEOUT</code> (allow full recovery)</li> <li>Unstable services: Use shorter <code>TIMEOUT</code> (retry sooner)</li> </ul>"},{"location":"guides/circuit-breaker/#4-test-circuit-breaker-behavior","title":"4. Test Circuit Breaker Behavior","text":"<p>Regularly test circuit breaker behavior in staging:</p> <pre><code># Simulate Keycloak failure\ndocker stop hw-keycloak\n\n# Watch circuit breaker open\nwatch -n 1 'curl -s http://localhost:8000/metrics | grep circuit_breaker_state'\n\n# Verify application continues functioning\ncurl http://localhost:8000/health  # Should return 200\n\n# Restore service\ndocker start hw-keycloak\n\n# Verify circuit closes after timeout\n</code></pre>"},{"location":"guides/circuit-breaker/#5-log-circuit-breaker-events","title":"5. Log Circuit Breaker Events","text":"<p>Circuit breaker events are automatically logged: - State changes (CLOSED \u2192 OPEN \u2192 HALF-OPEN \u2192 CLOSED) - Failure events - Circuit breaker initialization</p> <p>Review logs regularly to understand failure patterns.</p>"},{"location":"guides/circuit-breaker/#6-combine-with-other-patterns","title":"6. Combine with Other Patterns","text":"<p>Circuit breaker works best with complementary patterns: - Retry logic: Retry before circuit breaker opens - Timeouts: Set reasonable timeouts to avoid long waits - Bulkheads: Isolate failures to prevent full system impact - Fallbacks: Provide alternative behavior when circuit is open</p>"},{"location":"guides/circuit-breaker/#production-checklist","title":"Production Checklist","text":"<p>Before deploying to production:</p> <ul> <li> Circuit breaker enabled (<code>CIRCUIT_BREAKER_ENABLED=true</code>)</li> <li> Thresholds tuned for your traffic (<code>FAIL_MAX</code>, <code>TIMEOUT</code>)</li> <li> Grafana dashboard panels configured for circuit breaker metrics</li> <li> Prometheus alerts set up for circuit breaker states</li> <li> Application implements graceful degradation when circuits are open</li> <li> Client error handling accounts for 503 (Service Unavailable) responses</li> <li> Load testing performed with circuit breaker enabled</li> <li> Runbook created for responding to circuit breaker alerts</li> <li> Circuit breaker behavior tested in staging environment</li> <li> Logging and monitoring verified for circuit breaker events</li> </ul>"},{"location":"guides/circuit-breaker/#additional-resources","title":"Additional Resources","text":"<ul> <li>pybreaker Documentation: https://github.com/danielfm/pybreaker</li> <li>Circuit Breaker Pattern: https://martinfowler.com/bliki/CircuitBreaker.html</li> <li>Resilience Patterns: https://learn.microsoft.com/en-us/azure/architecture/patterns/circuit-breaker</li> <li>FastAPI Metrics Dashboard: http://localhost:3000/d/fastapi-metrics</li> <li>Prometheus Alerts: http://localhost:9090/alerts</li> </ul>"},{"location":"guides/database/","title":"Database Operations","text":""},{"location":"guides/database/#overview","title":"Overview","text":"<p>The application uses PostgreSQL with async SQLModel/SQLAlchemy for database operations.</p>"},{"location":"guides/database/#configuration","title":"Configuration","text":"<p>Database configuration in <code>app/settings.py</code>:</p> <pre><code>POSTGRES_SERVER: str = \"localhost\"\nPOSTGRES_PORT: int = 5432\nPOSTGRES_USER: str = \"postgres\"\nPOSTGRES_PASSWORD: str = \"postgres\"\nPOSTGRES_DB: str = \"app_db\"\n\n# Connection pool\nPOOL_SIZE: int = 5\nMAX_OVERFLOW: int = 10\n</code></pre>"},{"location":"guides/database/#session-management","title":"Session Management","text":""},{"location":"guides/database/#getting-a-session","title":"Getting a Session","text":"<p>Use the async context manager:</p> <pre><code>from app.storage.db import async_session\n\nasync with async_session() as session:\n    async with session.begin():\n        # Database operations here\n        result = await session.execute(select(Author))\n</code></pre>"},{"location":"guides/database/#dependency-injection","title":"Dependency Injection","text":"<p>For HTTP endpoints, use <code>SessionDep</code>:</p> <pre><code>from app.dependencies import SessionDep\n\n@router.get(\"/authors\")\nasync def get_authors(session: SessionDep) -&gt; list[Author]:\n    \"\"\"Session is automatically provided and cleaned up.\"\"\"\n    result = await session.execute(select(Author))\n    return list(result.scalars().all())\n</code></pre>"},{"location":"guides/database/#models","title":"Models","text":""},{"location":"guides/database/#defining-models","title":"Defining Models","text":"<pre><code>from sqlmodel import Field, SQLModel\n\nclass Author(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str = Field(index=True)\n    created_at: datetime = Field(default_factory=datetime.utcnow)\n</code></pre>"},{"location":"guides/database/#async-relationships","title":"Async Relationships","text":"<p>For models with relationships, inherit from <code>BaseModel</code>:</p> <pre><code>from app.models.base import BaseModel\nfrom sqlmodel import Relationship\n\nclass Author(BaseModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    name: str\n    books: list[\"Book\"] = Relationship(back_populates=\"author\")\n\nclass Book(BaseModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    title: str\n    author_id: int = Field(foreign_key=\"author.id\")\n    author: Author = Relationship(back_populates=\"books\")\n</code></pre>"},{"location":"guides/database/#eager-loading","title":"Eager Loading","text":"<pre><code>from sqlalchemy.orm import selectinload\n\n# Load author with all books\nstmt = select(Author).options(selectinload(Author.books))\nresult = await session.execute(stmt)\nauthor = result.scalar_one()\n\n# Relationship already loaded\nbooks = author.books  # No await needed!\n</code></pre>"},{"location":"guides/database/#crud-operations","title":"CRUD Operations","text":""},{"location":"guides/database/#create","title":"Create","text":"<pre><code>from app.storage.db import async_session\n\nasync with async_session() as session:\n    async with session.begin():\n        author = Author(name=\"John Doe\")\n        session.add(author)\n        await session.flush()  # Get ID\n        await session.refresh(author)\n        return author\n</code></pre>"},{"location":"guides/database/#read","title":"Read","text":"<pre><code>from sqlmodel import select\n\n# Get by ID\nasync with async_session() as session:\n    author = await session.get(Author, 1)\n\n# Query with filters\nasync with async_session() as session:\n    stmt = select(Author).where(Author.name == \"John Doe\")\n    result = await session.execute(stmt)\n    author = result.scalar_one_or_none()\n\n# Get all\nasync with async_session() as session:\n    result = await session.execute(select(Author))\n    authors = list(result.scalars().all())\n</code></pre>"},{"location":"guides/database/#update","title":"Update","text":"<pre><code>async with async_session() as session:\n    async with session.begin():\n        author = await session.get(Author, 1)\n        if author:\n            author.name = \"Jane Doe\"\n            session.add(author)\n            await session.flush()\n            await session.refresh(author)\n</code></pre>"},{"location":"guides/database/#delete","title":"Delete","text":"<pre><code>async with async_session() as session:\n    async with session.begin():\n        author = await session.get(Author, 1)\n        if author:\n            await session.delete(author)\n</code></pre>"},{"location":"guides/database/#repository-pattern","title":"Repository Pattern","text":""},{"location":"guides/database/#using-repositories","title":"Using Repositories","text":"<p>Encapsulate database logic in repositories:</p> <pre><code>from app.repositories.author_repository import AuthorRepository\n\nasync with async_session() as session:\n    repo = AuthorRepository(session)\n\n    # Create\n    author = await repo.create(Author(name=\"John Doe\"))\n\n    # Read\n    author = await repo.get_by_id(1)\n    authors = await repo.get_all()\n    john = await repo.get_by_name(\"John\")\n\n    # Update\n    author.name = \"Jane Doe\"\n    await repo.update(author)\n\n    # Delete\n    await repo.delete(author)\n</code></pre>"},{"location":"guides/database/#custom-queries","title":"Custom Queries","text":"<p>Add repository methods for complex queries:</p> <pre><code>class AuthorRepository(BaseRepository[Author]):\n    async def search_by_name(self, pattern: str) -&gt; list[Author]:\n        \"\"\"Search authors by name pattern.\"\"\"\n        stmt = select(Author).where(Author.name.ilike(f\"%{pattern}%\"))\n        result = await self.session.execute(stmt)\n        return list(result.scalars().all())\n</code></pre>"},{"location":"guides/database/#pagination","title":"Pagination","text":""},{"location":"guides/database/#using-get_paginated_results","title":"Using get_paginated_results","text":"<pre><code>from app.storage.db import get_paginated_results\n\nresults, meta = await get_paginated_results(\n    Author,\n    page=1,\n    per_page=20,\n    filters={\"name\": \"John\"}\n)\n\n# meta contains: page, per_page, total, pages\n</code></pre>"},{"location":"guides/database/#custom-pagination","title":"Custom Pagination","text":"<pre><code>from sqlmodel import select, func\n\nasync def get_paginated_authors(page: int, per_page: int):\n    async with async_session() as session:\n        # Count total\n        count_stmt = select(func.count(Author.id))\n        total = (await session.execute(count_stmt)).scalar_one()\n\n        # Get page\n        offset = (page - 1) * per_page\n        stmt = select(Author).offset(offset).limit(per_page)\n        result = await session.execute(stmt)\n        items = list(result.scalars().all())\n\n        return items, {\n            \"page\": page,\n            \"per_page\": per_page,\n            \"total\": total,\n            \"pages\": (total + per_page - 1) // per_page\n        }\n</code></pre>"},{"location":"guides/database/#transactions","title":"Transactions","text":""},{"location":"guides/database/#automatic-transactions","title":"Automatic Transactions","text":"<p>Using <code>session.begin()</code>:</p> <pre><code>async with async_session() as session:\n    async with session.begin():\n        # All operations in one transaction\n        author = Author(name=\"John\")\n        session.add(author)\n        await session.flush()\n\n        book = Book(title=\"Book\", author_id=author.id)\n        session.add(book)\n        # Commits automatically on exit\n</code></pre>"},{"location":"guides/database/#manual-commitrollback","title":"Manual Commit/Rollback","text":"<pre><code>async with async_session() as session:\n    try:\n        author = Author(name=\"John\")\n        session.add(author)\n        await session.commit()\n    except Exception:\n        await session.rollback()\n        raise\n</code></pre>"},{"location":"guides/database/#migrations","title":"Migrations","text":""},{"location":"guides/database/#create-migration","title":"Create Migration","text":"<pre><code>make migration msg=\"Add email to Author\"\n</code></pre>"},{"location":"guides/database/#apply-migrations","title":"Apply Migrations","text":"<pre><code>make migrate\n</code></pre>"},{"location":"guides/database/#rollback","title":"Rollback","text":"<pre><code>make rollback\n</code></pre> <p>See Database Migrations for full guide.</p>"},{"location":"guides/database/#error-handling","title":"Error Handling","text":""},{"location":"guides/database/#integrityerror","title":"IntegrityError","text":"<pre><code>from sqlalchemy.exc import IntegrityError\n\ntry:\n    author = Author(name=\"John\")\n    session.add(author)\n    await session.commit()\nexcept IntegrityError as e:\n    await session.rollback()\n    logger.error(f\"Constraint violation: {e}\")\n    raise HTTPException(status_code=400, detail=\"Duplicate entry\")\n</code></pre>"},{"location":"guides/database/#noresultfound","title":"NoResultFound","text":"<pre><code>from sqlalchemy.exc import NoResultFound\n\ntry:\n    stmt = select(Author).where(Author.id == 999)\n    author = (await session.execute(stmt)).scalar_one()\nexcept NoResultFound:\n    raise HTTPException(status_code=404, detail=\"Author not found\")\n</code></pre>"},{"location":"guides/database/#best-practices","title":"Best Practices","text":""},{"location":"guides/database/#1-always-use-sessions-as-context-managers","title":"1. Always Use Sessions as Context Managers","text":"<pre><code># \u2705 Good\nasync with async_session() as session:\n    async with session.begin():\n        # operations\n\n# \u274c Bad\nsession = async_session()\n# operations\nawait session.close()  # Easy to forget!\n</code></pre>"},{"location":"guides/database/#2-use-repositories","title":"2. Use Repositories","text":"<pre><code># \u2705 Good - testable, reusable\nrepo = AuthorRepository(session)\nauthors = await repo.get_all()\n\n# \u274c Bad - logic in handlers\nresult = await session.execute(select(Author))\nauthors = list(result.scalars().all())\n</code></pre>"},{"location":"guides/database/#3-eager-load-relationships","title":"3. Eager Load Relationships","text":"<pre><code># \u2705 Good - one query\nstmt = select(Author).options(selectinload(Author.books))\nauthors = (await session.execute(stmt)).scalars().all()\n\n# \u274c Bad - N+1 queries\nauthors = (await session.execute(select(Author))).scalars().all()\nfor author in authors:\n    books = await author.awaitable_attrs.books  # Separate query!\n</code></pre>"},{"location":"guides/database/#4-use-transactions","title":"4. Use Transactions","text":"<pre><code># \u2705 Good - atomic operation\nasync with session.begin():\n    author = Author(name=\"John\")\n    session.add(author)\n    await session.flush()\n\n    book = Book(author_id=author.id)\n    session.add(book)\n\n# \u274c Bad - partial commits possible\nauthor = Author(name=\"John\")\nsession.add(author)\nawait session.commit()\n\nbook = Book(author_id=author.id)\nsession.add(book)\nawait session.commit()  # If this fails, author still created!\n</code></pre>"},{"location":"guides/database/#performance","title":"Performance","text":""},{"location":"guides/database/#connection-pooling","title":"Connection Pooling","text":"<p>Adjust pool size in settings:</p> <pre><code>POOL_SIZE: int = 10\nMAX_OVERFLOW: int = 20\n</code></pre>"},{"location":"guides/database/#query-optimization","title":"Query Optimization","text":"<pre><code># Use select() for better performance\nstmt = select(Author).where(Author.name == \"John\")\n\n# Use indexes\nclass Author(SQLModel, table=True):\n    name: str = Field(index=True)  # Indexed!\n\n# Limit results\nstmt = select(Author).limit(100)\n</code></pre>"},{"location":"guides/database/#testing","title":"Testing","text":""},{"location":"guides/database/#test-with-in-memory-database","title":"Test with In-Memory Database","text":"<pre><code>import pytest\nfrom sqlmodel import create_engine, Session\n\n@pytest.fixture\ndef session():\n    engine = create_engine(\"sqlite:///:memory:\")\n    SQLModel.metadata.create_all(engine)\n    with Session(engine) as session:\n        yield session\n</code></pre>"},{"location":"guides/database/#mock-repository","title":"Mock Repository","text":"<pre><code>from unittest.mock import AsyncMock\n\n@pytest.fixture\ndef mock_repo():\n    repo = AsyncMock()\n    repo.get_by_id.return_value = Author(id=1, name=\"Test\")\n    return repo\n</code></pre>"},{"location":"guides/database/#related","title":"Related","text":"<ul> <li>Database Migrations</li> <li>Design Patterns</li> <li>Testing Guide</li> </ul>"},{"location":"guides/design-patterns-reference/","title":"Design Patterns Quick Reference","text":"<p>Quick lookup guide for implementing Repository + Command + DI patterns</p>"},{"location":"guides/design-patterns-reference/#checklist-adding-a-new-feature","title":"\ud83d\udccb Checklist: Adding a New Feature","text":"<ul> <li> Create model in <code>app/models/</code></li> <li> Create repository in <code>app/repositories/</code></li> <li> Create commands in <code>app/commands/</code></li> <li> Add repository dependency in <code>app/dependencies.py</code></li> <li> Create HTTP endpoint in <code>app/api/http/</code></li> <li> Create WebSocket handler in <code>app/api/ws/handlers/</code></li> <li> Write tests</li> </ul>"},{"location":"guides/design-patterns-reference/#quick-start-template","title":"\ud83d\ude80 Quick Start Template","text":""},{"location":"guides/design-patterns-reference/#1-model-data-structure","title":"1. Model (Data Structure)","text":"<pre><code># app/models/book.py\nfrom sqlmodel import Field, SQLModel\n\nclass Book(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    title: str\n    author_id: int\n    # Keep simple - no business logic!\n</code></pre>"},{"location":"guides/design-patterns-reference/#2-repository-data-access","title":"2. Repository (Data Access)","text":"<pre><code># app/repositories/book_repository.py\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom app.models.book import Book\nfrom app.repositories.base import BaseRepository\n\nclass BookRepository(BaseRepository[Book]):\n    def __init__(self, session: AsyncSession):\n        super().__init__(session, Book)\n\n    # Add custom queries\n    async def get_by_title(self, title: str) -&gt; Book | None:\n        from sqlmodel import select\n        stmt = select(Book).where(Book.title == title)\n        result = await self.session.exec(stmt)\n        return result.first()\n</code></pre>"},{"location":"guides/design-patterns-reference/#3-commands-business-logic","title":"3. Commands (Business Logic)","text":"<pre><code># app/commands/book_commands.py\nfrom pydantic import BaseModel\nfrom app.commands.base import BaseCommand\nfrom app.models.book import Book\nfrom app.repositories.book_repository import BookRepository\n\n# Input/Output models\nclass GetBooksInput(BaseModel):\n    title: str | None = None\n    author_id: int | None = None\n\nclass CreateBookInput(BaseModel):\n    title: str\n    author_id: int\n\n# Commands\nclass GetBooksCommand(BaseCommand[GetBooksInput, list[Book]]):\n    def __init__(self, repository: BookRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: GetBooksInput) -&gt; list[Book]:\n        filters = {}\n        if input_data.title:\n            filters[\"title\"] = input_data.title\n        if input_data.author_id:\n            filters[\"author_id\"] = input_data.author_id\n        return await self.repository.get_all(**filters)\n\nclass CreateBookCommand(BaseCommand[CreateBookInput, Book]):\n    def __init__(self, repository: BookRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: CreateBookInput) -&gt; Book:\n        # Business logic: Check for duplicates\n        existing = await self.repository.get_by_title(input_data.title)\n        if existing:\n            raise ValueError(f\"Book '{input_data.title}' already exists\")\n\n        book = Book(**input_data.model_dump())\n        return await self.repository.create(book)\n</code></pre>"},{"location":"guides/design-patterns-reference/#4-dependencies","title":"4. Dependencies","text":"<pre><code># app/dependencies.py\ndef get_book_repository(session: SessionDep) -&gt; BookRepository:\n    return BookRepository(session)\n\nBookRepoDep = Annotated[BookRepository, Depends(get_book_repository)]\n</code></pre>"},{"location":"guides/design-patterns-reference/#5-http-endpoint","title":"5. HTTP Endpoint","text":"<pre><code># app/api/http/book.py\nfrom fastapi import APIRouter, status\nfrom app.commands.book_commands import CreateBookCommand, CreateBookInput\nfrom app.dependencies import BookRepoDep, RBACDep\nfrom app.models.book import Book\n\nrouter = APIRouter(prefix=\"/books\", tags=[\"books\"])\n\n@router.post(\"\", response_model=Book, status_code=status.HTTP_201_CREATED)\nasync def create_book(\n    data: CreateBookInput,\n    repo: BookRepoDep,\n    rbac: RBACDep,\n) -&gt; Book:\n    try:\n        command = CreateBookCommand(repo)\n        return await command.execute(data)\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n</code></pre>"},{"location":"guides/design-patterns-reference/#6-websocket-handler","title":"6. WebSocket Handler","text":"<pre><code># app/api/ws/handlers/book_handlers.py\nfrom app.api.ws.constants import PkgID, RSPCode\nfrom app.commands.book_commands import CreateBookCommand, CreateBookInput\nfrom app.repositories.book_repository import BookRepository\nfrom app.routing import pkg_router\nfrom app.schemas.request import RequestModel\nfrom app.schemas.response import ResponseModel\nfrom app.storage.db import async_session\n\n@pkg_router.register(PkgID.CREATE_BOOK, roles=[\"create-book\"])\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    try:\n        async with async_session() as session:\n            async with session.begin():\n                repo = BookRepository(session)\n                command = CreateBookCommand(repo)\n                input_data = CreateBookInput(**request.data)\n                book = await command.execute(input_data)\n\n                return ResponseModel(\n                    pkg_id=request.pkg_id,\n                    req_id=request.req_id,\n                    data=book.model_dump()\n                )\n    except ValueError as e:\n        return ResponseModel.err_msg(\n            request.pkg_id,\n            request.req_id,\n            msg=str(e),\n            status_code=RSPCode.INVALID_DATA\n        )\n</code></pre>"},{"location":"guides/design-patterns-reference/#testing-templates","title":"\ud83e\uddea Testing Templates","text":""},{"location":"guides/design-patterns-reference/#repository-test","title":"Repository Test","text":"<pre><code># tests/test_book_repository.py\nimport pytest\nfrom unittest.mock import AsyncMock, MagicMock\nfrom app.repositories.book_repository import BookRepository\n\n@pytest.fixture\ndef mock_session():\n    session = AsyncMock()\n    session.add = MagicMock()\n    session.flush = AsyncMock()\n    session.exec = AsyncMock()\n    return session\n\n@pytest.mark.asyncio\nasync def test_create_book(mock_session):\n    repo = BookRepository(mock_session)\n    book = Book(title=\"Test\", author_id=1)\n\n    created = await repo.create(book)\n\n    assert created == book\n    mock_session.add.assert_called_once_with(book)\n    mock_session.flush.assert_called_once()\n</code></pre>"},{"location":"guides/design-patterns-reference/#command-test","title":"Command Test","text":"<pre><code># tests/test_book_commands.py\nimport pytest\nfrom unittest.mock import AsyncMock\nfrom app.commands.book_commands import CreateBookCommand, CreateBookInput\n\n@pytest.mark.asyncio\nasync def test_create_book_command():\n    mock_repo = AsyncMock()\n    mock_repo.get_by_title.return_value = None  # No duplicate\n    mock_repo.create.return_value = Book(id=1, title=\"New\", author_id=1)\n\n    command = CreateBookCommand(mock_repo)\n    result = await command.execute(CreateBookInput(title=\"New\", author_id=1))\n\n    assert result.title == \"New\"\n    mock_repo.create.assert_called_once()\n\n@pytest.mark.asyncio\nasync def test_create_duplicate_book():\n    mock_repo = AsyncMock()\n    mock_repo.get_by_title.return_value = Book(id=1, title=\"Existing\", author_id=1)\n\n    command = CreateBookCommand(mock_repo)\n\n    with pytest.raises(ValueError, match=\"already exists\"):\n        await command.execute(CreateBookInput(title=\"Existing\", author_id=1))\n</code></pre>"},{"location":"guides/design-patterns-reference/#common-patterns","title":"\ud83d\udcdd Common Patterns","text":""},{"location":"guides/design-patterns-reference/#pagination-in-commands","title":"Pagination in Commands","text":"<pre><code>class GetBooksInput(BaseModel):\n    page: int = 1\n    per_page: int = 20\n    title: str | None = None\n\nclass GetBooksCommand(BaseCommand[GetBooksInput, tuple[list[Book], MetadataModel]]):\n    async def execute(self, input_data: GetBooksInput):\n        from app.storage.db import get_paginated_results\n\n        filters = {}\n        if input_data.title:\n            filters[\"title\"] = input_data.title\n\n        results, meta = await get_paginated_results(\n            Book,\n            page=input_data.page,\n            per_page=input_data.per_page,\n            filters=filters\n        )\n        return results, meta\n</code></pre>"},{"location":"guides/design-patterns-reference/#transactions-in-commands","title":"Transactions in Commands","text":"<pre><code>class CreateBookWithAuthorsCommand(BaseCommand[CreateBookInput, Book]):\n    def __init__(\n        self,\n        book_repo: BookRepository,\n        author_repo: AuthorRepository\n    ):\n        self.book_repo = book_repo\n        self.author_repo = author_repo\n\n    async def execute(self, input_data: CreateBookInput) -&gt; Book:\n        # All operations in same transaction (same session)\n        # If any fails, all rollback\n        author = await self.author_repo.get_by_id(input_data.author_id)\n        if not author:\n            raise ValueError(\"Author not found\")\n\n        book = Book(**input_data.model_dump())\n        return await self.book_repo.create(book)\n</code></pre>"},{"location":"guides/design-patterns-reference/#update-pattern","title":"Update Pattern","text":"<pre><code>class UpdateBookInput(BaseModel):\n    id: int\n    title: str\n\nclass UpdateBookCommand(BaseCommand[UpdateBookInput, Book]):\n    async def execute(self, input_data: UpdateBookInput) -&gt; Book:\n        # Get existing\n        book = await self.repository.get_by_id(input_data.id)\n        if not book:\n            raise ValueError(f\"Book {input_data.id} not found\")\n\n        # Check for conflicts\n        existing = await self.repository.get_by_title(input_data.title)\n        if existing and existing.id != input_data.id:\n            raise ValueError(f\"Title '{input_data.title}' already exists\")\n\n        # Update\n        book.title = input_data.title\n        return await self.repository.update(book)\n</code></pre>"},{"location":"guides/design-patterns-reference/#delete-pattern","title":"Delete Pattern","text":"<pre><code>class DeleteBookCommand(BaseCommand[int, None]):\n    async def execute(self, book_id: int) -&gt; None:\n        book = await self.repository.get_by_id(book_id)\n        if not book:\n            raise ValueError(f\"Book {book_id} not found\")\n\n        await self.repository.delete(book)\n</code></pre>"},{"location":"guides/design-patterns-reference/#decision-tree","title":"\ud83c\udfaf Decision Tree","text":""},{"location":"guides/design-patterns-reference/#when-to-create-a-new-command","title":"When to Create a New Command?","text":"<pre><code>Is it a distinct business operation? \u2192 YES \u2192 Create new command\n                                    \u2192 NO  \u2192 Add to existing command\n\nDoes it have different validation rules? \u2192 YES \u2192 Create new command\n                                         \u2192 NO  \u2192 Use existing command\n\nIs it used in multiple places? \u2192 YES \u2192 Definitely create command\n                               \u2192 NO  \u2192 Still create it (future-proof)\n</code></pre>"},{"location":"guides/design-patterns-reference/#when-to-add-custom-repository-methods","title":"When to Add Custom Repository Methods?","text":"<pre><code>Is it a common query pattern? \u2192 YES \u2192 Add to repository\n                             \u2192 NO  \u2192 Use base repository methods\n\nDoes it need complex joins? \u2192 YES \u2192 Add to repository\n                           \u2192 NO  \u2192 Use get_all() with filters\n\nIs it specific to one entity? \u2192 YES \u2192 Add to specific repository\n                              \u2192 NO  \u2192 Consider a service layer\n</code></pre>"},{"location":"guides/design-patterns-reference/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"guides/design-patterns-reference/#common-issues","title":"Common Issues","text":"<p>Issue: Circular import errors <pre><code># \u274c Don't import from __init__.py\nfrom app.repositories import AuthorRepository\n\n# \u2705 Import directly from module\nfrom app.repositories.author_repository import AuthorRepository\n</code></pre></p> <p>Issue: Session not flushed <pre><code># \u274c Forgot to flush\nasync def create(self, entity):\n    self.session.add(entity)\n    return entity  # ID not set!\n\n# \u2705 Always flush\nasync def create(self, entity):\n    self.session.add(entity)\n    await self.session.flush()  # ID now set\n    await self.session.refresh(entity)\n    return entity\n</code></pre></p> <p>Issue: Can't mock dependencies in tests <pre><code># \u274c Direct instantiation\nrepo = AuthorRepository(session)\n\n# \u2705 Use dependency override\napp.dependency_overrides[get_author_repository] = lambda: MockRepo()\n</code></pre></p>"},{"location":"guides/design-patterns-reference/#see-also","title":"\ud83d\udcda See Also","text":"<ul> <li>Full Design Patterns Guide</li> <li>Testing Guide</li> <li>Example: Author Implementation</li> <li>Issue #29</li> </ul> <p>Last Updated: 2025-12-05</p>"},{"location":"guides/http-endpoints/","title":"Creating HTTP Endpoints","text":""},{"location":"guides/http-endpoints/#overview","title":"Overview","text":"<p>This guide shows how to create new HTTP endpoints using FastAPI with proper authentication, authorization, and the Repository + Command pattern.</p>"},{"location":"guides/http-endpoints/#quick-start","title":"Quick Start","text":""},{"location":"guides/http-endpoints/#1-define-the-model","title":"1. Define the Model","text":"<pre><code># app/models/book.py\nfrom sqlmodel import Field, SQLModel\n\nclass Book(SQLModel, table=True):\n    id: int | None = Field(default=None, primary_key=True)\n    title: str\n    author_id: int\n</code></pre>"},{"location":"guides/http-endpoints/#2-create-repository","title":"2. Create Repository","text":"<pre><code># app/repositories/book_repository.py\nfrom app.models.book import Book\nfrom app.repositories.base import BaseRepository\n\nclass BookRepository(BaseRepository[Book]):\n    def __init__(self, session: AsyncSession):\n        super().__init__(session, Book)\n</code></pre>"},{"location":"guides/http-endpoints/#3-create-commands","title":"3. Create Commands","text":"<pre><code># app/commands/book_commands.py\nfrom pydantic import BaseModel\nfrom app.commands.base import BaseCommand\n\nclass CreateBookInput(BaseModel):\n    title: str\n    author_id: int\n\nclass CreateBookCommand(BaseCommand[CreateBookInput, Book]):\n    def __init__(self, repository: BookRepository):\n        self.repository = repository\n\n    async def execute(self, input_data: CreateBookInput) -&gt; Book:\n        book = Book(**input_data.model_dump())\n        return await self.repository.create(book)\n</code></pre>"},{"location":"guides/http-endpoints/#4-add-dependency","title":"4. Add Dependency","text":"<pre><code># app/dependencies.py\ndef get_book_repository(session: SessionDep) -&gt; BookRepository:\n    return BookRepository(session)\n\nBookRepoDep = Annotated[BookRepository, Depends(get_book_repository)]\n</code></pre>"},{"location":"guides/http-endpoints/#5-create-router","title":"5. Create Router","text":"<pre><code># app/api/http/book.py\nfrom fastapi import APIRouter, Depends, status\nfrom app.commands.book_commands import CreateBookCommand, CreateBookInput\nfrom app.dependencies import BookRepoDep\nfrom app.dependencies.permissions import require_roles\n\nrouter = APIRouter(prefix=\"/books\", tags=[\"books\"])\n\n@router.post(\"\", response_model=Book, status_code=status.HTTP_201_CREATED)\nasync def create_book(\n    data: CreateBookInput,\n    repo: BookRepoDep,\n) -&gt; Book:\n    \"\"\"Create a new book.\"\"\"\n    command = CreateBookCommand(repo)\n    return await command.execute(data)\n\n@router.get(\"\", response_model=list[Book])\nasync def get_books(\n    repo: BookRepoDep,\n    dependencies=[Depends(require_roles(\"view-books\"))]\n) -&gt; list[Book]:\n    \"\"\"Get all books (requires 'view-books' role).\"\"\"\n    return await repo.get_all()\n</code></pre>"},{"location":"guides/http-endpoints/#adding-authentication","title":"Adding Authentication","text":""},{"location":"guides/http-endpoints/#public-endpoints","title":"Public Endpoints","text":"<p>No decorator needed - endpoint is public:</p> <pre><code>@router.get(\"/health\")\nasync def health_check():\n    \"\"\"Public health check endpoint.\"\"\"\n    return {\"status\": \"healthy\"}\n</code></pre>"},{"location":"guides/http-endpoints/#protected-endpoints","title":"Protected Endpoints","text":"<p>Use <code>require_roles()</code> dependency:</p> <pre><code>@router.get(\n    \"/books\",\n    dependencies=[Depends(require_roles(\"view-books\"))]\n)\nasync def get_books(repo: BookRepoDep) -&gt; list[Book]:\n    \"\"\"Requires 'view-books' role.\"\"\"\n    return await repo.get_all()\n</code></pre>"},{"location":"guides/http-endpoints/#multiple-roles","title":"Multiple Roles","text":"<p>Require ALL specified roles:</p> <pre><code>@router.delete(\n    \"/books/{book_id}\",\n    dependencies=[Depends(require_roles(\"delete-books\", \"admin\"))]\n)\nasync def delete_book(book_id: int, repo: BookRepoDep):\n    \"\"\"Requires BOTH 'delete-books' AND 'admin' roles.\"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(status_code=404, detail=\"Book not found\")\n    await repo.delete(book)\n    return {\"message\": \"Book deleted\"}\n</code></pre>"},{"location":"guides/http-endpoints/#request-validation","title":"Request Validation","text":""},{"location":"guides/http-endpoints/#path-parameters","title":"Path Parameters","text":"<pre><code>@router.get(\"/books/{book_id}\")\nasync def get_book(book_id: int, repo: BookRepoDep) -&gt; Book:\n    \"\"\"Get book by ID.\"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(status_code=404, detail=\"Book not found\")\n    return book\n</code></pre>"},{"location":"guides/http-endpoints/#query-parameters","title":"Query Parameters","text":"<pre><code>@router.get(\"/books\")\nasync def get_books(\n    repo: BookRepoDep,\n    title: str | None = None,\n    author_id: int | None = None,\n) -&gt; list[Book]:\n    \"\"\"Get books with optional filters.\"\"\"\n    filters = {}\n    if title:\n        filters[\"title\"] = title\n    if author_id:\n        filters[\"author_id\"] = author_id\n    return await repo.get_all(**filters)\n</code></pre>"},{"location":"guides/http-endpoints/#request-body","title":"Request Body","text":"<pre><code>class UpdateBookInput(BaseModel):\n    title: str\n    author_id: int\n\n@router.put(\"/books/{book_id}\")\nasync def update_book(\n    book_id: int,\n    data: UpdateBookInput,\n    repo: BookRepoDep,\n) -&gt; Book:\n    \"\"\"Update book.\"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(status_code=404, detail=\"Book not found\")\n\n    book.title = data.title\n    book.author_id = data.author_id\n    return await repo.update(book)\n</code></pre>"},{"location":"guides/http-endpoints/#pagination","title":"Pagination","text":"<pre><code>from app.storage.db import get_paginated_results\n\n@router.get(\"/books/paginated\")\nasync def get_books_paginated(\n    page: int = 1,\n    per_page: int = 20,\n) -&gt; dict:\n    \"\"\"Get paginated books.\"\"\"\n    results, meta = await get_paginated_results(\n        Book,\n        page=page,\n        per_page=per_page\n    )\n    return {\n        \"items\": [book.model_dump() for book in results],\n        \"meta\": meta.model_dump()\n    }\n</code></pre>"},{"location":"guides/http-endpoints/#error-handling","title":"Error Handling","text":"<pre><code>from fastapi import HTTPException\n\n@router.post(\"/books\")\nasync def create_book(data: CreateBookInput, repo: BookRepoDep) -&gt; Book:\n    \"\"\"Create book with error handling.\"\"\"\n    try:\n        command = CreateBookCommand(repo)\n        return await command.execute(data)\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Failed to create book: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n</code></pre>"},{"location":"guides/http-endpoints/#response-models","title":"Response Models","text":""},{"location":"guides/http-endpoints/#custom-response-models","title":"Custom Response Models","text":"<pre><code>class BookResponse(BaseModel):\n    id: int\n    title: str\n    author_name: str\n\n@router.get(\"/books/{book_id}\", response_model=BookResponse)\nasync def get_book(book_id: int, repo: BookRepoDep) -&gt; BookResponse:\n    \"\"\"Get book with custom response.\"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(status_code=404, detail=\"Book not found\")\n\n    return BookResponse(\n        id=book.id,\n        title=book.title,\n        author_name=\"...\"  # Load from relationship\n    )\n</code></pre>"},{"location":"guides/http-endpoints/#complete-example-book-api","title":"Complete Example: Book API","text":"<p>Here's a complete example combining all concepts:</p> <pre><code># app/api/http/book.py\nfrom fastapi import APIRouter, Depends, HTTPException, Query, status\nfrom pydantic import BaseModel\nfrom app.commands.book_commands import (\n    CreateBookCommand,\n    UpdateBookCommand,\n    DeleteBookCommand,\n)\nfrom app.dependencies import BookRepoDep\nfrom app.dependencies.permissions import require_roles\nfrom app.logging import logger\nfrom app.models.book import Book\nfrom app.storage.db import get_paginated_results\n\nrouter = APIRouter(prefix=\"/api/books\", tags=[\"books\"])\n\n\nclass CreateBookInput(BaseModel):\n    \"\"\"Input for creating a book.\"\"\"\n    title: str\n    author_id: int\n    isbn: str | None = None\n\n\nclass UpdateBookInput(BaseModel):\n    \"\"\"Input for updating a book.\"\"\"\n    title: str | None = None\n    author_id: int | None = None\n    isbn: str | None = None\n\n\nclass BookResponse(BaseModel):\n    \"\"\"Book response with additional metadata.\"\"\"\n    id: int\n    title: str\n    author_id: int\n    isbn: str | None\n    created_at: str\n\n\n@router.post(\n    \"\",\n    response_model=BookResponse,\n    status_code=status.HTTP_201_CREATED,\n    dependencies=[Depends(require_roles(\"create-book\"))],\n)\nasync def create_book(\n    data: CreateBookInput,\n    repo: BookRepoDep,\n) -&gt; Book:\n    \"\"\"\n    Create a new book.\n\n    Requires 'create-book' role.\n\n    Example request:\n        ```json\n        {\n            \"title\": \"The Pragmatic Programmer\",\n            \"author_id\": 1,\n            \"isbn\": \"978-0135957059\"\n        }\n        ```\n\n    Returns:\n        Book: Created book with ID and timestamp\n    \"\"\"\n    try:\n        command = CreateBookCommand(repo)\n        book = await command.execute(data)\n\n        logger.info(\n            f\"Book created: {book.title}\",\n            extra={\"book_id\": book.id, \"author_id\": book.author_id}\n        )\n\n        return book\n\n    except ValueError as e:\n        logger.warning(f\"Invalid book data: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n    except Exception as e:\n        logger.error(f\"Failed to create book: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Failed to create book\"\n        )\n\n\n@router.get(\n    \"\",\n    response_model=list[BookResponse],\n    dependencies=[Depends(require_roles(\"view-books\"))],\n)\nasync def get_books(\n    repo: BookRepoDep,\n    author_id: int | None = Query(None, description=\"Filter by author ID\"),\n    search: str | None = Query(None, description=\"Search by title\"),\n) -&gt; list[Book]:\n    \"\"\"\n    Get all books with optional filters.\n\n    Requires 'view-books' role.\n\n    Query Parameters:\n        - author_id: Filter books by author\n        - search: Search books by title (case-insensitive)\n\n    Example:\n        GET /api/books?author_id=1&amp;search=pragmatic\n    \"\"\"\n    filters = {}\n    if author_id:\n        filters[\"author_id\"] = author_id\n    if search:\n        filters[\"title_ilike\"] = f\"%{search}%\"\n\n    try:\n        books = await repo.get_all(**filters)\n        return books\n    except Exception as e:\n        logger.error(f\"Failed to get books: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Failed to retrieve books\"\n        )\n\n\n@router.get(\n    \"/paginated\",\n    dependencies=[Depends(require_roles(\"view-books\"))],\n)\nasync def get_books_paginated(\n    page: int = Query(1, ge=1, description=\"Page number\"),\n    per_page: int = Query(20, ge=1, le=100, description=\"Items per page\"),\n    author_id: int | None = Query(None, description=\"Filter by author ID\"),\n) -&gt; dict:\n    \"\"\"\n    Get paginated books.\n\n    Requires 'view-books' role.\n\n    Example:\n        GET /api/books/paginated?page=2&amp;per_page=10&amp;author_id=1\n\n    Returns:\n        ```json\n        {\n            \"items\": [...],\n            \"meta\": {\n                \"page\": 2,\n                \"per_page\": 10,\n                \"total\": 45,\n                \"pages\": 5\n            }\n        }\n        ```\n    \"\"\"\n    try:\n        filters = {\"author_id\": author_id} if author_id else {}\n\n        results, meta = await get_paginated_results(\n            Book,\n            page=page,\n            per_page=per_page,\n            filters=filters,\n        )\n\n        return {\n            \"items\": [book.model_dump() for book in results],\n            \"meta\": meta.model_dump()\n        }\n    except ValueError as e:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n    except Exception as e:\n        logger.error(f\"Failed to get paginated books: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Failed to retrieve books\"\n        )\n\n\n@router.get(\n    \"/{book_id}\",\n    response_model=BookResponse,\n    dependencies=[Depends(require_roles(\"view-books\"))],\n)\nasync def get_book(\n    book_id: int,\n    repo: BookRepoDep,\n) -&gt; Book:\n    \"\"\"\n    Get book by ID.\n\n    Requires 'view-books' role.\n\n    Example:\n        GET /api/books/123\n\n    Raises:\n        404: Book not found\n    \"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Book with ID {book_id} not found\"\n        )\n    return book\n\n\n@router.put(\n    \"/{book_id}\",\n    response_model=BookResponse,\n    dependencies=[Depends(require_roles(\"update-book\"))],\n)\nasync def update_book(\n    book_id: int,\n    data: UpdateBookInput,\n    repo: BookRepoDep,\n) -&gt; Book:\n    \"\"\"\n    Update book by ID.\n\n    Requires 'update-book' role.\n\n    Example request:\n        ```json\n        {\n            \"title\": \"The Pragmatic Programmer (2nd Edition)\",\n            \"isbn\": \"978-0135957059\"\n        }\n        ```\n\n    Only provided fields are updated (partial update).\n\n    Raises:\n        404: Book not found\n        400: Invalid data\n    \"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Book with ID {book_id} not found\"\n        )\n\n    try:\n        command = UpdateBookCommand(repo)\n        updated_book = await command.execute(book_id, data)\n\n        logger.info(\n            f\"Book updated: {updated_book.title}\",\n            extra={\"book_id\": book_id}\n        )\n\n        return updated_book\n\n    except ValueError as e:\n        logger.warning(f\"Invalid update data: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n    except Exception as e:\n        logger.error(f\"Failed to update book: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Failed to update book\"\n        )\n\n\n@router.delete(\n    \"/{book_id}\",\n    status_code=status.HTTP_204_NO_CONTENT,\n    dependencies=[Depends(require_roles(\"delete-book\", \"admin\"))],\n)\nasync def delete_book(\n    book_id: int,\n    repo: BookRepoDep,\n) -&gt; None:\n    \"\"\"\n    Delete book by ID.\n\n    Requires BOTH 'delete-book' AND 'admin' roles.\n\n    Example:\n        DELETE /api/books/123\n\n    Returns:\n        204 No Content on success\n\n    Raises:\n        404: Book not found\n        403: Insufficient permissions\n    \"\"\"\n    book = await repo.get_by_id(book_id)\n    if not book:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Book with ID {book_id} not found\"\n        )\n\n    try:\n        command = DeleteBookCommand(repo)\n        await command.execute(book_id)\n\n        logger.info(\n            f\"Book deleted: {book.title}\",\n            extra={\"book_id\": book_id}\n        )\n\n    except Exception as e:\n        logger.error(f\"Failed to delete book: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Failed to delete book\"\n        )\n</code></pre>"},{"location":"guides/http-endpoints/#testing","title":"Testing","text":""},{"location":"guides/http-endpoints/#basic-test","title":"Basic Test","text":"<pre><code>from fastapi.testclient import TestClient\n\ndef test_create_book(client: TestClient):\n    \"\"\"Test book creation.\"\"\"\n    response = client.post(\n        \"/api/books\",\n        json={\"title\": \"Test Book\", \"author_id\": 1},\n        headers={\"Authorization\": f\"Bearer {token}\"}\n    )\n    assert response.status_code == 201\n    assert response.json()[\"title\"] == \"Test Book\"\n</code></pre>"},{"location":"guides/http-endpoints/#complete-test-suite","title":"Complete Test Suite","text":"<pre><code>import pytest\nfrom fastapi.testclient import TestClient\nfrom unittest.mock import AsyncMock, patch\nfrom app.models.book import Book\nfrom app.repositories.book_repository import BookRepository\n\n\n@pytest.fixture\ndef mock_book_repo():\n    \"\"\"Mock book repository for testing.\"\"\"\n    repo = AsyncMock(spec=BookRepository)\n    repo.get_by_id.return_value = Book(\n        id=1,\n        title=\"Test Book\",\n        author_id=1,\n        isbn=\"978-0135957059\"\n    )\n    repo.get_all.return_value = [\n        Book(id=1, title=\"Book 1\", author_id=1),\n        Book(id=2, title=\"Book 2\", author_id=1),\n    ]\n    return repo\n\n\n@pytest.fixture\ndef auth_token():\n    \"\"\"Generate test authentication token.\"\"\"\n    # Mock Keycloak token with required roles\n    return \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n\n\nclass TestBookEndpoints:\n    \"\"\"Test suite for book endpoints.\"\"\"\n\n    def test_create_book_success(\n        self, client: TestClient, auth_token: str, mock_book_repo\n    ):\n        \"\"\"Test successful book creation.\"\"\"\n        with patch(\"app.dependencies.get_book_repository\", return_value=mock_book_repo):\n            response = client.post(\n                \"/api/books\",\n                json={\n                    \"title\": \"The Pragmatic Programmer\",\n                    \"author_id\": 1,\n                    \"isbn\": \"978-0135957059\"\n                },\n                headers={\"Authorization\": f\"Bearer {auth_token}\"}\n            )\n\n            assert response.status_code == 201\n            data = response.json()\n            assert data[\"title\"] == \"The Pragmatic Programmer\"\n            assert data[\"author_id\"] == 1\n            assert \"id\" in data\n            assert \"created_at\" in data\n\n    def test_create_book_missing_required_field(\n        self, client: TestClient, auth_token: str\n    ):\n        \"\"\"Test book creation with missing required field.\"\"\"\n        response = client.post(\n            \"/api/books\",\n            json={\"author_id\": 1},  # Missing 'title'\n            headers={\"Authorization\": f\"Bearer {auth_token}\"}\n        )\n\n        assert response.status_code == 422  # Validation error\n        assert \"title\" in response.json()[\"detail\"][0][\"loc\"]\n\n    def test_create_book_unauthorized(self, client: TestClient):\n        \"\"\"Test book creation without authentication.\"\"\"\n        response = client.post(\n            \"/api/books\",\n            json={\"title\": \"Test\", \"author_id\": 1}\n        )\n\n        assert response.status_code == 401\n\n    def test_get_books_with_filters(\n        self, client: TestClient, auth_token: str, mock_book_repo\n    ):\n        \"\"\"Test getting books with query filters.\"\"\"\n        with patch(\"app.dependencies.get_book_repository\", return_value=mock_book_repo):\n            response = client.get(\n                \"/api/books?author_id=1&amp;search=pragmatic\",\n                headers={\"Authorization\": f\"Bearer {auth_token}\"}\n            )\n\n            assert response.status_code == 200\n            books = response.json()\n            assert isinstance(books, list)\n            assert len(books) &gt; 0\n\n            mock_book_repo.get_all.assert_called_once()\n\n    def test_get_book_by_id_not_found(\n        self, client: TestClient, auth_token: str\n    ):\n        \"\"\"Test getting non-existent book.\"\"\"\n        mock_repo = AsyncMock(spec=BookRepository)\n        mock_repo.get_by_id.return_value = None\n\n        with patch(\"app.dependencies.get_book_repository\", return_value=mock_repo):\n            response = client.get(\n                \"/api/books/999\",\n                headers={\"Authorization\": f\"Bearer {auth_token}\"}\n            )\n\n            assert response.status_code == 404\n            assert \"not found\" in response.json()[\"detail\"].lower()\n\n    def test_update_book_partial(\n        self, client: TestClient, auth_token: str, mock_book_repo\n    ):\n        \"\"\"Test partial book update.\"\"\"\n        with patch(\"app.dependencies.get_book_repository\", return_value=mock_book_repo):\n            response = client.put(\n                \"/api/books/1\",\n                json={\"title\": \"Updated Title\"},\n                headers={\"Authorization\": f\"Bearer {auth_token}\"}\n            )\n\n            assert response.status_code == 200\n            data = response.json()\n            assert data[\"title\"] == \"Updated Title\"\n\n    def test_delete_book_requires_admin(\n        self, client: TestClient\n    ):\n        \"\"\"Test deletion requires admin role.\"\"\"\n        # Token without admin role\n        response = client.delete(\n            \"/api/books/1\",\n            headers={\"Authorization\": \"Bearer non_admin_token\"}\n        )\n\n        assert response.status_code == 403\n\n    def test_pagination_parameters(\n        self, client: TestClient, auth_token: str\n    ):\n        \"\"\"Test pagination with various parameters.\"\"\"\n        response = client.get(\n            \"/api/books/paginated?page=2&amp;per_page=10\",\n            headers={\"Authorization\": f\"Bearer {auth_token}\"}\n        )\n\n        assert response.status_code == 200\n        data = response.json()\n        assert \"items\" in data\n        assert \"meta\" in data\n        assert data[\"meta\"][\"page\"] == 2\n        assert data[\"meta\"][\"per_page\"] == 10\n</code></pre>"},{"location":"guides/http-endpoints/#related","title":"Related","text":"<ul> <li>Design Patterns Guide</li> <li>WebSocket Handlers</li> <li>Authentication Guide</li> <li>Testing Guide</li> </ul>"},{"location":"guides/monitoring/","title":"Monitoring Setup Guide","text":"<p>This application includes comprehensive observability with Prometheus metrics for monitoring and Grafana Loki for centralized log aggregation.</p>"},{"location":"guides/monitoring/#quick-start","title":"Quick Start","text":""},{"location":"guides/monitoring/#1-view-raw-metrics","title":"1. View Raw Metrics","text":"<p>Start your FastAPI application and navigate to: <pre><code>http://localhost:8000/metrics\n</code></pre></p> <p>You'll see Prometheus text format metrics like: <pre><code># HELP http_requests_total Total HTTP requests\n# TYPE http_requests_total counter\nhttp_requests_total{method=\"GET\",endpoint=\"/health\",status_code=\"200\"} 42.0\n\n# HELP ws_connections_active Active WebSocket connections\n# TYPE ws_connections_active gauge\nws_connections_active 5.0\n</code></pre></p>"},{"location":"guides/monitoring/#2-using-docker-compose-recommended","title":"2. Using Docker Compose (Recommended)","text":"<p>Start the full observability stack with your application:</p> <pre><code>cd docker\ndocker-compose up -d\n</code></pre> <p>Access the monitoring and logging tools: - Application: http://localhost:8000 - Prometheus UI: http://localhost:9090 - Grafana: http://localhost:3000 (admin/admin) - Loki API: http://localhost:3100 - Metrics Endpoint: http://localhost:8000/metrics</p>"},{"location":"guides/monitoring/#available-metrics","title":"Available Metrics","text":""},{"location":"guides/monitoring/#http-metrics","title":"HTTP Metrics","text":"<ul> <li><code>http_requests_total</code> - Total number of HTTP requests (counter)</li> <li>Labels: method, endpoint, status_code</li> <li><code>http_request_duration_seconds</code> - HTTP request duration (histogram)</li> <li>Labels: method, endpoint</li> <li>Buckets: 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0</li> <li><code>http_requests_in_progress</code> - In-progress HTTP requests (gauge)</li> <li>Labels: method, endpoint</li> </ul>"},{"location":"guides/monitoring/#websocket-metrics","title":"WebSocket Metrics","text":"<ul> <li><code>ws_connections_active</code> - Active WebSocket connections (gauge)</li> <li><code>ws_connections_total</code> - Total WebSocket connections (counter)</li> <li>Labels: status (accepted, rejected_auth, rejected_limit)</li> <li><code>ws_messages_received_total</code> - Total WebSocket messages received (counter)</li> <li><code>ws_messages_sent_total</code> - Total WebSocket messages sent (counter)</li> <li><code>ws_message_processing_duration_seconds</code> - Message processing duration (histogram)</li> <li>Labels: pkg_id</li> </ul>"},{"location":"guides/monitoring/#database-metrics-for-future-instrumentation","title":"Database Metrics (for future instrumentation)","text":"<ul> <li><code>db_query_duration_seconds</code> - Database query duration (histogram)</li> <li>Labels: operation</li> <li><code>db_connections_active</code> - Active database connections (gauge)</li> <li><code>db_query_errors_total</code> - Database query errors (counter)</li> <li>Labels: operation, error_type</li> </ul>"},{"location":"guides/monitoring/#redis-metrics-for-future-instrumentation","title":"Redis Metrics (for future instrumentation)","text":"<ul> <li><code>redis_operations_total</code> - Total Redis operations (counter)</li> <li>Labels: operation</li> <li><code>redis_operation_duration_seconds</code> - Redis operation duration (histogram)</li> <li>Labels: operation</li> </ul>"},{"location":"guides/monitoring/#authentication-rate-limiting","title":"Authentication &amp; Rate Limiting","text":"<ul> <li><code>auth_attempts_total</code> - Authentication attempts (counter)</li> <li>Labels: status</li> <li><code>auth_token_validations_total</code> - Token validations (counter)</li> <li>Labels: status</li> <li><code>rate_limit_hits_total</code> - Rate limit hits (counter)</li> <li>Labels: limit_type</li> </ul>"},{"location":"guides/monitoring/#application-metrics","title":"Application Metrics","text":"<ul> <li><code>app_errors_total</code> - Application errors (counter)</li> <li>Labels: error_type, handler</li> <li><code>app_info</code> - Application info (gauge)</li> <li>Labels: version, python_version, environment</li> </ul>"},{"location":"guides/monitoring/#circuit-breaker-metrics","title":"Circuit Breaker Metrics","text":"<p>The application includes circuit breaker pattern for external service resilience (Keycloak and Redis). These metrics are critical for monitoring service health and detecting failures.</p> <ul> <li><code>circuit_breaker_state</code> - Current circuit breaker state (gauge)</li> <li>Labels: service (keycloak, redis)</li> <li>Values: 0 = closed (healthy), 1 = open (failing), 2 = half_open (testing recovery)</li> <li><code>circuit_breaker_state_changes_total</code> - Circuit breaker state transitions (counter)</li> <li>Labels: service, from_state, to_state</li> <li>Tracks: closed\u2192open, open\u2192half_open, half_open\u2192closed, half_open\u2192open</li> <li><code>circuit_breaker_failures_total</code> - Failed external service calls (counter)</li> <li>Labels: service, error_type</li> </ul> <p>Key Insights: - Circuit breaker state = 1 (open) means service is down \u2192 immediate alert required - Frequent state changes indicate unstable service (flapping) - High failure count even when closed suggests approaching threshold</p> <p>Grafana Panels: - Panel 28: Circuit breaker state timeseries (visualizes 0/\u00bd states) - Panel 29: Circuit breaker failure rate (failures/second per service) - Panel 30: Circuit breaker state changes (bar chart of transitions)</p> <p>See: Circuit Breaker Guide for comprehensive documentation on configuration, tuning, and troubleshooting.</p>"},{"location":"guides/monitoring/#prometheus-queries","title":"Prometheus Queries","text":""},{"location":"guides/monitoring/#useful-promql-queries","title":"Useful PromQL Queries","text":"<p>Request rate (requests per second): <pre><code>rate(http_requests_total[5m])\n</code></pre></p> <p>95<sup>th</sup> percentile request duration: <pre><code>histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\n</code></pre></p> <p>Error rate: <pre><code>rate(http_requests_total{status_code=~\"5..\"}[5m])\n</code></pre></p> <p>WebSocket connection rate: <pre><code>rate(ws_connections_total[5m])\n</code></pre></p> <p>Rate limit hit rate: <pre><code>rate(rate_limit_hits_total[5m])\n</code></pre></p> <p>Average message processing time: <pre><code>rate(ws_message_processing_duration_seconds_sum[5m]) / rate(ws_message_processing_duration_seconds_count[5m])\n</code></pre></p> <p>Circuit breaker state (0=closed, 1=open, 2=half_open): <pre><code>circuit_breaker_state\n</code></pre></p> <p>Circuit breaker failure rate: <pre><code>rate(circuit_breaker_failures_total[5m])\n</code></pre></p> <p>Circuit breaker state changes (flapping detection): <pre><code>increase(circuit_breaker_state_changes_total[5m])\n</code></pre></p> <p>Detect open circuit breakers (alert condition): <pre><code>circuit_breaker_state &gt; 0\n</code></pre></p> <p>Time since last circuit breaker state change: <pre><code>time() - circuit_breaker_state_changes_total\n</code></pre></p>"},{"location":"guides/monitoring/#grafana-setup","title":"Grafana Setup","text":""},{"location":"guides/monitoring/#1-add-prometheus-data-source","title":"1. Add Prometheus Data Source","text":"<ol> <li>Login to Grafana at http://localhost:3000 (admin/admin)</li> <li>Go to Configuration \u2192 Data Sources</li> <li>Click \"Add data source\"</li> <li>Select \"Prometheus\"</li> <li>Set URL to <code>http://prometheus:9090</code></li> <li>Click \"Save &amp; Test\"</li> </ol>"},{"location":"guides/monitoring/#2-pre-configured-dashboards","title":"2. Pre-configured Dashboards","text":"<p>The project includes comprehensive pre-configured dashboards that are automatically provisioned when you start Grafana:</p> <p>Available Dashboards:</p> <ol> <li>FastAPI Metrics (<code>docker/grafana/provisioning/dashboards/fastapi-metrics.json</code>)</li> <li>HTTP request rate and duration</li> <li>WebSocket connections and message rate</li> <li>Rate limit metrics</li> <li>Application info and errors</li> <li> <p>Auto-provisioned on Grafana startup</p> </li> <li> <p>Application Logs (<code>docker/grafana/provisioning/dashboards/application-logs.json</code>)</p> </li> <li>Log volume by service</li> <li>Error logs and trends</li> <li>Service-specific log panels</li> <li> <p>Auto-provisioned on Grafana startup</p> </li> <li> <p>Keycloak Metrics (<code>docker/grafana/provisioning/dashboards/keycloak-metrics.json</code>)</p> </li> <li>Authentication metrics</li> <li>JVM and performance stats</li> <li> <p>Auto-provisioned on Grafana startup</p> </li> <li> <p>Traefik Metrics (<code>docker/grafana/provisioning/dashboards/traefik-metrics.json</code>)</p> </li> <li>Reverse proxy metrics</li> <li>Request routing stats</li> <li>Auto-provisioned on Grafana startup</li> </ol> <p>Accessing Dashboards: After starting the stack with <code>docker-compose up -d</code>, dashboards are automatically available at: - http://localhost:3000/dashboards (Browse all dashboards)</p>"},{"location":"guides/monitoring/#3-create-custom-panels","title":"3. Create Custom Panels","text":"<p>Example panel configurations:</p> <p>Error Rate Panel: <pre><code>{\n  \"expr\": \"rate(http_requests_total{status_code=~\\\"5..\\\"}[5m])\",\n  \"legendFormat\": \"{{method}} {{endpoint}} - {{status_code}}\"\n}\n</code></pre></p> <p>WebSocket Active Connections: <pre><code>{\n  \"expr\": \"ws_connections_active\",\n  \"legendFormat\": \"Active Connections\"\n}\n</code></pre></p>"},{"location":"guides/monitoring/#alerts","title":"Alerts","text":""},{"location":"guides/monitoring/#example-alert-rules","title":"Example Alert Rules","text":"<p>Create <code>prometheus-alerts.yml</code>:</p> <pre><code>groups:\n  - name: fastapi_alerts\n    interval: 30s\n    rules:\n      - alert: HighErrorRate\n        expr: rate(http_requests_total{status_code=~\"5..\"}[5m]) &gt; 0.05\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High error rate detected\"\n          description: \"Error rate is {{ $value }} requests/second\"\n\n      - alert: HighLatency\n        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) &gt; 1\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High latency detected\"\n          description: \"95th percentile latency is {{ $value }}s\"\n\n      - alert: RateLimitExceeded\n        expr: rate(rate_limit_hits_total[5m]) &gt; 10\n        for: 2m\n        labels:\n          severity: info\n        annotations:\n          summary: \"Rate limits being hit frequently\"\n          description: \"Rate limit hit rate: {{ $value }} hits/second\"\n</code></pre> <p>Update <code>prometheus.yml</code> to include alerts: <pre><code>rule_files:\n  - \"prometheus-alerts.yml\"\n\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets: ['alertmanager:9093']\n</code></pre></p>"},{"location":"guides/monitoring/#custom-metrics-in-code","title":"Custom Metrics in Code","text":""},{"location":"guides/monitoring/#adding-custom-metrics","title":"Adding Custom Metrics","text":"<pre><code>from app.utils.metrics import http_requests_total, db_query_duration_seconds\n\n# Increment counter\nhttp_requests_total.labels(\n    method=\"POST\",\n    endpoint=\"/api/custom\",\n    status_code=201\n).inc()\n\n# Observe histogram\ndb_query_duration_seconds.labels(operation=\"select\").observe(0.045)\n</code></pre>"},{"location":"guides/monitoring/#creating-new-metrics","title":"Creating New Metrics","text":"<p>Add to <code>app/utils/metrics.py</code>:</p> <pre><code>from prometheus_client import Counter\n\ncustom_events_total = Counter(\n    'custom_events_total',\n    'Total custom events',\n    ['event_type', 'status']\n)\n\n# Usage\ncustom_events_total.labels(event_type='user_action', status='success').inc()\n</code></pre>"},{"location":"guides/monitoring/#production-considerations","title":"Production Considerations","text":""},{"location":"guides/monitoring/#1-metric-cardinality","title":"1. Metric Cardinality","text":"<p>Avoid high-cardinality labels (e.g., user IDs, timestamps). Use aggregated labels instead:</p> <p>\u274c Bad: <pre><code>requests.labels(user_id=user.id)  # Unbounded cardinality\n</code></pre></p> <p>\u2705 Good: <pre><code>requests.labels(user_type=user.role)  # Bounded cardinality\n</code></pre></p>"},{"location":"guides/monitoring/#2-performance","title":"2. Performance","text":"<ul> <li>Metrics collection has minimal overhead (~microseconds per metric)</li> <li>Use histograms for latency tracking (pre-configured buckets)</li> <li>Consider sampling for very high-traffic endpoints if needed</li> </ul>"},{"location":"guides/monitoring/#3-retention","title":"3. Retention","text":"<p>Configure Prometheus retention in <code>docker-compose.yml</code>:</p> <pre><code>command:\n  - '--storage.tsdb.retention.time=30d'\n  - '--storage.tsdb.retention.size=10GB'\n</code></pre>"},{"location":"guides/monitoring/#4-security","title":"4. Security","text":"<p>For production: - Enable authentication on Prometheus and Grafana - Use TLS for metrics endpoints - Restrict network access to monitoring tools - Consider using read-only Prometheus API tokens</p>"},{"location":"guides/monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/monitoring/#metrics-not-appearing","title":"Metrics not appearing","text":"<ol> <li> <p>Check <code>/metrics</code> endpoint is accessible:    <pre><code>curl http://localhost:8000/metrics\n</code></pre></p> </li> <li> <p>Verify Prometheus is scraping:</p> </li> <li>Go to http://localhost:9090/targets</li> <li> <p>Check if <code>fastapi-app</code> target is UP</p> </li> <li> <p>Check Prometheus logs:    <pre><code>docker logs hw-prometheus\n</code></pre></p> </li> </ol>"},{"location":"guides/monitoring/#grafana-dashboard-shows-no-data","title":"Grafana dashboard shows no data","text":"<ol> <li>Verify data source connection:</li> <li> <p>Configuration \u2192 Data Sources \u2192 Prometheus \u2192 Test</p> </li> <li> <p>Check time range in dashboard (top right)</p> </li> <li> <p>Verify metrics exist in Prometheus:</p> </li> <li>Go to Prometheus \u2192 Graph</li> <li>Enter metric name and execute</li> </ol>"},{"location":"guides/monitoring/#high-memory-usage","title":"High memory usage","text":"<p>If Prometheus uses too much memory:</p> <ol> <li> <p>Reduce retention time:    <pre><code>--storage.tsdb.retention.time=15d\n</code></pre></p> </li> <li> <p>Reduce scrape frequency in <code>prometheus.yml</code>:    <pre><code>scrape_interval: 30s  # Instead of 15s\n</code></pre></p> </li> <li> <p>Review metric cardinality:    <pre><code>count({__name__=~\".+\"}) by (__name__)\n</code></pre></p> </li> </ol>"},{"location":"guides/monitoring/#centralized-logging-with-loki","title":"Centralized Logging with Loki","text":""},{"location":"guides/monitoring/#overview","title":"Overview","text":"<p>Grafana Loki provides centralized log aggregation for all Docker containers. Promtail collects logs from Docker containers and ships them to Loki for storage and querying.</p>"},{"location":"guides/monitoring/#architecture","title":"Architecture","text":"<pre><code>Docker Containers \u2192 Promtail \u2192 Loki \u2192 Grafana\n                      \u2193\n                 /var/run/docker.sock\n</code></pre> <ul> <li>Loki: Log aggregation system (similar to Prometheus but for logs)</li> <li>Promtail: Log collection agent that reads Docker container logs</li> <li>Grafana: Visualization layer for both metrics and logs</li> </ul>"},{"location":"guides/monitoring/#viewing-logs-in-grafana","title":"Viewing Logs in Grafana","text":""},{"location":"guides/monitoring/#1-using-the-logs-dashboard","title":"1. Using the Logs Dashboard","text":"<ol> <li>Navigate to Grafana: http://localhost:3000</li> <li>Go to Dashboards \u2192 Application Logs</li> <li>The dashboard includes:</li> <li>Log volume by service</li> <li>Log level distribution (ERROR, WARNING, INFO)</li> <li>Error logs panel</li> <li>Error rate trends</li> <li>Service-specific log panels</li> </ol>"},{"location":"guides/monitoring/#2-using-explore-ad-hoc-queries","title":"2. Using Explore (Ad-hoc Queries)","text":"<ol> <li>Go to Explore \u2192 Select \"Loki\" datasource</li> <li>Use LogQL to query logs</li> </ol>"},{"location":"guides/monitoring/#logql-query-examples","title":"LogQL Query Examples","text":"<p>Basic Queries:</p> <pre><code># All logs from shell service (FastAPI)\n{service=\"shell\"}\n\n# All logs from specific container\n{container=\"hw-shell\"}\n\n# Logs from multiple services\n{service=~\"shell|hw-db|hw-keycloak\"}\n</code></pre> <p>Filtering by Content:</p> <pre><code># All error logs\n{service=\"shell\"} |= \"ERROR\"\n\n# Case-insensitive error search\n{service=\"shell\"} |~ \"(?i)(error|exception)\"\n\n# Filter out health checks\n{service=\"shell\"} != \"GET /health\"\n\n# Python tracebacks\n{service=\"shell\"} |= \"Traceback\"\n</code></pre> <p>JSON Log Parsing:</p> <pre><code># Parse JSON logs and filter by level\n{service=\"shell\"} | json | level=\"ERROR\"\n\n# Extract specific JSON field\n{service=\"shell\"} | json | line_format \"{{.message}}\"\n\n# Filter by nested JSON field\n{service=\"shell\"} | json | error!=\"\"\n</code></pre> <p>Advanced Queries:</p> <pre><code># Count log lines per service\nsum by (service) (count_over_time({job=\"docker\"}[5m]))\n\n# Error rate per service\nsum by (service) (rate({job=\"docker\"} |~ \"(?i)error\" [5m]))\n\n# Top 10 error messages\ntopk(10, sum by (service) (count_over_time({job=\"docker\"} |~ \"(?i)error\" [1h])))\n\n# Filter by multiple conditions\n{service=\"shell\"}\n  | json\n  | level=\"ERROR\"\n  | line_format \"{{.timestamp}} - {{.message}}\"\n</code></pre> <p>Time-based Queries:</p> <pre><code># Logs in the last 5 minutes\n{service=\"shell\"} [5m]\n\n# Log volume rate\nrate({service=\"shell\"}[1m])\n\n# Count over time window\ncount_over_time({service=\"shell\"}[10m])\n</code></pre>"},{"location":"guides/monitoring/#log-retention","title":"Log Retention","text":"<p>By default, logs are retained for 7 days (168 hours). This is configured in docker/loki/loki-config.yml:</p> <pre><code>limits_config:\n  reject_old_samples_max_age: 168h  # 7 days\n\ncompactor:\n  retention_enabled: true\n  retention_delete_delay: 2h\n</code></pre> <p>To change retention: 1. Edit <code>docker/loki/loki-config.yml</code> 2. Update <code>reject_old_samples_max_age</code> value (e.g., <code>720h</code> for 30 days) 3. Restart Loki: <code>docker-compose restart loki</code></p>"},{"location":"guides/monitoring/#log-collection-configuration","title":"Log Collection Configuration","text":"<p>Promtail is configured to collect logs from all Docker containers in this project. Configuration is in docker/promtail/promtail-config.yml.</p> <p>What gets collected: - Container logs (stdout/stderr) - Service name from Docker Compose labels - Log stream (stdout vs stderr) - Container ID and name - Timestamps</p> <p>What gets filtered out: - Health check requests (<code>GET /health</code>) - Empty log lines</p>"},{"location":"guides/monitoring/#structured-logging-with-loki-integration","title":"Structured Logging with Loki Integration","text":"<p>This application uses structured JSON logging with automatic Loki integration. Logs are sent to Loki in JSON format with contextual fields for easy filtering.</p>"},{"location":"guides/monitoring/#built-in-features","title":"Built-in Features","text":"<p>The application automatically includes: - Correlation ID tracking: Each request gets a unique ID - Contextual fields: endpoint, method, status_code, user_id - JSON formatting: All logs sent to Loki are in JSON format - Human-readable console: Development logs are human-readable - Multiple handlers: Console, file, and Loki handlers</p>"},{"location":"guides/monitoring/#configuration","title":"Configuration","text":"<p>Loki integration is controlled via environment variables (see app/settings.py):</p> <pre><code># Enable/disable Loki integration\nLOKI_ENABLED=true\n\n# Loki server URL (inside Docker network)\nLOKI_URL=http://loki:3100\n\n# Log level (DEBUG, INFO, WARNING, ERROR)\nLOG_LEVEL=INFO\n\n# Environment tag for filtering\nENVIRONMENT=development\n</code></pre>"},{"location":"guides/monitoring/#basic-usage","title":"Basic Usage","text":"<p>Simply use the standard Python logger:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\n# Basic logging (automatically includes request_id, endpoint, user_id, etc.)\nlogger.info(\"Processing author creation\")\nlogger.warning(\"Rate limit approaching threshold\")\nlogger.error(\"Database connection failed\", exc_info=True)\n</code></pre>"},{"location":"guides/monitoring/#adding-custom-context","title":"Adding Custom Context","text":"<p>Add custom contextual fields to all logs within a request:</p> <pre><code>from app.logging import set_log_context, logger\n\n# In your endpoint or handler\nset_log_context(\n    operation=\"create_author\",\n    author_id=123,\n    ip_address=request.client.host\n)\n\nlogger.info(\"Author created successfully\")\n# Log will include: operation, author_id, ip_address, plus auto fields\n</code></pre>"},{"location":"guides/monitoring/#example-log-output","title":"Example Log Output","text":"<p>Console (Human-readable): <pre><code>2025-12-16 14:30:45 - [a1b2c3d4] INFO: Processing author creation\n2025-12-16 14:30:45 - [a1b2c3d4] INFO: app.api.http.author.create_author:42 - Author created successfully\n</code></pre></p> <p>Loki (JSON): <pre><code>{\n  \"timestamp\": \"2025-12-16T14:30:45.123Z\",\n  \"level\": \"INFO\",\n  \"logger\": \"app.api.http.author\",\n  \"message\": \"Author created successfully\",\n  \"module\": \"author\",\n  \"function\": \"create_author\",\n  \"line\": 42,\n  \"request_id\": \"a1b2c3d4\",\n  \"endpoint\": \"/api/authors\",\n  \"method\": \"POST\",\n  \"status_code\": 201,\n  \"user_id\": \"user-123\",\n  \"environment\": \"development\"\n}\n</code></pre></p>"},{"location":"guides/monitoring/#query-examples-for-structured-logs","title":"Query Examples for Structured Logs","text":"<p>Once logs are in Loki, you can query them using LogQL:</p> <pre><code># All requests from specific user\n{application=\"fastapi-app\"} | json | user_id=\"user-123\"\n\n# Failed requests (5xx status codes)\n{application=\"fastapi-app\"} | json | status_code &gt;= 500\n\n# Slow requests (custom field)\n{application=\"fastapi-app\"} | json | duration_ms &gt; 1000\n\n# Errors for specific endpoint\n{application=\"fastapi-app\"} | json | level=\"ERROR\" | endpoint=\"/api/authors\"\n\n# Requests by correlation ID (trace single request)\n{application=\"fastapi-app\"} | json | request_id=\"a1b2c3d4\"\n</code></pre>"},{"location":"guides/monitoring/#websocket-logging","title":"WebSocket Logging","text":"<p>For WebSocket handlers, manually add context:</p> <pre><code>from app.logging import set_log_context, logger\n\nasync def handle_websocket_message(request: RequestModel):\n    # Add WebSocket-specific context\n    set_log_context(\n        pkg_id=request.pkg_id,\n        req_id=request.req_id,\n        user_id=request.data.get(\"user_id\")\n    )\n\n    logger.info(f\"Processing WebSocket request {request.pkg_id}\")\n    # Process request...\n</code></pre>"},{"location":"guides/monitoring/#best-practices","title":"Best Practices","text":"<p>\u2705 Do: - Use logger.info() for normal operations - Use logger.warning() for recoverable issues - Use logger.error() with exc_info=True for exceptions - Add contextual fields with set_log_context() - Use correlation IDs to trace requests</p> <p>\u274c Don't: - Log sensitive data (passwords, tokens, PII) - Log at DEBUG level in production - Create new loggers without using logging.getLogger(name) - Include large objects in log messages (they're truncated anyway)</p>"},{"location":"guides/monitoring/#correlating-logs-with-metrics","title":"Correlating Logs with Metrics","text":"<p>In Grafana, you can correlate metrics spikes with logs:</p> <ol> <li>From Metrics Dashboard to Logs:</li> <li>Click on a metric spike in Prometheus dashboard</li> <li>Select \"Explore\" \u2192 Switch to Loki datasource</li> <li> <p>Logs from the same time range will appear</p> </li> <li> <p>From Logs to Metrics:</p> </li> <li>Find an error in logs</li> <li>Note the timestamp</li> <li>Switch to Prometheus datasource</li> <li> <p>Query metrics around that timestamp</p> </li> <li> <p>Split View:</p> </li> <li>Use Grafana's split view (Explore \u2192 Split)</li> <li>Prometheus on one side, Loki on the other</li> <li>Same time range for correlation</li> </ol>"},{"location":"guides/monitoring/#troubleshooting-loki","title":"Troubleshooting Loki","text":""},{"location":"guides/monitoring/#no-logs-appearing","title":"No logs appearing","text":"<ol> <li> <p>Check Promtail is running: <pre><code>docker ps | grep promtail\ndocker logs hw-promtail\n</code></pre></p> </li> <li> <p>Verify Promtail can access Docker socket: <pre><code>docker exec hw-promtail ls -la /var/run/docker.sock\n</code></pre></p> </li> <li> <p>Check Promtail targets: <pre><code>curl http://localhost:9080/targets\n</code></pre></p> </li> <li> <p>Verify Loki is receiving logs: <pre><code>curl http://localhost:3100/loki/api/v1/label\ncurl http://localhost:3100/loki/api/v1/label/service/values\n</code></pre></p> </li> </ol>"},{"location":"guides/monitoring/#logs-are-delayed","title":"Logs are delayed","text":"<ul> <li>Promtail buffers logs before sending to Loki</li> <li>Default refresh interval: 5 seconds</li> <li>Check Promtail logs for errors: <code>docker logs hw-promtail</code></li> </ul>"},{"location":"guides/monitoring/#high-loki-memory-usage","title":"High Loki memory usage","text":"<ol> <li> <p>Reduce retention period in <code>loki-config.yml</code>:    <pre><code>limits_config:\n  reject_old_samples_max_age: 72h  # 3 days instead of 7\n</code></pre></p> </li> <li> <p>Limit ingestion rate:    <pre><code>limits_config:\n  ingestion_rate_mb: 5  # Reduce from 10MB\n  ingestion_burst_size_mb: 10  # Reduce from 20MB\n</code></pre></p> </li> <li> <p>Filter noisy logs in <code>promtail-config.yml</code>:    <pre><code>pipeline_stages:\n  - drop:\n      expression: '.*DEBUG.*'\n      drop_counter_reason: debug_logs\n</code></pre></p> </li> </ol>"},{"location":"guides/monitoring/#cannot-query-old-logs","title":"Cannot query old logs","text":"<ul> <li>Check retention settings in <code>loki-config.yml</code></li> <li>Verify compactor is running:   <pre><code>docker logs hw-loki | grep compactor\n</code></pre></li> </ul>"},{"location":"guides/monitoring/#loki-api-usage","title":"Loki API Usage","text":"<p>Query logs programmatically:</p> <pre><code># Query logs via API\ncurl -G -s \"http://localhost:3100/loki/api/v1/query_range\" \\\n  --data-urlencode 'query={service=\"shell\"} |= \"error\"' \\\n  --data-urlencode \"start=$(date -d '1 hour ago' +%s)000000000\" \\\n  --data-urlencode \"end=$(date +%s)000000000\" \\\n  | jq '.data.result'\n\n# Get label values\ncurl -s \"http://localhost:3100/loki/api/v1/label/service/values\" | jq\n\n# Get all labels\ncurl -s \"http://localhost:3100/loki/api/v1/labels\" | jq\n</code></pre>"},{"location":"guides/monitoring/#logql-vs-promql","title":"LogQL vs PromQL","text":"Feature PromQL (Metrics) LogQL (Logs) Data type Time-series metrics Log lines Query <code>rate(http_requests_total[5m])</code> <code>{service=\"shell\"} \\|= \"error\"</code> Aggregation <code>sum by (method)</code> <code>count_over_time()</code> Filtering Label matchers Text search + JSON parsing Output Numbers Log lines + counts"},{"location":"guides/monitoring/#additional-resources","title":"Additional Resources","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Documentation</li> <li>Grafana Loki Documentation</li> <li>LogQL Documentation</li> <li>PromQL Cheat Sheet</li> <li>FastAPI Best Practices</li> </ul>"},{"location":"guides/performance-tuning/","title":"Performance Tuning Guide","text":"<p>Complete guide to optimizing application performance through caching, query optimization, connection pooling, and monitoring.</p>"},{"location":"guides/performance-tuning/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Database Query Optimization</li> <li>Caching Strategies</li> <li>Connection Pooling</li> <li>Slow Query Detection</li> <li>Performance Monitoring</li> <li>Profiling with Scalene</li> <li>Best Practices</li> <li>Troubleshooting</li> </ol>"},{"location":"guides/performance-tuning/#overview","title":"Overview","text":"<p>The application includes several built-in performance optimizations designed to handle high traffic loads while minimizing latency and resource usage.</p>"},{"location":"guides/performance-tuning/#key-performance-features","title":"Key Performance Features","text":"<ul> <li>\u2705 N+1 Query Prevention: Eager loading with <code>selectinload()</code></li> <li>\u2705 Pagination Count Caching: Redis-based COUNT query caching</li> <li>\u2705 Token Claim Caching: JWT validation result caching</li> <li>\u2705 Connection Pooling: Reusable DB and Redis connections</li> <li>\u2705 Circuit Breakers: Fail-fast when services are down</li> <li>\u2705 Slow Query Detection: Automatic monitoring and alerting</li> </ul>"},{"location":"guides/performance-tuning/#performance-targets","title":"Performance Targets","text":"Metric Target Measured HTTP P95 latency &lt; 200ms \u2705 WebSocket message latency &lt; 50ms \u2705 Database connection pool usage &lt; 80% \u2705 Redis connection pool usage &lt; 80% \u2705 Token cache hit rate &gt; 85% \u2705 85-95% Count cache hit rate &gt; 70% \u2705 50-90%"},{"location":"guides/performance-tuning/#database-query-optimization","title":"Database Query Optimization","text":""},{"location":"guides/performance-tuning/#n1-query-problem","title":"N+1 Query Problem","text":"<p>The N+1 query problem occurs when fetching a list of entities and then accessing their relationships in a loop:</p> <pre><code># \u274c BAD - N+1 queries (1 + N database queries)\nauthors = await session.exec(select(Author))  # 1 query\n\nfor author in authors:  # Loop through N authors\n    books = await author.awaitable_attrs.books  # N additional queries!\n    print(f\"{author.name}: {len(books)} books\")\n\n# Total: 1 + N queries (100 authors = 101 queries!)\n</code></pre>"},{"location":"guides/performance-tuning/#solution-eager-loading-with-selectinload","title":"Solution: Eager Loading with selectinload()","text":"<p>Use SQLAlchemy's <code>selectinload()</code> to load relationships efficiently:</p> <pre><code>from sqlalchemy.orm import selectinload\n\n# \u2705 GOOD - Only 2 queries total\nstmt = select(Author).options(selectinload(Author.books))\nresult = await session.execute(stmt)\nauthors = result.scalars().all()\n\n# Relationships already loaded, no await needed\nfor author in authors:\n    books = author.books  # \u2705 Already loaded!\n    print(f\"{author.name}: {len(books)} books\")\n\n# Total: 2 queries (1 for authors, 1 for all books in bulk)\n</code></pre>"},{"location":"guides/performance-tuning/#built-in-pagination-support","title":"Built-in Pagination Support","text":"<p>The <code>get_paginated_results()</code> function supports eager loading via the <code>eager_load</code> parameter:</p> <pre><code>from app.storage.db import get_paginated_results\n\n# Automatically prevents N+1 queries\nresults, meta = await get_paginated_results(\n    Author,\n    page=1,\n    per_page=20,\n    eager_load=[\"books\", \"reviews\"]  # Load multiple relationships\n)\n\n# Access relationships without additional queries\nfor author in results:\n    books = author.books  # Already loaded\n    reviews = author.reviews  # Already loaded\n</code></pre>"},{"location":"guides/performance-tuning/#when-to-use-eager-loading","title":"When to Use Eager Loading","text":"<p>\u2705 Use eager loading when: - Accessing relationships in loops (list views, reports) - Loading multiple related objects at once - Building API responses with nested data - Displaying paginated lists with related entities</p> <p>\u26a0\ufe0f Use lazy loading when: - Relationship might not be accessed (conditional logic) - Loading single object with specific relationship - Relationship access is rare or dynamic - Eager loading would load too much unnecessary data</p>"},{"location":"guides/performance-tuning/#performance-comparison","title":"Performance Comparison","text":"Strategy Query Count Best For Example Use Case Lazy Loading 1 + N Single relationship access Loading one author's books <code>selectinload()</code> 2 One-to-many, many-to-many Authors \u2192 books, users \u2192 roles <code>joinedload()</code> 1 (with JOIN) Many-to-one Books \u2192 author, orders \u2192 customer"},{"location":"guides/performance-tuning/#caching-strategies","title":"Caching Strategies","text":""},{"location":"guides/performance-tuning/#pagination-count-caching","title":"Pagination Count Caching","text":"<p>Expensive <code>COUNT(*)</code> queries are cached in Redis to improve pagination performance.</p> <p>How It Works:</p> <pre><code>from app.storage.db import get_paginated_results\n\n# First request - cache miss\nresults, meta = await get_paginated_results(\n    Author,\n    page=1,\n    per_page=20,\n    filters={\"status\": \"active\"}\n)\n# Executes: SELECT COUNT(*) FROM authors WHERE status = 'active'\n# Caches result with key: \"pagination:count:Author:8a3f2e1c\"\n\n# Subsequent requests - cache hit (same filters)\nresults, meta = await get_paginated_results(\n    Author,\n    page=2,\n    per_page=20,\n    filters={\"status\": \"active\"}\n)\n# Returns cached count (no COUNT query executed)\n</code></pre> <p>Configuration:</p> <ul> <li>Default TTL: 5 minutes</li> <li>Cache key: Based on model name + filter hash</li> <li>Storage: Redis (fail-open if unavailable)</li> </ul> <p>Performance Impact:</p> Table Size Without Cache With Cache Improvement 1,000 rows 5ms 1ms 80% faster 10,000 rows 45ms 1ms 98% faster 100,000 rows 450ms 1ms 99.8% faster"},{"location":"guides/performance-tuning/#cache-invalidation","title":"Cache Invalidation","text":"<p>CRITICAL: You must invalidate the count cache after any CREATE, UPDATE, or DELETE operation that affects the model.</p> <pre><code>from app.utils.pagination_cache import invalidate_count_cache\n\n# After creating a new record\nasync def create_author(author: Author, repo: AuthorRepository) -&gt; Author:\n    result = await repo.create(author)\n    await invalidate_count_cache(\"Author\")  # Invalidate all counts\n    return result\n\n# After deleting a record\nasync def delete_author(author_id: int, repo: AuthorRepository) -&gt; None:\n    await repo.delete(author_id)\n    await invalidate_count_cache(\"Author\")\n\n# After updating (if it affects filters)\nasync def update_author_status(\n    author_id: int, status: str, repo: AuthorRepository\n) -&gt; Author:\n    author = await repo.get_by_id(author_id)\n    old_status = author.status\n    author.status = status\n    result = await repo.update(author)\n\n    # Invalidate counts for both old and new status\n    await invalidate_count_cache(\"Author\", filters={\"status\": old_status})\n    await invalidate_count_cache(\"Author\", filters={\"status\": status})\n    return result\n</code></pre> <p>When to Invalidate:</p> <ul> <li>\u2705 Always: After INSERT or DELETE operations</li> <li>\u2705 Conditional: After UPDATE if updated field is in common filters</li> <li>\u274c Never: After SELECT/GET operations</li> <li>\u26a0\ufe0f Skip caching: For models with very frequent writes</li> </ul> <p>Granular Invalidation:</p> <pre><code># Invalidate all counts for a model\nawait invalidate_count_cache(\"Author\")\n\n# Invalidate only specific filter combination\nawait invalidate_count_cache(\"Author\", filters={\"status\": \"active\"})\n\n# Batch operations - invalidate once at the end\nasync def batch_create_authors(\n    authors: list[Author], repo: AuthorRepository\n) -&gt; None:\n    for author in authors:\n        await repo.create(author)\n\n    # Invalidate once after batch (not per record!)\n    await invalidate_count_cache(\"Author\")\n</code></pre>"},{"location":"guides/performance-tuning/#token-claim-caching","title":"Token Claim Caching","text":"<p>JWT token claims are cached in Redis to reduce CPU overhead and Keycloak validation load.</p> <p>How It Works:</p> <pre><code># Token validation flow (automatic in AuthBackend)\n# 1. Hash token with SHA-256\ntoken_hash = hashlib.sha256(token.encode()).hexdigest()\n\n# 2. Check Redis cache\ncached_claims = await redis.get(f\"token:claims:{token_hash}\")\nif cached_claims:\n    return json.loads(cached_claims)  # Cache hit\n\n# 3. Validate with Keycloak (cache miss)\nclaims = await keycloak_manager.openid.a_decode_token(token)\n\n# 4. Cache claims (TTL = token expiry - 30s buffer)\nttl = claims[\"exp\"] - time.time() - 30\nawait redis.setex(f\"token:claims:{token_hash}\", int(ttl), json.dumps(claims))\n</code></pre> <p>Performance Impact:</p> <ul> <li>90% reduction in token decode CPU time</li> <li>85-95% cache hit rate for repeated requests</li> <li>85-95% reduction in Keycloak API load</li> </ul> <p>Security Considerations:</p> <ul> <li>Token hash used as cache key (not full token)</li> <li>Short TTL matching token expiration</li> <li>Fail-open behavior if Redis unavailable</li> <li>No PII stored in cache keys</li> </ul>"},{"location":"guides/performance-tuning/#skip-count-for-real-time-data","title":"Skip Count for Real-Time Data","text":"<p>For endpoints where total count is not needed (e.g., infinite scroll):</p> <pre><code>results, meta = await get_paginated_results(\n    Message,\n    page=1,\n    per_page=50,\n    skip_count=True  # Skip expensive COUNT query\n)\n# meta.total will be 0, meta.pages will be 0\n</code></pre>"},{"location":"guides/performance-tuning/#layered-caching-memory-redis","title":"Layered Caching (Memory + Redis)","text":"<p>For hot keys (frequently accessed data), use the <code>CacheManager</code> with two-tier caching.</p> <p>Architecture:</p> <ul> <li>L1 Cache (Memory): Fastest access, no network latency, LRU eviction</li> <li>L2 Cache (Redis): Shared across instances, persistent</li> </ul> <p>When to Use:</p> <p>\u2705 Use CacheManager when: - Hot keys accessed very frequently (&gt; 100 requests/sec) - Data changes infrequently (&lt; 1 update/minute) - Single-instance deployment - Small objects (&lt; 100KB) - Redis latency is a bottleneck (&gt; 5ms p95)</p> <p>\u26a0\ufe0f Use with caution when: - Horizontally scaled deployment (cache coherence issues) - Data changes frequently (&gt; 10 updates/sec) - Large objects (&gt; 1MB)</p> <p>Example Usage:</p> <pre><code>from app.managers.cache_manager import get_cache_manager\n\n# Get singleton cache manager\ncache = get_cache_manager(\n    max_memory_entries=1000,  # LRU eviction after 1000 entries\n    default_ttl=300,          # 5 minutes default TTL\n)\n\n# Cache-aside pattern\nasync def get_user_profile(user_id: int):\n    cache_key = f\"user:profile:{user_id}\"\n\n    # Try cache first\n    profile = await cache.get(cache_key)\n    if profile is not None:\n        return profile\n\n    # Cache miss - query database\n    profile = await db.query_user_profile(user_id)\n\n    # Cache result\n    await cache.set(cache_key, profile, ttl=900)  # 15 minutes\n\n    return profile\n\n# Invalidate after updates\nasync def update_user_profile(user_id: int, data: dict):\n    await db.update_user_profile(user_id, data)\n\n    # CRITICAL: Invalidate cache after update\n    await cache.invalidate(f\"user:profile:{user_id}\")\n</code></pre> <p>Performance Impact:</p> Tier Latency Use Case Memory (L1) &lt; 1ms Hot keys, frequently accessed Redis (L2) 1-5ms Shared state, moderate access Database 10-100ms Cache miss, cold data <p>Memory vs Redis-Only Caching:</p> <pre><code># Memory + Redis (CacheManager) - Fastest for hot keys\ncache = get_cache_manager()\nawait cache.set(\"hot:key\", value)  # Cached in both memory and Redis\nvalue = await cache.get(\"hot:key\")  # &lt; 1ms (memory hit)\n\n# Redis-only (pagination_cache) - Better for shared state\nfrom app.utils.pagination_cache import set_cached_count\nawait set_cached_count(\"Author\", 100)  # Redis only\ncount = await get_cached_count(\"Author\")  # 1-5ms (Redis hit)\n</code></pre> <p>Monitoring:</p> <pre><code># Memory cache hit rate\nrate(memory_cache_hits_total[5m]) /\n(rate(memory_cache_hits_total[5m]) + rate(memory_cache_misses_total[5m]))\n\n# Memory cache size\nmemory_cache_size\n\n# LRU evictions\nrate(memory_cache_evictions_total[5m])\n</code></pre> <p>Multi-Instance Deployment:</p> <p>In horizontally scaled deployments: - Each instance has its own memory cache (not shared) - Redis cache is shared - Cache invalidation must happen on ALL instances</p> <p>Strategies: 1. Use short TTL to reduce stale data window (&lt; 1 minute) 2. Accept eventual consistency 3. Use Redis-only caching (skip memory layer)</p> <p>See: <code>examples/layered_cache_usage.py</code> for complete usage examples.</p>"},{"location":"guides/performance-tuning/#connection-pooling","title":"Connection Pooling","text":""},{"location":"guides/performance-tuning/#database-connection-pool","title":"Database Connection Pool","text":"<p>PostgreSQL connections are pooled for reuse across requests.</p> <p>Configuration (<code>app/settings.py</code>):</p> <pre><code># Database connection pool settings\nDB_POOL_SIZE = 20           # Max connections in pool\nDB_MAX_OVERFLOW = 10        # Additional connections when pool exhausted\nDB_POOL_TIMEOUT = 30        # Seconds to wait for connection\nDB_POOL_RECYCLE = 3600      # Recycle connections after 1 hour\n</code></pre> <p>Monitoring:</p> <pre><code># Grafana/Prometheus queries\n# Pool usage percentage\n(db_pool_connections_in_use / db_pool_max_connections) * 100\n\n# Pool exhaustion events\nrate(db_pool_exhausted_total[5m])\n</code></pre> <p>Best Practices:</p> <ol> <li>Size pool appropriately: <code>POOL_SIZE \u2248 (2 * CPU_CORES) + effective_spindle_count</code></li> <li>Monitor pool usage: Keep usage &lt; 80% under normal load</li> <li>Use async context managers: Ensure connections are returned to pool</li> <li>Close connections properly: Avoid connection leaks</li> </ol> <pre><code># \u2705 GOOD - Connection automatically returned to pool\nasync with async_session() as session:\n    result = await session.execute(query)\n    # Connection returned to pool when context exits\n\n# \u274c BAD - Connection leak (not returned to pool)\nsession = async_session()\nresult = await session.execute(query)\n# Connection never returned!\n</code></pre>"},{"location":"guides/performance-tuning/#redis-connection-pool","title":"Redis Connection Pool","text":"<p>Redis connections are pooled per database index.</p> <p>Configuration (<code>app/settings.py</code>):</p> <pre><code># Redis connection pool settings\nREDIS_MAX_CONNECTIONS = 50           # Max connections per pool\nREDIS_SOCKET_TIMEOUT = 5             # Socket operation timeout\nREDIS_CONNECT_TIMEOUT = 5            # Connection establishment timeout\nREDIS_HEALTH_CHECK_INTERVAL = 30     # Health check frequency\n</code></pre> <p>Monitoring:</p> <p>Redis pool metrics are tracked via background task (<code>app/tasks/redis_pool_metrics_task.py</code>):</p> <pre><code># Pool usage percentage\n(redis_pool_connections_in_use / redis_pool_max_connections) * 100\n\n# Available connections\nredis_pool_connections_available\n\n# Connection creation rate\nrate(redis_pool_connections_created_total[5m])\n</code></pre> <p>Alerts (<code>docker/prometheus/alerts.yml</code>):</p> <ul> <li><code>RedisPoolNearExhaustion</code>: Pool usage &gt; 80% for 3 minutes</li> <li><code>RedisPoolExhausted</code>: Pool usage \u2265 95% for 1 minute</li> <li><code>RedisPoolNoAvailableConnections</code>: Zero available connections</li> </ul>"},{"location":"guides/performance-tuning/#slow-query-detection","title":"Slow Query Detection","text":""},{"location":"guides/performance-tuning/#automatic-query-monitoring","title":"Automatic Query Monitoring","text":"<p>SQLAlchemy event listeners track all database query execution times.</p> <p>Configuration:</p> <pre><code># app/utils/query_monitor.py\nSLOW_QUERY_THRESHOLD = 0.1  # 100ms threshold\n\n# Enabled automatically in app/storage/db.py\nenable_query_monitoring()\n</code></pre> <p>Slow Query Logging:</p> <pre><code>WARNING - Slow query detected: 0.245s [SELECT] Statement: SELECT * FROM authors WHERE ...\n</code></pre> <p>Metrics Available:</p> <pre><code># Query duration histogram\ndb_query_duration_seconds{operation=\"select|insert|update|delete\"}\n\n# Slow query counter\ndb_slow_queries_total{operation=\"select|insert|update|delete\"}\n</code></pre> <p>Grafana Dashboard:</p> <p>Query performance metrics are visualized in the <code>fastapi-metrics</code> dashboard: - Panel 19: Database query duration (P50, P95, P99) - Panel 20: Slow query rate</p>"},{"location":"guides/performance-tuning/#identifying-slow-queries","title":"Identifying Slow Queries","text":"<ol> <li>Check application logs for slow query warnings</li> <li>Review Grafana database query duration panel</li> <li>Analyze query patterns using Prometheus:</li> </ol> <pre><code># Top 10 slowest queries (P95)\ntopk(10, histogram_quantile(0.95, rate(db_query_duration_seconds_bucket[5m])))\n\n# Slow query rate by operation\nrate(db_slow_queries_total[5m])\n</code></pre> <ol> <li>Profile specific queries with <code>EXPLAIN ANALYZE</code>:</li> </ol> <pre><code>EXPLAIN ANALYZE\nSELECT * FROM authors WHERE status = 'active' ORDER BY created_at DESC;\n</code></pre>"},{"location":"guides/performance-tuning/#optimizing-slow-queries","title":"Optimizing Slow Queries","text":"<p>Add Database Indexes:</p> <pre><code># In your SQLModel definitions\nclass Author(BaseModel, table=True):\n    name: str = Field(index=True)  # Frequently filtered\n    email: str = Field(unique=True, index=True)\n    status: str = Field(index=True)  # Frequently filtered\n    created_at: datetime = Field(index=True)  # Frequently sorted\n</code></pre> <p>Use Eager Loading:</p> <pre><code># Prevent N+1 queries\nstmt = select(Author).options(selectinload(Author.books))\n</code></pre> <p>Optimize Filters:</p> <pre><code># \u274c Avoid function calls in WHERE clause (prevents index usage)\nstmt = select(Author).where(func.lower(Author.name) == \"john\")\n\n# \u2705 Use indexed columns directly\nstmt = select(Author).where(Author.name == \"John\")\n</code></pre>"},{"location":"guides/performance-tuning/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"guides/performance-tuning/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Comprehensive metrics are available for performance monitoring:</p> <p>Database Metrics:</p> <ul> <li><code>db_query_duration_seconds{operation}</code> - Query execution time histogram</li> <li><code>db_slow_queries_total{operation}</code> - Slow query counter</li> <li><code>db_pool_connections_in_use</code> - Active database connections</li> <li><code>db_pool_connections_available</code> - Idle connections in pool</li> </ul> <p>Cache Metrics:</p> <ul> <li><code>token_cache_hits_total</code> - Token cache hits</li> <li><code>token_cache_misses_total</code> - Token cache misses</li> <li><code>pagination_count_cache_hits_total</code> - Count cache hits (if instrumented)</li> <li><code>pagination_count_cache_misses_total</code> - Count cache misses (if instrumented)</li> </ul> <p>HTTP Metrics:</p> <ul> <li><code>http_request_duration_seconds{method,endpoint}</code> - Request latency histogram</li> <li><code>http_requests_total{method,endpoint,status_code}</code> - Request counter</li> <li><code>http_requests_in_progress{method,endpoint}</code> - Concurrent requests</li> </ul> <p>WebSocket Metrics:</p> <ul> <li><code>ws_message_processing_duration_seconds{pkg_id}</code> - Message processing time</li> <li><code>ws_connections_active</code> - Active WebSocket connections</li> </ul>"},{"location":"guides/performance-tuning/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>FastAPI Metrics Dashboard (<code>fastapi-metrics</code>): - HTTP request rates and latency (panels 1-5) - WebSocket connection and message metrics (panels 6-10) - Database query performance (panels 19-20) - Redis pool usage (panels 25-27) - Token cache hit rates (panel integrated with auth metrics)</p> <p>Access: http://localhost:3000/d/fastapi-metrics</p>"},{"location":"guides/performance-tuning/#cache-hit-rate-calculation","title":"Cache Hit Rate Calculation","text":"<pre><code># Token cache hit rate\nrate(token_cache_hits_total[5m]) /\n(rate(token_cache_hits_total[5m]) + rate(token_cache_misses_total[5m]))\n\n# Target: &gt; 85%\n</code></pre>"},{"location":"guides/performance-tuning/#profiling-with-scalene","title":"Profiling with Scalene","text":"<p>For deep performance analysis, use Scalene profiler to identify CPU, memory, and GPU bottlenecks.</p> <p>Installation:</p> <pre><code>make profile-install\n# Or: uv sync --group profiling\n</code></pre> <p>Running Profiler:</p> <pre><code># Start application with profiling\nmake profile\n\n# Or directly with Scalene\nscalene run -- uvicorn app:application --host 0.0.0.0\n\n# View report in browser\nscalene view\n\n# View report in terminal\nscalene view --cli\n</code></pre> <p>What to Profile:</p> <ol> <li>Database query execution time - Identify slow queries</li> <li>Pydantic model validation overhead - Optimize schemas</li> <li>JSON serialization - Consider <code>orjson</code> for faster encoding</li> <li>WebSocket broadcast operations - Optimize loop iterations</li> <li>Memory leaks - Unclosed connections, growing caches</li> </ol> <p>See: CLAUDE.md Performance Profiling section for detailed guide.</p>"},{"location":"guides/performance-tuning/#best-practices","title":"Best Practices","text":""},{"location":"guides/performance-tuning/#1-use-pagination-count-caching","title":"1. Use Pagination Count Caching","text":"<p>Always use the built-in count caching for paginated endpoints:</p> <pre><code># \u2705 Automatic count caching\nresults, meta = await get_paginated_results(\n    Author,\n    page=1,\n    per_page=20,\n    filters={\"status\": \"active\"}\n)\n\n# Remember to invalidate cache after writes!\nawait invalidate_count_cache(\"Author\")\n</code></pre>"},{"location":"guides/performance-tuning/#2-prevent-n1-queries","title":"2. Prevent N+1 Queries","text":"<p>Use eager loading for relationships:</p> <pre><code># \u2705 Load relationships upfront\nresults, meta = await get_paginated_results(\n    Author,\n    page=1,\n    per_page=20,\n    eager_load=[\"books\", \"reviews\"]\n)\n</code></pre>"},{"location":"guides/performance-tuning/#3-add-database-indexes","title":"3. Add Database Indexes","text":"<p>Index frequently filtered and sorted columns:</p> <pre><code>class Author(BaseModel, table=True):\n    status: str = Field(index=True)      # Filtered often\n    created_at: datetime = Field(index=True)  # Sorted often\n    email: str = Field(unique=True, index=True)  # Unique lookup\n</code></pre>"},{"location":"guides/performance-tuning/#4-monitor-pool-usage","title":"4. Monitor Pool Usage","text":"<p>Keep connection pool usage &lt; 80%:</p> <pre><code># Alert when pool usage &gt; 80%\n(redis_pool_connections_in_use / redis_pool_max_connections) &gt; 0.8\n</code></pre>"},{"location":"guides/performance-tuning/#5-use-cursor-pagination-for-large-datasets","title":"5. Use Cursor Pagination for Large Datasets","text":"<p>Offset pagination gets slower with large offsets:</p> <pre><code># \u2705 Cursor pagination - O(1) performance\nresults, meta = await get_paginated_results(\n    Author,\n    per_page=20,\n    cursor=\"MjA=\",  # Base64-encoded last item ID\n)\n\n# \u274c Offset pagination - O(n) performance for large pages\nresults, meta = await get_paginated_results(\n    Author,\n    page=1000,  # Slow for large page numbers\n    per_page=20,\n)\n</code></pre>"},{"location":"guides/performance-tuning/#6-profile-before-optimizing","title":"6. Profile Before Optimizing","text":"<p>Use Scalene to identify actual bottlenecks:</p> <pre><code>scalene run -- uvicorn app:application --host 0.0.0.0\n# Generate load\nscalene view  # Analyze results\n</code></pre>"},{"location":"guides/performance-tuning/#7-cache-invalidation-strategy","title":"7. Cache Invalidation Strategy","text":"<p>Invalidate caches strategically:</p> <pre><code># \u2705 Invalidate after batch operations\nfor author in authors:\n    await repo.create(author)\nawait invalidate_count_cache(\"Author\")  # Once at the end\n\n# \u274c Don't invalidate per record in batch\nfor author in authors:\n    await repo.create(author)\n    await invalidate_count_cache(\"Author\")  # N Redis calls!\n</code></pre>"},{"location":"guides/performance-tuning/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/performance-tuning/#high-database-latency","title":"High Database Latency","text":"<p>Symptoms: - Slow HTTP responses - High P95 query duration - Database connection pool exhaustion</p> <p>Diagnosis:</p> <pre><code># Check query duration\nhistogram_quantile(0.95, rate(db_query_duration_seconds_bucket[5m]))\n\n# Identify slow queries\ndb_slow_queries_total\n</code></pre> <p>Solutions:</p> <ol> <li>Add indexes to frequently filtered columns</li> <li>Use eager loading to prevent N+1 queries</li> <li>Enable count caching for pagination</li> <li>Increase database connection pool size</li> <li>Optimize query filters (avoid function calls in WHERE clause)</li> </ol>"},{"location":"guides/performance-tuning/#low-cache-hit-rate","title":"Low Cache Hit Rate","text":"<p>Symptoms: - Token cache hit rate &lt; 85% - High Keycloak validation requests - Increased CPU usage</p> <p>Diagnosis:</p> <pre><code># Token cache hit rate\nrate(token_cache_hits_total[5m]) /\n(rate(token_cache_hits_total[5m]) + rate(token_cache_misses_total[5m]))\n</code></pre> <p>Solutions:</p> <ol> <li>Verify Redis is available and healthy</li> <li>Check token TTL configuration (should match token expiration)</li> <li>Monitor Redis memory usage (ensure not evicting cache entries)</li> <li>Increase Redis max memory if needed</li> </ol>"},{"location":"guides/performance-tuning/#redis-pool-exhaustion","title":"Redis Pool Exhaustion","text":"<p>Symptoms: - <code>RedisPoolExhausted</code> alert firing - High error rate for rate limiting - Cache operations failing</p> <p>Diagnosis:</p> <pre><code># Redis pool usage\n(redis_pool_connections_in_use / redis_pool_max_connections) * 100\n</code></pre> <p>Solutions:</p> <ol> <li>Increase <code>REDIS_MAX_CONNECTIONS</code> setting</li> <li>Check for connection leaks (unclosed connections)</li> <li>Reduce connection timeout values</li> <li>Scale Redis horizontally (add replicas)</li> </ol>"},{"location":"guides/performance-tuning/#memory-leaks","title":"Memory Leaks","text":"<p>Symptoms: - Increasing memory usage over time - Application restarts due to OOM - Slow garbage collection</p> <p>Diagnosis:</p> <pre><code># Profile with Scalene\nscalene run -- uvicorn app:application --host 0.0.0.0\n# Monitor memory allocation over time\n</code></pre> <p>Solutions:</p> <ol> <li>Check for unclosed database sessions</li> <li>Verify WebSocket connections are properly cleaned up</li> <li>Review in-memory caches for unbounded growth</li> <li>Use weak references for cached objects</li> <li>Implement cache size limits</li> </ol>"},{"location":"guides/performance-tuning/#slow-pagination","title":"Slow Pagination","text":"<p>Symptoms: - High latency for paginated endpoints - Increasing latency with higher page numbers</p> <p>Diagnosis:</p> <pre><code># Enable query logging\nLOG_LEVEL=DEBUG\n\n# Check for COUNT queries in logs\n# \"Executing query: SELECT COUNT(*) FROM authors\"\n</code></pre> <p>Solutions:</p> <ol> <li>Enable count caching (should be automatic)</li> <li>Use cursor pagination instead of offset</li> <li>Add <code>skip_count=True</code> for infinite scroll</li> <li>Verify cache invalidation is working</li> </ol>"},{"location":"guides/performance-tuning/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture Overview</li> <li>Monitoring Guide</li> <li>Database Migrations</li> <li>CLAUDE.md Performance Section</li> </ul>"},{"location":"guides/rate-limiting/","title":"Rate Limiting","text":""},{"location":"guides/rate-limiting/#overview","title":"Overview","text":"<p>The application implements Redis-based rate limiting for both HTTP and WebSocket connections to prevent abuse and ensure fair resource allocation.</p>"},{"location":"guides/rate-limiting/#configuration","title":"Configuration","text":"<p>Rate limiting is configured in <code>app/settings.py</code>:</p> <pre><code># HTTP Rate Limiting\nRATE_LIMIT_ENABLED: bool = True\nRATE_LIMIT_PER_MINUTE: int = 60  # Requests per minute\nRATE_LIMIT_BURST: int = 10       # Burst allowance\n\n# WebSocket Rate Limiting\nWS_MAX_CONNECTIONS_PER_USER: int = 5     # Max concurrent connections\nWS_MESSAGE_RATE_LIMIT: int = 100          # Messages per minute\n</code></pre>"},{"location":"guides/rate-limiting/#http-rate-limiting","title":"HTTP Rate Limiting","text":""},{"location":"guides/rate-limiting/#implementation","title":"Implementation","text":"<p>HTTP endpoints are protected by <code>RateLimitMiddleware</code>:</p> <p>Location: <code>app/middlewares/rate_limit.py</code></p> <p>Algorithm: Sliding window with Redis sorted sets</p> <p>Key: <code>user:{user_id}</code> or <code>ip:{ip_address}</code> for unauthenticated requests</p>"},{"location":"guides/rate-limiting/#response-headers","title":"Response Headers","text":"<p>All HTTP responses include rate limit information:</p> <pre><code>X-RateLimit-Limit: 60\nX-RateLimit-Remaining: 45\nX-RateLimit-Reset: 1705320000\n</code></pre>"},{"location":"guides/rate-limiting/#rate-limit-exceeded","title":"Rate Limit Exceeded","text":"<p>When limit is exceeded, returns <code>429 Too Many Requests</code>:</p> <pre><code>{\n  \"detail\": \"Rate limit exceeded. Try again in 30 seconds.\"\n}\n</code></pre>"},{"location":"guides/rate-limiting/#excluded-paths","title":"Excluded Paths","text":"<p>Some endpoints bypass rate limiting:</p> <ul> <li><code>/health</code> - Health checks</li> <li><code>/metrics</code> - Prometheus metrics</li> <li><code>/docs</code> - API documentation</li> <li><code>/redoc</code> - Alternative API docs</li> <li><code>/openapi.json</code> - OpenAPI schema</li> </ul>"},{"location":"guides/rate-limiting/#websocket-rate-limiting","title":"WebSocket Rate Limiting","text":""},{"location":"guides/rate-limiting/#connection-limiting","title":"Connection Limiting","text":"<p>Maximum Connections: 5 per user (configurable)</p> <p>Implementation: <code>ConnectionLimiter</code> in <code>app/utils/rate_limiter.py</code></p> <p>Enforcement: On connection in <code>PackageAuthWebSocketEndpoint.on_connect()</code></p> <p>Rejection Code: <code>1008</code> (Policy Violation)</p> <pre><code># Connection rejected\nws.close(1008, \"Maximum concurrent connections exceeded\")\n</code></pre>"},{"location":"guides/rate-limiting/#message-rate-limiting","title":"Message Rate Limiting","text":"<p>Limit: 100 messages per minute (configurable)</p> <p>Implementation: <code>RateLimiter</code> in <code>app/utils/rate_limiter.py</code></p> <p>Enforcement: In <code>Web.on_receive()</code> before message processing</p> <p>Error Response:</p> <pre><code>{\n  \"pkg_id\": 0,\n  \"req_id\": \"...\",\n  \"status_code\": 1,\n  \"data\": {\"msg\": \"Rate limit exceeded\"}\n}\n</code></pre>"},{"location":"guides/rate-limiting/#client-implementation","title":"Client Implementation","text":""},{"location":"guides/rate-limiting/#http-clients","title":"HTTP Clients","text":""},{"location":"guides/rate-limiting/#handle-rate-limits","title":"Handle Rate Limits","text":"<pre><code>import time\nimport requests\n\ndef api_call_with_retry(url, headers, max_retries=3):\n    \"\"\"Make API call with automatic retry on rate limit.\"\"\"\n    for attempt in range(max_retries):\n        response = requests.get(url, headers=headers)\n\n        if response.status_code == 429:\n            retry_after = int(response.headers.get('Retry-After', 60))\n            print(f\"Rate limited. Waiting {retry_after}s...\")\n            time.sleep(retry_after)\n            continue\n\n        return response\n\n    raise Exception(\"Max retries exceeded\")\n</code></pre>"},{"location":"guides/rate-limiting/#check-remaining-limit","title":"Check Remaining Limit","text":"<pre><code>response = requests.get(url, headers=headers)\n\nremaining = int(response.headers.get('X-RateLimit-Remaining', 0))\nif remaining &lt; 5:\n    print(f\"Warning: Only {remaining} requests remaining\")\n    time.sleep(1)  # Slow down\n</code></pre>"},{"location":"guides/rate-limiting/#websocket-clients","title":"WebSocket Clients","text":""},{"location":"guides/rate-limiting/#monitor-connection-count","title":"Monitor Connection Count","text":"<pre><code>let activeConnections = 0;\nconst MAX_CONNECTIONS = 5;\n\nfunction connect() {\n  if (activeConnections &gt;= MAX_CONNECTIONS) {\n    console.error('Max connections reached');\n    return;\n  }\n\n  const ws = new WebSocket(`ws://localhost:8000/web?token=${token}`);\n\n  ws.onopen = () =&gt; {\n    activeConnections++;\n  };\n\n  ws.onclose = (event) =&gt; {\n    activeConnections--;\n\n    if (event.code === 1008) {\n      console.error('Connection rejected: Rate limit exceeded');\n    }\n  };\n}\n</code></pre>"},{"location":"guides/rate-limiting/#throttle-messages","title":"Throttle Messages","text":"<pre><code>const messageQueue = [];\nconst MESSAGE_RATE = 100; // per minute\nconst MESSAGE_INTERVAL = 60000 / MESSAGE_RATE; // ms between messages\n\nsetInterval(() =&gt; {\n  if (messageQueue.length &gt; 0 &amp;&amp; ws.readyState === WebSocket.OPEN) {\n    const message = messageQueue.shift();\n    ws.send(JSON.stringify(message));\n  }\n}, MESSAGE_INTERVAL);\n\nfunction sendMessage(data) {\n  messageQueue.push(data);\n}\n</code></pre>"},{"location":"guides/rate-limiting/#rate-limiter-implementation","title":"Rate Limiter Implementation","text":""},{"location":"guides/rate-limiting/#sliding-window-algorithm","title":"Sliding Window Algorithm","text":"<pre><code>async def check_rate_limit(\n    self,\n    key: str,\n    limit: int,\n    window_seconds: int,\n    burst: int = 0\n) -&gt; tuple[bool, int]:\n    \"\"\"\n    Check if request is within rate limit.\n\n    Args:\n        key: Rate limit key (e.g., \"user:123\")\n        limit: Max requests in window\n        window_seconds: Time window in seconds\n        burst: Additional burst allowance\n\n    Returns:\n        (is_allowed, remaining_requests)\n    \"\"\"\n    now = time.time()\n    window_start = now - window_seconds\n\n    # Remove old entries\n    await redis.zremrangebyscore(key, '-inf', window_start)\n\n    # Count requests in current window\n    current_count = await redis.zcard(key)\n\n    max_allowed = limit + burst\n\n    if current_count &gt;= max_allowed:\n        return False, 0\n\n    # Add current request\n    await redis.zadd(key, {str(uuid.uuid4()): now})\n\n    # Set expiry\n    await redis.expire(key, window_seconds * 2)\n\n    remaining = max_allowed - current_count - 1\n    return True, remaining\n</code></pre>"},{"location":"guides/rate-limiting/#connection-limiter","title":"Connection Limiter","text":"<pre><code>async def add_connection(\n    self,\n    user_id: str,\n    connection_id: str\n) -&gt; bool:\n    \"\"\"\n    Add connection and check limit.\n\n    Args:\n        user_id: User identifier\n        connection_id: Unique connection identifier\n\n    Returns:\n        True if connection allowed, False if limit exceeded\n    \"\"\"\n    key = f\"ws:connections:{user_id}\"\n\n    # Add connection to set\n    await redis.sadd(key, connection_id)\n\n    # Count connections\n    count = await redis.scard(key)\n\n    if count &gt; self.max_connections:\n        # Remove and reject\n        await redis.srem(key, connection_id)\n        return False\n\n    return True\n</code></pre>"},{"location":"guides/rate-limiting/#monitoring","title":"Monitoring","text":""},{"location":"guides/rate-limiting/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Rate limit violations are tracked:</p> <pre><code># Rate limit hits\nrate_limit_hits_total{limit_type=\"http\"} 123\nrate_limit_hits_total{limit_type=\"ws_connection\"} 5\nrate_limit_hits_total{limit_type=\"ws_message\"} 45\n</code></pre>"},{"location":"guides/rate-limiting/#logs","title":"Logs","text":"<p>Rate limit events are logged:</p> <pre><code>logger.warning(\n    f\"Rate limit exceeded for user {user_id}\",\n    extra={\n        \"user_id\": user_id,\n        \"limit_type\": \"http\",\n        \"current_count\": current_count,\n        \"limit\": limit\n    }\n)\n</code></pre>"},{"location":"guides/rate-limiting/#tuning","title":"Tuning","text":""},{"location":"guides/rate-limiting/#adjusting-limits","title":"Adjusting Limits","text":"<p>Edit <code>app/settings.py</code> or set environment variables:</p> <pre><code># HTTP\nexport RATE_LIMIT_PER_MINUTE=120\nexport RATE_LIMIT_BURST=20\n\n# WebSocket\nexport WS_MAX_CONNECTIONS_PER_USER=10\nexport WS_MESSAGE_RATE_LIMIT=200\n</code></pre>"},{"location":"guides/rate-limiting/#per-endpoint-limits","title":"Per-Endpoint Limits","text":"<p>Currently not supported - all endpoints share same limit. To implement:</p> <ol> <li>Add endpoint-specific configuration</li> <li>Modify middleware to check endpoint</li> <li>Use different Redis keys per endpoint</li> </ol>"},{"location":"guides/rate-limiting/#testing","title":"Testing","text":""},{"location":"guides/rate-limiting/#test-rate-limiting","title":"Test Rate Limiting","text":"<pre><code>import pytest\n\n@pytest.mark.asyncio\nasync def test_rate_limit():\n    \"\"\"Test rate limiting blocks excess requests.\"\"\"\n    rate_limiter = RateLimiter(redis)\n\n    # Make requests up to limit\n    for i in range(60):\n        allowed, remaining = await rate_limiter.check_rate_limit(\n            key=\"test:user\",\n            limit=60,\n            window_seconds=60\n        )\n        assert allowed is True\n\n    # Next request should be blocked\n    allowed, remaining = await rate_limiter.check_rate_limit(\n        key=\"test:user\",\n        limit=60,\n        window_seconds=60\n    )\n    assert allowed is False\n    assert remaining == 0\n</code></pre>"},{"location":"guides/rate-limiting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/rate-limiting/#redis-connection-issues","title":"Redis Connection Issues","text":"<p>If rate limiting fails due to Redis errors: - HTTP middleware fails open (allows requests) - WebSocket connection limiter fails closed (denies connections)</p>"},{"location":"guides/rate-limiting/#high-false-positives","title":"High False Positives","text":"<p>If legitimate users hit limits: 1. Increase <code>RATE_LIMIT_PER_MINUTE</code> 2. Increase <code>RATE_LIMIT_BURST</code> for traffic spikes 3. Implement per-user or per-role limits</p>"},{"location":"guides/rate-limiting/#performance-issues","title":"Performance Issues","text":"<p>If Redis becomes bottleneck: 1. Use Redis cluster for horizontal scaling 2. Implement local caching with eventual consistency 3. Use approximate counting algorithms</p>"},{"location":"guides/rate-limiting/#related","title":"Related","text":"<ul> <li>HTTP API</li> <li>WebSocket API</li> <li>Monitoring Guide</li> </ul>"},{"location":"guides/security-best-practices/","title":"Security Best Practices","text":"<p>Comprehensive guide to security features, configuration, and deployment best practices for this FastAPI + WebSocket application.</p>"},{"location":"guides/security-best-practices/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Security Overview</li> <li>Authentication</li> <li>Authorization (RBAC)</li> <li>Security Headers</li> <li>Input Validation</li> <li>Rate Limiting</li> <li>WebSocket Security</li> <li>Audit Logging</li> <li>IP Spoofing Protection</li> <li>Circuit Breakers</li> <li>Security Deployment Checklist</li> <li>Common Security Pitfalls</li> <li>Security Testing</li> <li>Troubleshooting</li> </ol>"},{"location":"guides/security-best-practices/#security-overview","title":"Security Overview","text":"<p>This application implements defense-in-depth security with multiple layers:</p> <pre><code>graph TD\n    A[Client Request] --&gt; B[TLS/HTTPS]\n    B --&gt; C[Security Headers]\n    C --&gt; D[Request Size Limit]\n    D --&gt; E[Rate Limiting]\n    E --&gt; F[Authentication]\n    F --&gt; G[Authorization RBAC]\n    G --&gt; H[Input Validation]\n    H --&gt; I[Handler Logic]\n    I --&gt; J[Audit Logging]\n    J --&gt; K[Response]</code></pre> <p>All security features are already implemented - this guide explains how to configure and use them properly.</p>"},{"location":"guides/security-best-practices/#security-features-matrix","title":"Security Features Matrix","text":"Feature HTTP WebSocket Configuration Status Authentication (JWT) \u2705 \u2705 Keycloak Implemented Authorization (RBAC) \u2705 \u2705 Code-based Implemented Rate Limiting \u2705 \u2705 Settings Implemented CSRF Protection \u2705 (Framework) \u2705 (Origin) Settings Implemented Input Validation \u2705 \u2705 Pydantic/Schema Implemented Security Headers \u2705 N/A Middleware Implemented Audit Logging \u2705 \u2705 Settings Implemented Request Size Limit \u2705 N/A Settings Implemented IP Spoofing Protection \u2705 \u2705 Settings Implemented Circuit Breakers \u2705 \u2705 Settings Implemented"},{"location":"guides/security-best-practices/#authentication","title":"Authentication","text":""},{"location":"guides/security-best-practices/#overview","title":"Overview","text":"<p>Authentication uses Keycloak with JWT tokens: - HTTP requests: Token in <code>Authorization</code> header - WebSocket connections: Token in query parameter (browser limitation) - Token validation with Redis caching (85-95% cache hit rate) - Circuit breaker protection for Keycloak outages</p>"},{"location":"guides/security-best-practices/#token-flow-diagram","title":"Token Flow Diagram","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant App\n    participant Redis\n    participant Keycloak\n\n    Client-&gt;&gt;App: Request with JWT token\n    App-&gt;&gt;Redis: Check token cache\n    alt Cache Hit (85-95%)\n        Redis--&gt;&gt;App: Cached user claims\n        App-&gt;&gt;App: Create UserModel\n    else Cache Miss\n        App-&gt;&gt;Keycloak: Validate token\n        Keycloak--&gt;&gt;App: Token claims\n        App-&gt;&gt;Redis: Cache claims (TTL = token exp - 30s)\n        App-&gt;&gt;App: Create UserModel\n    end\n    App-&gt;&gt;Client: Authenticated response</code></pre>"},{"location":"guides/security-best-practices/#http-authentication","title":"HTTP Authentication","text":"<p>HTTP authentication is automatic via middleware:</p> <pre><code>from fastapi import APIRouter, Depends\nfrom app.schemas.user import UserModel\nfrom app.dependencies import get_current_user\n\nrouter = APIRouter()\n\n@router.get(\"/profile\")\nasync def get_profile(user: UserModel = Depends(get_current_user)):\n    \"\"\"\n    Protected endpoint - requires valid JWT token.\n\n    User is automatically extracted from Authorization header.\n    \"\"\"\n    return {\n        \"user_id\": user.user_id,\n        \"username\": user.username,\n        \"roles\": user.roles\n    }\n\n# Client request example:\n# GET /profile\n# Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6...\n</code></pre>"},{"location":"guides/security-best-practices/#websocket-authentication","title":"WebSocket Authentication","text":"<p>WebSocket connections authenticate via query parameter (browser WebSocket API limitation):</p> <pre><code># Client-side JavaScript\nconst token = 'Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6...';\nconst wsUrl = `wss://api.example.com/web?Authorization=${encodeURIComponent(token)}`;\nconst ws = new WebSocket(wsUrl);\n</code></pre> <p>Security Considerations:</p> <p>\u26a0\ufe0f Query parameters have security implications: - Tokens appear in server access logs - Tokens stored in browser history - Risk of accidental token sharing via URLs</p> <p>\u2705 Required mitigations (already implemented): - Always use WSS (WebSocket over TLS) in production - Short-lived tokens (Keycloak default: 5 minutes) - Referrer-Policy header prevents token leakage - Origin validation for CSRF protection</p> <p>Client Best Practices:</p> <pre><code>// \u2705 GOOD - Get fresh token before connecting\nconst token = await getAccessToken();\nconst ws = new WebSocket(`wss://api.example.com/web?Authorization=${encodeURIComponent(token)}`);\ntoken = null;  // Clear from memory\n\n// \u2705 GOOD - Reconnect with new token before expiration\nsetInterval(async () =&gt; {\n    ws.close();\n    const newToken = await refreshAccessToken();\n    ws = new WebSocket(`wss://api.example.com/web?Authorization=${encodeURIComponent(newToken)}`);\n}, 4 * 60 * 1000);  // Every 4 minutes (before 5-minute expiry)\n\n// \u274c BAD - Log token in URL\nconsole.log('Connecting to:', wsUrl);  // Exposes token!\n\n// \u274c BAD - Reuse same token for hours\nconst ws = new WebSocket(wsUrl);  // Token will expire!\n</code></pre>"},{"location":"guides/security-best-practices/#token-caching","title":"Token Caching","text":"<p>Token validation is cached in Redis for performance:</p> <p>How It Works: 1. SHA-256 hash of token used as cache key (full token never stored) 2. Cache stores decoded claims with TTL = token expiration - 30 seconds 3. 85-95% cache hit rate reduces Keycloak load by 85-95% 4. Fail-open behavior (falls back to token decode if Redis unavailable)</p> <p>Metrics: <pre><code># Cache hit rate\nrate(token_cache_hits_total[5m]) /\n(rate(token_cache_hits_total[5m]) + rate(token_cache_misses_total[5m]))\n\n# Should be 85-95% for typical workloads\n</code></pre></p> <p>Configuration:</p> <pre><code># app/utils/token_cache.py\nTOKEN_CACHE_BUFFER_SECONDS = 30  # Cache expires 30s before token expiration\n</code></pre>"},{"location":"guides/security-best-practices/#excluded-paths","title":"Excluded Paths","text":"<p>Public endpoints (no authentication required):</p> <pre><code># app/settings.py\nEXCLUDED_PATHS = re.compile(\n    r\"^/(health|metrics|docs|openapi\\.json|redoc)\"\n)\n\n# Example: Add custom public endpoint\nEXCLUDED_PATHS = re.compile(\n    r\"^/(health|metrics|docs|openapi\\.json|redoc|public-api)\"\n)\n</code></pre>"},{"location":"guides/security-best-practices/#circuit-breaker-protection","title":"Circuit Breaker Protection","text":"<p>Keycloak operations are protected by circuit breaker to prevent cascading failures:</p> <p>Configuration:</p> <pre><code># app/settings.py\nCIRCUIT_BREAKER_ENABLED = True\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX = 5  # Open after 5 failures\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT = 60  # Keep open for 60 seconds\n</code></pre> <p>States: - Closed (normal): All requests pass through - Open (failing): Requests fail immediately with <code>CircuitBreakerError</code> - Half-Open (testing): One request allowed to test recovery</p> <p>Prometheus Metrics:</p> <pre><code># Circuit breaker state (0=closed, 1=open, 2=half_open)\ncircuit_breaker_state{service=\"keycloak\"}\n\n# State transitions\ncircuit_breaker_state_changes_total{service=\"keycloak\", from_state=\"closed\", to_state=\"open\"}\n</code></pre>"},{"location":"guides/security-best-practices/#token-expiration-handling","title":"Token Expiration Handling","text":"<p>Client-Side:</p> <pre><code># Python client example\nimport requests\nfrom datetime import datetime, timedelta\n\nclass APIClient:\n    def __init__(self, keycloak_url, client_id, username, password):\n        self.keycloak_url = keycloak_url\n        self.client_id = client_id\n        self.username = username\n        self.password = password\n        self.token = None\n        self.token_expires_at = None\n\n    def _refresh_token_if_needed(self):\n        if not self.token or datetime.now() &gt;= self.token_expires_at:\n            # Get new token from Keycloak\n            response = requests.post(\n                f\"{self.keycloak_url}/realms/your-realm/protocol/openid-connect/token\",\n                data={\n                    \"grant_type\": \"password\",\n                    \"client_id\": self.client_id,\n                    \"username\": self.username,\n                    \"password\": self.password\n                }\n            )\n            data = response.json()\n            self.token = data[\"access_token\"]\n            # Refresh 1 minute before expiration\n            self.token_expires_at = datetime.now() + timedelta(seconds=data[\"expires_in\"] - 60)\n\n    def make_request(self, endpoint):\n        self._refresh_token_if_needed()\n        headers = {\"Authorization\": f\"Bearer {self.token}\"}\n        return requests.get(f\"https://api.example.com{endpoint}\", headers=headers)\n</code></pre> <p>Server-Side:</p> <p>The server automatically handles expired tokens:</p> <pre><code># app/auth.py (AuthBackend.authenticate)\ntry:\n    user_data = keycloak_manager.openid.a_decode_token(access_token)\nexcept JWTExpired:\n    raise AuthenticationError(\"token_expired: Token has expired\")\n    # Client receives HTTP 401 or WebSocket close with PERMISSION_DENIED\n</code></pre>"},{"location":"guides/security-best-practices/#authorization-rbac","title":"Authorization (RBAC)","text":""},{"location":"guides/security-best-practices/#overview_1","title":"Overview","text":"<p>Role-Based Access Control (RBAC) uses Keycloak roles with decorator-based configuration: - Roles defined in Keycloak (not in code) - HTTP: <code>require_roles()</code> dependency - WebSocket: <code>roles</code> parameter in <code>@pkg_router.register()</code> - AND logic: User must have ALL required roles</p>"},{"location":"guides/security-best-practices/#keycloak-role-setup","title":"Keycloak Role Setup","text":"<p>1. Create Realm Roles in Keycloak:</p> <p>Navigate to: Keycloak Admin Console \u2192 Your Realm \u2192 Roles \u2192 Create Role</p> <pre><code>Role Name: create-author\nDescription: Permission to create new authors\n</code></pre> <p>2. Assign Roles to Users:</p> <p>Navigate to: Users \u2192 Select User \u2192 Role Mappings \u2192 Assign Role</p> <p>3. Include Roles in Token:</p> <p>Keycloak automatically includes realm roles in JWT <code>realm_access.roles</code> claim.</p>"},{"location":"guides/security-best-practices/#http-endpoint-protection","title":"HTTP Endpoint Protection","text":"<p>Use <code>require_roles()</code> dependency for HTTP endpoints:</p> <pre><code>from fastapi import APIRouter, Depends\nfrom app.dependencies.permissions import require_roles\nfrom app.schemas.author import Author\n\nrouter = APIRouter(prefix=\"/api\", tags=[\"authors\"])\n\n# Single role required\n@router.post(\n    \"/authors\",\n    dependencies=[Depends(require_roles(\"create-author\"))]\n)\nasync def create_author(author: Author) -&gt; Author:\n    \"\"\"Create author - requires 'create-author' role.\"\"\"\n    # Implementation\n    pass\n\n# Multiple roles required (AND logic - user must have ALL)\n@router.delete(\n    \"/authors/{author_id}\",\n    dependencies=[Depends(require_roles(\"delete-author\", \"admin\"))]\n)\nasync def delete_author(author_id: int) -&gt; None:\n    \"\"\"Delete author - requires BOTH 'delete-author' AND 'admin' roles.\"\"\"\n    # Implementation\n    pass\n\n# Public endpoint - no authentication required\n@router.get(\"/public-stats\")\nasync def get_public_stats():\n    \"\"\"Public endpoint - no require_roles() = no authentication.\"\"\"\n    return {\"total_authors\": 1234}\n</code></pre> <p>Response Codes: - <code>401 Unauthorized</code>: No token or invalid token - <code>403 Forbidden</code>: Valid token but insufficient roles</p>"},{"location":"guides/security-best-practices/#websocket-handler-protection","title":"WebSocket Handler Protection","text":"<p>Use <code>roles</code> parameter in <code>@pkg_router.register()</code>:</p> <pre><code>from app.routing import pkg_router\nfrom app.api.ws.constants import PkgID\nfrom app.schemas.ws import RequestModel, ResponseModel\n\n# Single role required\n@pkg_router.register(\n    PkgID.CREATE_AUTHOR,\n    json_schema=CreateAuthorSchema,\n    roles=[\"create-author\"]\n)\nasync def create_author_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Create author - requires 'create-author' role.\"\"\"\n    # Implementation\n    return ResponseModel.success(request.pkg_id, request.req_id, data={...})\n\n# Multiple roles required (AND logic)\n@pkg_router.register(\n    PkgID.DELETE_AUTHOR,\n    roles=[\"delete-author\", \"admin\"]\n)\nasync def delete_author_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Delete author - requires BOTH 'delete-author' AND 'admin' roles.\"\"\"\n    # Implementation\n    return ResponseModel.success(...)\n\n# Public handler - no authentication required\n@pkg_router.register(PkgID.PUBLIC_DATA)\nasync def public_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Public handler - no roles = no authentication.\"\"\"\n    return ResponseModel.success(...)\n</code></pre> <p>Response: <pre><code>{\n    \"pkg_id\": 101,\n    \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n    \"status_code\": 403,  // RSPCode.PERMISSION_DENIED\n    \"data\": null,\n    \"meta\": null\n}\n</code></pre></p>"},{"location":"guides/security-best-practices/#custom-permission-checking","title":"Custom Permission Checking","text":"<p>For complex permission logic:</p> <pre><code>from app.managers.rbac_manager import rbac_manager\nfrom app.dependencies import get_current_user\n\n@router.get(\"/sensitive-data\")\nasync def get_sensitive_data(user: UserModel = Depends(get_current_user)):\n    \"\"\"Custom permission logic.\"\"\"\n    # Check if user has required role\n    has_permission, missing_roles = rbac_manager.check_user_has_roles(\n        user,\n        [\"view-sensitive-data\"]\n    )\n\n    if not has_permission:\n        raise HTTPException(\n            status_code=403,\n            detail=f\"Missing roles: {', '.join(missing_roles)}\"\n        )\n\n    # Additional business logic checks\n    if user.user_id not in allowed_users:\n        raise HTTPException(status_code=403, detail=\"Access denied\")\n\n    return {\"sensitive\": \"data\"}\n</code></pre>"},{"location":"guides/security-best-practices/#role-composition-patterns","title":"Role Composition Patterns","text":"<p>AND Logic (all roles required):</p> <pre><code># User must have BOTH roles\n@router.delete(\"/critical\", dependencies=[Depends(require_roles(\"delete\", \"admin\"))])\n</code></pre> <p>OR Logic (any role sufficient):</p> <pre><code># User needs either role (implement custom dependency)\nfrom app.dependencies import require_any_role\n\n@router.get(\"/stats\", dependencies=[Depends(require_any_role(\"viewer\", \"admin\"))])\n</code></pre> <p>Hierarchical Roles:</p> <p>Use Keycloak's composite roles feature: 1. Create composite role: <code>admin</code> 2. Add child roles: <code>create-author</code>, <code>delete-author</code>, <code>view-stats</code> 3. Users with <code>admin</code> role automatically get all child roles</p>"},{"location":"guides/security-best-practices/#security-headers","title":"Security Headers","text":""},{"location":"guides/security-best-practices/#overview_2","title":"Overview","text":"<p>Security headers protect against common web vulnerabilities and are added automatically to all HTTP responses.</p> <p>Implementation: <code>app/middlewares/security_headers.py</code></p>"},{"location":"guides/security-best-practices/#headers-explained","title":"Headers Explained","text":""},{"location":"guides/security-best-practices/#1-x-frame-options-deny","title":"1. X-Frame-Options: DENY","text":"<p>Protects Against: Clickjacking attacks</p> <pre><code>X-Frame-Options: DENY\n</code></pre> <p>What It Does: - Prevents your site from being embedded in <code>&lt;iframe&gt;</code>, <code>&lt;frame&gt;</code>, or <code>&lt;object&gt;</code> tags - Stops attackers from overlaying transparent iframes to trick users into clicking malicious content</p> <p>When to Customize: <pre><code># If you need to allow framing (not recommended):\nresponse.headers[\"X-Frame-Options\"] = \"SAMEORIGIN\"  # Same domain only\n# Or\nresponse.headers[\"X-Frame-Options\"] = \"ALLOW-FROM https://trusted-site.com\"\n</code></pre></p>"},{"location":"guides/security-best-practices/#2-x-content-type-options-nosniff","title":"2. X-Content-Type-Options: nosniff","text":"<p>Protects Against: MIME type sniffing attacks</p> <pre><code>X-Content-Type-Options: nosniff\n</code></pre> <p>What It Does: - Forces browsers to respect declared <code>Content-Type</code> - Prevents browser from interpreting files as different type (e.g., image as script) - Blocks execution of incorrectly labeled content</p>"},{"location":"guides/security-best-practices/#3-x-xss-protection-1-modeblock","title":"3. X-XSS-Protection: 1; mode=block","text":"<p>Protects Against: Cross-Site Scripting (XSS) in legacy browsers</p> <pre><code>X-XSS-Protection: 1; mode=block\n</code></pre> <p>What It Does: - Enables XSS filter in older browsers (IE, Chrome &lt;79) - Modern browsers rely on CSP instead - <code>mode=block</code> stops rendering page if XSS detected</p>"},{"location":"guides/security-best-practices/#4-strict-transport-security-hsts","title":"4. Strict-Transport-Security (HSTS)","text":"<p>Protects Against: Man-in-the-middle attacks, SSL stripping</p> <pre><code>Strict-Transport-Security: max-age=31536000; includeSubDomains\n</code></pre> <p>What It Does: - Forces HTTPS for 1 year (31536000 seconds) - Applies to all subdomains - Prevents downgrade attacks to HTTP</p> <p>\u26a0\ufe0f Important: Only enable HSTS after confirming HTTPS works everywhere!</p> <pre><code># For development (HTTP), comment out HSTS:\n# response.headers[\"Strict-Transport-Security\"] = ...\n\n# For production with HTTPS:\nresponse.headers[\"Strict-Transport-Security\"] = \"max-age=31536000; includeSubDomains; preload\"\n</code></pre>"},{"location":"guides/security-best-practices/#5-referrer-policy-strict-origin-when-cross-origin","title":"5. Referrer-Policy: strict-origin-when-cross-origin","text":"<p>Protects Against: Referrer leakage</p> <pre><code>Referrer-Policy: strict-origin-when-cross-origin\n</code></pre> <p>What It Does: - Same-origin requests: Full URL in Referer header - Cross-origin HTTPS\u2192HTTPS: Origin only (no path) - HTTPS\u2192HTTP: No referrer sent (prevents token leakage!)</p> <p>Critical for WebSocket security: Prevents token in query parameter from leaking via Referer.</p>"},{"location":"guides/security-best-practices/#6-permissions-policy","title":"6. Permissions-Policy","text":"<p>Protects Against: Unauthorized use of browser features</p> <pre><code>Permissions-Policy: geolocation=(), microphone=(), camera=()\n</code></pre> <p>What It Does: - Disables geolocation, microphone, camera access - Prevents malicious code from accessing sensitive hardware</p> <p>Customize for your needs: <pre><code># Allow geolocation from same origin:\nresponse.headers[\"Permissions-Policy\"] = \"geolocation=(self), microphone=(), camera=()\"\n</code></pre></p>"},{"location":"guides/security-best-practices/#7-content-security-policy-csp","title":"7. Content-Security-Policy (CSP)","text":"<p>Protects Against: XSS, injection attacks, data exfiltration</p> <pre><code>Content-Security-Policy: default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self'; connect-src 'self' ws: wss:; frame-ancestors 'none'; base-uri 'self'; form-action 'self'; upgrade-insecure-requests\n</code></pre> <p>Directives Explained:</p> Directive Value Purpose <code>default-src</code> <code>'self'</code> Default policy: only same-origin resources <code>script-src</code> <code>'self'</code> Block inline scripts and eval() <code>style-src</code> <code>'self' 'unsafe-inline'</code> Allow inline styles (needed for API docs) <code>img-src</code> <code>'self' data:</code> Same-origin images + data URIs <code>font-src</code> <code>'self'</code> Same-origin fonts only <code>connect-src</code> <code>'self' ws: wss:</code> Critical: Allow WebSocket connections <code>frame-ancestors</code> <code>'none'</code> Prevent clickjacking (reinforces X-Frame-Options) <code>base-uri</code> <code>'self'</code> Restrict <code>&lt;base&gt;</code> tag to same origin <code>form-action</code> <code>'self'</code> Only submit forms to same origin <code>upgrade-insecure-requests</code> - Auto-upgrade HTTP to HTTPS <p>\u26a0\ufe0f Critical for WebSocket: <code>connect-src 'self' ws: wss:'</code> is required for WebSocket connections!</p> <p>Testing CSP:</p> <pre><code># Check CSP header\ncurl -I https://your-api.com | grep -i content-security\n\n# Test CSP violations (browser console)\n# Attempt to load external script - should be blocked by CSP\n</code></pre> <p>Reporting CSP Violations:</p> <pre><code># Add report-uri directive to log violations:\ncsp_directives.append(\"report-uri /csp-report\")\n\n# Create endpoint to receive reports:\n@router.post(\"/csp-report\")\nasync def csp_report(request: Request):\n    report = await request.json()\n    logger.warning(f\"CSP violation: {report}\")\n    return {}\n</code></pre>"},{"location":"guides/security-best-practices/#testing-security-headers","title":"Testing Security Headers","text":"<p>1. Manual Testing:</p> <pre><code>curl -I https://your-api.com\n</code></pre> <p>2. Security Header Scanners:</p> <ul> <li>https://securityheaders.com/</li> <li>https://observatory.mozilla.org/</li> </ul> <p>3. Expected Output:</p> <pre><code>HTTP/2 200\nx-frame-options: DENY\nx-content-type-options: nosniff\nx-xss-protection: 1; mode=block\nstrict-transport-security: max-age=31536000; includeSubDomains\nreferrer-policy: strict-origin-when-cross-origin\npermissions-policy: geolocation=(), microphone=(), camera=()\ncontent-security-policy: default-src 'self'; script-src 'self'; ...\n</code></pre>"},{"location":"guides/security-best-practices/#common-issues","title":"Common Issues","text":"<p>Problem: API requests failing with CSP errors</p> <p>Solution: Check <code>connect-src</code> directive includes your API domain:</p> <pre><code># If API is on different subdomain:\n\"connect-src 'self' api.example.com ws: wss:\"\n</code></pre> <p>Problem: WebSocket connections blocked by CSP</p> <p>Solution: Ensure <code>connect-src</code> includes <code>ws:</code> and <code>wss:</code>:</p> <pre><code>\"connect-src 'self' ws: wss:\"  # Required for WebSocket\n</code></pre> <p>Problem: Third-party fonts/CDN resources blocked</p> <p>Solution: Add specific domains to CSP:</p> <pre><code>\"font-src 'self' fonts.gstatic.com\",\n\"style-src 'self' 'unsafe-inline' fonts.googleapis.com\"\n</code></pre>"},{"location":"guides/security-best-practices/#input-validation","title":"Input Validation","text":""},{"location":"guides/security-best-practices/#overview_3","title":"Overview","text":"<p>All input is validated before processing: - HTTP: Pydantic models (automatic FastAPI validation) - WebSocket: Pydantic + optional JSON Schema + Protobuf - Database: SQLModel field constraints - Automatic sanitization of sensitive fields in audit logs</p>"},{"location":"guides/security-best-practices/#pydantic-validation-patterns","title":"Pydantic Validation Patterns","text":""},{"location":"guides/security-best-practices/#basic-field-validation","title":"Basic Field Validation","text":"<pre><code>from pydantic import BaseModel, Field, EmailStr, field_validator\n\nclass CreateUserInput(BaseModel):\n    \"\"\"Input validation for user creation.\"\"\"\n\n    username: str = Field(\n        min_length=3,\n        max_length=50,\n        pattern=r'^[a-zA-Z0-9_]+$',  # Alphanumeric + underscore only\n        description=\"Unique username\"\n    )\n\n    email: EmailStr  # Built-in email validation\n\n    age: int = Field(ge=13, le=120)  # Greater than or equal, less than or equal\n\n    bio: str | None = Field(None, max_length=500)\n\n    website: str | None = Field(None, pattern=r'^https?://')  # HTTP(S) URLs only\n\n# FastAPI automatically validates and returns 422 Unprocessable Entity for invalid data\n</code></pre>"},{"location":"guides/security-best-practices/#custom-validators","title":"Custom Validators","text":"<pre><code>class CreateAuthorInput(BaseModel):\n    name: str = Field(min_length=1, max_length=100)\n    email: EmailStr\n    country_code: str = Field(pattern=r'^[A-Z]{2}$')  # ISO 3166-1 alpha-2\n\n    @field_validator('name')\n    @classmethod\n    def validate_name(cls, v: str) -&gt; str:\n        \"\"\"Validate name doesn't contain reserved words.\"\"\"\n        reserved = ['admin', 'root', 'system', 'anonymous']\n        if v.lower() in reserved:\n            raise ValueError(f'Reserved name: {v}')\n        return v.strip()  # Remove leading/trailing whitespace\n\n    @field_validator('email')\n    @classmethod\n    def validate_email_domain(cls, v: str) -&gt; str:\n        \"\"\"Block disposable email domains.\"\"\"\n        disposable_domains = ['tempmail.com', '10minutemail.com']\n        domain = v.split('@')[1]\n        if domain in disposable_domains:\n            raise ValueError(f'Disposable email addresses not allowed')\n        return v.lower()  # Normalize to lowercase\n</code></pre>"},{"location":"guides/security-best-practices/#model-validators-multiple-fields","title":"Model Validators (Multiple Fields)","text":"<pre><code>from pydantic import model_validator\n\nclass CreateBookInput(BaseModel):\n    title: str\n    author_id: int\n    isbn: str | None = None\n    asin: str | None = None\n\n    @model_validator(mode='after')\n    def validate_identifiers(self) -&gt; 'CreateBookInput':\n        \"\"\"At least one identifier (ISBN or ASIN) required.\"\"\"\n        if not self.isbn and not self.asin:\n            raise ValueError('Either ISBN or ASIN must be provided')\n        return self\n</code></pre>"},{"location":"guides/security-best-practices/#validation-error-handling","title":"Validation Error Handling","text":"<pre><code>from fastapi import HTTPException\nfrom pydantic import ValidationError\n\n@router.post(\"/authors\")\nasync def create_author(data: CreateAuthorInput):\n    try:\n        # Validation happens automatically\n        # If we get here, data is valid\n        author = await create_author_logic(data)\n        return author\n    except ValidationError as e:\n        # FastAPI handles this automatically, but you can customize:\n        raise HTTPException(\n            status_code=422,\n            detail=e.errors()\n        )\n</code></pre>"},{"location":"guides/security-best-practices/#websocket-json-schema-validation","title":"WebSocket JSON Schema Validation","text":"<p>For WebSocket handlers, add JSON Schema validation:</p> <pre><code># Define schema (schemas/create_author.json)\n{\n    \"type\": \"object\",\n    \"properties\": {\n        \"name\": {\"type\": \"string\", \"minLength\": 1, \"maxLength\": 100},\n        \"email\": {\"type\": \"string\", \"format\": \"email\"}\n    },\n    \"required\": [\"name\", \"email\"],\n    \"additionalProperties\": false\n}\n\n# Register handler with schema\nfrom app.utils.file_io import load_json_schema\n\ncreate_author_schema = load_json_schema(\"schemas/create_author.json\")\n\n@pkg_router.register(\n    PkgID.CREATE_AUTHOR,\n    json_schema=create_author_schema,\n    roles=[\"create-author\"]\n)\nasync def create_author_handler(request: RequestModel) -&gt; ResponseModel:\n    # request.data is already validated against JSON schema\n    author = Author(**request.data)\n    # ...\n</code></pre>"},{"location":"guides/security-best-practices/#protobuf-validation","title":"Protobuf Validation","text":"<p>For binary message validation:</p> <pre><code>// proto/websocket.proto\nmessage CreateAuthorRequest {\n    string name = 1;\n    string email = 2;\n    optional string bio = 3;\n}\n</code></pre> <pre><code># Client sends binary message\nfrom app.schemas.proto import CreateAuthorRequest\n\nrequest = CreateAuthorRequest()\nrequest.name = \"John Doe\"\nrequest.email = \"john@example.com\"\nbinary_data = request.SerializeToString()\n\nawait websocket.send(binary_data)\n</code></pre>"},{"location":"guides/security-best-practices/#string-length-limits","title":"String Length Limits","text":"<p>Always set maximum lengths to prevent DoS attacks:</p> <pre><code># \u274c BAD - No length limit (DoS vulnerability)\nclass UserInput(BaseModel):\n    bio: str\n\n# \u2705 GOOD - Reasonable length limit\nclass UserInput(BaseModel):\n    bio: str = Field(max_length=500)\n</code></pre>"},{"location":"guides/security-best-practices/#sql-injection-prevention","title":"SQL Injection Prevention","text":"<p>SQLModel/SQLAlchemy uses parameterized queries automatically:</p> <pre><code># \u2705 SAFE - Parameterized query\nstmt = select(Author).where(Author.name == user_input)\nresult = await session.execute(stmt)\n\n# \u274c DANGEROUS - Never use string formatting!\n# stmt = text(f\"SELECT * FROM authors WHERE name = '{user_input}'\")\n</code></pre>"},{"location":"guides/security-best-practices/#path-traversal-prevention","title":"Path Traversal Prevention","text":"<pre><code>from pathlib import Path\n\n@router.get(\"/files/{filename}\")\nasync def get_file(filename: str):\n    # \u274c VULNERABLE to path traversal\n    # file_path = f\"/files/{filename}\"  # filename could be \"../../../etc/passwd\"\n\n    # \u2705 SAFE - Validate filename\n    safe_filename = Path(filename).name  # Removes directory components\n    if not safe_filename.endswith('.pdf'):\n        raise HTTPException(400, \"Only PDF files allowed\")\n\n    file_path = Path(\"/files\") / safe_filename\n    if not file_path.exists():\n        raise HTTPException(404, \"File not found\")\n\n    return FileResponse(file_path)\n</code></pre>"},{"location":"guides/security-best-practices/#sensitive-data-sanitization","title":"Sensitive Data Sanitization","text":"<p>Audit logs automatically sanitize sensitive fields:</p> <pre><code># app/utils/audit_logger.py\nSENSITIVE_FIELDS = [\n    \"password\", \"passwd\", \"pwd\",\n    \"token\", \"access_token\", \"refresh_token\",\n    \"secret\", \"api_key\", \"private_key\",\n    \"ssn\", \"social_security_number\",\n    \"credit_card\", \"card_number\", \"cvv\",\n    \"authorization\"\n]\n\n# Before logging:\nrequest_data = {\n    \"username\": \"john\",\n    \"password\": \"secret123\",\n    \"email\": \"john@example.com\"\n}\n\n# After sanitization:\nsanitized_data = {\n    \"username\": \"john\",\n    \"password\": \"[REDACTED]\",\n    \"email\": \"john@example.com\"\n}\n</code></pre>"},{"location":"guides/security-best-practices/#rate-limiting","title":"Rate Limiting","text":""},{"location":"guides/security-best-practices/#overview_4","title":"Overview","text":"<p>Rate limiting prevents abuse and ensures fair resource usage: - HTTP: Per-user or IP-based, sliding window algorithm - WebSocket: Connection limits + message rate limits - Redis-based: Distributed rate limiting across instances - Fail modes: Configurable fail-open (allow) or fail-closed (deny)</p>"},{"location":"guides/security-best-practices/#http-rate-limiting","title":"HTTP Rate Limiting","text":"<p>Configuration:</p> <pre><code># app/settings.py\nRATE_LIMIT_ENABLED = True\nRATE_LIMIT_PER_MINUTE = 60  # Requests per minute\nRATE_LIMIT_BURST = 10  # Additional burst allowance\nRATE_LIMIT_FAIL_MODE = \"open\"  # or \"closed\"\n</code></pre> <p>How It Works:</p> <pre><code># Middleware: app/middlewares/rate_limit.py\n# Automatically applied to all HTTP endpoints\n\n# Rate limit key:\n# - Authenticated: \"rate_limit:user:{username}\"\n# - Unauthenticated: \"rate_limit:ip:{ip_address}\"\n\n# Response headers:\nX-RateLimit-Limit: 60\nX-RateLimit-Remaining: 45\nX-RateLimit-Reset: 1609459200\n\n# When limit exceeded:\nHTTP/1.1 429 Too Many Requests\nRetry-After: 60\n{\n    \"detail\": \"Rate limit exceeded. Try again in 60 seconds.\"\n}\n</code></pre> <p>Excluded Paths:</p> <pre><code># Excluded from rate limiting (health checks, metrics)\nEXCLUDED_PATHS = re.compile(r\"^/(health|metrics|docs|openapi\\.json)\")\n</code></pre> <p>Burst Allowance:</p> <p>Burst allows temporary traffic spikes:</p> <pre><code>RATE_LIMIT_PER_MINUTE = 60  # Base limit\nRATE_LIMIT_BURST = 20  # Burst allowance\n\n# Total allowed: 80 requests per minute (60 + 20)\n# After burst consumed, limited to 60/minute\n</code></pre> <p>Sliding Window Algorithm:</p> <pre><code># Redis sorted set implementation\n# Key: rate_limit:user:john\n# Score: timestamp\n# Member: request_id\n\n# Check rate limit:\n1. Remove expired entries (outside window)\n2. Count requests in current window\n3. If count &lt; limit: Allow\n4. If count &gt;= limit: Deny with 429\n</code></pre> <p>Fail Modes:</p> <pre><code># Fail-open (default): Allow requests if Redis unavailable\nRATE_LIMIT_FAIL_MODE = \"open\"\n# Use for: High availability over strict rate limiting\n\n# Fail-closed: Deny requests if Redis unavailable\nRATE_LIMIT_FAIL_MODE = \"closed\"\n# Use for: Strict rate limiting over availability (production)\n</code></pre>"},{"location":"guides/security-best-practices/#websocket-rate-limiting","title":"WebSocket Rate Limiting","text":"<p>Two-Level Protection:</p>"},{"location":"guides/security-best-practices/#1-connection-limit","title":"1. Connection Limit","text":"<p>Prevents users from opening excessive connections:</p> <pre><code># app/settings.py\nWS_MAX_CONNECTIONS_PER_USER = 5  # Max concurrent connections per user\n</code></pre> <p>Enforcement:</p> <pre><code># In PackageAuthWebSocketEndpoint.on_connect()\nconnection_limiter = ConnectionLimiter()\nsuccess = await connection_limiter.add_connection(user.user_id, connection_id)\n\nif not success:\n    await websocket.close(\n        code=WS_1008_POLICY_VIOLATION,\n        reason=f\"Connection limit exceeded: {WS_MAX_CONNECTIONS_PER_USER}\"\n    )\n</code></pre> <p>Redis Storage:</p> <pre><code>Redis Key: ws_connections:{user_id}\nType: SET\nMembers: [connection_id1, connection_id2, ...]\nTTL: Auto-cleanup on disconnect\n</code></pre>"},{"location":"guides/security-best-practices/#2-message-rate-limit","title":"2. Message Rate Limit","text":"<p>Prevents message flooding:</p> <pre><code># app/settings.py\nWS_MESSAGE_RATE_LIMIT = 100  # Messages per minute\n</code></pre> <p>Enforcement:</p> <pre><code># In Web.on_receive()\nrate_limiter = RateLimiter()\nis_allowed, remaining = await rate_limiter.check_rate_limit(\n    key=f\"ws_msg:{user.user_id}\",\n    limit=WS_MESSAGE_RATE_LIMIT,\n    window_seconds=60\n)\n\nif not is_allowed:\n    await websocket.close(\n        code=WS_1008_POLICY_VIOLATION,\n        reason=\"Message rate limit exceeded\"\n    )\n</code></pre>"},{"location":"guides/security-best-practices/#custom-rate-limits","title":"Custom Rate Limits","text":"<p>For specific endpoints:</p> <pre><code>from app.utils.rate_limiter import RateLimiter\n\n@router.post(\"/expensive-operation\")\nasync def expensive_operation(user: UserModel = Depends(get_current_user)):\n    \"\"\"Custom rate limit for expensive operation.\"\"\"\n    rate_limiter = RateLimiter()\n\n    # 10 requests per hour\n    is_allowed, remaining = await rate_limiter.check_rate_limit(\n        key=f\"expensive_op:{user.user_id}\",\n        limit=10,\n        window_seconds=3600\n    )\n\n    if not is_allowed:\n        raise HTTPException(\n            status_code=429,\n            detail=f\"Rate limit exceeded. Remaining: {remaining}\"\n        )\n\n    # Expensive operation\n    result = await perform_expensive_operation()\n    return result\n</code></pre>"},{"location":"guides/security-best-practices/#rate-limit-monitoring","title":"Rate Limit Monitoring","text":"<p>Prometheus Metrics:</p> <pre><code># Rate limit hits (429 responses)\nrate(rate_limit_hits_total{limit_type=\"http\"}[5m])\n\n# WebSocket connection rejections\nrate(ws_connections_total{status=\"rejected_limit\"}[5m])\n\n# WebSocket message rate limit violations\nrate(ws_messages_rejected_total{reason=\"rate_limit\"}[5m])\n</code></pre> <p>Grafana Alerts:</p> <pre><code># docker/prometheus/alerts.yml\n- alert: HighRateLimitHits\n  expr: rate(rate_limit_hits_total[5m]) &gt; 10\n  for: 5m\n  labels:\n    severity: info\n  annotations:\n    summary: \"High rate limit hit rate\"\n    description: \"Rate limit being hit frequently ({{ $value }}/s)\"\n</code></pre>"},{"location":"guides/security-best-practices/#rate-limit-best-practices","title":"Rate Limit Best Practices","text":"<p>1. Choose appropriate limits:</p> <pre><code># Public API: Strict limits\nRATE_LIMIT_PER_MINUTE = 10\n\n# Authenticated users: Generous limits\nRATE_LIMIT_PER_MINUTE = 100\n\n# Internal services: Very high limits or disabled\nRATE_LIMIT_PER_MINUTE = 1000\n</code></pre> <p>2. Different limits for different endpoints:</p> <pre><code># General endpoints: 100/minute\n# Auth endpoints: 10/minute (prevent brute force)\n# File uploads: 5/hour\n</code></pre> <p>3. Communicate limits to clients:</p> <pre><code># Document in API docs\n# Include X-RateLimit-* headers in responses\n# Return clear error messages with Retry-After header\n</code></pre> <p>4. Monitor and adjust:</p> <pre><code># Track rate limit hits\n# Adjust based on legitimate vs abusive traffic\n# Whitelist trusted IPs if needed\n</code></pre>"},{"location":"guides/security-best-practices/#websocket-security","title":"WebSocket Security","text":""},{"location":"guides/security-best-practices/#overview_5","title":"Overview","text":"<p>WebSocket connections have unique security considerations: - CSRF protection via Origin header validation - Per-user connection limits - Message rate limiting - Token refresh strategies for long-lived connections</p>"},{"location":"guides/security-best-practices/#csrf-protection","title":"CSRF Protection","text":"<p>Attack Scenario:</p> <pre><code>&lt;!-- Malicious site: evil.com --&gt;\n&lt;script&gt;\n// Attempt WebSocket connection to your API\nconst ws = new WebSocket('wss://your-api.com/web?token=stolen_token');\n// Origin header: https://evil.com\n&lt;/script&gt;\n</code></pre> <p>Protection:</p> <pre><code># app/api/ws/websocket.py (PackageAuthWebSocketEndpoint._is_origin_allowed)\n\n# Configuration\nALLOWED_WS_ORIGINS = [\n    \"https://app.example.com\",\n    \"https://admin.example.com\"\n]\n\n# Validation Flow:\n1. Extract Origin header from WebSocket request\n2. If wildcard \"*\" in ALLOWED_WS_ORIGINS \u2192 Allow all (dev only!)\n3. If no Origin header \u2192 Same-origin request, allow\n4. If Origin in ALLOWED_WS_ORIGINS \u2192 Allow\n5. Otherwise \u2192 Reject with WS_1008_POLICY_VIOLATION\n</code></pre> <p>Configuration:</p> <pre><code># Development - allow all origins\nALLOWED_WS_ORIGINS = [\"*\"]\n\n# Production - restrict to specific origins\nALLOWED_WS_ORIGINS = [\n    \"https://app.example.com\",\n    \"https://admin.example.com\",\n    \"https://*.example.com\"  # Wildcard subdomain (if supported)\n]\n</code></pre> <p>How It Works:</p> <pre><code># Browser automatically sends Origin header\nOrigin: https://app.example.com\n\n# Server validates:\nif origin not in ALLOWED_WS_ORIGINS:\n    await websocket.close(\n        code=WS_1008_POLICY_VIOLATION,\n        reason=\"Origin not allowed\"\n    )\n</code></pre>"},{"location":"guides/security-best-practices/#connection-lifecycle-security","title":"Connection Lifecycle Security","text":"<p>1. Connection Establishment:</p> <pre><code>async def on_connect(websocket: WebSocket):\n    # Step 1: Origin validation (CSRF protection)\n    if not _is_origin_allowed(websocket):\n        await websocket.close(WS_1008_POLICY_VIOLATION, \"Origin not allowed\")\n        return\n\n    # Step 2: Authentication (JWT token from query param)\n    user = websocket.scope[\"user\"]\n    if not user or not user.is_authenticated:\n        await websocket.close(WS_1008_POLICY_VIOLATION, \"Authentication required\")\n        return\n\n    # Step 3: Connection limit enforcement\n    if await connection_limiter.is_limit_exceeded(user.user_id):\n        await websocket.close(WS_1008_POLICY_VIOLATION, \"Connection limit exceeded\")\n        return\n\n    # Step 4: Accept connection\n    await websocket.accept()\n\n    # Step 5: Register in connection manager\n    await connection_manager.connect(websocket, user)\n</code></pre> <p>2. Message Handling:</p> <pre><code>async def on_receive(websocket: WebSocket, data):\n    # Step 1: Rate limit check\n    if not await check_message_rate_limit(user):\n        await websocket.close(WS_1008_POLICY_VIOLATION, \"Rate limit exceeded\")\n        return\n\n    # Step 2: Input validation (Pydantic/JSON Schema/Protobuf)\n    try:\n        request = RequestModel(**data)\n    except ValidationError:\n        await websocket.close(WS_1003_UNSUPPORTED_DATA, \"Invalid data\")\n        return\n\n    # Step 3: Permission check\n    if not rbac_manager.check_ws_permission(request.pkg_id, user):\n        response = ResponseModel.error(request.pkg_id, request.req_id, \"Permission denied\")\n        await websocket.send_response(response)\n        return\n\n    # Step 4: Handler dispatch\n    response = await pkg_router.handle_request(user, request)\n    await websocket.send_response(response)\n</code></pre> <p>3. Disconnection:</p> <pre><code>async def on_disconnect(websocket: WebSocket, close_code: int):\n    # Step 1: Remove from connection manager\n    await connection_manager.disconnect(websocket)\n\n    # Step 2: Remove from connection limiter\n    await connection_limiter.remove_connection(user.user_id, connection_id)\n\n    # Step 3: Clean up user session in Redis\n    await redis.delete(f\"ws_session:{connection_id}\")\n\n    # Step 4: Log disconnect\n    logger.info(f\"WebSocket disconnected: {user.user_id}, code={close_code}\")\n</code></pre>"},{"location":"guides/security-best-practices/#token-refresh-strategies","title":"Token Refresh Strategies","text":"<p>WebSocket connections can last hours - tokens expire in minutes.</p> <p>Strategy 1: Reconnect Before Expiration</p> <pre><code>// Client-side\nlet ws;\nconst TOKEN_LIFETIME = 5 * 60 * 1000;  // 5 minutes\nconst REFRESH_BUFFER = 60 * 1000;  // Reconnect 1 minute before expiration\n\nfunction connect() {\n    const token = getAccessToken();\n    ws = new WebSocket(`wss://api.example.com/web?Authorization=${encodeURIComponent(token)}`);\n\n    // Reconnect before token expires\n    setTimeout(() =&gt; {\n        ws.close();\n        connect();\n    }, TOKEN_LIFETIME - REFRESH_BUFFER);\n}\n\nconnect();\n</code></pre> <p>Strategy 2: Server-Initiated Reconnection</p> <pre><code># Server sends reconnection message before token expires\nif token_expires_in &lt; 60:  # Less than 1 minute remaining\n    response = ResponseModel(\n        pkg_id=PkgID.SYSTEM_MESSAGE,\n        req_id=generate_uuid(),\n        status_code=RSPCode.TOKEN_EXPIRING,\n        data={\"message\": \"Token expiring soon, please reconnect\"}\n    )\n    await websocket.send_response(response)\n</code></pre> <p>Strategy 3: Token Refresh via WebSocket</p> <pre><code>@pkg_router.register(PkgID.REFRESH_TOKEN)\nasync def refresh_token_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"\n    Refresh access token via WebSocket.\n\n    Client sends refresh_token, receives new access_token.\n    \"\"\"\n    refresh_token = request.data.get(\"refresh_token\")\n\n    try:\n        new_token = await keycloak_manager.refresh_token(refresh_token)\n        return ResponseModel.success(\n            request.pkg_id,\n            request.req_id,\n            data={\"access_token\": new_token}\n        )\n    except Exception as e:\n        return ResponseModel.error(request.pkg_id, request.req_id, str(e))\n</code></pre>"},{"location":"guides/security-best-practices/#message-format-negotiation","title":"Message Format Negotiation","text":"<p>Clients can choose JSON or Protobuf:</p> <pre><code>// JSON format (default)\nconst ws = new WebSocket('wss://api.example.com/web?Authorization=...&amp;format=json');\n\n// Protobuf format (smaller, faster)\nconst ws = new WebSocket('wss://api.example.com/web?Authorization=...&amp;format=protobuf');\n</code></pre> <p>Security: Both formats are validated, but Protobuf has stronger type safety.</p>"},{"location":"guides/security-best-practices/#broadcast-security","title":"Broadcast Security","text":"<p>Problem: Sending sensitive data to all connected users</p> <p>Solution: Filter broadcasts by user permissions</p> <pre><code>async def broadcast_sensitive_data(data: dict):\n    \"\"\"Broadcast only to users with permission.\"\"\"\n    for connection in connection_manager.active_connections:\n        user = connection.user\n\n        # Check if user has permission to receive this data\n        if rbac_manager.check_user_has_roles(user, [\"view-sensitive-data\"]):\n            await connection.websocket.send_json(data)\n</code></pre>"},{"location":"guides/security-best-practices/#connection-monitoring","title":"Connection Monitoring","text":"<p>Metrics:</p> <pre><code># Active connections\nws_connections_active\n\n# Connection rejections\nrate(ws_connections_total{status=\"rejected_auth\"}[5m])\nrate(ws_connections_total{status=\"rejected_limit\"}[5m])\n\n# Message rate\nrate(ws_messages_received_total[5m])\nrate(ws_messages_sent_total[5m])\n</code></pre> <p>Alerts:</p> <pre><code>- alert: HighWebSocketRejections\n  expr: rate(ws_connections_total{status=~\"rejected_.*\"}[5m]) &gt; 5\n  for: 3m\n  labels:\n    severity: warning\n  annotations:\n    summary: \"High WebSocket rejection rate\"\n    description: \"{{ $value }} connections/s being rejected\"\n</code></pre>"},{"location":"guides/security-best-practices/#websocket-security-checklist","title":"WebSocket Security Checklist","text":"<ul> <li> Origin validation enabled and configured for production</li> <li> ALLOWED_WS_ORIGINS does not contain wildcard \"*\" in production</li> <li> Connection limits per user configured appropriately</li> <li> Message rate limits prevent flooding</li> <li> Token expiration handled gracefully (reconnection strategy)</li> <li> Input validation on all message types</li> <li> RBAC permissions checked before handling messages</li> <li> Sensitive data not broadcast to unauthorized users</li> <li> WSS (WebSocket over TLS) used in production</li> <li> Audit logging enabled for WebSocket connections and messages</li> </ul>"},{"location":"guides/security-best-practices/#audit-logging","title":"Audit Logging","text":""},{"location":"guides/security-best-practices/#overview_6","title":"Overview","text":"<p>Comprehensive audit logging for compliance and security monitoring: - Non-blocking async queue-based logging - Automatic sanitization of sensitive data - Batch processing for performance - Backpressure mechanism prevents data loss</p> <p>Implementation: <code>app/utils/audit_logger.py</code></p>"},{"location":"guides/security-best-practices/#what-gets-logged","title":"What Gets Logged","text":"<p>Every user action is logged with:</p> <pre><code># User context\nuser_id: str  # Keycloak user ID\nusername: str  # Keycloak username\nuser_roles: list[str]  # Roles at time of action\n\n# Action details\naction_type: str  # HTTP method or WS:PKG_ID\nresource: str  # Endpoint path or resource identifier\noutcome: str  # \"success\", \"error\", \"permission_denied\"\n\n# Request context\nip_address: str  # Client IP (with spoofing protection)\nuser_agent: str  # Client user agent\nrequest_id: str  # Correlation ID for tracing\nrequest_data: dict  # Request payload (sanitized)\n\n# Response context\nresponse_status: int  # HTTP status code or RSPCode\nerror_message: str | None  # Error details if failed\nduration_ms: int  # Request processing time\n\n# Metadata\ntimestamp: datetime  # UTC timestamp\n</code></pre>"},{"location":"guides/security-best-practices/#async-queue-architecture","title":"Async Queue Architecture","text":"<pre><code>graph LR\n    A[HTTP/WS Request] --&gt; B[log_user_action]\n    B --&gt; C[Async Queue]\n    C --&gt; D[Batch Worker]\n    D --&gt; E[Bulk DB Insert]\n    E --&gt; F[PostgreSQL]\n\n    style C fill:#f9f,stroke:#333\n    style D fill:#bbf,stroke:#333</code></pre> <p>Benefits: - Non-blocking: Returns immediately, no impact on request latency - Batch processing: Efficient bulk inserts (100 logs per batch) - Backpressure: Waits for queue space instead of dropping logs - Resilient: Graceful degradation on database issues</p>"},{"location":"guides/security-best-practices/#configuration","title":"Configuration","text":"<pre><code># app/settings.py\nAUDIT_LOG_ENABLED = True\nAUDIT_QUEUE_MAX_SIZE = 10000  # Max queued logs before backpressure\nAUDIT_BATCH_SIZE = 100  # Logs per database transaction\nAUDIT_BATCH_TIMEOUT = 1.0  # Seconds to wait for full batch\nAUDIT_QUEUE_TIMEOUT = 1.0  # Seconds to wait for queue space (backpressure)\n</code></pre>"},{"location":"guides/security-best-practices/#backpressure-mechanism","title":"Backpressure Mechanism","text":"<p>Queue Full Scenario:</p> <pre><code># Default behavior (AUDIT_QUEUE_TIMEOUT = 1.0):\n1. Queue is full (10,000 logs)\n2. New log arrival \u2192 Wait up to 1 second for space\n3. If space available within 1s \u2192 Log enqueued\n4. If timeout expires \u2192 Log dropped with warning\n\n# Legacy behavior (AUDIT_QUEUE_TIMEOUT = 0):\n1. Queue is full\n2. New log arrival \u2192 Drop immediately\n</code></pre> <p>Why Backpressure? - Compliance: Reduces log loss during traffic spikes - Transparency: Logs wait time vs immediate drops - Metrics: <code>audit_logs_dropped_total</code> tracks actual data loss</p>"},{"location":"guides/security-best-practices/#sensitive-data-sanitization_1","title":"Sensitive Data Sanitization","text":"<p>Automatically redacted fields:</p> <pre><code>SENSITIVE_FIELDS = [\n    \"password\", \"passwd\", \"pwd\",\n    \"token\", \"access_token\", \"refresh_token\",\n    \"secret\", \"api_key\", \"private_key\",\n    \"ssn\", \"social_security_number\",\n    \"credit_card\", \"card_number\", \"cvv\",\n    \"authorization\"\n]\n</code></pre> <p>Example:</p> <pre><code># Original request data\nrequest_data = {\n    \"username\": \"john\",\n    \"password\": \"SuperSecret123!\",\n    \"email\": \"john@example.com\",\n    \"api_key\": \"sk_live_1234567890\"\n}\n\n# Stored in audit log\nsanitized_data = {\n    \"username\": \"john\",\n    \"password\": \"[REDACTED]\",\n    \"email\": \"john@example.com\",\n    \"api_key\": \"[REDACTED]\"\n}\n</code></pre>"},{"location":"guides/security-best-practices/#usage-in-endpoints","title":"Usage in Endpoints","text":"<p>HTTP Endpoints (Automatic):</p> <pre><code># Middleware: app/middlewares/audit_middleware.py\n# Automatically logs all HTTP requests\n\n# No code needed - middleware intercepts all requests\n</code></pre> <p>WebSocket Handlers (Manual):</p> <pre><code>from app.utils.audit_logger import log_user_action\n\n@pkg_router.register(PkgID.DELETE_AUTHOR, roles=[\"delete-author\"])\nasync def delete_author_handler(request: RequestModel) -&gt; ResponseModel:\n    user = request.user  # From context\n\n    try:\n        # Business logic\n        await author_repository.delete(request.data[\"author_id\"])\n\n        # Log success\n        await log_user_action(\n            user_id=user.user_id,\n            username=user.username,\n            user_roles=user.roles,\n            action_type=f\"WS:{PkgID.DELETE_AUTHOR.name}\",\n            resource=f\"author:{request.data['author_id']}\",\n            outcome=\"success\",\n            ip_address=get_client_ip(request),\n            request_data=request.data,\n            response_status=RSPCode.OK,\n            duration_ms=45\n        )\n\n        return ResponseModel.success(...)\n\n    except Exception as e:\n        # Log error\n        await log_user_action(\n            user_id=user.user_id,\n            username=user.username,\n            user_roles=user.roles,\n            action_type=f\"WS:{PkgID.DELETE_AUTHOR.name}\",\n            resource=f\"author:{request.data.get('author_id', 'unknown')}\",\n            outcome=\"error\",\n            error_message=str(e),\n            ip_address=get_client_ip(request),\n            request_data=request.data,\n            response_status=RSPCode.ERROR,\n            duration_ms=12\n        )\n        raise\n</code></pre>"},{"location":"guides/security-best-practices/#querying-audit-logs","title":"Querying Audit Logs","text":"<p>Grafana Dashboard:</p> <p>The Audit Logs Dashboard (<code>audit-logs</code>) provides: - Time series of events by outcome - Top users by activity - Recent audit events table - Failed/denied actions table</p> <p>Access at: http://localhost:3000/d/audit-logs</p> <p>SQL Queries:</p> <pre><code>-- Find all actions by specific user\nSELECT timestamp, action_type, resource, outcome, error_message\nFROM user_actions\nWHERE username = 'john.doe'\nORDER BY timestamp DESC\nLIMIT 100;\n\n-- Find all failed login attempts\nSELECT timestamp, username, ip_address, error_message\nFROM user_actions\nWHERE action_type = 'POST' AND resource = '/auth/login' AND outcome = 'error'\nAND timestamp &gt; NOW() - INTERVAL '24 hours';\n\n-- Find all permission denied events\nSELECT timestamp, username, action_type, resource, user_roles\nFROM user_actions\nWHERE outcome = 'permission_denied'\nORDER BY timestamp DESC;\n\n-- Track user activity patterns\nSELECT\n    DATE_TRUNC('hour', timestamp) AS hour,\n    username,\n    COUNT(*) AS action_count,\n    SUM(CASE WHEN outcome = 'error' THEN 1 ELSE 0 END) AS errors\nFROM user_actions\nWHERE timestamp &gt; NOW() - INTERVAL '7 days'\nGROUP BY hour, username\nORDER BY hour, action_count DESC;\n</code></pre>"},{"location":"guides/security-best-practices/#compliance-considerations","title":"Compliance Considerations","text":"<p>GDPR Compliance:</p> <pre><code># Data retention policy\nDELETE FROM user_actions\nWHERE timestamp &lt; NOW() - INTERVAL '2 years';\n\n# User data deletion (right to be forgotten)\nDELETE FROM user_actions\nWHERE user_id = '&lt;user_id_to_delete&gt;';\n\n# Pseudonymization for analytics\nUPDATE user_actions\nSET username = 'user_' || MD5(username)\nWHERE timestamp &lt; NOW() - INTERVAL '90 days';\n</code></pre> <p>SOX/HIPAA Compliance:</p> <pre><code># Immutability - audit logs should never be modified\n# Implement as database trigger:\nCREATE TRIGGER prevent_audit_log_modification\nBEFORE UPDATE ON user_actions\nFOR EACH ROW\nEXECUTE FUNCTION prevent_modification();\n\n# Separate audit log database with restricted access\n# Only audit service can write, only auditors can read\n</code></pre>"},{"location":"guides/security-best-practices/#monitoring-audit-logs","title":"Monitoring Audit Logs","text":"<p>Prometheus Metrics:</p> <pre><code># Total audit logs created\nrate(audit_logs_total{outcome=\"success\"}[5m])\n\n# Audit logs dropped due to queue overflow\nrate(audit_logs_dropped_total[5m])\n\n# Queue depth\naudit_queue_size\n\n# Batch processing efficiency\naudit_batch_size\n</code></pre> <p>Alerts:</p> <pre><code>- alert: AuditLogDropping\n  expr: rate(audit_logs_dropped_total[2m]) &gt; 1\n  for: 2m\n  labels:\n    severity: critical\n  annotations:\n    summary: \"Audit logs being dropped\"\n    description: \"{{ $value }} logs/s dropped (compliance risk!)\"\n\n- alert: HighAuditLogDropRate\n  expr: |\n    (rate(audit_logs_dropped_total[2m]) /\n     rate(audit_logs_total[2m])) &gt; 0.01\n  for: 2m\n  labels:\n    severity: warning\n  annotations:\n    summary: \"High audit log drop rate\"\n    description: \"{{ $value | humanizePercentage }} of logs being dropped\"\n</code></pre>"},{"location":"guides/security-best-practices/#troubleshooting","title":"Troubleshooting","text":"<p>Problem: Audit logs being dropped</p> <pre><code># Check queue size\ncurl http://localhost:9090/api/v1/query?query=audit_queue_size\n\n# Check drop rate\ncurl http://localhost:9090/api/v1/query?query=rate(audit_logs_dropped_total[5m])\n</code></pre> <p>Solutions: 1. Increase queue size: <code>AUDIT_QUEUE_MAX_SIZE = 20000</code> 2. Increase batch size for faster processing: <code>AUDIT_BATCH_SIZE = 200</code> 3. Optimize database write performance (indexes, connection pool) 4. Scale horizontally (add more application instances)</p> <p>Problem: Slow database writes</p> <pre><code># Check batch write duration\ncurl http://localhost:9090/api/v1/query?query=audit_log_creation_duration_seconds\n</code></pre> <p>Solutions: 1. Add database index on <code>timestamp</code>, <code>username</code>, <code>user_id</code> 2. Increase database connection pool size 3. Consider partitioning <code>user_actions</code> table by time</p>"},{"location":"guides/security-best-practices/#ip-spoofing-protection","title":"IP Spoofing Protection","text":""},{"location":"guides/security-best-practices/#overview_7","title":"Overview","text":"<p>Prevents attackers from forging IP addresses via <code>X-Forwarded-For</code> header: - Validates proxy authenticity - Supports CIDR notation for trusted proxy ranges - Logs warnings for untrusted sources</p> <p>Implementation: <code>app/utils/ip_utils.py</code></p>"},{"location":"guides/security-best-practices/#how-ip-spoofing-works","title":"How IP Spoofing Works","text":"<p>Attack Scenario:</p> <pre><code># Attacker sends request with forged X-Forwarded-For header\nGET /api/sensitive HTTP/1.1\nHost: api.example.com\nX-Forwarded-For: 192.168.1.1  # Forged internal IP\n\n# Without validation:\n# - Rate limiting bypassed (new IP each request)\n# - Audit logs show wrong IP\n# - IP-based access controls bypassed\n</code></pre>"},{"location":"guides/security-best-practices/#trusted-proxy-validation","title":"Trusted Proxy Validation","text":"<p>Configuration:</p> <pre><code># app/settings.py\nTRUSTED_PROXIES = [\n    \"10.0.0.0/8\",      # Private network\n    \"172.16.0.0/12\",   # Private network\n    \"192.168.0.0/16\",  # Private network\n    \"203.0.113.0/24\"   # Your CDN/load balancer IPs\n]\n</code></pre> <p>How It Works:</p> <pre><code>def get_client_ip(request: Request) -&gt; str:\n    \"\"\"\n    Safely extract client IP with spoofing protection.\n\n    Priority:\n    1. X-Forwarded-For header (if from trusted proxy)\n    2. Direct client.host (fallback)\n    \"\"\"\n    # Check if request came through trusted proxy\n    direct_ip = request.client.host\n\n    if is_trusted_proxy(direct_ip):\n        # Trust X-Forwarded-For from trusted proxy\n        forwarded_for = request.headers.get(\"X-Forwarded-For\", \"\")\n        if forwarded_for:\n            # First IP in comma-separated list is the client\n            client_ip = forwarded_for.split(\",\")[0].strip()\n            return client_ip\n\n    # Not from trusted proxy - use direct IP\n    # Log warning if X-Forwarded-For present (potential spoof attempt)\n    if \"X-Forwarded-For\" in request.headers:\n        logger.warning(\n            f\"Untrusted X-Forwarded-For header from {direct_ip}: \"\n            f\"{request.headers['X-Forwarded-For']}\"\n        )\n\n    return direct_ip\n</code></pre>"},{"location":"guides/security-best-practices/#production-deployment","title":"Production Deployment","text":"<p>AWS/ELB:</p> <pre><code># Trust ALB/ELB IP ranges\nTRUSTED_PROXIES = [\n    \"10.0.0.0/8\",  # VPC private IPs\n    # Add AWS ALB IP ranges for your region\n]\n</code></pre> <p>Nginx Reverse Proxy:</p> <pre><code># Trust Nginx server IP\nTRUSTED_PROXIES = [\n    \"172.17.0.2\",  # Docker nginx container\n    \"10.0.1.0/24\"  # Nginx server subnet\n]\n\n# Nginx configuration (set real IP from X-Forwarded-For)\n# /etc/nginx/nginx.conf\nset_real_ip_from 10.0.0.0/8;\nreal_ip_header X-Forwarded-For;\n</code></pre> <p>Cloudflare:</p> <pre><code># Trust Cloudflare IP ranges\n# https://www.cloudflare.com/ips/\nTRUSTED_PROXIES = [\n    \"173.245.48.0/20\",\n    \"103.21.244.0/22\",\n    # ... add all Cloudflare ranges\n]\n</code></pre>"},{"location":"guides/security-best-practices/#testing","title":"Testing","text":"<pre><code># Test with trusted proxy\ncurl -H \"X-Forwarded-For: 1.2.3.4\" http://localhost:8000/api/test\n# Result: IP logged as 1.2.3.4 (trusted)\n\n# Test with untrusted source (direct connection)\ncurl -H \"X-Forwarded-For: 1.2.3.4\" http://your-api.com/api/test\n# Result: IP logged as your actual IP (untrusted header ignored)\n# Warning logged: \"Untrusted X-Forwarded-For header from &lt;your_ip&gt;\"\n</code></pre>"},{"location":"guides/security-best-practices/#cidr-notation-support","title":"CIDR Notation Support","text":"<pre><code>def is_trusted_proxy(ip_address: str) -&gt; bool:\n    \"\"\"Check if IP belongs to trusted proxy (supports CIDR).\"\"\"\n    import ipaddress\n\n    try:\n        ip = ipaddress.ip_address(ip_address)\n\n        for trusted in TRUSTED_PROXIES:\n            # Single IP\n            if \"/\" not in trusted:\n                if str(ip) == trusted:\n                    return True\n            # CIDR notation (e.g., \"10.0.0.0/8\")\n            else:\n                network = ipaddress.ip_network(trusted, strict=False)\n                if ip in network:\n                    return True\n\n        return False\n    except ValueError:\n        logger.error(f\"Invalid IP address: {ip_address}\")\n        return False\n</code></pre>"},{"location":"guides/security-best-practices/#usage-in-application","title":"Usage in Application","text":"<p>Audit Logging:</p> <pre><code># app/middlewares/audit_middleware.py\nip_address = get_client_ip(request)  # Safe IP extraction\n\nawait log_user_action(\n    ...\n    ip_address=ip_address,  # Accurate IP in audit logs\n    ...\n)\n</code></pre> <p>Rate Limiting:</p> <pre><code># app/middlewares/rate_limit.py\nif user:\n    rate_limit_key = f\"rate_limit:user:{user.username}\"\nelse:\n    # Fall back to IP-based rate limit\n    ip_address = get_client_ip(request)  # Protected from spoofing\n    rate_limit_key = f\"rate_limit:ip:{ip_address}\"\n</code></pre>"},{"location":"guides/security-best-practices/#circuit-breakers","title":"Circuit Breakers","text":""},{"location":"guides/security-best-practices/#overview_8","title":"Overview","text":"<p>Circuit breakers prevent cascading failures when external services (Keycloak, Redis) are unavailable: - Fail-fast instead of waiting for timeouts - Automatic recovery testing - Prometheus metrics for monitoring</p> <p>Implementation: - Keycloak: <code>app/managers/keycloak_manager.py</code> - Redis: <code>app/storage/redis.py</code></p>"},{"location":"guides/security-best-practices/#how-circuit-breakers-work","title":"How Circuit Breakers Work","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Closed: Normal Operation\n    Closed --&gt; Open: N Failures\n    Open --&gt; HalfOpen: Timeout Expires\n    HalfOpen --&gt; Closed: Success\n    HalfOpen --&gt; Open: Failure\n\n    note right of Closed\n        All requests pass through\n        Failures counted\n    end note\n\n    note right of Open\n        Requests fail immediately\n        No calls to service\n    end note\n\n    note right of HalfOpen\n        One request allowed\n        Test if service recovered\n    end note</code></pre>"},{"location":"guides/security-best-practices/#keycloak-circuit-breaker","title":"Keycloak Circuit Breaker","text":"<p>Configuration:</p> <pre><code># app/settings.py\nCIRCUIT_BREAKER_ENABLED = True\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX = 5  # Open after 5 failures\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT = 60  # Keep open for 60 seconds\n</code></pre> <p>Protected Operations:</p> <pre><code># app/managers/keycloak_manager.py\n@CircuitBreaker(fail_max=KEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX,\n                 timeout_seconds=KEYCLOAK_CIRCUIT_BREAKER_TIMEOUT)\nasync def login_async(username: str, password: str) -&gt; dict:\n    \"\"\"\n    Login to Keycloak.\n\n    Protected by circuit breaker - fails fast if Keycloak is down.\n    \"\"\"\n    return await self.openid.a_token(username, password)\n</code></pre> <p>Behavior:</p> <pre><code># Closed (normal):\nresult = await keycloak_manager.login_async(username, password)\n# Calls Keycloak, returns token\n\n# Open (after 5 failures):\nresult = await keycloak_manager.login_async(username, password)\n# Raises CircuitBreakerError immediately (no call to Keycloak)\n\n# Half-Open (after 60 seconds):\nresult = await keycloak_manager.login_async(username, password)\n# Allows ONE test request\n# If successful \u2192 Closed\n# If failed \u2192 Open for another 60 seconds\n</code></pre>"},{"location":"guides/security-best-practices/#redis-circuit-breaker","title":"Redis Circuit Breaker","text":"<p>Configuration:</p> <pre><code># app/settings.py\nREDIS_CIRCUIT_BREAKER_FAIL_MAX = 3  # Open after 3 failures\nREDIS_CIRCUIT_BREAKER_TIMEOUT = 30  # Keep open for 30 seconds\n</code></pre> <p>Protected Operations:</p> <pre><code># app/storage/redis.py\n@CircuitBreaker(fail_max=REDIS_CIRCUIT_BREAKER_FAIL_MAX,\n                 timeout_seconds=REDIS_CIRCUIT_BREAKER_TIMEOUT)\nasync def get_redis_connection(db: int = 1) -&gt; Redis | None:\n    \"\"\"\n    Get Redis connection.\n\n    Protected by circuit breaker for resilience.\n    \"\"\"\n    return await RedisPool.get_instance(db)\n</code></pre> <p>Fail-Open Behavior:</p> <pre><code># Rate limiter with fail-open\nasync def check_rate_limit(key, limit):\n    try:\n        redis = await get_redis_connection()\n        # Use Redis for rate limiting\n    except CircuitBreakerError:\n        # Redis circuit is open - fail-open\n        logger.warning(\"Redis circuit breaker open, allowing request\")\n        return (True, limit)  # Allow request\n</code></pre>"},{"location":"guides/security-best-practices/#monitoring-circuit-breakers","title":"Monitoring Circuit Breakers","text":"<p>Prometheus Metrics:</p> <pre><code># Circuit breaker state (0=closed, 1=open, 2=half_open)\ncircuit_breaker_state{service=\"keycloak\"}\ncircuit_breaker_state{service=\"redis\"}\n\n# State transitions\ncircuit_breaker_state_changes_total{service=\"keycloak\", from_state=\"closed\", to_state=\"open\"}\n\n# Total failures detected\ncircuit_breaker_failures_total{service=\"keycloak\"}\n</code></pre> <p>Grafana Visualization:</p> <pre><code># Circuit breaker state over time\ncircuit_breaker_state{service=\"keycloak\"}\n\n# Alert when circuit is open\ncircuit_breaker_state{service=\"keycloak\"} == 1\n</code></pre> <p>Alerts:</p> <pre><code>- alert: KeycloakCircuitBreakerOpen\n  expr: circuit_breaker_state{service=\"keycloak\"} == 1\n  for: 1m\n  labels:\n    severity: critical\n  annotations:\n    summary: \"Keycloak circuit breaker is OPEN\"\n    description: \"Authentication will fail until Keycloak recovers\"\n\n- alert: RedisCircuitBreakerOpen\n  expr: circuit_breaker_state{service=\"redis\"} == 1\n  for: 1m\n  labels:\n    severity: warning\n  annotations:\n    summary: \"Redis circuit breaker is OPEN\"\n    description: \"Rate limiting and caching degraded\"\n</code></pre>"},{"location":"guides/security-best-practices/#benefits","title":"Benefits","text":"<p>1. Fail-Fast: <pre><code># Without circuit breaker:\n# - Keycloak down\n# - Every auth attempt waits for 30s timeout\n# - Request latency: 30+ seconds\n# - Resource exhaustion from waiting threads\n\n# With circuit breaker:\n# - Keycloak down\n# - Circuit opens after 5 failures (~150s)\n# - Future requests fail immediately (&lt; 1ms)\n# - Resources freed for other tasks\n</code></pre></p> <p>2. Automatic Recovery: <pre><code># Circuit automatically tests service recovery\n# No manual intervention needed\n# Half-open state allows safe testing\n</code></pre></p> <p>3. Clear Visibility: <pre><code># Metrics show service health\n# Alerts notify when services degraded\n# Dashboard shows circuit breaker state\n</code></pre></p>"},{"location":"guides/security-best-practices/#tuning-circuit-breakers","title":"Tuning Circuit Breakers","text":"<p>Aggressive (Fail-fast):</p> <pre><code># Open quickly, short timeout\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX = 3  # 3 failures\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT = 30  # 30 seconds\n\n# Use for: Critical path, strict SLA requirements\n</code></pre> <p>Conservative (Tolerant):</p> <pre><code># Open slowly, long timeout\nKEYCLOAK_CIRCUIT_BREAKER_FAIL_MAX = 10  # 10 failures\nKEYCLOAK_CIRCUIT_BREAKER_TIMEOUT = 120  # 2 minutes\n\n# Use for: Non-critical path, intermittent issues\n</code></pre> <p>Disable for Development:</p> <pre><code># Disable circuit breakers in development\nCIRCUIT_BREAKER_ENABLED = False\n</code></pre>"},{"location":"guides/security-best-practices/#security-deployment-checklist","title":"Security Deployment Checklist","text":"<p>Use this checklist before deploying to production:</p>"},{"location":"guides/security-best-practices/#environment-configuration","title":"Environment Configuration","text":"<ul> <li> <code>ENV=production</code> in environment variables</li> <li> All <code>CHANGE_ME</code> values replaced in <code>.env.production</code></li> <li> Strong secret keys generated (not default values)</li> <li> Database credentials not in code (environment variables only)</li> <li> Redis password set (if exposed outside Docker network)</li> </ul>"},{"location":"guides/security-best-practices/#https-tls","title":"HTTPS / TLS","text":"<ul> <li> HTTPS enforced (redirect HTTP \u2192 HTTPS)</li> <li> Valid SSL/TLS certificate installed (not self-signed)</li> <li> HSTS header enabled (<code>Strict-Transport-Security</code>)</li> <li> TLS 1.2+ only (disable TLS 1.0, 1.1)</li> <li> Strong cipher suites configured</li> </ul>"},{"location":"guides/security-best-practices/#authentication-authorization","title":"Authentication &amp; Authorization","text":"<ul> <li> Keycloak token TTL configured (5-15 minutes recommended)</li> <li> Token refresh mechanism implemented for long sessions</li> <li> RBAC permissions configured for all sensitive endpoints</li> <li> Public endpoints intentionally marked (no accidental public access)</li> <li> Excluded paths reviewed (only health checks, metrics should bypass auth)</li> </ul>"},{"location":"guides/security-best-practices/#rate-limiting_1","title":"Rate Limiting","text":"<ul> <li> Rate limiting enabled (<code>RATE_LIMIT_ENABLED=true</code>)</li> <li> Appropriate limits configured for API usage patterns</li> <li> Fail mode set to <code>closed</code> for strict enforcement</li> <li> Burst allowances configured for traffic spikes</li> <li> WebSocket connection limits per user configured</li> <li> WebSocket message rate limits configured</li> </ul>"},{"location":"guides/security-best-practices/#websocket-security_1","title":"WebSocket Security","text":"<ul> <li> <code>ALLOWED_WS_ORIGINS</code> set to specific domains (no wildcard \"*\")</li> <li> Origin validation enabled in production</li> <li> WSS (WebSocket over TLS) used (not WS)</li> <li> Connection limits prevent resource exhaustion</li> <li> Token refresh strategy implemented for long-lived connections</li> </ul>"},{"location":"guides/security-best-practices/#network-security","title":"Network Security","text":"<ul> <li> <code>ALLOWED_HOSTS</code> configured (no wildcard \"*\")</li> <li> Trusted proxies configured for <code>X-Forwarded-For</code> validation</li> <li> IP spoofing protection verified</li> <li> Firewall rules restrict database/Redis access</li> <li> Prometheus <code>/metrics</code> endpoint secured (network policy or auth)</li> </ul>"},{"location":"guides/security-best-practices/#audit-logging_1","title":"Audit Logging","text":"<ul> <li> Audit logging enabled (<code>AUDIT_LOG_ENABLED=true</code>)</li> <li> Log retention policy configured (GDPR/compliance)</li> <li> Audit log backups scheduled</li> <li> Alerts configured for dropped audit logs</li> <li> Log aggregation configured (Loki/ELK)</li> </ul>"},{"location":"guides/security-best-practices/#security-headers_1","title":"Security Headers","text":"<ul> <li> Security headers verified with scanner</li> <li> CSP configured appropriately for your app</li> <li> HSTS preload considered (if public site)</li> <li> Referrer-Policy prevents token leakage</li> </ul>"},{"location":"guides/security-best-practices/#input-validation_1","title":"Input Validation","text":"<ul> <li> Pydantic models used for all input validation</li> <li> String length limits on all user input</li> <li> JSON Schema validation for WebSocket messages</li> <li> SQL injection prevention verified (parameterized queries)</li> <li> Path traversal prevention in file operations</li> </ul>"},{"location":"guides/security-best-practices/#monitoring-alerting","title":"Monitoring &amp; Alerting","text":"<ul> <li> Prometheus alerts configured for security events</li> <li> High authentication failure rate alert</li> <li> Rate limit violation alerts</li> <li> Circuit breaker open alerts</li> <li> Audit log dropping alerts</li> <li> Grafana dashboards configured</li> </ul>"},{"location":"guides/security-best-practices/#dependency-security","title":"Dependency Security","text":"<ul> <li> All dependencies up to date</li> <li> <code>skjold</code> vulnerability scan passing</li> <li> <code>bandit</code> security scan passing</li> <li> Dependabot enabled for automatic updates</li> <li> Regular security update schedule established</li> </ul>"},{"location":"guides/security-best-practices/#incident-response","title":"Incident Response","text":"<ul> <li> Security incident response plan documented</li> <li> Contact information for security team</li> <li> Log aggregation for forensic analysis</li> <li> Backup and recovery procedures tested</li> <li> Rollback procedures documented</li> </ul>"},{"location":"guides/security-best-practices/#documentation","title":"Documentation","text":"<ul> <li> Security documentation accessible to team</li> <li> API documentation includes auth requirements</li> <li> Deployment guide includes security setup</li> <li> Security best practices communicated to developers</li> </ul>"},{"location":"guides/security-best-practices/#common-security-pitfalls","title":"Common Security Pitfalls","text":""},{"location":"guides/security-best-practices/#1-mass-assignment","title":"1. Mass Assignment","text":"<p>Problem:</p> <pre><code># \u274c VULNERABLE - Accepts any field from user input\n@router.post(\"/users\")\nasync def create_user(data: dict):\n    user = User(**data)  # Attacker can set is_admin=True!\n    await session.add(user)\n</code></pre> <p>Solution:</p> <pre><code># \u2705 SAFE - Pydantic model whitelists allowed fields\nclass CreateUserInput(BaseModel):\n    username: str\n    email: EmailStr\n    # is_admin NOT included - cannot be set by user\n\n@router.post(\"/users\")\nasync def create_user(data: CreateUserInput):\n    user = User(**data.model_dump())  # Only whitelisted fields\n    await session.add(user)\n</code></pre>"},{"location":"guides/security-best-practices/#2-sql-injection","title":"2. SQL Injection","text":"<p>Problem:</p> <pre><code># \u274c VULNERABLE - String formatting in query\n@router.get(\"/users\")\nasync def search_users(name: str):\n    query = f\"SELECT * FROM users WHERE name = '{name}'\"\n    result = await session.execute(text(query))\n    # Attacker: name = \"'; DROP TABLE users; --\"\n</code></pre> <p>Solution:</p> <pre><code># \u2705 SAFE - Parameterized query\n@router.get(\"/users\")\nasync def search_users(name: str):\n    stmt = select(User).where(User.name == name)\n    result = await session.execute(stmt)\n    # SQLAlchemy automatically parameterizes\n</code></pre>"},{"location":"guides/security-best-practices/#3-broken-authentication","title":"3. Broken Authentication","text":"<p>Problem:</p> <pre><code># \u274c VULNERABLE - No token validation\n@router.get(\"/profile\")\nasync def get_profile(user_id: str):\n    # Attacker can access any user's profile!\n    user = await get_user(user_id)\n    return user\n</code></pre> <p>Solution:</p> <pre><code># \u2705 SAFE - Token validation + user context\n@router.get(\"/profile\")\nasync def get_profile(user: UserModel = Depends(get_current_user)):\n    # User is authenticated via JWT token\n    # Can only access their own profile\n    return user\n</code></pre>"},{"location":"guides/security-best-practices/#4-sensitive-data-exposure","title":"4. Sensitive Data Exposure","text":"<p>Problem:</p> <pre><code># \u274c VULNERABLE - Logging sensitive data\nlogger.info(f\"User login: {username}, password: {password}\")\n\n# \u274c VULNERABLE - Returning sensitive data\n@router.get(\"/users/{id}\")\nasync def get_user(id: int):\n    user = await get_user(id)\n    return user  # Includes password_hash, api_keys, etc.!\n</code></pre> <p>Solution:</p> <pre><code># \u2705 SAFE - Don't log sensitive data\nlogger.info(f\"User login: {username}\")\n\n# \u2705 SAFE - Response model excludes sensitive fields\nclass UserResponse(BaseModel):\n    id: int\n    username: str\n    email: str\n    # password_hash excluded\n\n@router.get(\"/users/{id}\")\nasync def get_user(id: int) -&gt; UserResponse:\n    user = await get_user(id)\n    return UserResponse(**user.model_dump())\n</code></pre>"},{"location":"guides/security-best-practices/#5-broken-access-control","title":"5. Broken Access Control","text":"<p>Problem:</p> <pre><code># \u274c VULNERABLE - No permission check\n@router.delete(\"/users/{id}\")\nasync def delete_user(id: int, user: UserModel = Depends(get_current_user)):\n    # Any authenticated user can delete any user!\n    await delete_user_logic(id)\n</code></pre> <p>Solution:</p> <pre><code># \u2705 SAFE - Permission check\n@router.delete(\n    \"/users/{id}\",\n    dependencies=[Depends(require_roles(\"delete-user\", \"admin\"))]\n)\nasync def delete_user(id: int, user: UserModel = Depends(get_current_user)):\n    # Only users with required roles can delete\n    await delete_user_logic(id)\n</code></pre>"},{"location":"guides/security-best-practices/#6-security-misconfiguration","title":"6. Security Misconfiguration","text":"<p>Problem:</p> <pre><code># \u274c VULNERABLE - Production settings\nENV = \"development\"  # Debug mode in production!\nALLOWED_HOSTS = [\"*\"]  # Any host accepted\nALLOWED_WS_ORIGINS = [\"*\"]  # No CSRF protection\nRATE_LIMIT_ENABLED = False  # No rate limiting\n</code></pre> <p>Solution:</p> <pre><code># \u2705 SAFE - Production settings\nENV = \"production\"\nALLOWED_HOSTS = [\"api.example.com\"]\nALLOWED_WS_ORIGINS = [\"https://app.example.com\"]\nRATE_LIMIT_ENABLED = True\n</code></pre>"},{"location":"guides/security-best-practices/#7-injection-attacks","title":"7. Injection Attacks","text":"<p>Problem:</p> <pre><code># \u274c VULNERABLE - Command injection\nimport os\n\n@router.get(\"/ping\")\nasync def ping(host: str):\n    result = os.system(f\"ping -c 1 {host}\")\n    # Attacker: host = \"example.com; rm -rf /\"\n</code></pre> <p>Solution:</p> <pre><code># \u2705 SAFE - Input validation + whitelist\nimport subprocess\n\n@router.get(\"/ping\")\nasync def ping(host: str = Field(pattern=r'^[a-zA-Z0-9.-]+$')):\n    # Validate hostname format\n    if not is_valid_hostname(host):\n        raise HTTPException(400, \"Invalid hostname\")\n\n    # Use subprocess with argument list (not shell)\n    result = subprocess.run(\n        [\"ping\", \"-c\", \"1\", host],\n        capture_output=True,\n        timeout=5\n    )\n    return {\"output\": result.stdout.decode()}\n</code></pre>"},{"location":"guides/security-best-practices/#8-insecure-deserialization","title":"8. Insecure Deserialization","text":"<p>Problem:</p> <pre><code># \u274c VULNERABLE - pickle deserialization\nimport pickle\n\n@router.post(\"/data\")\nasync def process_data(data: bytes):\n    obj = pickle.loads(data)  # Attacker can execute arbitrary code!\n</code></pre> <p>Solution:</p> <pre><code># \u2705 SAFE - Pydantic validation\n@router.post(\"/data\")\nasync def process_data(data: MyDataModel):\n    # Pydantic validates and deserializes safely\n    return process_logic(data)\n</code></pre>"},{"location":"guides/security-best-practices/#9-insufficient-logging","title":"9. Insufficient Logging","text":"<p>Problem:</p> <pre><code># \u274c BAD - No logging\n@router.post(\"/admin/delete-all\")\nasync def delete_all_data():\n    await delete_everything()\n    # No audit trail! Who did this?\n</code></pre> <p>Solution:</p> <pre><code># \u2705 GOOD - Comprehensive logging\n@router.post(\"/admin/delete-all\")\nasync def delete_all_data(user: UserModel = Depends(get_current_user)):\n    logger.warning(\n        f\"Delete all data requested by {user.username} ({user.user_id})\"\n    )\n    await log_user_action(\n        user_id=user.user_id,\n        username=user.username,\n        action_type=\"DELETE_ALL\",\n        outcome=\"success\"\n    )\n    await delete_everything()\n</code></pre>"},{"location":"guides/security-best-practices/#10-using-components-with-known-vulnerabilities","title":"10. Using Components with Known Vulnerabilities","text":"<p>Problem:</p> <pre><code># \u274c BAD - Outdated dependencies\nfastapi==0.68.0  # Contains known CVE\nrequests==2.25.0  # Vulnerable version\n</code></pre> <p>Solution:</p> <pre><code># \u2705 GOOD - Regular updates\nuv sync  # Update dependencies\nmake skjold-scan  # Check for vulnerabilities\nmake outdated-pkgs-scan  # Check for outdated packages\n\n# Enable Dependabot for automatic PRs\n</code></pre>"},{"location":"guides/security-best-practices/#security-testing","title":"Security Testing","text":""},{"location":"guides/security-best-practices/#automated-security-scanning","title":"Automated Security Scanning","text":"<p>1. Static Application Security Testing (SAST):</p> <pre><code># Bandit - Python security scanner\nmake bandit-scan\n# Or: uvx bandit -r app/ -ll -confidence-level=low\n\n# Scans for:\n# - SQL injection vulnerabilities\n# - Command injection\n# - Hardcoded passwords\n# - Insecure cryptography\n# - Path traversal\n</code></pre> <p>2. Dependency Vulnerability Scanning:</p> <pre><code># Skjold - Dependency vulnerability scanner\nmake skjold-scan\n# Or: uvx skjold audit\n\n# Checks against:\n# - GitHub Advisory Database\n# - PyPA Advisory Database\n# - Known CVEs\n</code></pre> <p>3. Outdated Package Detection:</p> <pre><code># Check for outdated packages\nmake outdated-pkgs-scan\n# Or: uv pip list --outdated\n</code></pre>"},{"location":"guides/security-best-practices/#manual-security-testing","title":"Manual Security Testing","text":"<p>1. Test Authentication:</p> <pre><code># Test missing token\ncurl -X GET http://localhost:8000/api/protected\n# Expected: 401 Unauthorized\n\n# Test invalid token\ncurl -H \"Authorization: Bearer invalid_token\" \\\n    http://localhost:8000/api/protected\n# Expected: 401 Unauthorized\n\n# Test expired token\ncurl -H \"Authorization: Bearer &lt;expired_token&gt;\" \\\n    http://localhost:8000/api/protected\n# Expected: 401 Unauthorized\n</code></pre> <p>2. Test Authorization (RBAC):</p> <pre><code># Test insufficient permissions\ncurl -H \"Authorization: Bearer &lt;user_token&gt;\" \\\n    -X DELETE http://localhost:8000/api/authors/1\n# Expected: 403 Forbidden (if user lacks delete-author role)\n\n# Test with admin role\ncurl -H \"Authorization: Bearer &lt;admin_token&gt;\" \\\n    -X DELETE http://localhost:8000/api/authors/1\n# Expected: 200 OK\n</code></pre> <p>3. Test Rate Limiting:</p> <pre><code># Rapid requests\nfor i in {1..100}; do\n    curl http://localhost:8000/api/endpoint\ndone\n# Expected: 429 Too Many Requests after limit exceeded\n</code></pre> <p>4. Test Input Validation:</p> <pre><code># SQL injection attempt\ncurl -X POST http://localhost:8000/api/users \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"username\": \"admin; DROP TABLE users;--\"}'\n# Expected: 422 Unprocessable Entity (validation error)\n\n# XSS attempt\ncurl -X POST http://localhost:8000/api/comments \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"text\": \"&lt;script&gt;alert(1)&lt;/script&gt;\"}'\n# Expected: 422 (if pattern validation) or sanitized on output\n</code></pre> <p>5. Test Security Headers:</p> <pre><code># Check security headers\ncurl -I http://localhost:8000/\n\n# Verify presence of:\n# - X-Frame-Options: DENY\n# - X-Content-Type-Options: nosniff\n# - Content-Security-Policy: ...\n# - Strict-Transport-Security: ...\n</code></pre> <p>6. Test WebSocket Security:</p> <pre><code># Test origin validation (requires custom script)\n# Connect with Origin: https://evil.com\n# Expected: Connection closed with WS_1008_POLICY_VIOLATION\n</code></pre>"},{"location":"guides/security-best-practices/#security-header-scanners","title":"Security Header Scanners","text":"<pre><code># Online scanners\nhttps://securityheaders.com/?q=https://your-api.com\nhttps://observatory.mozilla.org/analyze/your-api.com\n\n# Expected Grade: A or A+\n</code></pre>"},{"location":"guides/security-best-practices/#penetration-testing","title":"Penetration Testing","text":"<p>Recommended Tools:</p> <ol> <li>OWASP ZAP - Automated web app scanner</li> <li>Burp Suite - Manual penetration testing</li> <li>sqlmap - SQL injection testing</li> <li>Nmap - Port scanning and service detection</li> </ol> <p>Penetration Testing Checklist:</p> <ul> <li> Authentication bypass attempts</li> <li> Authorization bypass (access other users' data)</li> <li> SQL injection in all input fields</li> <li> XSS in user-generated content</li> <li> CSRF token validation</li> <li> File upload vulnerabilities</li> <li> Directory traversal</li> <li> API rate limiting enforcement</li> <li> Session fixation/hijacking</li> <li> Brute force protection</li> </ul> <p>Example with OWASP ZAP:</p> <pre><code># Docker container\ndocker run -t owasp/zap2docker-stable zap-baseline.py \\\n    -t http://your-api.com\n\n# Full scan\ndocker run -t owasp/zap2docker-stable zap-full-scan.py \\\n    -t http://your-api.com\n</code></pre>"},{"location":"guides/security-best-practices/#troubleshooting_1","title":"Troubleshooting","text":""},{"location":"guides/security-best-practices/#authentication-issues","title":"Authentication Issues","text":"<p>Problem: Token validation failing</p> <pre><code>AuthenticationError: token_decode_error\n</code></pre> <p>Diagnosis:</p> <pre><code># Check Keycloak is reachable\ncurl http://keycloak:8080/health\n\n# Check circuit breaker state\ncurl http://localhost:9090/api/v1/query?query=circuit_breaker_state{service=\"keycloak\"}\n\n# Check token cache\nredis-cli\n&gt; KEYS token:claims:*\n&gt; TTL token:claims:&lt;hash&gt;\n</code></pre> <p>Solutions:</p> <ol> <li>Verify Keycloak is running and healthy</li> <li>Check token hasn't expired (decode JWT at jwt.io)</li> <li>Verify Keycloak client settings match configuration</li> <li>Check Redis is available (token cache)</li> <li>Review circuit breaker configuration</li> </ol> <p>Problem: CORS errors in browser</p> <pre><code>Access to fetch at 'http://api.example.com' from origin 'http://localhost:3000' has been blocked by CORS policy\n</code></pre> <p>Solution:</p> <pre><code># app/__init__.py\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\"],  # Frontend origin\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n</code></pre>"},{"location":"guides/security-best-practices/#rate-limiting-issues","title":"Rate Limiting Issues","text":"<p>Problem: Legitimate users being rate limited</p> <p>Diagnosis:</p> <pre><code># Check rate limit hit rate\nrate(rate_limit_hits_total[5m])\n\n# Check per-user rate limits\n# (requires custom logging)\n</code></pre> <p>Solutions:</p> <ol> <li>Increase rate limits: <code>RATE_LIMIT_PER_MINUTE = 120</code></li> <li>Add burst allowance: <code>RATE_LIMIT_BURST = 30</code></li> <li>Whitelist specific IPs/users (custom implementation)</li> <li>Implement tiered rate limits based on user roles</li> </ol> <p>Problem: Rate limiting not working (Redis down)</p> <p>Diagnosis:</p> <pre><code># Check Redis connection\nredis-cli PING\n\n# Check circuit breaker\ncurl http://localhost:9090/api/v1/query?query=circuit_breaker_state{service=\"redis\"}\n</code></pre> <p>Solutions:</p> <ol> <li>Fix Redis connection</li> <li>Check circuit breaker timeout</li> <li>Verify <code>RATE_LIMIT_FAIL_MODE</code> setting (fail-open vs fail-closed)</li> </ol>"},{"location":"guides/security-best-practices/#websocket-issues","title":"WebSocket Issues","text":"<p>Problem: WebSocket connections being rejected</p> <pre><code>WebSocket close code: 1008 (Policy Violation)\n</code></pre> <p>Diagnosis:</p> <pre><code># Check connection rejections by reason\ncurl http://localhost:9090/api/v1/query?query=ws_connections_total{status=\"rejected_auth\"}\ncurl http://localhost:9090/api/v1/query?query=ws_connections_total{status=\"rejected_limit\"}\n</code></pre> <p>Solutions:</p> <ol> <li>Authentication: Verify token is valid and not expired</li> <li>Origin: Check Origin header matches <code>ALLOWED_WS_ORIGINS</code></li> <li>Connection limit: Increase <code>WS_MAX_CONNECTIONS_PER_USER</code></li> <li>Message rate limit: Increase <code>WS_MESSAGE_RATE_LIMIT</code></li> </ol> <p>Problem: CSP blocking WebSocket connections</p> <pre><code>Refused to connect to 'ws://localhost:8000/web' because it violates the following Content Security Policy directive: \"connect-src 'self'\"\n</code></pre> <p>Solution:</p> <pre><code># app/middlewares/security_headers.py\n# Ensure connect-src includes ws: and wss:\n\"connect-src 'self' ws: wss:\",\n</code></pre>"},{"location":"guides/security-best-practices/#audit-log-issues","title":"Audit Log Issues","text":"<p>Problem: Audit logs being dropped</p> <p>Diagnosis:</p> <pre><code># Check drop rate\nrate(audit_logs_dropped_total[5m])\n\n# Check queue size\naudit_queue_size\n</code></pre> <p>Solutions:</p> <ol> <li>Increase queue size: <code>AUDIT_QUEUE_MAX_SIZE = 20000</code></li> <li>Increase batch size: <code>AUDIT_BATCH_SIZE = 200</code></li> <li>Optimize database (indexes, connection pool)</li> <li>Scale horizontally (more app instances)</li> </ol> <p>Problem: Slow audit log writes</p> <p>Diagnosis:</p> <pre><code># Check write duration\naudit_log_creation_duration_seconds\n\n# Check batch size\naudit_batch_size\n</code></pre> <p>Solutions:</p> <pre><code>-- Add database indexes\nCREATE INDEX idx_user_actions_timestamp ON user_actions(timestamp);\nCREATE INDEX idx_user_actions_username ON user_actions(username);\nCREATE INDEX idx_user_actions_user_id ON user_actions(user_id);\n\n-- Partition table by time (for very large tables)\n-- (requires migration script)\n</code></pre>"},{"location":"guides/security-best-practices/#related-documentation","title":"Related Documentation","text":"<ul> <li>Authentication Guide - Keycloak setup and configuration</li> <li>WebSocket Protocol - WebSocket message format and usage</li> <li>Monitoring Guide - Prometheus, Grafana, alerts</li> <li>Testing Guide - Security testing patterns</li> </ul>"},{"location":"guides/security-best-practices/#additional-resources","title":"Additional Resources","text":"<p>OWASP Resources: - OWASP Top 10 - OWASP API Security Top 10 - OWASP Cheat Sheet Series</p> <p>Security Tools: - Bandit - Python security scanner - Skjold - Dependency vulnerability scanner - OWASP ZAP - Web application scanner</p> <p>FastAPI Security: - FastAPI Security Documentation - FastAPI CORS Documentation</p> <p>Compliance: - GDPR Compliance Checklist - HIPAA Security Rule - SOX IT Controls</p>"},{"location":"guides/websocket-handlers/","title":"Creating WebSocket Handlers","text":""},{"location":"guides/websocket-handlers/#overview","title":"Overview","text":"<p>This guide shows how to create new WebSocket handlers using the package-based routing system with proper authentication and authorization.</p>"},{"location":"guides/websocket-handlers/#quick-start","title":"Quick Start","text":""},{"location":"guides/websocket-handlers/#1-add-package-id","title":"1. Add Package ID","text":"<pre><code># app/api/ws/constants.py\nclass PkgID(IntEnum):\n    GET_AUTHORS = 1\n    GET_PAGINATED_AUTHORS = 2\n    CREATE_BOOK = 3  # Add new PkgID\n</code></pre>"},{"location":"guides/websocket-handlers/#2-create-handler","title":"2. Create Handler","text":"<pre><code># app/api/ws/handlers/book_handlers.py\nfrom app.api.ws.constants import PkgID, RSPCode\nfrom app.commands.book_commands import CreateBookCommand, CreateBookInput\nfrom app.repositories.book_repository import BookRepository\nfrom app.routing import pkg_router\nfrom app.schemas.request import RequestModel\nfrom app.schemas.response import ResponseModel\nfrom app.storage.db import async_session\n\n@pkg_router.register(\n    PkgID.CREATE_BOOK,\n    roles=[\"create-book\"]  # Required role\n)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Create a new book via WebSocket.\"\"\"\n    try:\n        async with async_session() as session:\n            async with session.begin():\n                repo = BookRepository(session)\n                command = CreateBookCommand(repo)\n                input_data = CreateBookInput(**request.data)\n                book = await command.execute(input_data)\n\n                return ResponseModel.success(\n                    pkg_id=request.pkg_id,\n                    req_id=request.req_id,\n                    data=book.model_dump()\n                )\n    except ValueError as e:\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=str(e),\n            status_code=RSPCode.INVALID_DATA\n        )\n    except Exception as e:\n        logger.error(f\"Handler error: {e}\", exc_info=True)\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=\"Internal error\",\n            status_code=RSPCode.ERROR\n        )\n</code></pre>"},{"location":"guides/websocket-handlers/#3-verify-registration","title":"3. Verify Registration","text":"<pre><code>make ws-handlers\n</code></pre>"},{"location":"guides/websocket-handlers/#handler-registration","title":"Handler Registration","text":""},{"location":"guides/websocket-handlers/#basic-handler","title":"Basic Handler","text":"<pre><code>@pkg_router.register(PkgID.GET_BOOKS)\nasync def get_books_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Public handler (no authentication required).\"\"\"\n    async with async_session() as session:\n        repo = BookRepository(session)\n        books = await repo.get_all()\n        return ResponseModel.success(\n            request.pkg_id,\n            request.req_id,\n            data=[b.model_dump() for b in books]\n        )\n</code></pre>"},{"location":"guides/websocket-handlers/#handler-with-rbac","title":"Handler with RBAC","text":"<pre><code>@pkg_router.register(\n    PkgID.DELETE_BOOK,\n    roles=[\"delete-book\", \"admin\"]  # Requires BOTH roles\n)\nasync def delete_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Protected handler - requires 'delete-book' AND 'admin' roles.\"\"\"\n    # Handler logic\n    pass\n</code></pre>"},{"location":"guides/websocket-handlers/#handler-with-json-schema-validation","title":"Handler with JSON Schema Validation","text":"<pre><code>from pydantic import BaseModel\n\nclass CreateBookSchema(BaseModel):\n    title: str\n    author_id: int\n\n@pkg_router.register(\n    PkgID.CREATE_BOOK,\n    json_schema=CreateBookSchema,\n    roles=[\"create-book\"]\n)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Handler with automatic schema validation.\"\"\"\n    # request.data is already validated against CreateBookSchema\n    pass\n</code></pre>"},{"location":"guides/websocket-handlers/#request-handling","title":"Request Handling","text":""},{"location":"guides/websocket-handlers/#accessing-request-data","title":"Accessing Request Data","text":"<pre><code>async def handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Access request data.\"\"\"\n    pkg_id = request.pkg_id  # Package ID\n    req_id = request.req_id  # Request UUID\n    data = request.data     # Request payload (dict)\n\n    # Extract specific fields\n    book_id = data.get(\"id\")\n    filters = data.get(\"filters\", {})\n</code></pre>"},{"location":"guides/websocket-handlers/#using-commands","title":"Using Commands","text":"<p>Reuse business logic from HTTP endpoints:</p> <pre><code>@pkg_router.register(PkgID.CREATE_BOOK)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"Handler using command pattern.\"\"\"\n    async with async_session() as session:\n        async with session.begin():\n            repo = BookRepository(session)\n            command = CreateBookCommand(repo)  # Same command as HTTP!\n            input_data = CreateBookInput(**request.data)\n            book = await command.execute(input_data)\n\n            return ResponseModel.success(\n                request.pkg_id,\n                request.req_id,\n                data=book.model_dump()\n            )\n</code></pre>"},{"location":"guides/websocket-handlers/#response-handling","title":"Response Handling","text":""},{"location":"guides/websocket-handlers/#success-response","title":"Success Response","text":"<pre><code>return ResponseModel.success(\n    pkg_id=request.pkg_id,\n    req_id=request.req_id,\n    data=[{\"id\": 1, \"title\": \"Book\"}]\n)\n</code></pre>"},{"location":"guides/websocket-handlers/#error-response","title":"Error Response","text":"<pre><code>return ResponseModel.err_msg(\n    pkg_id=request.pkg_id,\n    req_id=request.req_id,\n    msg=\"Book not found\",\n    status_code=RSPCode.ERROR\n)\n</code></pre>"},{"location":"guides/websocket-handlers/#paginated-response","title":"Paginated Response","text":"<pre><code>from app.storage.db import get_paginated_results\n\nresults, meta = await get_paginated_results(\n    Book,\n    page=request.data.get(\"page\", 1),\n    per_page=request.data.get(\"per_page\", 20)\n)\n\nreturn ResponseModel.success(\n    request.pkg_id,\n    request.req_id,\n    data=[r.model_dump() for r in results],\n    meta=meta\n)\n</code></pre>"},{"location":"guides/websocket-handlers/#error-handling","title":"Error Handling","text":""},{"location":"guides/websocket-handlers/#database-errors","title":"Database Errors","text":"<pre><code>from sqlalchemy.exc import IntegrityError\n\ntry:\n    book = await repo.create(book)\nexcept IntegrityError:\n    return ResponseModel.err_msg(\n        request.pkg_id,\n        request.req_id,\n        msg=\"Book already exists\",\n        status_code=RSPCode.INVALID_DATA\n    )\n</code></pre>"},{"location":"guides/websocket-handlers/#validation-errors","title":"Validation Errors","text":"<pre><code>from pydantic import ValidationError\n\ntry:\n    input_data = CreateBookInput(**request.data)\nexcept ValidationError as e:\n    return ResponseModel.err_msg(\n        request.pkg_id,\n        request.req_id,\n        msg=str(e),\n        status_code=RSPCode.INVALID_DATA\n    )\n</code></pre>"},{"location":"guides/websocket-handlers/#complete-example-book-websocket-handler","title":"Complete Example: Book WebSocket Handler","text":"<p>Here's a complete example combining all concepts:</p> <pre><code># app/api/ws/handlers/book_handlers.py\nfrom pydantic import BaseModel, Field\nfrom app.api.ws.constants import PkgID, RSPCode\nfrom app.commands.book_commands import (\n    CreateBookCommand,\n    UpdateBookCommand,\n    DeleteBookCommand,\n)\nfrom app.logging import logger\nfrom app.managers.websocket_connection_manager import connection_manager\nfrom app.models.book import Book\nfrom app.repositories.book_repository import BookRepository\nfrom app.routing import pkg_router\nfrom app.schemas.request import RequestModel\nfrom app.schemas.response import ResponseModel\nfrom app.storage.db import async_session, get_paginated_results\nfrom app.utils.pagination_cache import invalidate_count_cache\n\n\nclass CreateBookSchema(BaseModel):\n    \"\"\"Schema for creating a book via WebSocket.\"\"\"\n    title: str = Field(..., min_length=1, max_length=200)\n    author_id: int = Field(..., gt=0)\n    isbn: str | None = Field(None, pattern=r\"^978-\\d{10}$\")\n\n\nclass UpdateBookSchema(BaseModel):\n    \"\"\"Schema for updating a book via WebSocket.\"\"\"\n    id: int = Field(..., gt=0)\n    title: str | None = Field(None, min_length=1, max_length=200)\n    author_id: int | None = Field(None, gt=0)\n    isbn: str | None = Field(None, pattern=r\"^978-\\d{10}$\")\n\n\n@pkg_router.register(\n    PkgID.CREATE_BOOK,\n    json_schema=CreateBookSchema,\n    roles=[\"create-book\"]\n)\nasync def create_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"\n    Create a new book via WebSocket.\n\n    Requires 'create-book' role.\n\n    Request Data:\n        {\n            \"title\": \"The Pragmatic Programmer\",\n            \"author_id\": 1,\n            \"isbn\": \"978-0135957059\"\n        }\n\n    Response:\n        {\n            \"pkg_id\": 3,\n            \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n            \"status_code\": 0,\n            \"data\": {\n                \"id\": 123,\n                \"title\": \"The Pragmatic Programmer\",\n                \"author_id\": 1,\n                \"isbn\": \"978-0135957059\",\n                \"created_at\": \"2025-01-29T10:30:00Z\"\n            }\n        }\n\n    Error Codes:\n        1 (INVALID_DATA): Invalid book data\n        2 (ERROR): Internal server error\n    \"\"\"\n    try:\n        async with async_session() as session:\n            async with session.begin():\n                repo = BookRepository(session)\n                command = CreateBookCommand(repo)\n\n                # request.data is already validated against CreateBookSchema\n                input_data = CreateBookSchema(**request.data)\n                book = await command.execute(input_data)\n\n                # Invalidate pagination cache\n                await invalidate_count_cache(\"Book\")\n\n                logger.info(\n                    f\"Book created via WebSocket: {book.title}\",\n                    extra={\"book_id\": book.id, \"pkg_id\": request.pkg_id}\n                )\n\n                # Broadcast to all connected clients\n                await connection_manager.broadcast({\n                    \"pkg_id\": PkgID.BOOK_CREATED,\n                    \"req_id\": \"00000000-0000-0000-0000-000000000000\",\n                    \"data\": {\n                        \"id\": book.id,\n                        \"title\": book.title,\n                        \"action\": \"created\"\n                    }\n                })\n\n                return ResponseModel.success(\n                    pkg_id=request.pkg_id,\n                    req_id=request.req_id,\n                    data=book.model_dump()\n                )\n\n    except ValueError as e:\n        logger.warning(f\"Invalid book data: {e}\")\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=str(e),\n            status_code=RSPCode.INVALID_DATA\n        )\n    except Exception as e:\n        logger.error(f\"Handler error: {e}\", exc_info=True)\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=\"Failed to create book\",\n            status_code=RSPCode.ERROR\n        )\n\n\n@pkg_router.register(\n    PkgID.GET_BOOKS,\n    roles=[\"view-books\"]\n)\nasync def get_books_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"\n    Get all books with optional filters and pagination.\n\n    Requires 'view-books' role.\n\n    Request Data:\n        {\n            \"page\": 1,\n            \"per_page\": 20,\n            \"filters\": {\n                \"author_id\": 1\n            }\n        }\n\n    Response:\n        {\n            \"pkg_id\": 4,\n            \"req_id\": \"...\",\n            \"status_code\": 0,\n            \"data\": [\n                {\"id\": 1, \"title\": \"Book 1\", ...},\n                {\"id\": 2, \"title\": \"Book 2\", ...}\n            ],\n            \"meta\": {\n                \"page\": 1,\n                \"per_page\": 20,\n                \"total\": 45,\n                \"pages\": 3\n            }\n        }\n    \"\"\"\n    try:\n        async with async_session() as session:\n            repo = BookRepository(session)\n\n            # Extract pagination parameters\n            page = request.data.get(\"page\", 1)\n            per_page = request.data.get(\"per_page\", 20)\n            filters = request.data.get(\"filters\", {})\n\n            # Get paginated results\n            results, meta = await get_paginated_results(\n                Book,\n                page=page,\n                per_page=per_page,\n                filters=filters,\n                eager_load=[\"author\"]  # Prevent N+1 queries\n            )\n\n            logger.debug(\n                f\"Retrieved {len(results)} books\",\n                extra={\"page\": page, \"total\": meta.total}\n            )\n\n            return ResponseModel.success(\n                pkg_id=request.pkg_id,\n                req_id=request.req_id,\n                data=[book.model_dump() for book in results],\n                meta=meta\n            )\n\n    except ValueError as e:\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=f\"Invalid pagination parameters: {str(e)}\",\n            status_code=RSPCode.INVALID_DATA\n        )\n    except Exception as e:\n        logger.error(f\"Failed to get books: {e}\", exc_info=True)\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=\"Failed to retrieve books\",\n            status_code=RSPCode.ERROR\n        )\n\n\n@pkg_router.register(\n    PkgID.UPDATE_BOOK,\n    json_schema=UpdateBookSchema,\n    roles=[\"update-book\"]\n)\nasync def update_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"\n    Update book by ID.\n\n    Requires 'update-book' role.\n\n    Request Data:\n        {\n            \"id\": 123,\n            \"title\": \"Updated Title\",\n            \"isbn\": \"978-0135957059\"\n        }\n\n    Only provided fields are updated (partial update).\n    \"\"\"\n    try:\n        async with async_session() as session:\n            async with session.begin():\n                repo = BookRepository(session)\n                command = UpdateBookCommand(repo)\n\n                book_id = request.data[\"id\"]\n                update_data = UpdateBookSchema(**request.data)\n\n                # Check if book exists\n                existing_book = await repo.get_by_id(book_id)\n                if not existing_book:\n                    return ResponseModel.err_msg(\n                        pkg_id=request.pkg_id,\n                        req_id=request.req_id,\n                        msg=f\"Book with ID {book_id} not found\",\n                        status_code=RSPCode.ERROR\n                    )\n\n                updated_book = await command.execute(book_id, update_data)\n\n                logger.info(\n                    f\"Book updated: {updated_book.title}\",\n                    extra={\"book_id\": book_id}\n                )\n\n                # Broadcast update to all clients\n                await connection_manager.broadcast({\n                    \"pkg_id\": PkgID.BOOK_UPDATED,\n                    \"req_id\": \"00000000-0000-0000-0000-000000000000\",\n                    \"data\": {\n                        \"id\": updated_book.id,\n                        \"title\": updated_book.title,\n                        \"action\": \"updated\"\n                    }\n                })\n\n                return ResponseModel.success(\n                    pkg_id=request.pkg_id,\n                    req_id=request.req_id,\n                    data=updated_book.model_dump()\n                )\n\n    except ValueError as e:\n        logger.warning(f\"Invalid update data: {e}\")\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=str(e),\n            status_code=RSPCode.INVALID_DATA\n        )\n    except Exception as e:\n        logger.error(f\"Failed to update book: {e}\", exc_info=True)\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=\"Failed to update book\",\n            status_code=RSPCode.ERROR\n        )\n\n\n@pkg_router.register(\n    PkgID.DELETE_BOOK,\n    roles=[\"delete-book\", \"admin\"]\n)\nasync def delete_book_handler(request: RequestModel) -&gt; ResponseModel:\n    \"\"\"\n    Delete book by ID.\n\n    Requires BOTH 'delete-book' AND 'admin' roles.\n\n    Request Data:\n        {\n            \"id\": 123\n        }\n\n    Response:\n        {\n            \"pkg_id\": 6,\n            \"req_id\": \"...\",\n            \"status_code\": 0,\n            \"data\": {\n                \"message\": \"Book deleted successfully\"\n            }\n        }\n    \"\"\"\n    try:\n        async with async_session() as session:\n            async with session.begin():\n                repo = BookRepository(session)\n                command = DeleteBookCommand(repo)\n\n                book_id = request.data.get(\"id\")\n                if not book_id:\n                    return ResponseModel.err_msg(\n                        pkg_id=request.pkg_id,\n                        req_id=request.req_id,\n                        msg=\"Missing 'id' field\",\n                        status_code=RSPCode.INVALID_DATA\n                    )\n\n                # Check if book exists\n                book = await repo.get_by_id(book_id)\n                if not book:\n                    return ResponseModel.err_msg(\n                        pkg_id=request.pkg_id,\n                        req_id=request.req_id,\n                        msg=f\"Book with ID {book_id} not found\",\n                        status_code=RSPCode.ERROR\n                    )\n\n                await command.execute(book_id)\n\n                # Invalidate pagination cache\n                await invalidate_count_cache(\"Book\")\n\n                logger.info(\n                    f\"Book deleted: {book.title}\",\n                    extra={\"book_id\": book_id}\n                )\n\n                # Broadcast deletion to all clients\n                await connection_manager.broadcast({\n                    \"pkg_id\": PkgID.BOOK_DELETED,\n                    \"req_id\": \"00000000-0000-0000-0000-000000000000\",\n                    \"data\": {\n                        \"id\": book_id,\n                        \"action\": \"deleted\"\n                    }\n                })\n\n                return ResponseModel.success(\n                    pkg_id=request.pkg_id,\n                    req_id=request.req_id,\n                    data={\"message\": \"Book deleted successfully\"}\n                )\n\n    except Exception as e:\n        logger.error(f\"Failed to delete book: {e}\", exc_info=True)\n        return ResponseModel.err_msg(\n            pkg_id=request.pkg_id,\n            req_id=request.req_id,\n            msg=\"Failed to delete book\",\n            status_code=RSPCode.ERROR\n        )\n</code></pre>"},{"location":"guides/websocket-handlers/#testing","title":"Testing","text":""},{"location":"guides/websocket-handlers/#basic-test","title":"Basic Test","text":"<pre><code>import pytest\nfrom unittest.mock import AsyncMock\n\n@pytest.mark.asyncio\nasync def test_create_book_handler():\n    \"\"\"Test WebSocket handler.\"\"\"\n    # Mock repository\n    mock_repo = AsyncMock()\n    mock_repo.create.return_value = Book(id=1, title=\"Test\")\n\n    # Create request\n    request = RequestModel(\n        pkg_id=PkgID.CREATE_BOOK,\n        req_id=\"test-uuid\",\n        data={\"title\": \"Test\", \"author_id\": 1}\n    )\n\n    # Call handler\n    response = await create_book_handler(request)\n\n    # Verify response\n    assert response.status_code == RSPCode.OK\n    assert response.data[\"title\"] == \"Test\"\n</code></pre>"},{"location":"guides/websocket-handlers/#complete-test-suite","title":"Complete Test Suite","text":"<pre><code>import pytest\nfrom unittest.mock import AsyncMock, patch\nfrom app.api.ws.constants import PkgID, RSPCode\nfrom app.models.book import Book\nfrom app.repositories.book_repository import BookRepository\nfrom app.schemas.request import RequestModel\nfrom tests.conftest import create_request_model_fixture\n\n\n@pytest.fixture\ndef mock_book_repo():\n    \"\"\"Mock book repository for testing.\"\"\"\n    repo = AsyncMock(spec=BookRepository)\n    repo.get_by_id.return_value = Book(\n        id=1,\n        title=\"Test Book\",\n        author_id=1,\n        isbn=\"978-0135957059\"\n    )\n    repo.create.return_value = Book(\n        id=1,\n        title=\"New Book\",\n        author_id=1\n    )\n    return repo\n\n\nclass TestBookHandlers:\n    \"\"\"Test suite for book WebSocket handlers.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_create_book_success(self, mock_book_repo):\n        \"\"\"Test successful book creation.\"\"\"\n        request = create_request_model_fixture(\n            pkg_id=PkgID.CREATE_BOOK,\n            data={\n                \"title\": \"The Pragmatic Programmer\",\n                \"author_id\": 1,\n                \"isbn\": \"978-0135957059\"\n            }\n        )\n\n        with patch(\"app.api.ws.handlers.book_handlers.BookRepository\",\n                   return_value=mock_book_repo):\n            response = await create_book_handler(request)\n\n            assert response.status_code == RSPCode.OK\n            assert response.pkg_id == PkgID.CREATE_BOOK\n            assert response.req_id == request.req_id\n            assert \"id\" in response.data\n            mock_book_repo.create.assert_called_once()\n\n    @pytest.mark.asyncio\n    async def test_create_book_invalid_data(self):\n        \"\"\"Test book creation with invalid data.\"\"\"\n        request = create_request_model_fixture(\n            pkg_id=PkgID.CREATE_BOOK,\n            data={\"author_id\": 1}  # Missing 'title'\n        )\n\n        response = await create_book_handler(request)\n\n        assert response.status_code == RSPCode.INVALID_DATA\n        assert \"title\" in response.data[\"msg\"].lower()\n\n    @pytest.mark.asyncio\n    async def test_get_books_with_pagination(self, mock_book_repo):\n        \"\"\"Test getting books with pagination.\"\"\"\n        mock_book_repo.get_all.return_value = [\n            Book(id=1, title=\"Book 1\", author_id=1),\n            Book(id=2, title=\"Book 2\", author_id=1),\n        ]\n\n        request = create_request_model_fixture(\n            pkg_id=PkgID.GET_BOOKS,\n            data={\n                \"page\": 1,\n                \"per_page\": 10,\n                \"filters\": {\"author_id\": 1}\n            }\n        )\n\n        with patch(\"app.api.ws.handlers.book_handlers.get_paginated_results\") as mock_paginate:\n            mock_meta = MetadataModel(page=1, per_page=10, total=2, pages=1)\n            mock_paginate.return_value = (mock_book_repo.get_all.return_value, mock_meta)\n\n            response = await get_books_handler(request)\n\n            assert response.status_code == RSPCode.OK\n            assert len(response.data) == 2\n            assert response.meta.page == 1\n            assert response.meta.total == 2\n\n    @pytest.mark.asyncio\n    async def test_update_book_not_found(self, mock_book_repo):\n        \"\"\"Test updating non-existent book.\"\"\"\n        mock_book_repo.get_by_id.return_value = None\n\n        request = create_request_model_fixture(\n            pkg_id=PkgID.UPDATE_BOOK,\n            data={\n                \"id\": 999,\n                \"title\": \"Updated Title\"\n            }\n        )\n\n        with patch(\"app.api.ws.handlers.book_handlers.BookRepository\",\n                   return_value=mock_book_repo):\n            response = await update_book_handler(request)\n\n            assert response.status_code == RSPCode.ERROR\n            assert \"not found\" in response.data[\"msg\"].lower()\n\n    @pytest.mark.asyncio\n    async def test_delete_book_success(self, mock_book_repo):\n        \"\"\"Test successful book deletion.\"\"\"\n        request = create_request_model_fixture(\n            pkg_id=PkgID.DELETE_BOOK,\n            data={\"id\": 1}\n        )\n\n        with patch(\"app.api.ws.handlers.book_handlers.BookRepository\",\n                   return_value=mock_book_repo):\n            response = await delete_book_handler(request)\n\n            assert response.status_code == RSPCode.OK\n            assert \"deleted successfully\" in response.data[\"message\"]\n            mock_book_repo.delete.assert_called_once()\n\n    @pytest.mark.asyncio\n    async def test_delete_book_missing_id(self):\n        \"\"\"Test deletion without book ID.\"\"\"\n        request = create_request_model_fixture(\n            pkg_id=PkgID.DELETE_BOOK,\n            data={}  # Missing 'id'\n        )\n\n        response = await delete_book_handler(request)\n\n        assert response.status_code == RSPCode.INVALID_DATA\n        assert \"missing 'id'\" in response.data[\"msg\"].lower()\n\n    @pytest.mark.asyncio\n    async def test_handler_broadcasts_on_create(self, mock_book_repo):\n        \"\"\"Test that handler broadcasts to all clients on create.\"\"\"\n        request = create_request_model_fixture(\n            pkg_id=PkgID.CREATE_BOOK,\n            data={\"title\": \"Test\", \"author_id\": 1}\n        )\n\n        with patch(\"app.api.ws.handlers.book_handlers.connection_manager\") as mock_manager:\n            with patch(\"app.api.ws.handlers.book_handlers.BookRepository\",\n                       return_value=mock_book_repo):\n                response = await create_book_handler(request)\n\n                assert response.status_code == RSPCode.OK\n                mock_manager.broadcast.assert_called_once()\n\n                # Verify broadcast message structure\n                broadcast_call = mock_manager.broadcast.call_args[0][0]\n                assert broadcast_call[\"pkg_id\"] == PkgID.BOOK_CREATED\n                assert broadcast_call[\"data\"][\"action\"] == \"created\"\n</code></pre>"},{"location":"guides/websocket-handlers/#broadcasting","title":"Broadcasting","text":"<p>Send messages to all connected clients:</p> <pre><code>from app.managers.websocket_connection_manager import connection_manager\n\n# In handler\nawait connection_manager.broadcast({\n    \"pkg_id\": PkgID.BOOK_CREATED,\n    \"req_id\": \"00000000-0000-0000-0000-000000000000\",\n    \"data\": book.model_dump()\n})\n</code></pre>"},{"location":"guides/websocket-handlers/#generator-script","title":"Generator Script","text":"<p>Generate new handler from template:</p> <pre><code>make new-ws-handlers\n</code></pre> <p>Follow the prompts to create a new handler file.</p>"},{"location":"guides/websocket-handlers/#related","title":"Related","text":"<ul> <li>WebSocket API</li> <li>Design Patterns Guide</li> <li>HTTP Endpoints</li> <li>Testing Guide</li> </ul>"},{"location":"guides/websocket-protocol/","title":"WebSocket Protocol Specification","text":"<p>This document provides a comprehensive specification of the WebSocket API protocol for client developers implementing WebSocket clients in any programming language.</p>"},{"location":"guides/websocket-protocol/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Connection URL</li> <li>Message Format</li> <li>Status Codes (RSPCode)</li> <li>Available Package IDs (PkgID)</li> <li>Connection Lifecycle</li> <li>Authentication Flow</li> <li>Error Handling</li> <li>Rate Limiting</li> <li>Best Practices</li> </ul>"},{"location":"guides/websocket-protocol/#connection-url","title":"Connection URL","text":""},{"location":"guides/websocket-protocol/#websocket-endpoint","title":"WebSocket Endpoint","text":"<pre><code>ws://localhost:8000/web?Authorization=Bearer%20{token}&amp;format=json\n</code></pre> <p>Production (with TLS): <pre><code>wss://api.example.com/web?Authorization=Bearer%20{token}&amp;format=json\n</code></pre></p>"},{"location":"guides/websocket-protocol/#query-parameters","title":"Query Parameters","text":"Parameter Required Type Description Example <code>Authorization</code> Yes string URL-encoded Bearer token <code>Bearer%20eyJhbGc...</code> <code>format</code> No string Message format: <code>json</code> (default) or <code>protobuf</code> <code>json</code> <p>Important: The <code>Authorization</code> parameter must be URL-encoded. In JavaScript:</p> <pre><code>const token = 'eyJhbGc...';\nconst encoded = encodeURIComponent(`Bearer ${token}`);\nconst url = `ws://localhost:8000/web?Authorization=${encoded}`;\n</code></pre>"},{"location":"guides/websocket-protocol/#message-format","title":"Message Format","text":""},{"location":"guides/websocket-protocol/#json-format-default","title":"JSON Format (Default)","text":""},{"location":"guides/websocket-protocol/#request-message","title":"Request Message","text":"<p>Clients send requests in the following JSON format:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"data\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"filters\": {\"status\": \"active\"}\n  }\n}\n</code></pre> <p>Field Descriptions:</p> Field Type Required Description <code>pkg_id</code> integer Yes Package identifier (see Available Package IDs) <code>req_id</code> string (UUID) Yes Unique request identifier for correlating requests/responses <code>data</code> object Yes Request payload (schema varies by pkg_id)"},{"location":"guides/websocket-protocol/#response-message","title":"Response Message","text":"<p>Server responds with the following JSON format:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 0,\n  \"data\": [\n    {\"id\": 1, \"name\": \"John Doe\"},\n    {\"id\": 2, \"name\": \"Jane Smith\"}\n  ],\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 100,\n    \"pages\": 5,\n    \"next_cursor\": null,\n    \"has_more\": false\n  }\n}\n</code></pre> <p>Field Descriptions:</p> Field Type Required Description <code>pkg_id</code> integer Yes Same as request pkg_id <code>req_id</code> string (UUID) Yes Same as request req_id <code>status_code</code> integer Yes Response status code (see Status Codes) <code>data</code> any Yes Response payload (type varies by pkg_id) <code>meta</code> object | null No Pagination metadata (for list endpoints)"},{"location":"guides/websocket-protocol/#error-response","title":"Error Response","text":"<p>When an error occurs, the response contains error details:</p> <pre><code>{\n  \"pkg_id\": 1,\n  \"req_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"status_code\": 3,\n  \"data\": {\"error\": \"Permission denied: missing required role 'get-authors'\"},\n  \"meta\": null\n}\n</code></pre>"},{"location":"guides/websocket-protocol/#protobuf-format-optional","title":"Protobuf Format (Optional)","text":"<p>For better performance and smaller message sizes, clients can use Protocol Buffers by setting <code>format=protobuf</code> in the connection URL.</p> <p>Benefits of Protobuf: - 30-50% smaller message size - 2-5x faster serialization/deserialization - Strong typing with schema validation</p> <p>See examples/clients/websocket_protobuf_client.py for implementation.</p>"},{"location":"guides/websocket-protocol/#status-codes-rspcode","title":"Status Codes (RSPCode)","text":"<p>The server uses the following status codes to indicate request outcomes:</p> Code Name Description HTTP Equivalent 0 OK Request successful 200 OK 1 ERROR General error occurred 500 Internal Server Error 2 INVALID_DATA Invalid or malformed request data 400 Bad Request 3 PERMISSION_DENIED User lacks required permissions 403 Forbidden <p>Example error handling:</p> <pre><code>const response = await client.request(pkgId, data);\n\nif (response.status_code === 0) {\n  // Success\n  console.log('Data:', response.data);\n} else if (response.status_code === 3) {\n  // Permission denied\n  console.error('Access denied:', response.data.error);\n} else if (response.status_code === 2) {\n  // Invalid data\n  console.error('Validation error:', response.data.error);\n} else {\n  // General error\n  console.error('Server error:', response.data.error);\n}\n</code></pre>"},{"location":"guides/websocket-protocol/#available-package-ids-pkgid","title":"Available Package IDs (PkgID)","text":"<p>Package IDs identify different WebSocket handler operations. Each PkgID has specific request/response schemas and required roles.</p> PkgID Name Description Roles Required Request Schema Response Type 1 GET_AUTHORS Get all authors <code>get-authors</code> <code>{filters?: object}</code> <code>Author[]</code> 2 GET_PAGINATED_AUTHORS Get paginated authors <code>get-authors</code> <code>{page: number, per_page: number, filters?: object}</code> <code>Author[]</code> with <code>meta</code> 3 CREATE_AUTHOR Create new author <code>create-author</code> <code>{name: string}</code> <code>Author</code>"},{"location":"guides/websocket-protocol/#author-schema","title":"Author Schema","text":"<pre><code>interface Author {\n  id: number;\n  name: string;\n}\n</code></pre>"},{"location":"guides/websocket-protocol/#pagination-metadata","title":"Pagination Metadata","text":"<pre><code>interface PaginationMeta {\n  page: number;           // Current page number\n  per_page: number;       // Items per page\n  total: number;          // Total number of items\n  pages: number;          // Total number of pages\n  next_cursor: string | null;  // Cursor for next page (cursor pagination)\n  has_more: boolean;      // Whether more results exist\n}\n</code></pre>"},{"location":"guides/websocket-protocol/#connection-lifecycle","title":"Connection Lifecycle","text":""},{"location":"guides/websocket-protocol/#1-connection-establishment","title":"1. Connection Establishment","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Server\n    participant Keycloak\n\n    Client-&gt;&gt;Server: WebSocket handshake&lt;br/&gt;GET /web?Authorization=Bearer...\n    Server-&gt;&gt;Server: Extract JWT from query params\n    Server-&gt;&gt;Keycloak: Validate JWT token\n    alt Token Valid\n        Keycloak--&gt;&gt;Server: User data + roles\n        Server-&gt;&gt;Server: Check connection limit\n        alt Connections &lt; Max\n            Server--&gt;&gt;Client: 101 Switching Protocols\n            Note over Client,Server: WebSocket connection established\n        else Too Many Connections\n            Server--&gt;&gt;Client: Close (1008 Policy Violation)\n        end\n    else Token Invalid/Expired\n        Server--&gt;&gt;Client: Close (1008 Policy Violation)\n    end</code></pre>"},{"location":"guides/websocket-protocol/#2-message-exchange","title":"2. Message Exchange","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Server\n    participant Handler\n\n    Client-&gt;&gt;Server: {\"pkg_id\": 1, \"req_id\": \"...\", \"data\": {...}}\n    Server-&gt;&gt;Server: Rate limit check\n    alt Rate Limit OK\n        Server-&gt;&gt;Server: Validate request schema\n        Server-&gt;&gt;Server: Check RBAC permissions\n        alt Permissions OK\n            Server-&gt;&gt;Handler: Process request\n            Handler--&gt;&gt;Server: Response data\n            Server--&gt;&gt;Client: {\"status_code\": 0, \"data\": [...]}\n        else Permission Denied\n            Server--&gt;&gt;Client: {\"status_code\": 3, \"data\": {\"error\": \"...\"}}\n        end\n    else Rate Limit Exceeded\n        Server--&gt;&gt;Client: Close (1008 Policy Violation)\n    end</code></pre>"},{"location":"guides/websocket-protocol/#3-connection-termination","title":"3. Connection Termination","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Server\n    participant ConnectionManager\n\n    alt Client Initiated\n        Client-&gt;&gt;Server: Close frame\n        Server-&gt;&gt;ConnectionManager: Remove connection\n        Server--&gt;&gt;Client: Close acknowledgment\n    else Server Initiated\n        Server-&gt;&gt;Client: Close frame (reason)\n        Client--&gt;&gt;Server: Close acknowledgment\n        Server-&gt;&gt;ConnectionManager: Remove connection\n    else Session Expiry\n        Note over Server: Redis session expired event\n        Server-&gt;&gt;ConnectionManager: Find connection by user_id\n        Server-&gt;&gt;Client: Close (session expired)\n        Server-&gt;&gt;ConnectionManager: Remove connection\n    end</code></pre>"},{"location":"guides/websocket-protocol/#authentication-flow","title":"Authentication Flow","text":""},{"location":"guides/websocket-protocol/#token-based-authentication","title":"Token-Based Authentication","text":"<p>WebSocket connections authenticate using JWT tokens in the query string (browser WebSocket API limitation).</p> <p>Security Considerations:</p> <p>\u26a0\ufe0f Always use WSS (WebSocket over TLS) in production to protect tokens in transit.</p> <p>Token Requirements: - Valid Keycloak JWT access token - Not expired (default: 5 minutes) - Contains required roles for requested operations</p> <p>Best Practices:</p> <ol> <li> <p>Get fresh token before connecting: <pre><code>// Get fresh token immediately before WebSocket connection\nconst token = await getAccessToken();\nconst ws = new WebSocket(`wss://api.example.com/web?Authorization=${encodeURIComponent('Bearer ' + token)}`);\n</code></pre></p> </li> <li> <p>Reconnect before token expiration: <pre><code>// Reconnect every 4 minutes (before 5-minute expiry)\nsetInterval(async () =&gt; {\n  ws.close();\n  const newToken = await refreshAccessToken();\n  ws = new WebSocket(`wss://api.example.com/web?Authorization=${encodeURIComponent('Bearer ' + newToken)}`);\n}, 4 * 60 * 1000);\n</code></pre></p> </li> <li> <p>Never log tokens: <pre><code>// \u274c Bad - logs token\nconsole.log('Connecting to:', wsUrl);\n\n// \u2705 Good - logs without token\nconsole.log('WebSocket connecting...');\n</code></pre></p> </li> </ol>"},{"location":"guides/websocket-protocol/#error-handling","title":"Error Handling","text":""},{"location":"guides/websocket-protocol/#common-error-scenarios","title":"Common Error Scenarios","text":""},{"location":"guides/websocket-protocol/#1-authentication-errors","title":"1. Authentication Errors","text":"<p>Scenario: Invalid or expired JWT token</p> <p>Server Response: Connection closed with code 1008 (Policy Violation)</p> <p>Client Handling: <pre><code>ws.onerror = (error) =&gt; {\n  console.error('Connection error:', error);\n  // Refresh token and retry\n  refreshTokenAndReconnect();\n};\n\nws.onclose = (event) =&gt; {\n  if (event.code === 1008) {\n    console.error('Authentication failed - invalid or expired token');\n    // Redirect to login or refresh token\n  }\n};\n</code></pre></p>"},{"location":"guides/websocket-protocol/#2-rate-limit-exceeded","title":"2. Rate Limit Exceeded","text":"<p>Scenario: Client sends too many messages</p> <p>Server Response: Connection closed with code 1008</p> <p>Client Handling: <pre><code>// Implement client-side rate limiting\nclass RateLimitedWebSocket {\n  constructor(url, maxMessagesPerMinute = 100) {\n    this.ws = new WebSocket(url);\n    this.maxMessages = maxMessagesPerMinute;\n    this.messageTimestamps = [];\n  }\n\n  send(data) {\n    const now = Date.now();\n    this.messageTimestamps = this.messageTimestamps.filter(\n      t =&gt; now - t &lt; 60000\n    );\n\n    if (this.messageTimestamps.length &gt;= this.maxMessages) {\n      throw new Error('Rate limit exceeded');\n    }\n\n    this.messageTimestamps.push(now);\n    this.ws.send(data);\n  }\n}\n</code></pre></p>"},{"location":"guides/websocket-protocol/#3-permission-denied","title":"3. Permission Denied","text":"<p>Scenario: User lacks required role</p> <p>Server Response: <pre><code>{\n  \"status_code\": 3,\n  \"data\": {\"error\": \"Permission denied: missing required role 'create-author'\"}\n}\n</code></pre></p> <p>Client Handling: <pre><code>if (response.status_code === 3) {\n  // Hide UI elements requiring this permission\n  document.getElementById('create-button').style.display = 'none';\n  showNotification('You do not have permission to perform this action');\n}\n</code></pre></p>"},{"location":"guides/websocket-protocol/#4-invalid-request-data","title":"4. Invalid Request Data","text":"<p>Scenario: Malformed or invalid request payload</p> <p>Server Response: <pre><code>{\n  \"status_code\": 2,\n  \"data\": {\"error\": \"Validation error: 'name' is required\"}\n}\n</code></pre></p> <p>Client Handling: <pre><code>if (response.status_code === 2) {\n  // Show validation errors to user\n  showValidationError(response.data.error);\n}\n</code></pre></p>"},{"location":"guides/websocket-protocol/#rate-limiting","title":"Rate Limiting","text":""},{"location":"guides/websocket-protocol/#connection-limits","title":"Connection Limits","text":"<ul> <li>Max concurrent connections per user: 5 (configurable via <code>WS_MAX_CONNECTIONS_PER_USER</code>)</li> <li>Enforcement: New connections rejected if limit exceeded</li> </ul>"},{"location":"guides/websocket-protocol/#message-rate-limits","title":"Message Rate Limits","text":"<ul> <li>Max messages per minute: 100 (configurable via <code>WS_MESSAGE_RATE_LIMIT</code>)</li> <li>Enforcement: Connection closed if limit exceeded</li> </ul> <p>Client-side rate limiting: <pre><code>class RateLimiter {\n  constructor(maxPerMinute) {\n    this.max = maxPerMinute;\n    this.timestamps = [];\n  }\n\n  canSend() {\n    const now = Date.now();\n    this.timestamps = this.timestamps.filter(t =&gt; now - t &lt; 60000);\n    return this.timestamps.length &lt; this.max;\n  }\n\n  recordSend() {\n    this.timestamps.push(Date.now());\n  }\n}\n</code></pre></p>"},{"location":"guides/websocket-protocol/#best-practices","title":"Best Practices","text":""},{"location":"guides/websocket-protocol/#1-request-id-generation","title":"1. Request ID Generation","text":"<p>Always use UUIDs (v4) for request IDs:</p> <pre><code>// \u2705 Good - UUID v4\nconst reqId = crypto.randomUUID();\n\n// \u274c Bad - sequential IDs (collision risk)\nconst reqId = `${Date.now()}-${Math.random()}`;\n</code></pre>"},{"location":"guides/websocket-protocol/#2-timeout-handling","title":"2. Timeout Handling","text":"<p>Implement request timeouts to handle unresponsive servers:</p> <pre><code>class WebSocketClient {\n  async request(pkgId, data, timeout = 30000) {\n    const reqId = crypto.randomUUID();\n\n    return new Promise((resolve, reject) =&gt; {\n      const timeoutId = setTimeout(() =&gt; {\n        this.pendingRequests.delete(reqId);\n        reject(new Error('Request timeout'));\n      }, timeout);\n\n      this.pendingRequests.set(reqId, { resolve, reject, timeoutId });\n\n      this.ws.send(JSON.stringify({ pkg_id: pkgId, req_id: reqId, data }));\n    });\n  }\n}\n</code></pre>"},{"location":"guides/websocket-protocol/#3-reconnection-strategy","title":"3. Reconnection Strategy","text":"<p>Implement exponential backoff for reconnection:</p> <pre><code>class ReconnectingWebSocket {\n  connect(attempt = 0) {\n    this.ws = new WebSocket(this.url);\n\n    this.ws.onerror = () =&gt; {\n      const delay = Math.min(1000 * Math.pow(2, attempt), 30000);\n      console.log(`Reconnecting in ${delay}ms...`);\n      setTimeout(() =&gt; this.connect(attempt + 1), delay);\n    };\n  }\n}\n</code></pre>"},{"location":"guides/websocket-protocol/#4-graceful-shutdown","title":"4. Graceful Shutdown","text":"<p>Clean up resources on disconnect:</p> <pre><code>window.addEventListener('beforeunload', () =&gt; {\n  ws.close(1000, 'Client closing');\n});\n</code></pre>"},{"location":"guides/websocket-protocol/#5-message-validation","title":"5. Message Validation","text":"<p>Validate responses before processing:</p> <pre><code>function validateResponse(response) {\n  if (!response || typeof response !== 'object') {\n    throw new Error('Invalid response format');\n  }\n\n  if (!('pkg_id' in response) || !('req_id' in response) || !('status_code' in response)) {\n    throw new Error('Missing required response fields');\n  }\n\n  return response;\n}\n</code></pre>"},{"location":"guides/websocket-protocol/#related-documentation","title":"Related Documentation","text":"<ul> <li>WebSocket Handlers Guide - Implementing server-side handlers</li> <li>WebSocket API Reference - Detailed API documentation</li> <li>Authentication Guide - Keycloak integration and token management</li> <li>Rate Limiting Guide - Rate limiting configuration</li> </ul>"},{"location":"guides/websocket-protocol/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/websocket-protocol/#connection-refused","title":"Connection Refused","text":"<p>Problem: Cannot establish WebSocket connection</p> <p>Solutions: 1. Check server is running: <code>curl http://localhost:8000/health</code> 2. Verify WebSocket endpoint: <code>ws://localhost:8000/web</code> (not <code>/ws</code> or <code>/websocket</code>) 3. Ensure token is properly URL-encoded</p>"},{"location":"guides/websocket-protocol/#connection-closes-immediately","title":"Connection Closes Immediately","text":"<p>Problem: Connection closes right after opening</p> <p>Solutions: 1. Check token validity: Decode JWT and verify expiration 2. Verify user has required roles for initial connection 3. Check server logs for authentication errors 4. Ensure connection limit not exceeded</p>"},{"location":"guides/websocket-protocol/#no-response-to-messages","title":"No Response to Messages","text":"<p>Problem: Server doesn't respond to requests</p> <p>Solutions: 1. Verify <code>pkg_id</code> is valid (see Available Package IDs) 2. Check request data matches expected schema 3. Ensure user has required roles for the operation 4. Look for rate limiting (connection closes after timeout)</p>"},{"location":"guides/websocket-protocol/#invalid-json-errors","title":"\"Invalid JSON\" Errors","text":"<p>Problem: Server rejects messages with JSON parse errors</p> <p>Solutions: 1. Ensure message is valid JSON: <code>JSON.parse(message)</code> 2. Verify required fields are present: <code>pkg_id</code>, <code>req_id</code>, <code>data</code> 3. Check data types match schema (numbers vs strings)</p>"}]}