// Grafana Alloy configuration for log collection
// Migrated from Promtail to Alloy (Promtail deprecated as of Feb 2025)
// Collects logs from Docker containers and sends to Loki

// Loki write endpoint
loki.write "loki" {
  endpoint {
    url = "http://loki:3100/loki/api/v1/push"
  }
}

// Docker service discovery
discovery.docker "docker" {
  host = "unix:///var/run/docker.sock"
  refresh_interval = "5s"

  filter {
    name   = "label"
    values = ["com.docker.compose.project=docker"]
  }
}

// Relabel Docker containers to extract metadata
discovery.relabel "docker" {
  targets = discovery.docker.docker.targets

  // Extract container name
  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/(.*)"
    target_label  = "container"
  }

  // Extract container ID (short version)
  rule {
    source_labels = ["__meta_docker_container_id"]
    regex         = "(.{12})"
    target_label  = "container_id"
  }

  // Extract log stream (stdout/stderr)
  rule {
    source_labels = ["__meta_docker_container_log_stream"]
    target_label  = "stream"
  }

  // Extract docker compose service name
  rule {
    source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
    target_label  = "service"
  }

  // Extract image name
  rule {
    source_labels = ["__meta_docker_container_label_com_docker_compose_image"]
    target_label  = "image"
  }

  // Add static labels
  rule {
    target_label = "environment"
    replacement  = "development"
  }

  rule {
    target_label = "job"
    replacement  = "docker"
  }
}

// Scrape Docker container logs
loki.source.docker "docker" {
  host    = "unix:///var/run/docker.sock"
  targets = discovery.relabel.docker.output

  forward_to = [loki.process.docker.receiver]
}

// Process logs with pipeline stages
loki.process "docker" {
  forward_to = [loki.write.loki.receiver]

  // Strip ANSI escape codes (basic cleanup for any remaining escape sequences)
  stage.replace {
    expression = "\\x1b\\[[0-9;?]*[a-zA-Z]"
    replace    = ""
  }

  // Parse JSON logs if present
  stage.json {
    expressions = {
      level       = "level",
      timestamp   = "timestamp",
      logger      = "logger",
      message     = "message",
      error       = "error",
      request_id  = "request_id",
      user_id     = "user_id",
      endpoint    = "endpoint",
      status_code = "status_code",
      environment = "environment",
    }
  }

  // Extract log level from text logs (fallback if not JSON)
  stage.regex {
    expression = "^(?P<time>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}[,\\.]\\d{3}) (?P<level>\\w+) "
  }

  // Set log level and other structured fields as labels for fast querying
  stage.labels {
    values = {
      level       = "",
      logger      = "",
      request_id  = "",
      user_id     = "",
      status_code = "",
      environment = "",
      endpoint    = "",
    }
  }

  // Parse timestamp (app now logs RFC3339 UTC)
  stage.timestamp {
    source = "timestamp"
    format = "RFC3339"
    fallback_formats = [
      "2006-01-02 15:04:05.000",
      "2006-01-02 15:04:05,000",
    ]
    location = "UTC"
  }

  // Drop health check and metrics access logs to reduce noise
  // Only matches uvicorn access log lines (contain the HTTP method + path literally)
  stage.drop {
    expression  = "\"GET /health HTTP"
    drop_counter_reason = "health_check"
  }

  stage.drop {
    expression  = "\"GET /metrics HTTP"
    drop_counter_reason = "health_check"
  }

  // Drop empty lines
  stage.match {
    selector = "{job=\"docker\"}"

    stage.drop {
      expression  = "^$"
      drop_counter_reason = "empty_line"
    }
  }
}
